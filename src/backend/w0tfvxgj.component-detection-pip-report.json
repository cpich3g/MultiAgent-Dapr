{
  "version": "1",
  "pip_version": "25.2",
  "install": [
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/47/3b/54d0f49363eb3ed2c3ceb068acce2ca4c8c01d4dec68470cd455cbc5180e/semantic_kernel-1.32.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b887eaab14d6fa0a40ad1904cf5729e3bbc5e0720e766ed7c30ee043a44e0ab3",
          "hashes": {
            "sha256": "b887eaab14d6fa0a40ad1904cf5729e3bbc5e0720e766ed7c30ee043a44e0ab3"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "semantic-kernel",
        "version": "1.32.2",
        "summary": "Semantic Kernel Python SDK",
        "description": "# Get Started with Semantic Kernel Python\n\nHighlights\n- Flexible Agent Framework: build, orchestrate, and deploy AI agents and multi-agent systems\n- Multi-Agent Systems: Model workflows and collaboration between AI specialists\n- Plugin Ecosystem: Extend with Python, OpenAPI, Model Context Protocol (MCP), and more\n- LLM Support: OpenAI, Azure OpenAI, Hugging Face, Mistral, Vertex AI, ONNX, Ollama, NVIDIA NIM, and others\n- Vector DB Support: Azure AI Search, Elasticsearch, Chroma, and more\n- Process Framework: Build structured business processes with workflow modeling\n- Multimodal: Text, vision, audio\n\n## Quick Install\n\n```bash\npip install --upgrade semantic-kernel\n# Optional: Add integrations\npip install --upgrade semantic-kernel[hugging_face]\npip install --upgrade semantic-kernel[all]\n```\n\nSupported Platforms:\n- Python: 3.10+\n- OS: Windows, macOS, Linux\n\n## 1. Setup API Keys\n\nSet as environment variables, or create a .env file at your project root:\n\n```bash\nOPENAI_API_KEY=sk-...\nOPENAI_CHAT_MODEL_ID=...\n...\nAZURE_OPENAI_API_KEY=...\nAZURE_OPENAI_ENDPOINT=...\nAZURE_OPENAI_CHAT_DEPLOYMENT_NAME=...\n...\n```\n\nYou can also override environment variables by explicitly passing configuration parameters to the AI service constructor:\n\n```python\nchat_service = AzureChatCompletion(\n    api_key=...,\n    endpoint=...,\n    deployment_name=...,\n    api_version=...,\n)\n```\n\nSee the following [setup guide](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/setup) for more information.\n\n## 2. Use the Kernel for Prompt Engineering\n\nCreate prompt functions and invoke them via the `Kernel`:\n\n```python\nimport asyncio\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\nfrom semantic_kernel.functions import KernelArguments\n\nkernel = Kernel()\nkernel.add_service(OpenAIChatCompletion())\n\nprompt = \"\"\"\n1) A robot may not injure a human being...\n2) A robot must obey orders given it by human beings...\n3) A robot must protect its own existence...\n\nGive me the TLDR in exactly {{$num_words}} words.\"\"\"\n\n\nasync def main():\n    result = await kernel.invoke_prompt(prompt, arguments=KernelArguments(num_words=5))\n    print(result)\n\n\nasyncio.run(main())\n# Output: Protect humans, obey, self-preserve, prioritized.\n```\n\n## 3. Directly Use AI Services (No Kernel Required)\n\nYou can use the AI service classes directly for advanced workflows:\n\n```python\nimport asyncio\nimport asyncio\n\nfrom semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAIChatPromptExecutionSettings\nfrom semantic_kernel.contents import ChatHistory\n\n\nasync def main():\n    service = OpenAIChatCompletion()\n    settings = OpenAIChatPromptExecutionSettings()\n\n    chat_history = ChatHistory(system_message=\"You are a helpful assistant.\")\n    chat_history.add_user_message(\"Write a haiku about Semantic Kernel.\")\n    response = await service.get_chat_message_content(chat_history=chat_history, settings=settings)\n    print(response.content)\n\n    \"\"\"\n    Output:\n\n    Thoughts weave through context,  \n    Semantic threads interlaceâ€”  \n    Kernel sparks meaning.\n    \"\"\"\n\n\nasyncio.run(main())\n```\n\n## 4. Build an Agent with Plugins and Tools\n\nAdd Python functions as plugins or Pydantic models as structured outputs;\n\nEnhance your agent with custom tools (plugins) and structured output:\n\n```python\nimport asyncio\nfrom typing import Annotated\nfrom pydantic import BaseModel\nfrom semantic_kernel.agents import ChatCompletionAgent\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatPromptExecutionSettings\nfrom semantic_kernel.functions import kernel_function, KernelArguments\n\nclass MenuPlugin:\n    @kernel_function(description=\"Provides a list of specials from the menu.\")\n    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n        return \"\"\"\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        \"\"\"\n\n    @kernel_function(description=\"Provides the price of the requested menu item.\")\n    def get_item_price(\n        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n        return \"$9.99\"\n\nclass MenuItem(BaseModel):\n    # Used for structured outputs\n    price: float\n    name: str\n\nasync def main():\n    # Configure structured outputs format\n    settings = OpenAIChatPromptExecutionSettings()\n    settings.response_format = MenuItem\n\n    # Create agent with plugin and settings\n    agent = ChatCompletionAgent(\n        service=AzureChatCompletion(),\n        name=\"SK-Assistant\",\n        instructions=\"You are a helpful assistant.\",\n        plugins=[MenuPlugin()],\n        arguments=KernelArguments(settings)\n    )\n\n    response = await agent.get_response(\"What is the price of the soup special?\")\n    print(response.content)\n\n    # Output:\n    # The price of the Clam Chowder, which is the soup special, is $9.99.\n\nasyncio.run(main()) \n```\n\nYou can explore additional getting started agent samples [here](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_agents).\n\n## 5. Multi-Agent Orchestration\n\nCoordinate a group of agents to iteratively solve a problem or refine content together:\n\n```python\nimport asyncio\nfrom semantic_kernel.agents import ChatCompletionAgent, GroupChatOrchestration, RoundRobinGroupChatManager\nfrom semantic_kernel.agents.runtime import InProcessRuntime\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n\ndef get_agents():\n    return [\n        ChatCompletionAgent(\n            name=\"Writer\",\n            instructions=\"You are a creative content writer. Generate and refine slogans based on feedback.\",\n            service=AzureChatCompletion(),\n        ),\n        ChatCompletionAgent(\n            name=\"Reviewer\",\n            instructions=\"You are a critical reviewer. Provide detailed feedback on proposed slogans.\",\n            service=AzureChatCompletion(),\n        ),\n    ]\n\nasync def main():\n    agents = get_agents()\n    group_chat = GroupChatOrchestration(\n        members=agents,\n        manager=RoundRobinGroupChatManager(max_rounds=5),\n    )\n    runtime = InProcessRuntime()\n    runtime.start()\n    result = await group_chat.invoke(\n        task=\"Create a slogan for a new electric SUV that is affordable and fun to drive.\",\n        runtime=runtime,\n    )\n    value = await result.get()\n    print(f\"Final Slogan: {value}\")\n\n    # Example Output:\n    # Final Slogan: \"Feel the Charge: Adventure Meets Affordability in Your New Electric SUV!\"\n\n    await runtime.stop_when_idle()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nFor orchestration-focused examples, see [these orchestration samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_agents/multi_agent_orchestration).\n\n## More Examples & Notebooks\n\n- [Getting Started with Agents](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_agents): Practical agent orchestration and tool use  \n- [Getting Started with Processes](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_processes): Modeling structured workflows with the Process framework  \n- [Concept Samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts): Advanced scenarios, integrations, and SK patterns  \n- [Getting Started Notebooks](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started): Interactive Python notebooks for rapid experimentation  \n\n## Semantic Kernel Documentation\n\n- [Getting Started with Semantic Kernel Python](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-python)  \n- [Agent Framework Guide](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/?pivots=programming-language-python)  \n- [Process Framework Guide](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/process/process-framework)\n",
        "description_content_type": "text/markdown",
        "author_email": "Microsoft <SK-Support@microsoft.com>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Framework :: Pydantic :: 2",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "azure-ai-projects >= 1.0.0b11",
          "azure-ai-agents >= 1.0.0",
          "aiohttp ~= 3.8",
          "cloudevents ~=1.0",
          "pydantic >=2.0,!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12",
          "pydantic-settings ~= 2.0",
          "defusedxml ~= 0.7",
          "azure-identity >= 1.13",
          "numpy >= 1.25.0; python_version < '3.12'",
          "numpy >= 1.26.0; python_version >= '3.12'",
          "openai >= 1.67",
          "openapi_core >= 0.18,<0.20",
          "websockets >= 13, < 16",
          "aiortc>=1.9.0",
          "opentelemetry-api ~= 1.24",
          "opentelemetry-sdk ~= 1.24",
          "prance >= 23.6.21,< 25.4.9",
          "pybars4 ~= 0.9",
          "jinja2 ~= 3.1",
          "nest-asyncio ~= 1.6",
          "scipy>=1.15.1",
          "websockets >= 13, < 16",
          "aiortc>=1.9.0",
          "protobuf",
          "typing-extensions>=4.13",
          "anthropic ~= 0.32 ; extra == \"anthropic\"",
          "autogen-agentchat >= 0.2, <0.4 ; extra == \"autogen\"",
          "boto3>=1.36.4,<1.39.0 ; extra == \"aws\"",
          "azure-ai-inference >= 1.0.0b6 ; extra == \"azure\"",
          "azure-core-tracing-opentelemetry >= 1.0.0b11 ; extra == \"azure\"",
          "azure-search-documents >= 11.6.0b4 ; extra == \"azure\"",
          "azure-cosmos ~= 4.7 ; extra == \"azure\"",
          "chromadb >= 0.5,< 1.1 ; extra == \"chroma\"",
          "dapr>=1.14.0 ; extra == \"dapr\"",
          "dapr-ext-fastapi>=1.14.0 ; extra == \"dapr\"",
          "flask-dapr>=1.14.0 ; extra == \"dapr\"",
          "faiss-cpu>=1.10.0 ; extra == \"faiss\"",
          "google-cloud-aiplatform == 1.93.0 ; extra == \"google\"",
          "google-generativeai ~= 0.8 ; extra == \"google\"",
          "transformers[torch] ~= 4.28 ; extra == \"hugging-face\"",
          "sentence-transformers >= 2.2,< 5.0 ; extra == \"hugging-face\"",
          "torch == 2.7.0 ; extra == \"hugging-face\"",
          "mcp>=1.8 ; extra == \"mcp\"",
          "pymilvus >= 2.3,< 2.6 ; extra == \"milvus\"",
          "milvus >= 2.3,<2.3.8 ; extra == \"milvus\" and ( platform_system != 'Windows')",
          "mistralai >= 1.2,< 2.0 ; extra == \"mistralai\"",
          "pymongo >= 4.8.0, < 4.13 ; extra == \"mongo\"",
          "motor >= 3.3.2,< 3.8.0 ; extra == \"mongo\"",
          "ipykernel ~= 6.29 ; extra == \"notebooks\"",
          "ollama ~= 0.4 ; extra == \"ollama\"",
          "onnxruntime-genai ~= 0.7 ; extra == \"onnx\"",
          "pandas ~= 2.2 ; extra == \"pandas\"",
          "pinecone[asyncio, grpc] ~= 6.0 ; extra == \"pinecone\"",
          "psycopg[binary, pool] ~= 3.2 ; extra == \"postgres\"",
          "qdrant-client ~= 1.9 ; extra == \"qdrant\"",
          "websockets >= 13, < 16 ; extra == \"realtime\"",
          "aiortc>=1.9.0 ; extra == \"realtime\"",
          "redis[hiredis] >= 5,< 6 ; extra == \"redis\"",
          "types-redis ~= 4.6.0.20240425 ; extra == \"redis\"",
          "redisvl ~= 0.4 ; extra == \"redis\"",
          "pyodbc >= 5.2 ; extra == \"sql\"",
          "usearch ~= 2.16 ; extra == \"usearch\"",
          "pyarrow >= 12.0,< 21.0 ; extra == \"usearch\"",
          "weaviate-client>=4.10,<5.0 ; extra == \"weaviate\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://learn.microsoft.com/en-us/semantic-kernel/overview/",
          "issues, https://github.com/microsoft/semantic-kernel/issues",
          "release_notes, https://github.com/microsoft/semantic-kernel/releases?q=tag%3Apython-1&expanded=true",
          "source, https://github.com/microsoft/semantic-kernel/tree/main/python"
        ],
        "provides_extra": [
          "anthropic",
          "autogen",
          "aws",
          "azure",
          "chroma",
          "dapr",
          "faiss",
          "google",
          "hugging-face",
          "mcp",
          "milvus",
          "mistralai",
          "mongo",
          "notebooks",
          "ollama",
          "onnx",
          "pandas",
          "pinecone",
          "postgres",
          "qdrant",
          "realtime",
          "redis",
          "sql",
          "usearch",
          "weaviate"
        ]
      },
      "requested_extras": [
        "azure"
      ]
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3e/2d/5502377ecc07677365a1e86be64d8cb9959eb6e9b605fcc28f1f68d3777a/azure_ai_projects-1.0.0b11-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=3572f2989627e896ecfebe2fa7326d5b940f920cc581e98809b244af7a38cbf0",
          "hashes": {
            "sha256": "3572f2989627e896ecfebe2fa7326d5b940f920cc581e98809b244af7a38cbf0"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.1",
        "name": "azure-ai-projects",
        "version": "1.0.0b11",
        "summary": "Microsoft Azure AI Projects Client Library for Python",
        "description": "# Azure AI Projects client library for Python\n\nThe AI Projects client library (in preview) is part of the Azure AI Foundry SDK, and provides easy access to\nresources in your Azure AI Foundry Project. Use it to:\n\n* **Create and run Agents** using the `.agents` property on the client.\n* **Get an AzureOpenAI client** using the `.inference.get_azure_openai_client` method.\n* **Enumerate AI Models** deployed to your Foundry Project using the `.deployments` operations.\n* **Enumerate connected Azure resources** in your Foundry project using the `.connections` operations.\n* **Upload documents and create Datasets** to reference them using the `.datasets` operations.\n* **Create and enumerate Search Indexes** using the `.indexes` operations.\n* **Get an Azure AI Inference client** for chat completions, text or image embeddings using the `.inference` operations.\n* **Read a Prompty file or string** and render messages for inference clients, using the `PromptTemplate` class.\n* **Run Evaluations** to assess the performance of generative AI applications, using the `evaluations` operations.\n* **Enable OpenTelemetry tracing** using the `enable_telemetry` function.\n\n> **Note:** There have been significant updates with the release of version 1.0.0b11, including breaking changes.\nplease see new code snippets below and the samples folder. Agents are now implemented in a separate package `azure-ai-agents`\nwhich will get installed automatically when you install `azure-ai-projects`. You can continue using \".agents\"\noperations on the `AIProjectsClient` to create, run and delete agents, as before.\nSee [full set of Agents samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-agents/samples)\nin their new location. Also see the [change log for the 1.0.0b11 release](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/CHANGELOG.md).\n\n[Product documentation](https://aka.ms/azsdk/azure-ai-projects/product-doc)\n| [Samples][samples]\n| [API reference documentation](https://aka.ms/azsdk/azure-ai-projects/python/reference)\n| [Package (PyPI)](https://aka.ms/azsdk/azure-ai-projects/python/package)\n| [SDK source code](https://aka.ms/azsdk/azure-ai-projects/python/code)\n\n## Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention the package name \"azure-ai-projects\" in the title or content.\n\n## Getting started\n\n### Prerequisite\n\n- Python 3.9 or later.\n- An [Azure subscription][azure_sub].\n- A [project in Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/create-projects).\n- The project endpoint URL of the form `https://<your-ai-services-account-name>.services.ai.azure.com/api/projects/<your-project-name>`. It can be found in your Azure AI Foundry Project overview page. Below we will assume the environment variable `PROJECT_ENDPOINT` was defined to hold this value.\n- An Entra ID token for authentication. Your application needs an object that implements the [TokenCredential](https://learn.microsoft.com/python/api/azure-core/azure.core.credentials.tokencredential) interface. Code samples here use [DefaultAzureCredential](https://learn.microsoft.com/python/api/azure-identity/azure.identity.defaultazurecredential). To get that working, you will need:\n  * An appropriate role assignment. see [Role-based access control in Azure AI Foundry portal](https://learn.microsoft.com/azure/ai-foundry/concepts/rbac-ai-foundry). Role assigned can be done via the \"Access Control (IAM)\" tab of your Azure AI Project resource in the Azure portal.\n  * [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed.\n  * You are logged into your Azure account by running `az login`.\n\n### Install the package\n\n```bash\npip install azure-ai-projects\n```\n\n## Key concepts\n\n### Create and authenticate the client with Entra ID\n\nEntra ID is the only authentication method supported at the moment by the client.\n\nTo construct a synchronous client:\n\n```python\nimport os\nfrom azure.ai.projects import AIProjectClient\nfrom azure.identity import DefaultAzureCredential\n\nproject_client = AIProjectClient(\n    credential=DefaultAzureCredential(),\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n)\n```\n\nTo construct an asynchronous client, Install the additional package [aiohttp](https://pypi.org/project/aiohttp/):\n\n```bash\npip install aiohttp\n```\n\nand update the code above to import `asyncio`, and import `AIProjectClient` from the `azure.ai.projects.aio` namespace:\n\n```python\nimport os\nimport asyncio\nfrom azure.ai.projects.aio import AIProjectClient\nfrom azure.core.credentials import AzureKeyCredential\n\nproject_client = AIProjectClient.from_connection_string(\n    credential=DefaultAzureCredential(),\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n)\n```\n\n## Examples\n\n### Performing Agent operations\n\nThe `.agents` property on the `AIProjectsClient` gives you access to an authenticated `AgentsClient` from the `azure-ai-agents` package. Below we show how to create an Agent and delete it. To see what you can do with the `agent` you created, see the [many samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-agents/samples) associated with the `azure-ai-agents` package.\n\nThe code below assumes `model_deployment_name` (a string) is defined. It's the deployment name of an AI model in your Foundry Project, as shown in the \"Models + endpoints\" tab, under the \"Name\" column.\n\n<!-- SNIPPET:sample_agents.agents_sample -->\n\n```python\nagent = project_client.agents.create_agent(\n    model=model_deployment_name,\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n)\nprint(f\"Created agent, agent ID: {agent.id}\")\n\n# Do something with your Agent!\n# See samples here https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-agents/samples\n\nproject_client.agents.delete_agent(agent.id)\nprint(\"Deleted agent\")\n```\n\n<!-- END SNIPPET -->\n\n### Get an authenticated AzureOpenAI client\n\nYour Azure AI Foundry project may have one or more OpenAI models deployed that support chat completions. Use the code below to get an authenticated [AzureOpenAI](https://github.com/openai/openai-python?tab=readme-ov-file#microsoft-azure-openai) from the [openai](https://pypi.org/project/openai/) package, and execute a chat completions call.\n\nThe code below assumes `model_deployment_name` (a string) is defined. It's the deployment name of an AI model in your Foundry Project, or a connected Azure OpenAI resource. As shown in the \"Models + endpoints\" tab, under the \"Name\" column.\n\nUpdate the `api_version` value with one found in the \"Data plane - inference\" row [in this table](https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs).\n\n<!-- SNIPPET:sample_chat_completions_with_azure_openai_client.aoai_sample-->\n\n```python\nprint(\n    \"Get an authenticated Azure OpenAI client for the parent AI Services resource, and perform a chat completion operation:\"\n)\nwith project_client.inference.get_azure_openai_client(api_version=\"2024-10-21\") as client:\n\n    response = client.chat.completions.create(\n        model=model_deployment_name,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"How many feet are in a mile?\",\n            },\n        ],\n    )\n\n    print(response.choices[0].message.content)\n\nprint(\n    \"Get an authenticated Azure OpenAI client for a connected Azure OpenAI service, and perform a chat completion operation:\"\n)\nwith project_client.inference.get_azure_openai_client(\n    api_version=\"2024-10-21\", connection_name=connection_name\n) as client:\n\n    response = client.chat.completions.create(\n        model=model_deployment_name,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"How many feet are in a mile?\",\n            },\n        ],\n    )\n\n    print(response.choices[0].message.content)\n```\n\n<!-- END SNIPPET -->\n\nSee the \"inference\" folder in the [package samples][samples] for additional samples.\n\n### Get an authenticated ChatCompletionsClient\n\nYour Azure AI Foundry project may have one or more AI models deployed that support chat completions. These could be OpenAI models, Microsoft models, or models from other providers. Use the code below to get an authenticated [ChatCompletionsClient](https://learn.microsoft.com/python/api/azure-ai-inference/azure.ai.inference.chatcompletionsclient) from the [azure-ai-inference](https://pypi.org/project/azure-ai-inference/) package, and execute a chat completions call.\n\nFirst, install the package:\n\n```bash\npip install azure-ai-inference\n```\n\nThen run the code below. Here we assume `model_deployment_name` (a string) is defined. It's the deployment name of an AI model in your Foundry Project, as shown in the \"Models + endpoints\" tab, under the \"Name\" column.\n\n<!-- SNIPPET:sample_chat_completions_with_azure_ai_inference_client.inference_sample-->\n\n```python\nwith project_client.inference.get_chat_completions_client() as client:\n\n    response = client.complete(\n        model=model_deployment_name, messages=[UserMessage(content=\"How many feet are in a mile?\")]\n    )\n\n    print(response.choices[0].message.content)\n```\n\n<!-- END SNIPPET -->\n\nSee the \"inference\" folder in the [package samples][samples] for additional samples, including getting an authenticated [EmbeddingsClient](https://learn.microsoft.com/python/api/azure-ai-inference/azure.ai.inference.embeddingsclient) and [ImageEmbeddingsClient](https://learn.microsoft.com/python/api/azure-ai-inference/azure.ai.inference.imageembeddingsclient).\n\n### Deployments operations\n\nThe code below shows some Deployments operations, which allow you to enumerate the AI models deployed to your AI Foundry Projects. These models can be seen in the \"Models + endpoints\" tab in your AI Foundry Project. Full samples can be found under the \"deployment\" folder in the [package samples][samples].\n\n<!-- SNIPPET:sample_deployments.deployments_sample-->\n\n```python\nprint(\"List all deployments:\")\nfor deployment in project_client.deployments.list():\n    print(deployment)\n\nprint(f\"List all deployments by the model publisher `{model_publisher}`:\")\nfor deployment in project_client.deployments.list(model_publisher=model_publisher):\n    print(deployment)\n\nprint(f\"List all deployments of model `{model_name}`:\")\nfor deployment in project_client.deployments.list(model_name=model_name):\n    print(deployment)\n\nprint(f\"Get a single deployment named `{model_deployment_name}`:\")\ndeployment = project_client.deployments.get(model_deployment_name)\nprint(deployment)\n```\n\n<!-- END SNIPPET -->\n\n### Connections operations\n\nThe code below shows some Connection operations, which allow you to enumerate the Azure Resources connected to your AI Foundry Projects. These connections can be seen in the \"Management Center\", in the \"Connected resources\" tab in your AI Foundry Project. Full samples can be found under the \"connections\" folder in the [package samples][samples].\n\n<!-- SNIPPET:sample_connections.connections_sample-->\n\n```python\nprint(\"List all connections:\")\nfor connection in project_client.connections.list():\n    print(connection)\n\nprint(\"List all connections of a particular type:\")\nfor connection in project_client.connections.list(\n    connection_type=ConnectionType.AZURE_OPEN_AI,\n):\n    print(connection)\n\nprint(\"Get the default connection of a particular type, without its credentials:\")\nconnection = project_client.connections.get_default(connection_type=ConnectionType.AZURE_OPEN_AI)\nprint(connection)\n\nprint(\"Get the default connection of a particular type, with its credentials:\")\nconnection = project_client.connections.get_default(\n    connection_type=ConnectionType.AZURE_OPEN_AI, include_credentials=True\n)\nprint(connection)\n\nprint(f\"Get the connection named `{connection_name}`, without its credentials:\")\nconnection = project_client.connections.get(connection_name)\nprint(connection)\n\nprint(f\"Get the connection named `{connection_name}`, with its credentials:\")\nconnection = project_client.connections.get(connection_name, include_credentials=True)\nprint(connection)\n```\n\n<!-- END SNIPPET -->\n\n### Dataset operations\n\nThe code below shows some Dataset operations. Full samples can be found under the \"datasets\"\nfolder in the [package samples][samples].\n\n<!-- SNIPPET:sample_datasets.datasets_sample-->\n\n```python\nprint(\n    f\"Upload a single file and create a new Dataset `{dataset_name}`, version `{dataset_version_1}`, to reference the file.\"\n)\ndataset: DatasetVersion = project_client.datasets.upload_file(\n    name=dataset_name,\n    version=dataset_version_1,\n    file_path=data_file,\n    connection_name=connection_name,\n)\nprint(dataset)\n\nprint(\n    f\"Upload files in a folder (including sub-folders) and create a new version `{dataset_version_2}` in the same Dataset, to reference the files.\"\n)\ndataset = project_client.datasets.upload_folder(\n    name=dataset_name,\n    version=dataset_version_2,\n    folder=data_folder,\n    connection_name=connection_name,\n    file_pattern=re.compile(r\"\\.(txt|csv|md)$\", re.IGNORECASE),\n)\nprint(dataset)\n\nprint(f\"Get an existing Dataset version `{dataset_version_1}`:\")\ndataset = project_client.datasets.get(name=dataset_name, version=dataset_version_1)\nprint(dataset)\n\nprint(f\"Get credentials of an existing Dataset version `{dataset_version_1}`:\")\nasset_credential = project_client.datasets.get_credentials(name=dataset_name, version=dataset_version_1)\nprint(asset_credential)\n\nprint(\"List latest versions of all Datasets:\")\nfor dataset in project_client.datasets.list():\n    print(dataset)\n\nprint(f\"Listing all versions of the Dataset named `{dataset_name}`:\")\nfor dataset in project_client.datasets.list_versions(name=dataset_name):\n    print(dataset)\n\nprint(\"Delete all Dataset versions created above:\")\nproject_client.datasets.delete(name=dataset_name, version=dataset_version_1)\nproject_client.datasets.delete(name=dataset_name, version=dataset_version_2)\n```\n\n<!-- END SNIPPET -->\n\n### Indexes operations\n\nThe code below shows some Indexes operations. Full samples can be found under the \"indexes\"\nfolder in the [package samples][samples].\n\n<!-- SNIPPET:sample_indexes.indexes_sample-->\n\n```python\nprint(\n    f\"Create Index `{index_name}` with version `{index_version}`, referencing an existing AI Search resource:\"\n)\nindex = project_client.indexes.create_or_update(\n    name=index_name,\n    version=index_version,\n    body=AzureAISearchIndex(connection_name=ai_search_connection_name, index_name=ai_search_index_name),\n)\nprint(index)\n\nprint(f\"Get Index `{index_name}` version `{index_version}`:\")\nindex = project_client.indexes.get(name=index_name, version=index_version)\nprint(index)\n\nprint(\"List latest versions of all Indexes:\")\nfor index in project_client.indexes.list():\n    print(index)\n\nprint(f\"Listing all versions of the Index named `{index_name}`:\")\nfor index in project_client.indexes.list_versions(name=index_name):\n    print(index)\n\nprint(f\"Delete Index `{index_name}` version `{index_version}`:\")\nproject_client.indexes.delete(name=index_name, version=index_version)\n```\n\n<!-- END SNIPPET -->\n\n### Evaluation\n\nEvaluation in Azure AI Project client library provides quantitive, AI-assisted quality and safety metrics to asses performance and Evaluate LLM Models, GenAI Application and Agents. Metrics are defined as evaluators. Built-in or custom evaluators can provide comprehensive evaluation insights.\n\nThe code below shows some evaluation operations. Full list of sample can be found under \"evaluation\" folder in the [package samples][samples]\n\n<!-- SNIPPET:sample_evaluations.evaluations_sample-->\n\n```python\nprint(\"Upload a single file and create a new Dataset to reference the file.\")\ndataset: DatasetVersion = project_client.datasets.upload_file(\n    name=dataset_name,\n    version=dataset_version,\n    file_path=data_file,\n)\nprint(dataset)\n\nprint(\"Create an evaluation\")\nevaluation: Evaluation = Evaluation(\n    display_name=\"Sample Evaluation Test\",\n    description=\"Sample evaluation for testing\",\n    # Sample Dataset Id : azureai://accounts/<account_name>/projects/<project_name>/data/<dataset_name>/versions/<version>\n    data=InputDataset(id=dataset.id if dataset.id else \"\"),\n    evaluators={\n        \"relevance\": EvaluatorConfiguration(\n            id=EvaluatorIds.RELEVANCE.value,\n            init_params={\n                \"deployment_name\": model_deployment_name,\n            },\n            data_mapping={\n                \"query\": \"${data.query}\",\n                \"response\": \"${data.response}\",\n            },\n        ),\n        \"violence\": EvaluatorConfiguration(\n            id=EvaluatorIds.VIOLENCE.value,\n            init_params={\n                \"azure_ai_project\": endpoint,\n            },\n        ),\n        \"bleu_score\": EvaluatorConfiguration(\n            id=EvaluatorIds.BLEU_SCORE.value,\n        ),\n    },\n)\n\nevaluation_response: Evaluation = project_client.evaluations.create(\n    evaluation,\n    headers={\n        \"model-endpoint\": model_endpoint,\n        \"api-key\": model_api_key,\n    },\n)\nprint(evaluation_response)\n\nprint(\"Get evaluation\")\nget_evaluation_response: Evaluation = project_client.evaluations.get(evaluation_response.name)\n\nprint(get_evaluation_response)\n\nprint(\"List evaluations\")\nfor evaluation in project_client.evaluations.list():\n    print(evaluation)\n```\n\n<!-- END SNIPPET -->\n\n## Troubleshooting\n\n### Exceptions\n\nClient methods that make service calls raise an [HttpResponseError](https://learn.microsoft.com/python/api/azure-core/azure.core.exceptions.httpresponseerror) exception for a non-success HTTP status code response from the service. The exception's `status_code` will hold the HTTP response status code (with `reason` showing the friendly name). The exception's `error.message` contains a detailed message that may be helpful in diagnosing the issue:\n\n```python\nfrom azure.core.exceptions import HttpResponseError\n\n...\n\ntry:\n    result = project_client.connections.list()\nexcept HttpResponseError as e:\n    print(f\"Status code: {e.status_code} ({e.reason})\")\n    print(e.message)\n```\n\nFor example, when you provide wrong credentials:\n\n```text\nStatus code: 401 (Unauthorized)\nOperation returned an invalid status 'Unauthorized'\n```\n\n### Logging\n\nThe client uses the standard [Python logging library](https://docs.python.org/3/library/logging.html). The SDK logs HTTP request and response details, which may be useful in troubleshooting. To log to stdout, add the following at the top of your Python script:\n\n```python\nimport sys\nimport logging\n\n# Acquire the logger for this client library. Use 'azure' to affect both\n# 'azure.core` and `azure.ai.inference' libraries.\nlogger = logging.getLogger(\"azure\")\n\n# Set the desired logging level. logging.INFO or logging.DEBUG are good options.\nlogger.setLevel(logging.DEBUG)\n\n# Direct logging output to stdout:\nhandler = logging.StreamHandler(stream=sys.stdout)\n# Or direct logging output to a file:\n# handler = logging.FileHandler(filename=\"sample.log\")\nlogger.addHandler(handler)\n\n# Optional: change the default logging format. Here we add a timestamp.\n#formatter = logging.Formatter(\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\")\n#handler.setFormatter(formatter)\n```\n\nBy default logs redact the values of URL query strings, the values of some HTTP request and response headers (including `Authorization` which holds the key or token), and the request and response payloads. To create logs without redaction, add `logging_enable=True` to the client constructor:\n\n```python\nproject_client = AIProjectClient(\n    credential=DefaultAzureCredential(),\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n    logging_enable = True\n)\n```\n\nNote that the log level must be set to `logging.DEBUG` (see above code). Logs will be redacted with any other log level.\n\nBe sure to protect non redacted logs to avoid compromising security.\n\nFor more information, see [Configure logging in the Azure libraries for Python](https://aka.ms/azsdk/python/logging)\n\n### Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention the package name \"azure-ai-projects\" in the title or content.\n\n## Next steps\n\nHave a look at the [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-projects/samples) folder, containing fully runnable Python code for synchronous and asynchronous clients.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require\nyou to agree to a Contributor License Agreement (CLA) declaring that you have\nthe right to, and actually do, grant us the rights to use your contribution.\nFor details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether\nyou need to provide a CLA and decorate the PR appropriately (e.g., label,\ncomment). Simply follow the instructions provided by the bot. You will only\nneed to do this once across all repos using our CLA.\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct][code_of_conduct]. For more information,\nsee the Code of Conduct FAQ or contact opencode@microsoft.com with any\nadditional questions or comments.\n\n<!-- LINKS -->\n[samples]: https://aka.ms/azsdk/azure-ai-projects/python/samples/\n[code_of_conduct]: https://opensource.microsoft.com/codeofconduct/\n[azure_sub]: https://azure.microsoft.com/free/\n[evaluators]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk\n[azure_ai_evaluation]: https://learn.microsoft.com/python/api/overview/azure/ai-evaluation-readme\n[evaluator_library]: https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-generative-ai-app#view-and-manage-the-evaluators-in-the-evaluator-library\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure sdk",
          "azure",
          "ai",
          "agents",
          "foundry",
          "inference",
          "chat completion",
          "project",
          "evaluation"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-projects",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License",
          "Topic :: Scientific/Engineering :: Artificial Intelligence"
        ],
        "requires_dist": [
          "isodate>=0.6.1",
          "azure-core>=1.30.0",
          "typing-extensions>=4.12.2",
          "azure-storage-blob>=12.15.0",
          "azure-ai-agents>=1.0.0b1",
          "prompty; extra == \"prompts\""
        ],
        "requires_python": ">=3.9",
        "provides_extra": [
          "prompts"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/2a/10/f245db006a860dbc1f2e2c8382e0a1762c7753e7971ba43a1dc3f3ec1404/openai-1.84.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=7ec4436c3c933d68dc0f5a0cef0cb3dbc0864a54d62bddaf2ed5f3d521844711",
          "hashes": {
            "sha256": "7ec4436c3c933d68dc0f5a0cef0cb3dbc0864a54d62bddaf2ed5f3d521844711"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.3",
        "name": "openai",
        "version": "1.84.0",
        "summary": "The official Python library for the openai API",
        "description": "# OpenAI Python API library\n\n[![PyPI version](https://img.shields.io/pypi/v/openai.svg)](https://pypi.org/project/openai/)\n\nThe OpenAI Python library provides convenient access to the OpenAI REST API from any Python 3.8+\napplication. The library includes type definitions for all request params and response fields,\nand offers both synchronous and asynchronous clients powered by [httpx](https://github.com/encode/httpx).\n\nIt is generated from our [OpenAPI specification](https://github.com/openai/openai-openapi) with [Stainless](https://stainlessapi.com/).\n\n## Documentation\n\nThe REST API documentation can be found on [platform.openai.com](https://platform.openai.com/docs/api-reference). The full API of this library can be found in [api.md](https://github.com/openai/openai-python/tree/main/api.md).\n\n## Installation\n\n```sh\n# install from PyPI\npip install openai\n```\n\n## Usage\n\nThe full API of this library can be found in [api.md](https://github.com/openai/openai-python/tree/main/api.md).\n\nThe primary API for interacting with OpenAI models is the [Responses API](https://platform.openai.com/docs/api-reference/responses). You can generate text from the model with the code below.\n\n```python\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    instructions=\"You are a coding assistant that talks like a pirate.\",\n    input=\"How do I check if a Python object is an instance of a class?\",\n)\n\nprint(response.output_text)\n```\n\nThe previous standard (supported indefinitely) for generating text is the [Chat Completions API](https://platform.openai.com/docs/api-reference/chat). You can use that API to generate text from the model with the code below.\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"developer\", \"content\": \"Talk like a pirate.\"},\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I check if a Python object is an instance of a class?\",\n        },\n    ],\n)\n\nprint(completion.choices[0].message.content)\n```\n\nWhile you can provide an `api_key` keyword argument,\nwe recommend using [python-dotenv](https://pypi.org/project/python-dotenv/)\nto add `OPENAI_API_KEY=\"My API Key\"` to your `.env` file\nso that your API key is not stored in source control.\n[Get an API key here](https://platform.openai.com/settings/organization/api-keys).\n\n### Vision\n\nWith an image URL:\n\n```python\nprompt = \"What is in this image?\"\nimg_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2023_06_08_Raccoon1.jpg/1599px-2023_06_08_Raccoon1.jpg\"\n\nresponse = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"input_text\", \"text\": prompt},\n                {\"type\": \"input_image\", \"image_url\": f\"{img_url}\"},\n            ],\n        }\n    ],\n)\n```\n\nWith the image as a base64 encoded string:\n\n```python\nimport base64\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nprompt = \"What is in this image?\"\nwith open(\"path/to/image.png\", \"rb\") as image_file:\n    b64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nresponse = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"input_text\", \"text\": prompt},\n                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"},\n            ],\n        }\n    ],\n)\n```\n\n## Async usage\n\nSimply import `AsyncOpenAI` instead of `OpenAI` and use `await` with each API call:\n\n```python\nimport os\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI(\n    # This is the default and can be omitted\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n\n\nasync def main() -> None:\n    response = await client.responses.create(\n        model=\"gpt-4o\", input=\"Explain disestablishmentarianism to a smart five year old.\"\n    )\n    print(response.output_text)\n\n\nasyncio.run(main())\n```\n\nFunctionality between the synchronous and asynchronous clients is otherwise identical.\n\n## Streaming responses\n\nWe provide support for streaming responses using Server Side Events (SSE).\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nstream = client.responses.create(\n    model=\"gpt-4o\",\n    input=\"Write a one-sentence bedtime story about a unicorn.\",\n    stream=True,\n)\n\nfor event in stream:\n    print(event)\n```\n\nThe async client uses the exact same interface.\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\nasync def main():\n    stream = await client.responses.create(\n        model=\"gpt-4o\",\n        input=\"Write a one-sentence bedtime story about a unicorn.\",\n        stream=True,\n    )\n\n    async for event in stream:\n        print(event)\n\n\nasyncio.run(main())\n```\n\n## Realtime API beta\n\nThe Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as [function calling](https://platform.openai.com/docs/guides/function-calling) through a WebSocket connection.\n\nUnder the hood the SDK uses the [`websockets`](https://websockets.readthedocs.io/en/stable/) library to manage connections.\n\nThe Realtime API works through a combination of client-sent events and server-sent events. Clients can send events to do things like update session configuration or send text and audio inputs. Server events confirm when audio responses have completed, or when a text response from the model has been received. A full event reference can be found [here](https://platform.openai.com/docs/api-reference/realtime-client-events) and a guide can be found [here](https://platform.openai.com/docs/guides/realtime).\n\nBasic text based example:\n\n```py\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def main():\n    client = AsyncOpenAI()\n\n    async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as connection:\n        await connection.session.update(session={'modalities': ['text']})\n\n        await connection.conversation.item.create(\n            item={\n                \"type\": \"message\",\n                \"role\": \"user\",\n                \"content\": [{\"type\": \"input_text\", \"text\": \"Say hello!\"}],\n            }\n        )\n        await connection.response.create()\n\n        async for event in connection:\n            if event.type == 'response.text.delta':\n                print(event.delta, flush=True, end=\"\")\n\n            elif event.type == 'response.text.done':\n                print()\n\n            elif event.type == \"response.done\":\n                break\n\nasyncio.run(main())\n```\n\nHowever the real magic of the Realtime API is handling audio inputs / outputs, see this example [TUI script](https://github.com/openai/openai-python/blob/main/examples/realtime/push_to_talk_app.py) for a fully fledged example.\n\n### Realtime error handling\n\nWhenever an error occurs, the Realtime API will send an [`error` event](https://platform.openai.com/docs/guides/realtime-model-capabilities#error-handling) and the connection will stay open and remain usable. This means you need to handle it yourself, as _no errors are raised directly_ by the SDK when an `error` event comes in.\n\n```py\nclient = AsyncOpenAI()\n\nasync with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as connection:\n    ...\n    async for event in connection:\n        if event.type == 'error':\n            print(event.error.type)\n            print(event.error.code)\n            print(event.error.event_id)\n            print(event.error.message)\n```\n\n## Using types\n\nNested request parameters are [TypedDicts](https://docs.python.org/3/library/typing.html#typing.TypedDict). Responses are [Pydantic models](https://docs.pydantic.dev) which also provide helper methods for things like:\n\n- Serializing back into JSON, `model.to_json()`\n- Converting to a dictionary, `model.to_dict()`\n\nTyped requests and responses provide autocomplete and documentation within your editor. If you would like to see type errors in VS Code to help catch bugs earlier, set `python.analysis.typeCheckingMode` to `basic`.\n\n## Pagination\n\nList methods in the OpenAI API are paginated.\n\nThis library provides auto-paginating iterators with each list response, so you do not have to request successive pages manually:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nall_jobs = []\n# Automatically fetches more pages as needed.\nfor job in client.fine_tuning.jobs.list(\n    limit=20,\n):\n    # Do something with job here\n    all_jobs.append(job)\nprint(all_jobs)\n```\n\nOr, asynchronously:\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\nasync def main() -> None:\n    all_jobs = []\n    # Iterate through items across all pages, issuing requests as needed.\n    async for job in client.fine_tuning.jobs.list(\n        limit=20,\n    ):\n        all_jobs.append(job)\n    print(all_jobs)\n\n\nasyncio.run(main())\n```\n\nAlternatively, you can use the `.has_next_page()`, `.next_page_info()`, or `.get_next_page()` methods for more granular control working with pages:\n\n```python\nfirst_page = await client.fine_tuning.jobs.list(\n    limit=20,\n)\nif first_page.has_next_page():\n    print(f\"will fetch next page using these details: {first_page.next_page_info()}\")\n    next_page = await first_page.get_next_page()\n    print(f\"number of items we just fetched: {len(next_page.data)}\")\n\n# Remove `await` for non-async usage.\n```\n\nOr just work directly with the returned data:\n\n```python\nfirst_page = await client.fine_tuning.jobs.list(\n    limit=20,\n)\n\nprint(f\"next page cursor: {first_page.after}\")  # => \"next page cursor: ...\"\nfor job in first_page.data:\n    print(job.id)\n\n# Remove `await` for non-async usage.\n```\n\n## Nested params\n\nNested parameters are dictionaries, typed using `TypedDict`, for example:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.responses.create(\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How much ?\",\n        }\n    ],\n    model=\"gpt-4o\",\n    response_format={\"type\": \"json_object\"},\n)\n```\n\n## File uploads\n\nRequest parameters that correspond to file uploads can be passed as `bytes`, or a [`PathLike`](https://docs.python.org/3/library/os.html#os.PathLike) instance or a tuple of `(filename, contents, media type)`.\n\n```python\nfrom pathlib import Path\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nclient.files.create(\n    file=Path(\"input.jsonl\"),\n    purpose=\"fine-tune\",\n)\n```\n\nThe async client uses the exact same interface. If you pass a [`PathLike`](https://docs.python.org/3/library/os.html#os.PathLike) instance, the file contents will be read asynchronously automatically.\n\n## Handling errors\n\nWhen the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of `openai.APIConnectionError` is raised.\n\nWhen the API returns a non-success status code (that is, 4xx or 5xx\nresponse), a subclass of `openai.APIStatusError` is raised, containing `status_code` and `response` properties.\n\nAll errors inherit from `openai.APIError`.\n\n```python\nimport openai\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ntry:\n    client.fine_tuning.jobs.create(\n        model=\"gpt-4o\",\n        training_file=\"file-abc123\",\n    )\nexcept openai.APIConnectionError as e:\n    print(\"The server could not be reached\")\n    print(e.__cause__)  # an underlying Exception, likely raised within httpx.\nexcept openai.RateLimitError as e:\n    print(\"A 429 status code was received; we should back off a bit.\")\nexcept openai.APIStatusError as e:\n    print(\"Another non-200-range status code was received\")\n    print(e.status_code)\n    print(e.response)\n```\n\nError codes are as follows:\n\n| Status Code | Error Type                 |\n| ----------- | -------------------------- |\n| 400         | `BadRequestError`          |\n| 401         | `AuthenticationError`      |\n| 403         | `PermissionDeniedError`    |\n| 404         | `NotFoundError`            |\n| 422         | `UnprocessableEntityError` |\n| 429         | `RateLimitError`           |\n| >=500       | `InternalServerError`      |\n| N/A         | `APIConnectionError`       |\n\n## Request IDs\n\n> For more information on debugging requests, see [these docs](https://platform.openai.com/docs/api-reference/debugging-requests)\n\nAll object responses in the SDK provide a `_request_id` property which is added from the `x-request-id` response header so that you can quickly log failing requests and report them back to OpenAI.\n\n```python\nresponse = await client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=\"Say 'this is a test'.\",\n)\nprint(response._request_id)  # req_123\n```\n\nNote that unlike other properties that use an `_` prefix, the `_request_id` property\n_is_ public. Unless documented otherwise, _all_ other `_` prefix properties,\nmethods and modules are _private_.\n\n> [!IMPORTANT]  \n> If you need to access request IDs for failed requests you must catch the `APIStatusError` exception\n\n```python\nimport openai\n\ntry:\n    completion = await client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}], model=\"gpt-4\"\n    )\nexcept openai.APIStatusError as exc:\n    print(exc.request_id)  # req_123\n    raise exc\n```\n\n## Retries\n\nCertain errors are automatically retried 2 times by default, with a short exponential backoff.\nConnection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,\n429 Rate Limit, and >=500 Internal errors are all retried by default.\n\nYou can use the `max_retries` option to configure or disable retry settings:\n\n```python\nfrom openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # default is 2\n    max_retries=0,\n)\n\n# Or, configure per-request:\nclient.with_options(max_retries=5).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I get the name of the current day in JavaScript?\",\n        }\n    ],\n    model=\"gpt-4o\",\n)\n```\n\n## Timeouts\n\nBy default requests time out after 10 minutes. You can configure this with a `timeout` option,\nwhich accepts a float or an [`httpx.Timeout`](https://www.python-httpx.org/advanced/timeouts/#fine-tuning-the-configuration) object:\n\n```python\nfrom openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # 20 seconds (default is 10 minutes)\n    timeout=20.0,\n)\n\n# More granular control:\nclient = OpenAI(\n    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),\n)\n\n# Override per-request:\nclient.with_options(timeout=5.0).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I list all files in a directory using Python?\",\n        }\n    ],\n    model=\"gpt-4o\",\n)\n```\n\nOn timeout, an `APITimeoutError` is thrown.\n\nNote that requests that time out are [retried twice by default](https://github.com/openai/openai-python/tree/main/#retries).\n\n## Advanced\n\n### Logging\n\nWe use the standard library [`logging`](https://docs.python.org/3/library/logging.html) module.\n\nYou can enable logging by setting the environment variable `OPENAI_LOG` to `info`.\n\n```shell\n$ export OPENAI_LOG=info\n```\n\nOr to `debug` for more verbose logging.\n\n### How to tell whether `None` means `null` or missing\n\nIn an API response, a field may be explicitly `null`, or missing entirely; in either case, its value is `None` in this library. You can differentiate the two cases with `.model_fields_set`:\n\n```py\nif response.my_field is None:\n  if 'my_field' not in response.model_fields_set:\n    print('Got json like {}, without a \"my_field\" key present at all.')\n  else:\n    print('Got json like {\"my_field\": null}.')\n```\n\n### Accessing raw response data (e.g. headers)\n\nThe \"raw\" Response object can be accessed by prefixing `.with_raw_response.` to any HTTP method call, e.g.,\n\n```py\nfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.chat.completions.with_raw_response.create(\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Say this is a test\",\n    }],\n    model=\"gpt-4o\",\n)\nprint(response.headers.get('X-My-Header'))\n\ncompletion = response.parse()  # get the object that `chat.completions.create()` would have returned\nprint(completion)\n```\n\nThese methods return a [`LegacyAPIResponse`](https://github.com/openai/openai-python/tree/main/src/openai/_legacy_response.py) object. This is a legacy class as we're changing it slightly in the next major version.\n\nFor the sync client this will mostly be the same with the exception\nof `content` & `text` will be methods instead of properties. In the\nasync client, all methods will be async.\n\nA migration script will be provided & the migration in general should\nbe smooth.\n\n#### `.with_streaming_response`\n\nThe above interface eagerly reads the full response body when you make the request, which may not always be what you want.\n\nTo stream the response body, use `.with_streaming_response` instead, which requires a context manager and only reads the response body once you call `.read()`, `.text()`, `.json()`, `.iter_bytes()`, `.iter_text()`, `.iter_lines()` or `.parse()`. In the async client, these are async methods.\n\nAs such, `.with_streaming_response` methods return a different [`APIResponse`](https://github.com/openai/openai-python/tree/main/src/openai/_response.py) object, and the async client returns an [`AsyncAPIResponse`](https://github.com/openai/openai-python/tree/main/src/openai/_response.py) object.\n\n```python\nwith client.chat.completions.with_streaming_response.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        }\n    ],\n    model=\"gpt-4o\",\n) as response:\n    print(response.headers.get(\"X-My-Header\"))\n\n    for line in response.iter_lines():\n        print(line)\n```\n\nThe context manager is required so that the response will reliably be closed.\n\n### Making custom/undocumented requests\n\nThis library is typed for convenient access to the documented API.\n\nIf you need to access undocumented endpoints, params, or response properties, the library can still be used.\n\n#### Undocumented endpoints\n\nTo make requests to undocumented endpoints, you can make requests using `client.get`, `client.post`, and other\nhttp verbs. Options on the client will be respected (such as retries) when making this request.\n\n```py\nimport httpx\n\nresponse = client.post(\n    \"/foo\",\n    cast_to=httpx.Response,\n    body={\"my_param\": True},\n)\n\nprint(response.headers.get(\"x-foo\"))\n```\n\n#### Undocumented request params\n\nIf you want to explicitly send an extra param, you can do so with the `extra_query`, `extra_body`, and `extra_headers` request\noptions.\n\n#### Undocumented response properties\n\nTo access undocumented response properties, you can access the extra fields like `response.unknown_prop`. You\ncan also get all the extra fields on the Pydantic model as a dict with\n[`response.model_extra`](https://docs.pydantic.dev/latest/api/base_model/#pydantic.BaseModel.model_extra).\n\n### Configuring the HTTP client\n\nYou can directly override the [httpx client](https://www.python-httpx.org/api/#client) to customize it for your use case, including:\n\n- Support for [proxies](https://www.python-httpx.org/advanced/proxies/)\n- Custom [transports](https://www.python-httpx.org/advanced/transports/)\n- Additional [advanced](https://www.python-httpx.org/advanced/clients/) functionality\n\n```python\nimport httpx\nfrom openai import OpenAI, DefaultHttpxClient\n\nclient = OpenAI(\n    # Or use the `OPENAI_BASE_URL` env var\n    base_url=\"http://my.test.server.example.com:8083/v1\",\n    http_client=DefaultHttpxClient(\n        proxy=\"http://my.test.proxy.example.com\",\n        transport=httpx.HTTPTransport(local_address=\"0.0.0.0\"),\n    ),\n)\n```\n\nYou can also customize the client on a per-request basis by using `with_options()`:\n\n```python\nclient.with_options(http_client=DefaultHttpxClient(...))\n```\n\n### Managing HTTP resources\n\nBy default the library closes underlying HTTP connections whenever the client is [garbage collected](https://docs.python.org/3/reference/datamodel.html#object.__del__). You can manually close the client using the `.close()` method if desired, or with a context manager that closes when exiting.\n\n```py\nfrom openai import OpenAI\n\nwith OpenAI() as client:\n  # make requests here\n  ...\n\n# HTTP client is now closed\n```\n\n## Microsoft Azure OpenAI\n\nTo use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the `AzureOpenAI`\nclass instead of the `OpenAI` class.\n\n> [!IMPORTANT]\n> The Azure API shape differs from the core API shape which means that the static types for responses / params\n> won't always be correct.\n\n```py\nfrom openai import AzureOpenAI\n\n# gets the API Key from environment variable AZURE_OPENAI_API_KEY\nclient = AzureOpenAI(\n    # https://learn.microsoft.com/azure/ai-services/openai/reference#rest-api-versioning\n    api_version=\"2023-07-01-preview\",\n    # https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n    azure_endpoint=\"https://example-endpoint.openai.azure.com\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"deployment-name\",  # e.g. gpt-35-instant\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.to_json())\n```\n\nIn addition to the options provided in the base `OpenAI` client, the following options are provided:\n\n- `azure_endpoint` (or the `AZURE_OPENAI_ENDPOINT` environment variable)\n- `azure_deployment`\n- `api_version` (or the `OPENAI_API_VERSION` environment variable)\n- `azure_ad_token` (or the `AZURE_OPENAI_AD_TOKEN` environment variable)\n- `azure_ad_token_provider`\n\nAn example of using the client with Microsoft Entra ID (formerly known as Azure Active Directory) can be found [here](https://github.com/openai/openai-python/blob/main/examples/azure_ad.py).\n\n## Versioning\n\nThis package generally follows [SemVer](https://semver.org/spec/v2.0.0.html) conventions, though certain backwards-incompatible changes may be released as minor versions:\n\n1. Changes that only affect static types, without breaking runtime behavior.\n2. Changes to library internals which are technically public but not intended or documented for external use. _(Please open a GitHub issue to let us know if you are relying on such internals.)_\n3. Changes that we do not expect to impact the vast majority of users in practice.\n\nWe take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.\n\nWe are keen for your feedback; please open an [issue](https://www.github.com/openai/openai-python/issues) with questions, bugs, or suggestions.\n\n### Determining the installed version\n\nIf you've upgraded to the latest version but aren't seeing any new features you were expecting then your python environment is likely still using an older version.\n\nYou can determine the version that is being used at runtime with:\n\n```py\nimport openai\nprint(openai.__version__)\n```\n\n## Requirements\n\nPython 3.8 or higher.\n\n## Contributing\n\nSee [the contributing documentation](https://github.com/openai/openai-python/tree/main/./CONTRIBUTING.md).\n",
        "description_content_type": "text/markdown",
        "author_email": "OpenAI <support@openai.com>",
        "license": "Apache-2.0",
        "classifier": [
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: MacOS",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: OS Independent",
          "Operating System :: POSIX",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "anyio<5,>=3.5.0",
          "distro<2,>=1.7.0",
          "httpx<1,>=0.23.0",
          "jiter<1,>=0.4.0",
          "pydantic<3,>=1.9.0",
          "sniffio",
          "tqdm>4",
          "typing-extensions<5,>=4.11",
          "numpy>=1; extra == 'datalib'",
          "pandas-stubs>=1.1.0.11; extra == 'datalib'",
          "pandas>=1.2.3; extra == 'datalib'",
          "websockets<16,>=13; extra == 'realtime'",
          "numpy>=2.0.2; extra == 'voice-helpers'",
          "sounddevice>=0.5.1; extra == 'voice-helpers'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/openai/openai-python",
          "Repository, https://github.com/openai/openai-python"
        ],
        "provides_extra": [
          "datalib",
          "realtime",
          "voice-helpers"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4f/0f/27520da74769db6e58327d96c98e7b9a07ce686dff582c9a5ec60b03f9dd/azure_ai_inference-1.0.0b9-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=49823732e674092dad83bb8b0d1b65aa73111fab924d61349eb2a8cdc0493990",
          "hashes": {
            "sha256": "49823732e674092dad83bb8b0d1b65aa73111fab924d61349eb2a8cdc0493990"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.1",
        "name": "azure-ai-inference",
        "version": "1.0.0b9",
        "summary": "Microsoft Azure AI Inference Client Library for Python",
        "description": "# Azure AI Inference client library for Python\n\nUse the Inference client library (in preview) to:\n\n* Authenticate against the service\n* Get information about the AI model\n* Do chat completions\n* Get text embeddings\n* Get image embeddings\n\nThe Inference client library supports AI models deployed to the following services:\n\n* [GitHub Models](https://github.com/marketplace/models) - Free-tier endpoint for AI models from different providers\n* Serverless API endpoints and Managed Compute endpoints - AI models from different providers deployed from [Azure AI Foundry](https://ai.azure.com). See [Overview: Deploy models, flows, and web apps with Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/concepts/deployments-overview).\n* Azure OpenAI Service - OpenAI models deployed from [Azure AI Foundry](https://oai.azure.com/). See [What is Azure OpenAI Service?](https://learn.microsoft.com/azure/ai-services/openai/overview). Although we recommend you use the official [OpenAI client library](https://pypi.org/project/openai/) in your production code for this service, you can use the Azure AI Inference client library to easily compare the performance of OpenAI models to other models, using the same client library and Python code.\n\nThe Inference client library makes services calls using REST API version `2024-05-01-preview`, as documented in [Azure AI Model Inference API](https://aka.ms/azureai/modelinference).\n\n[Product documentation](https://aka.ms/aiservices/inference)\n| [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples)\n| [API reference documentation](https://aka.ms/azsdk/azure-ai-inference/python/reference)\n| [Package (Pypi)](https://aka.ms/azsdk/azure-ai-inference/python/package)\n| [SDK source code](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/azure/ai/inference)\n\n## Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention the package name \"azure-ai-inference\" in the title or content.\n\n## Getting started\n\n### Prerequisites\n\n* [Python 3.8](https://www.python.org/) or later installed, including [pip](https://pip.pypa.io/en/stable/).\n* For GitHub models\n  * The AI model name, such as \"gpt-4o\" or \"mistral-large\"\n  * A GitHub personal access token. [Create one here](https://github.com/settings/tokens). You do not need to give any permissions to the token. The token is a string that starts with `github_pat_`.\n* For Serverless API endpoints or Managed Compute endpoints\n  * An [Azure subscription](https://azure.microsoft.com/free).\n  * An [AI Model from the catalog](https://ai.azure.com/explore/models) deployed through Azure AI Foundry.\n  * The endpoint URL of your model, in of the form `https://<your-host-name>.<your-azure-region>.models.ai.azure.com`, where `your-host-name` is your unique model deployment host name and `your-azure-region` is the Azure region where the model is deployed (e.g. `eastus2`).\n  * Depending on your authentication preference, you either need an API key to authenticate against the service, or Entra ID credentials.\n* For Azure OpenAI (AOAI) service\n  * An [Azure subscription](https://azure.microsoft.com/free).\n  * An [OpenAI Model from the catalog](https://oai.azure.com/resource/models) deployed through Azure AI Foundry.\n  * The endpoint URL of your model, in the form `https://<your-resouce-name>.openai.azure.com/openai/deployments/<your-deployment-name>`, where `your-resource-name` is your globally unique AOAI resource name, and `your-deployment-name` is your AI Model deployment name.\n  * Depending on your authentication preference, you either need an API key to authenticate against the service, or Entra ID credentials.\n  * An api-version. Latest preview or GA version listed in the `Data plane - inference` row in [the API Specs table](https://aka.ms/azsdk/azure-ai-inference/azure-openai-api-versions). At the time of writing, latest GA version was \"2024-06-01\".\n\n### Install the package\n\nTo install the Azure AI Inferencing package use the following command:\n\n```bash\npip install azure-ai-inference\n```\n\nTo update an existing installation of the package, use:\n\n```bash\npip install --upgrade azure-ai-inference\n```\n\nIf you want to install Azure AI Inferencing package with support for OpenTelemetry based tracing, use the following command:\n\n```bash\npip install azure-ai-inference[opentelemetry]\n```\n\n## Key concepts\n\n### Create and authenticate a client directly, using API key or GitHub token\n\nThe package includes two clients `ChatCompletionsClient` and `EmbeddingsClient`<!-- and `ImageGenerationClients`-->. Both can be created in the similar manner. For example, assuming `endpoint`, `key` and `github_token` are strings holding your endpoint URL, API key or GitHub token, this Python code will create and authenticate a synchronous `ChatCompletionsClient`:\n\n```python\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.core.credentials import AzureKeyCredential\n\n# For GitHub models\nclient = ChatCompletionsClient(\n    endpoint=\"https://models.inference.ai.azure.com\",\n    credential=AzureKeyCredential(github_token),\n    model=\"mistral-large\" # Update as needed. Alternatively, you can include this is the `complete` call.\n)\n\n# For Serverless API or Managed Compute endpoints\nclient = ChatCompletionsClient(\n    endpoint=endpoint,  # Of the form https://<your-host-name>.<your-azure-region>.models.ai.azure.com\n    credential=AzureKeyCredential(key)\n)\n\n# For Azure OpenAI endpoint\nclient = ChatCompletionsClient(\n    endpoint=endpoint,  # Of the form https://<your-resouce-name>.openai.azure.com/openai/deployments/<your-deployment-name>\n    credential=AzureKeyCredential(key),\n    api_version=\"2024-06-01\",  # Azure OpenAI api-version. See https://aka.ms/azsdk/azure-ai-inference/azure-openai-api-versions\n)\n```\n\nA synchronous client supports synchronous inference methods, meaning they will block until the service responds with inference results. For simplicity the code snippets below all use synchronous methods. The client offers equivalent asynchronous methods which are more commonly used in production.\n\nTo create an asynchronous client, Install the additional package [aiohttp](https://pypi.org/project/aiohttp/):\n\n```bash\npip install aiohttp\n```\n\nand update the code above to import `asyncio`, and import `ChatCompletionsClient` from the `azure.ai.inference.aio` namespace instead of `azure.ai.inference`. For example:\n\n```python\nimport asyncio\nfrom azure.ai.inference.aio import ChatCompletionsClient\nfrom azure.core.credentials import AzureKeyCredential\n\n# For Serverless API or Managed Compute endpoints\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(key)\n)\n```\n\n### Create and authenticate a client directly, using Entra ID\n\n_Note: At the time of writing, only Managed Compute endpoints and Azure OpenAI endpoints support Entra ID authentication.\n\nTo use an Entra ID token credential, first install the [azure-identity](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity) package:\n\n```python\npip install azure.identity\n```\n\nYou will need to provide the desired credential type obtained from that package. A common selection is [DefaultAzureCredential](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#defaultazurecredential) and it can be used as follows:\n\n```python\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.identity import DefaultAzureCredential\n\n# For Managed Compute endpoints\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=DefaultAzureCredential(exclude_interactive_browser_credential=False)\n)\n\n# For Azure OpenAI endpoint\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=DefaultAzureCredential(exclude_interactive_browser_credential=False),\n    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n    api_version=\"2024-06-01\",  # Azure OpenAI api-version. See https://aka.ms/azsdk/azure-ai-inference/azure-openai-api-versions\n)\n```\n\nDuring application development, you would typically set up the environment for authentication using Entra ID by first [Installing the Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli), running `az login` in your console window, then entering your credentials in the browser window that was opened. The call to `DefaultAzureCredential()` will then succeed. Setting `exclude_interactive_browser_credential=False` in that call will enable launching a browser window if the user isn't already logged in.\n\n### Defining default settings while creating the clients\n\nYou can define default chat completions or embeddings configurations while constructing the relevant client. These configurations will be applied to all future service calls.\n\nFor example, here we create a `ChatCompletionsClient` using API key authentication, and apply two settings, `temperature` and `max_tokens`:\n\n```python\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.core.credentials import AzureKeyCredential\n\n# For Serverless API or Managed Compute endpoints\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(key),\n    temperature=0.5,\n    max_tokens=1000\n)\n```\n\nDefault settings can be overridden in individual service calls.\n\n### Create and authenticate clients using `load_client`\n\nIf you are using Serverless API or Managed Compute endpoints, there is an alternative to creating a specific client directly. You can instead use the function `load_client` to return the relevant client (of types `ChatCompletionsClient` or `EmbeddingsClient`) based on the provided endpoint:\n\n```python\nfrom azure.ai.inference import load_client\nfrom azure.core.credentials import AzureKeyCredential\n\n# For Serverless API or Managed Compute endpoints only.\n# This will not work on GitHub Models endpoint or Azure OpenAI endpoint.\nclient = load_client(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(key)\n)\n\nprint(f\"Created client of type `{type(client).__name__}`.\")\n```\n\nTo load an asynchronous client, import the `load_client` function from `azure.ai.inference.aio` instead.\n\nEntra ID authentication is also supported by the `load_client` function. Replace the key authentication above with `credential=DefaultAzureCredential(exclude_interactive_browser_credential=False)` for example.\n\n### Get AI model information\n\nIf you are using Serverless API or Managed Compute endpoints, you can call the client method `get_model_info` to retrive AI model information. This makes a REST call to the `/info` route on the provided endpoint, as documented in [the REST API reference](https://learn.microsoft.com/azure/ai-studio/reference/reference-model-inference-info). This call will not work for GitHub Models or Azure OpenAI endpoints.\n\n<!-- SNIPPET:sample_get_model_info.get_model_info -->\n\n```python\nmodel_info = client.get_model_info()\n\nprint(f\"Model name: {model_info.model_name}\")\nprint(f\"Model provider name: {model_info.model_provider_name}\")\nprint(f\"Model type: {model_info.model_type}\")\n```\n\n<!-- END SNIPPET -->\n\nAI model information is cached in the client, and futher calls to `get_model_info` will access the cached value and wil not result in a REST API call. Note that if you created the client using `load_client` function, model information will already be cached in the client.\n\nAI model information is displayed (if available) when you `print(client)`.\n\n### Chat Completions\n\nThe `ChatCompletionsClient` has a method named `complete`. The method makes a REST API call to the `/chat/completions` route on the provided endpoint, as documented in [the REST API reference](https://learn.microsoft.com/azure/ai-studio/reference/reference-model-inference-chat-completions).\n\nSee simple chat completion examples below. More can be found in the [samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples) folder.\n\n### Text Embeddings\n\nThe `EmbeddingsClient` has a method named `embed`. The method makes a REST API call to the `/embeddings` route on the provided endpoint, as documented in [the REST API reference](https://learn.microsoft.com/azure/ai-studio/reference/reference-model-inference-embeddings).\n\nSee simple text embedding example below. More can be found in the [samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples) folder.\n\n### Image Embeddings\n\nThe `ImageEmbeddingsClient` has a method named `embed`. The method makes a REST API call to the `/images/embeddings` route on the provided endpoint, as documented in [the REST API reference](https://learn.microsoft.com/azure/ai-studio/reference/reference-model-inference-images-embeddings).\n\nSee simple image embedding example below. More can be found in the [samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples) folder.\n\n## Examples\n\nIn the following sections you will find simple examples of:\n\n* [Chat completions](#chat-completions-example)\n* [Streaming chat completions](#streaming-chat-completions-example)\n* [Adding model-specific parameters](#adding-model-specific-parameters)\n* [Adding HTTP request headers](#adding-http-request-headers)\n* [Text Embeddings](#text-embeddings-example)\n* [Image Embeddings](#image-embeddings-example)\n\nThe examples create a synchronous client assuming a Serverless API or Managed Compute endpoint. Modify client\nconstruction code as descirbed in [Key concepts](#key-concepts) to have it work with GitHub Models endpoint or Azure OpenAI\nendpoint. Only mandatory input settings are shown for simplicity.\n\nSee the [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples) folder for full working samples for synchronous and asynchronous clients.\n\n### Chat completions example\n\nThis example demonstrates how to generate a single chat completions, for a Serverless API or Managed Compute endpoint, with key authentication, assuming `endpoint` and `key` are already defined. For Entra ID authentication, GitHub models endpoint or Azure OpenAI endpoint, modify the code to create the client as specified in the above sections.\n\n<!-- SNIPPET:sample_chat_completions.chat_completions -->\n\n```python\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import SystemMessage, UserMessage\nfrom azure.core.credentials import AzureKeyCredential\n\nclient = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n\nresponse = client.complete(\n    messages=[\n        SystemMessage(\"You are a helpful assistant.\"),\n        UserMessage(\"How many feet are in a mile?\"),\n    ],\n)\n\nprint(response.choices[0].message.content)\nprint(f\"\\nToken usage: {response.usage}\")\n```\n\n<!-- END SNIPPET -->\n\nThe following types of messages are supported: `SystemMessage`,`UserMessage`, `AssistantMessage`, `ToolMessage`, `DeveloperMessage`. See also samples:\n\n* [sample_chat_completions_with_tools.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_tools.py) for usage of `ToolMessage`.\n* [sample_chat_completions_with_image_url.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_image_url.py) for usage of `UserMessage` that\nincludes sending an image URL.\n* [sample_chat_completions_with_image_data.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_image_data.py) for usage of `UserMessage` that\nincludes sending image data read from a local file.\n* [sample_chat_completions_with_audio_data.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_image_data.py) for usage of `UserMessage` that includes sending audio data read from a local file.\n* [sample_chat_completions_with_structured_output.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_structured_output.py) and [sample_chat_completions_with_structured_output_pydantic.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-inference/samples/sample_chat_completions_with_structured_output_pydantic.py) for configuring the service to respond with a JSON-formatted string, adhering to your schema.\n\nAlternatively, you can provide the full request body as a Python dictionary (`dict` object) instead of using the strongly typed classes like `SystemMessage` and `UserMessage`:\n\n<!-- SNIPPET:sample_chat_completions_from_input_dict.chat_completions_full_request_as_dict -->\n\n```python\nresponse = client.complete(\n    {\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an AI assistant that helps people find information. Your replies are short, no more than two sentences.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": \"What year was construction of the International Space Station mostly done?\",\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": \"The main construction of the International Space Station (ISS) was completed between 1998 and 2011. During this period, more than 30 flights by US space shuttles and 40 by Russian rockets were conducted to transport components and modules to the station.\",\n            },\n            {\"role\": \"user\", \"content\": \"And what was the estimated cost to build it?\"},\n        ]\n    }\n)\n```\n\n<!-- END SNIPPET -->\n\nOr you can provide just the `messages` input argument as a list of Python `dict`:\n\n<!-- SNIPPET:sample_chat_completions_from_input_dict.chat_completions_messages_as_dict -->\n\n```python\nresponse = client.complete(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an AI assistant that helps people find information.\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"How many feet are in a mile?\",\n        },\n    ]\n)\n```\n\n<!-- END SNIPPET -->\n\nTo generate completions for additional messages, simply call `client.complete` multiple times using the same `client`.\n\n### Streaming chat completions example\n\nThis example demonstrates how to generate a single chat completions with streaming response, for a Serverless API or Managed Compute endpoint, with key authentication, assuming `endpoint` and `key` are already defined. You simply need to add `stream=True` to the `complete` call to enable streaming.\n\nFor Entra ID authentication, GitHub models endpoint or Azure OpenAI endpoint, modify the code to create the client as specified in the above sections.\n\n<!-- SNIPPET:sample_chat_completions_streaming.chat_completions_streaming -->\n\n```python\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import SystemMessage, UserMessage\nfrom azure.core.credentials import AzureKeyCredential\n\nclient = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n\nresponse = client.complete(\n    stream=True,\n    messages=[\n        SystemMessage(\"You are a helpful assistant.\"),\n        UserMessage(\"Give me 5 good reasons why I should exercise every day.\"),\n    ],\n)\n\nfor update in response:\n    if update.choices and update.choices[0].delta:\n        print(update.choices[0].delta.content or \"\", end=\"\", flush=True)\n    if update.usage:\n        print(f\"\\n\\nToken usage: {update.usage}\")\n\nclient.close()\n```\n\n<!-- END SNIPPET -->\n\nIn the above `for` loop that prints the results you should see the answer progressively get longer as updates get streamed to the client.\n\nTo generate completions for additional messages, simply call `client.complete` multiple times using the same `client`.\n\n### Adding model-specific parameters\n\nIn this example, extra JSON elements are inserted at the root of the request body by setting `model_extras` when calling the `complete` method of the `ChatCompletionsClient`. These are intended for AI models that require additional model-specific parameters beyond what is defined in the REST API [Request Body table](https://learn.microsoft.com/azure/ai-studio/reference/reference-model-inference-chat-completions#request-body).\n\n<!-- SNIPPET:sample_chat_completions_with_model_extras.model_extras -->\n\n```python\nresponse = client.complete(\n    messages=[\n        SystemMessage(\"You are a helpful assistant.\"),\n        UserMessage(\"How many feet are in a mile?\"),\n    ],\n    model_extras={\"key1\": \"value1\", \"key2\": \"value2\"},  # Optional. Additional parameters to pass to the model.\n)\n```\n\n<!-- END SNIPPET -->\nIn the above example, this will be the JSON payload in the HTTP request:\n\n```json\n{\n    \"messages\":\n    [\n        {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n        {\"role\":\"user\",\"content\":\"How many feet are in a mile?\"}\n    ],\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n}\n```\n\nNote that by default, the service will reject any request payload that includes extra parameters. In order to change the default service behaviour, when the `complete` method includes `model_extras`, the client library will automatically add the HTTP request header `\"extra-parameters\": \"pass-through\"`.\n\nUse the same method to add additional paramaters in the request of other clients in this package.\n\n### Adding HTTP request headers\n\nTo add your own HTTP request headers, include a `headers` keyword in the client constructor, and specify a `dict` with your\nheader names and values. For example:\n\n```python\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(key),\n    headers={\"header1\", \"value1\", \"header2\", \"value2\"}\n)\n```\n\nAnd similarly for the other clients in this package.\n\n### Text Embeddings example\n\nThis example demonstrates how to get text embeddings, for a Serverless API or Managed Compute endpoint, with key authentication, assuming `endpoint` and `key` are already defined. For Entra ID authentication, GitHub models endpoint or Azure OpenAI endpoint, modify the code to create the client as specified in the above sections.\n\n<!-- SNIPPET:sample_embeddings.embeddings -->\n\n```python\nfrom azure.ai.inference import EmbeddingsClient\nfrom azure.core.credentials import AzureKeyCredential\n\nclient = EmbeddingsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n\nresponse = client.embed(input=[\"first phrase\", \"second phrase\", \"third phrase\"])\n\nfor item in response.data:\n    length = len(item.embedding)\n    print(\n        f\"data[{item.index}]: length={length}, [{item.embedding[0]}, {item.embedding[1]}, \"\n        f\"..., {item.embedding[length-2]}, {item.embedding[length-1]}]\"\n    )\n```\n\n<!-- END SNIPPET -->\n\nThe length of the embedding vector depends on the model, but you should see something like this:\n\n```text\ndata[0]: length=1024, [0.0013399124, -0.01576233, ..., 0.007843018, 0.000238657]\ndata[1]: length=1024, [0.036590576, -0.0059547424, ..., 0.011405945, 0.004863739]\ndata[2]: length=1024, [0.04196167, 0.029083252, ..., -0.0027484894, 0.0073127747]\n```\n\nTo generate embeddings for additional phrases, simply call `client.embed` multiple times using the same `client`.\n\n### Image Embeddings example\n\nThis example demonstrates how to get image embeddings, for a Serverless API or Managed Compute endpoint, with key authentication, assuming `endpoint` and `key` are already defined. For Entra ID authentication, GitHub models endpoint or Azure OpenAI endpoint, modify the code to create the client as specified in the above sections.\n\n<!-- SNIPPET:sample_image_embeddings.image_embeddings -->\n\n```python\nfrom azure.ai.inference import ImageEmbeddingsClient\nfrom azure.ai.inference.models import ImageEmbeddingInput\nfrom azure.core.credentials import AzureKeyCredential\n\nclient = ImageEmbeddingsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n\nresponse = client.embed(input=[ImageEmbeddingInput.load(image_file=\"sample1.png\", image_format=\"png\")])\n\nfor item in response.data:\n    length = len(item.embedding)\n    print(\n        f\"data[{item.index}]: length={length}, [{item.embedding[0]}, {item.embedding[1]}, \"\n        f\"..., {item.embedding[length-2]}, {item.embedding[length-1]}]\"\n    )\n```\n\n<!-- END SNIPPET -->\n\nThe length of the embedding vector depends on the model, but you should see something like this:\n\n```text\ndata[0]: length=1024, [0.0103302, -0.04425049, ..., -0.011543274, -0.0009088516]\n```\n\nTo generate image embeddings for additional images, simply call `client.embed` multiple times using the same `client`.\n\n## Troubleshooting\n\n### Exceptions\n\nThe `complete`, `embed` and `get_model_info` methods on the clients raise an [HttpResponseError](https://learn.microsoft.com/python/api/azure-core/azure.core.exceptions.httpresponseerror) exception for a non-success HTTP status code response from the service. The exception's `status_code` will hold the HTTP response status code (with `reason` showing the friendly name). The exception's `error.message` contains a detailed message that may be helpful in diagnosing the issue:\n\n```python\nfrom azure.core.exceptions import HttpResponseError\n\n...\n\ntry:\n    result = client.complete( ... )\nexcept HttpResponseError as e:\n    print(f\"Status code: {e.status_code} ({e.reason})\")\n    print(e.message)\n```\n\nFor example, when you provide a wrong authentication key:\n\n```text\nStatus code: 401 (Unauthorized)\nOperation returned an invalid status 'Unauthorized'\n```\n\nOr when you create an `EmbeddingsClient` and call `embed` on the client, but the endpoint does not\nsupport the `/embeddings` route:\n\n```text\nStatus code: 405 (Method Not Allowed)\nOperation returned an invalid status 'Method Not Allowed'\n```\n\n### Logging\n\nThe client uses the standard [Python logging library](https://docs.python.org/3/library/logging.html). The SDK logs HTTP request and response details, which may be useful in troubleshooting. To log to stdout, add the following:\n\n```python\nimport sys\nimport logging\n\n# Acquire the logger for this client library. Use 'azure' to affect both\n# 'azure.core` and `azure.ai.inference' libraries.\nlogger = logging.getLogger(\"azure\")\n\n# Set the desired logging level. logging.INFO or logging.DEBUG are good options.\nlogger.setLevel(logging.DEBUG)\n\n# Direct logging output to stdout:\nhandler = logging.StreamHandler(stream=sys.stdout)\n# Or direct logging output to a file:\n# handler = logging.FileHandler(filename=\"sample.log\")\nlogger.addHandler(handler)\n\n# Optional: change the default logging format. Here we add a timestamp.\nformatter = logging.Formatter(\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\")\nhandler.setFormatter(formatter)\n```\n\nBy default logs redact the values of URL query strings, the values of some HTTP request and response headers (including `Authorization` which holds the key or token), and the request and response payloads. To create logs without redaction, do these two things:\n\n1. Set the method argument `logging_enable = True` when you construct the client library, or when you call the client's `complete` or `embed`  methods.\n    ```python\n    client = ChatCompletionsClient(\n        endpoint=endpoint,\n        credential=AzureKeyCredential(key),\n        logging_enable=True\n    )\n    ```\n1. Set the log level to `logging.DEBUG`. Logs will be redacted with any other log level.\n\nBe sure to protect non redacted logs to avoid compromising security.\n\nFor more information, see [Configure logging in the Azure libraries for Python](https://aka.ms/azsdk/python/logging)\n\n### Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention \"azure-ai-inference\" in the title or content.\n\n## Observability With OpenTelemetry\n\nThe Azure AI Inference client library provides experimental support for tracing with OpenTelemetry.\n\nYou can capture prompt and completion contents by setting `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED` environment to `true` (case insensitive).\nBy default prompts, completions, function name, parameters or outputs are not recorded.\n\n### Setup with Azure Monitor\n\nWhen using Azure AI Inference library with [Azure Monitor OpenTelemetry Distro](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python),\ndistributed tracing for Azure AI Inference calls is enabled by default when using latest version of the distro.\n\n### Setup with OpenTelemetry\n\nCheck out your observability vendor documentation on how to configure OpenTelemetry or refer to the [official OpenTelemetry documentation](https://opentelemetry.io/docs/languages/python/).\n\n#### Installation\n\nMake sure to install OpenTelemetry and the Azure SDK tracing plugin via\n\n```bash\npip install opentelemetry\npip install azure-core-tracing-opentelemetry\n```\n\nYou will also need an exporter to send telemetry to your observability backend. You can print traces to the console or use a local viewer such as [Aspire Dashboard](https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash).\n\nTo connect to Aspire Dashboard or another OpenTelemetry compatible backend, install OTLP exporter:\n\n```bash\npip install opentelemetry-exporter-otlp\n```\n\n#### Configuration\n\nTo enable Azure SDK tracing set `AZURE_SDK_TRACING_IMPLEMENTATION` environment variable to `opentelemetry`.\n\nOr configure it in the code with the following snippet:\n\n<!-- SNIPPET:sample_chat_completions_with_tracing.trace_setting -->\n\n```python\nfrom azure.core.settings import settings\n\nsettings.tracing_implementation = \"opentelemetry\"\n```\n\n<!-- END SNIPPET -->\n\nPlease refer to [azure-core-tracing-documentation](https://learn.microsoft.com/python/api/overview/azure/core-tracing-opentelemetry-readme) for more information.\n\nThe final step is to enable Azure AI Inference instrumentation with the following code snippet:\n\n<!-- SNIPPET:sample_chat_completions_with_tracing.instrument_inferencing -->\n\n```python\nfrom azure.ai.inference.tracing import AIInferenceInstrumentor\n\n# Instrument AI Inference API\nAIInferenceInstrumentor().instrument()\n```\n\n<!-- END SNIPPET -->\n\n\nIt is also possible to uninstrument the Azure AI Inferencing API by using the uninstrument call. After this call, the traces will no longer be emitted by the Azure AI Inferencing API until instrument is called again.\n\n<!-- SNIPPET:sample_chat_completions_with_tracing.uninstrument_inferencing -->\n\n```python\nAIInferenceInstrumentor().uninstrument()\n```\n\n<!-- END SNIPPET -->\n\n### Tracing Your Own Functions\n\nThe `@tracer.start_as_current_span` decorator can be used to trace your own functions. This will trace the function parameters and their values. You can also add further attributes to the span in the function implementation as demonstrated below. Note that you will have to setup the tracer in your code before using the decorator. More information is available [here](https://opentelemetry.io/docs/languages/python/).\n\n<!-- SNIPPET:sample_chat_completions_with_tracing.trace_function -->\n\n```python\nfrom opentelemetry.trace import get_tracer\n\ntracer = get_tracer(__name__)\n\n\n# The tracer.start_as_current_span decorator will trace the function call and enable adding additional attributes\n# to the span in the function implementation. Note that this will trace the function parameters and their values.\n@tracer.start_as_current_span(\"get_temperature\")  # type: ignore\ndef get_temperature(city: str) -> str:\n\n    # Adding attributes to the current span\n    span = trace.get_current_span()\n    span.set_attribute(\"requested_city\", city)\n\n    if city == \"Seattle\":\n        return \"75\"\n    elif city == \"New York City\":\n        return \"80\"\n    else:\n        return \"Unavailable\"\n```\n\n<!-- END SNIPPET -->\n\n## Next steps\n\n* Have a look at the [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference/samples) folder, containing fully runnable Python code for doing inference using synchronous and asynchronous clients.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require\nyou to agree to a Contributor License Agreement (CLA) declaring that you have\nthe right to, and actually do, grant us the rights to use your contribution.\nFor details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether\nyou need to provide a CLA and decorate the PR appropriately (e.g., label,\ncomment). Simply follow the instructions provided by the bot. You will only\nneed to do this once across all repos using our CLA.\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct). For more information,\nsee the Code of Conduct FAQ or contact opencode@microsoft.com with any\nadditional questions or comments.\n\n\n<!-- Note: I did not use LINKS section here with a list of `[link-label](link-url)` because these\nlinks don't work in the Sphinx generated documentation. The index.html page of these docs\ninclude this README, but with broken links.-->\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "isodate >=0.6.1",
          "azure-core >=1.30.0",
          "typing-extensions >=4.6.0",
          "azure-core-tracing-opentelemetry ; extra == 'opentelemetry'",
          "pyyaml ; extra == 'prompts'"
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "opentelemetry",
          "prompts"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/96/31/6607dab48616902f76885dfcf62c08d929796fc3b2d2318faf9fd54dbed9/pytest_asyncio-0.24.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=a811296ed596b69bf0b6f3dc40f83bcaf341b155a269052d82efa2b25ac7037b",
          "hashes": {
            "sha256": "a811296ed596b69bf0b6f3dc40f83bcaf341b155a269052d82efa2b25ac7037b"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.1",
        "name": "pytest-asyncio",
        "version": "0.24.0",
        "summary": "Pytest support for asyncio",
        "description": "pytest-asyncio\n==============\n\n.. image:: https://img.shields.io/pypi/v/pytest-asyncio.svg\n    :target: https://pypi.python.org/pypi/pytest-asyncio\n.. image:: https://github.com/pytest-dev/pytest-asyncio/workflows/CI/badge.svg\n    :target: https://github.com/pytest-dev/pytest-asyncio/actions?workflow=CI\n.. image:: https://codecov.io/gh/pytest-dev/pytest-asyncio/branch/main/graph/badge.svg\n    :target: https://codecov.io/gh/pytest-dev/pytest-asyncio\n.. image:: https://img.shields.io/pypi/pyversions/pytest-asyncio.svg\n    :target: https://github.com/pytest-dev/pytest-asyncio\n    :alt: Supported Python versions\n.. image:: https://img.shields.io/badge/Matrix-%23pytest--asyncio-brightgreen\n    :alt: Matrix chat room: #pytest-asyncio\n    :target: https://matrix.to/#/#pytest-asyncio:matrix.org\n\n`pytest-asyncio <https://pytest-asyncio.readthedocs.io/en/latest/>`_ is a `pytest <https://docs.pytest.org/en/latest/contents.html>`_ plugin. It facilitates testing of code that uses the `asyncio <https://docs.python.org/3/library/asyncio.html>`_ library.\n\nSpecifically, pytest-asyncio provides support for coroutines as test functions. This allows users to *await* code inside their tests. For example, the following code is executed as a test item by pytest:\n\n.. code-block:: python\n\n    @pytest.mark.asyncio\n    async def test_some_asyncio_code():\n        res = await library.do_something()\n        assert b\"expected result\" == res\n\nMore details can be found in the `documentation <https://pytest-asyncio.readthedocs.io/en/latest/>`_.\n\nNote that test classes subclassing the standard `unittest <https://docs.python.org/3/library/unittest.html>`__ library are not supported. Users\nare advised to use `unittest.IsolatedAsyncioTestCase <https://docs.python.org/3/library/unittest.html#unittest.IsolatedAsyncioTestCase>`__\nor an async framework such as `asynctest <https://asynctest.readthedocs.io/en/latest>`__.\n\n\npytest-asyncio is available under the `Apache License 2.0 <https://github.com/pytest-dev/pytest-asyncio/blob/main/LICENSE>`_.\n\n\nInstallation\n------------\n\nTo install pytest-asyncio, simply:\n\n.. code-block:: bash\n\n    $ pip install pytest-asyncio\n\nThis is enough for pytest to pick up pytest-asyncio.\n\n\nContributing\n------------\nContributions are very welcome. Tests can be run with ``tox``, please ensure\nthe coverage at least stays the same before you submit a pull request.\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/pytest-dev/pytest-asyncio",
        "author": "Tin TvrtkoviÄ‡ <tinchester@gmail.com>",
        "author_email": "tinchester@gmail.com",
        "license": "Apache 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Testing",
          "Framework :: AsyncIO",
          "Framework :: Pytest",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "pytest<9,>=8.2",
          "sphinx>=5.3; extra == \"docs\"",
          "sphinx-rtd-theme>=1.0; extra == \"docs\"",
          "coverage>=6.2; extra == \"testing\"",
          "hypothesis>=5.7.1; extra == \"testing\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://pytest-asyncio.readthedocs.io",
          "Changelog, https://pytest-asyncio.readthedocs.io/en/latest/reference/changelog.html",
          "Source Code, https://github.com/pytest-dev/pytest-asyncio",
          "Bug Tracker, https://github.com/pytest-dev/pytest-asyncio/issues"
        ],
        "provides_extra": [
          "docs",
          "testing"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/78/3a/af5b4fa5961d9a1e6237b530eb87dd04aea6eb83da09d2a4073d81b54ccf/pytest_cov-5.0.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4f0764a1219df53214206bf1feea4633c3b558a2925c8b59f144f682861ce652",
          "hashes": {
            "sha256": "4f0764a1219df53214206bf1feea4633c3b558a2925c8b59f144f682861ce652"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.1",
        "name": "pytest-cov",
        "version": "5.0.0",
        "summary": "Pytest plugin for measuring coverage.",
        "description": "========\nOverview\n========\n\n.. start-badges\n\n.. list-table::\n    :stub-columns: 1\n\n    * - docs\n      - |docs|\n    * - tests\n      - |github-actions|\n    * - package\n      - |version| |conda-forge| |wheel| |supported-versions| |supported-implementations| |commits-since|\n.. |docs| image:: https://readthedocs.org/projects/pytest-cov/badge/?style=flat\n    :target: https://readthedocs.org/projects/pytest-cov/\n    :alt: Documentation Status\n\n.. |github-actions| image:: https://github.com/pytest-dev/pytest-cov/actions/workflows/test.yml/badge.svg\n    :alt: GitHub Actions Status\n    :target: https://github.com/pytest-dev/pytest-cov/actions\n\n.. |version| image:: https://img.shields.io/pypi/v/pytest-cov.svg\n    :alt: PyPI Package latest release\n    :target: https://pypi.org/project/pytest-cov\n\n.. |conda-forge| image:: https://img.shields.io/conda/vn/conda-forge/pytest-cov.svg\n    :target: https://anaconda.org/conda-forge/pytest-cov\n.. |wheel| image:: https://img.shields.io/pypi/wheel/pytest-cov.svg\n    :alt: PyPI Wheel\n    :target: https://pypi.org/project/pytest-cov\n\n.. |supported-versions| image:: https://img.shields.io/pypi/pyversions/pytest-cov.svg\n    :alt: Supported versions\n    :target: https://pypi.org/project/pytest-cov\n\n.. |supported-implementations| image:: https://img.shields.io/pypi/implementation/pytest-cov.svg\n    :alt: Supported implementations\n    :target: https://pypi.org/project/pytest-cov\n\n.. |commits-since| image:: https://img.shields.io/github/commits-since/pytest-dev/pytest-cov/v5.0.0.svg\n    :alt: Commits since latest release\n    :target: https://github.com/pytest-dev/pytest-cov/compare/v5.0.0...master\n\n.. end-badges\n\nThis plugin produces coverage reports. Compared to just using ``coverage run`` this plugin does some extras:\n\n* Subprocess support: you can fork or run stuff in a subprocess and will get covered without any fuss.\n* Xdist support: you can use all of pytest-xdist's features and still get coverage.\n* Consistent pytest behavior. If you run ``coverage run -m pytest`` you will have slightly different ``sys.path`` (CWD will be\n  in it, unlike when running ``pytest``).\n\nAll features offered by the coverage package should work, either through pytest-cov's command line options or\nthrough coverage's config file.\n\n* Free software: MIT license\n\nInstallation\n============\n\nInstall with pip::\n\n    pip install pytest-cov\n\nFor distributed testing support install pytest-xdist::\n\n    pip install pytest-xdist\n\nUpgrading from ancient pytest-cov\n---------------------------------\n\n`pytest-cov 2.0` is using a new ``.pth`` file (``pytest-cov.pth``). You may want to manually remove the older\n``init_cov_core.pth`` from site-packages as it's not automatically removed.\n\nUninstalling\n------------\n\nUninstall with pip::\n\n    pip uninstall pytest-cov\n\nUnder certain scenarios a stray ``.pth`` file may be left around in site-packages.\n\n* `pytest-cov 2.0` may leave a ``pytest-cov.pth`` if you installed without wheels\n  (``easy_install``, ``setup.py install`` etc).\n* `pytest-cov 1.8 or older` will leave a ``init_cov_core.pth``.\n\nUsage\n=====\n\n::\n\n    pytest --cov=myproj tests/\n\nWould produce a report like::\n\n    -------------------- coverage: ... ---------------------\n    Name                 Stmts   Miss  Cover\n    ----------------------------------------\n    myproj/__init__          2      0   100%\n    myproj/myproj          257     13    94%\n    myproj/feature4286      94      7    92%\n    ----------------------------------------\n    TOTAL                  353     20    94%\n\nDocumentation\n=============\n\n    https://pytest-cov.readthedocs.io/en/latest/\n\n\n\n\n\n\nCoverage Data File\n==================\n\nThe data file is erased at the beginning of testing to ensure clean data for each test run. If you\nneed to combine the coverage of several test runs you can use the ``--cov-append`` option to append\nthis coverage data to coverage data from previous test runs.\n\nThe data file is left at the end of testing so that it is possible to use normal coverage tools to\nexamine it.\n\nLimitations\n===========\n\nFor distributed testing the workers must have the pytest-cov package installed.  This is needed since\nthe plugin must be registered through setuptools for pytest to start the plugin on the\nworker.\n\nFor subprocess measurement environment variables must make it from the main process to the\nsubprocess.  The python used by the subprocess must have pytest-cov installed.  The subprocess must\ndo normal site initialisation so that the environment variables can be detected and coverage\nstarted.\n\n\nAcknowledgements\n================\n\nWhilst this plugin has been built fresh from the ground up it has been influenced by the work done\non pytest-coverage (Ross Lawley, James Mills, Holger Krekel) and nose-cover (Jason Pellerin) which are\nother coverage plugins.\n\nNed Batchelder for coverage and its ability to combine the coverage results of parallel runs.\n\nHolger Krekel for pytest with its distributed testing support.\n\nJason Pellerin for nose.\n\nMichael Foord for unittest2.\n\nNo doubt others have contributed to these tools as well.\n\n\nChangelog\n=========\n\n5.0.0 (2024-03-24)\n------------------\n\n* Removed support for xdist rsync (now deprecated).\n  Contributed by Matthias Reichenbach in `#623 <https://github.com/pytest-dev/pytest-cov/pull/623>`_.\n* Switched docs theme to Furo.\n* Various legacy Python cleanup and CI improvements.\n  Contributed by Christian Clauss and Hugo van Kemenade in\n  `#630 <https://github.com/pytest-dev/pytest-cov/pull/630>`_,\n  `#631 <https://github.com/pytest-dev/pytest-cov/pull/631>`_,\n  `#632 <https://github.com/pytest-dev/pytest-cov/pull/632>`_ and\n  `#633 <https://github.com/pytest-dev/pytest-cov/pull/633>`_.\n* Added a ``pyproject.toml`` example in the docs.\n  Contributed by Dawn James in `#626 <https://github.com/pytest-dev/pytest-cov/pull/626>`_.\n* Modernized project's pre-commit hooks to use ruff. Initial POC contributed by\n  Christian Clauss in `#584 <https://github.com/pytest-dev/pytest-cov/pull/584>`_.\n\n4.1.0 (2023-05-24)\n------------------\n\n* Updated CI with new Pythons and dependencies.\n* Removed rsyncdir support. This makes pytest-cov compatible with xdist 3.0.\n  Contributed by Sorin Sbarnea in `#558 <https://github.com/pytest-dev/pytest-cov/pull/558>`_.\n* Optimized summary generation to not be performed if no reporting is active (for example,\n  when ``--cov-report=''`` is used without ``--cov-fail-under``).\n  Contributed by Jonathan Stewmon in `#589 <https://github.com/pytest-dev/pytest-cov/pull/589>`_.\n* Added support for JSON reporting.\n  Contributed by Matthew Gamble in `#582 <https://github.com/pytest-dev/pytest-cov/pull/582>`_.\n* Refactored code to use f-strings.\n  Contributed by Mark Mayo in `#572 <https://github.com/pytest-dev/pytest-cov/pull/572>`_.\n* Fixed a skip in the test suite for some old xdist.\n  Contributed by a bunch of people in `#565 <https://github.com/pytest-dev/pytest-cov/pull/565>`_.\n\n\n4.0.0 (2022-09-28)\n------------------\n\n**Note that this release drops support for multiprocessing.**\n\n\n* `--cov-fail-under` no longer causes `pytest --collect-only` to fail\n  Contributed by Zac Hatfield-Dodds in `#511 <https://github.com/pytest-dev/pytest-cov/pull/511>`_.\n* Dropped support for multiprocessing (mostly because `issue 82408 <https://github.com/python/cpython/issues/82408>`_). This feature was\n  mostly working but very broken in certain scenarios and made the test suite very flaky and slow.\n\n  There is builtin multiprocessing support in coverage and you can migrate to that. All you need is this in your\n  ``.coveragerc``::\n\n    [run]\n    concurrency = multiprocessing\n    parallel = true\n    sigterm = true\n* Fixed deprecation in ``setup.py`` by trying to import setuptools before distutils.\n  Contributed by Ben Greiner in `#545 <https://github.com/pytest-dev/pytest-cov/pull/545>`_.\n* Removed undesirable new lines that were displayed while reporting was disabled.\n  Contributed by Delgan in `#540 <https://github.com/pytest-dev/pytest-cov/pull/540>`_.\n* Documentation fixes.\n  Contributed by Andre Brisco in `#543 <https://github.com/pytest-dev/pytest-cov/pull/543>`_\n  and Colin O'Dell in `#525 <https://github.com/pytest-dev/pytest-cov/pull/525>`_.\n* Added support for LCOV output format via `--cov-report=lcov`. Only works with coverage 6.3+.\n  Contributed by Christian Fetzer in `#536 <https://github.com/pytest-dev/pytest-cov/pull/536>`_.\n* Modernized pytest hook implementation.\n  Contributed by Bruno Oliveira in `#549 <https://github.com/pytest-dev/pytest-cov/pull/549>`_\n  and Ronny Pfannschmidt in `#550 <https://github.com/pytest-dev/pytest-cov/pull/550>`_.\n\n\n3.0.0 (2021-10-04)\n-------------------\n\n**Note that this release drops support for Python 2.7 and Python 3.5.**\n\n* Added support for Python 3.10 and updated various test dependencies.\n  Contributed by Hugo van Kemenade in\n  `#500 <https://github.com/pytest-dev/pytest-cov/pull/500>`_.\n* Switched from Travis CI to GitHub Actions. Contributed by Hugo van Kemenade in\n  `#494 <https://github.com/pytest-dev/pytest-cov/pull/494>`_ and\n  `#495 <https://github.com/pytest-dev/pytest-cov/pull/495>`_.\n* Add a ``--cov-reset`` CLI option.\n  Contributed by Danilo Å egan in\n  `#459 <https://github.com/pytest-dev/pytest-cov/pull/459>`_.\n* Improved validation of ``--cov-fail-under`` CLI option.\n  Contributed by ... Ronny Pfannschmidt's desire for skark in\n  `#480 <https://github.com/pytest-dev/pytest-cov/pull/480>`_.\n* Dropped Python 2.7 support.\n  Contributed by Thomas Grainger in\n  `#488 <https://github.com/pytest-dev/pytest-cov/pull/488>`_.\n* Updated trove classifiers. Contributed by MichaÅ‚ Bielawski in\n  `#481 <https://github.com/pytest-dev/pytest-cov/pull/481>`_.\n* Reverted change for `toml` requirement.\n  Contributed by Thomas Grainger in\n  `#477 <https://github.com/pytest-dev/pytest-cov/pull/477>`_.\n\n2.12.1 (2021-06-01)\n-------------------\n\n* Changed the `toml` requirement to be always be directly required (instead of being required through a coverage extra).\n  This fixes issues with pip-compile (`pip-tools#1300 <https://github.com/jazzband/pip-tools/issues/1300>`_).\n  Contributed by Sorin Sbarnea in `#472 <https://github.com/pytest-dev/pytest-cov/pull/472>`_.\n* Documented ``show_contexts``.\n  Contributed by Brian Rutledge in `#473 <https://github.com/pytest-dev/pytest-cov/pull/473>`_.\n\n2.12.0 (2021-05-14)\n-------------------\n\n* Added coverage's `toml` extra to install requirements in setup.py.\n  Contributed by Christian Riedel in `#410 <https://github.com/pytest-dev/pytest-cov/pull/410>`_.\n* Fixed ``pytest_cov.__version__`` to have the right value (string with version instead of a string\n  including ``__version__ =``).\n* Fixed license classifier in ``setup.py``.\n  Contributed by Chris Sreesangkom in `#467 <https://github.com/pytest-dev/pytest-cov/pull/467>`_.\n* Fixed *commits since* badge.\n  Contributed by Terence Honles in `#470 <https://github.com/pytest-dev/pytest-cov/pull/470>`_.\n\n2.11.1 (2021-01-20)\n-------------------\n\n* Fixed support for newer setuptools (v42+).\n  Contributed by MichaÅ‚ GÃ³rny in `#451 <https://github.com/pytest-dev/pytest-cov/pull/451>`_.\n\n2.11.0 (2021-01-18)\n-------------------\n\n* Bumped minimum coverage requirement to 5.2.1. This prevents reporting issues.\n  Contributed by Mateus Berardo de Souza Terra in `#433 <https://github.com/pytest-dev/pytest-cov/pull/433>`_.\n* Improved sample projects (from the `examples <https://github.com/pytest-dev/pytest-cov/tree/master/examples>`_\n  directory) to support running `tox -e pyXY`. Now the example configures a suffixed coverage data file,\n  and that makes the cleanup environment unnecessary.\n  Contributed by Ganden Schaffner in `#435 <https://github.com/pytest-dev/pytest-cov/pull/435>`_.\n* Removed the empty `console_scripts` entrypoint that confused some Gentoo build script.\n  I didn't ask why it was so broken cause I didn't want to ruin my day.\n  Contributed by MichaÅ‚ GÃ³rny in `#434 <https://github.com/pytest-dev/pytest-cov/pull/434>`_.\n* Fixed the missing `coverage context <https://coverage.readthedocs.io/en/latest/contexts.html>`_\n  when using subprocesses.\n  Contributed by BernÃ¡t GÃ¡bor in `#443 <https://github.com/pytest-dev/pytest-cov/pull/443>`_.\n* Updated the config section in the docs.\n  Contributed by Pamela McA'Nulty in `#429 <https://github.com/pytest-dev/pytest-cov/pull/429>`_.\n* Migrated CI to travis-ci.com (from .org).\n\n2.10.1 (2020-08-14)\n-------------------\n\n* Support for ``pytest-xdist`` 2.0, which breaks compatibility with ``pytest-xdist`` before 1.22.3 (from 2017).\n  Contributed by Zac Hatfield-Dodds in `#412 <https://github.com/pytest-dev/pytest-cov/pull/412>`_.\n* Fixed the ``LocalPath has no attribute startswith`` failure that occurred when using the ``pytester`` plugin\n  in inline mode.\n\n2.10.0 (2020-06-12)\n-------------------\n\n* Improved the ``--no-cov`` warning. Now it's only shown if ``--no-cov`` is present before ``--cov``.\n* Removed legacy pytest support. Changed ``setup.py`` so that ``pytest>=4.6`` is required.\n\n2.9.0 (2020-05-22)\n------------------\n\n* Fixed ``RemovedInPytest4Warning`` when using Pytest 3.10.\n  Contributed by Michael Manganiello in `#354 <https://github.com/pytest-dev/pytest-cov/pull/354>`_.\n* Made pytest startup faster when plugin not active by lazy-importing.\n  Contributed by Anders HovmÃ¶ller in `#339 <https://github.com/pytest-dev/pytest-cov/pull/339>`_.\n* Various CI improvements.\n  Contributed by Daniel Hahler in `#363 <https://github.com/pytest-dev/pytest-cov/pull/363>`_ and\n  `#364 <https://github.com/pytest-dev/pytest-cov/pull/364>`_.\n* Various Python support updates (drop EOL 3.4, test against 3.8 final).\n  Contributed by Hugo van Kemenade in\n  `#336 <https://github.com/pytest-dev/pytest-cov/pull/336>`_ and\n  `#367 <https://github.com/pytest-dev/pytest-cov/pull/367>`_.\n* Changed ``--cov-append`` to always enable ``data_suffix`` (a coverage setting).\n  Contributed by Harm Geerts in\n  `#387 <https://github.com/pytest-dev/pytest-cov/pull/387>`_.\n* Changed ``--cov-append`` to handle loading previous data better\n  (fixes various path aliasing issues).\n* Various other testing improvements, github issue templates, example updates.\n* Fixed internal failures that are caused by tests that change the current working directory by\n  ensuring a consistent working directory when coverage is called.\n  See `#306 <https://github.com/pytest-dev/pytest-cov/issues/306>`_ and\n  `coveragepy#881 <https://github.com/nedbat/coveragepy/issues/881>`_\n\n2.8.1 (2019-10-05)\n------------------\n\n* Fixed `#348 <https://github.com/pytest-dev/pytest-cov/issues/348>`_ -\n  regression when only certain reports (html or xml) are used then ``--cov-fail-under`` always fails.\n\n2.8.0 (2019-10-04)\n------------------\n\n* Fixed ``RecursionError`` that can occur when using\n  `cleanup_on_signal <https://pytest-cov.readthedocs.io/en/latest/subprocess-support.html#if-you-got-custom-signal-handling>`__ or\n  `cleanup_on_sigterm <https://pytest-cov.readthedocs.io/en/latest/subprocess-support.html#if-you-got-custom-signal-handling>`__.\n  See: `#294 <https://github.com/pytest-dev/pytest-cov/issues/294>`_.\n  The 2.7.x releases of pytest-cov should be considered broken regarding aforementioned cleanup API.\n* Added compatibility with future xdist release that deprecates some internals\n  (match pytest-xdist master/worker terminology).\n  Contributed by Thomas Grainger in `#321 <https://github.com/pytest-dev/pytest-cov/pull/321>`_\n* Fixed breakage that occurs when multiple reporting options are used.\n  Contributed by Thomas Grainger in `#338 <https://github.com/pytest-dev/pytest-cov/pull/338>`_.\n* Changed internals to use a stub instead of ``os.devnull``.\n  Contributed by Thomas Grainger in `#332 <https://github.com/pytest-dev/pytest-cov/pull/332>`_.\n* Added support for Coverage 5.0.\n  Contributed by Ned Batchelder in `#319 <https://github.com/pytest-dev/pytest-cov/pull/319>`_.\n* Added support for float values in ``--cov-fail-under``.\n  Contributed by MartÃ­n GaitÃ¡n in `#311 <https://github.com/pytest-dev/pytest-cov/pull/311>`_.\n* Various documentation fixes. Contributed by\n  Juanjo BazÃ¡n,\n  Andrew Murray and\n  Albert Tugushev in\n  `#298 <https://github.com/pytest-dev/pytest-cov/pull/298>`_,\n  `#299 <https://github.com/pytest-dev/pytest-cov/pull/299>`_ and\n  `#307 <https://github.com/pytest-dev/pytest-cov/pull/307>`_.\n* Various testing improvements. Contributed by\n  Ned Batchelder,\n  Daniel Hahler,\n  Ionel Cristian MÄƒrieÈ™ and\n  Hugo van Kemenade in\n  `#313 <https://github.com/pytest-dev/pytest-cov/pull/313>`_,\n  `#314 <https://github.com/pytest-dev/pytest-cov/pull/314>`_,\n  `#315 <https://github.com/pytest-dev/pytest-cov/pull/315>`_,\n  `#316 <https://github.com/pytest-dev/pytest-cov/pull/316>`_,\n  `#325 <https://github.com/pytest-dev/pytest-cov/pull/325>`_,\n  `#326 <https://github.com/pytest-dev/pytest-cov/pull/326>`_,\n  `#334 <https://github.com/pytest-dev/pytest-cov/pull/334>`_ and\n  `#335 <https://github.com/pytest-dev/pytest-cov/pull/335>`_.\n* Added the ``--cov-context`` CLI options that enables coverage contexts. Only works with coverage 5.0+.\n  Contributed by Ned Batchelder in `#345 <https://github.com/pytest-dev/pytest-cov/pull/345>`_.\n\n2.7.1 (2019-05-03)\n------------------\n\n* Fixed source distribution manifest so that garbage ain't included in the tarball.\n\n2.7.0 (2019-05-03)\n------------------\n\n* Fixed ``AttributeError: 'NoneType' object has no attribute 'configure_node'`` error when ``--no-cov`` is used.\n  Contributed by Alexander Shadchin in `#263 <https://github.com/pytest-dev/pytest-cov/pull/263>`_.\n* Various testing and CI improvements. Contributed by Daniel Hahler in\n  `#255 <https://github.com/pytest-dev/pytest-cov/pull/255>`_,\n  `#266 <https://github.com/pytest-dev/pytest-cov/pull/266>`_,\n  `#272 <https://github.com/pytest-dev/pytest-cov/pull/272>`_,\n  `#271 <https://github.com/pytest-dev/pytest-cov/pull/271>`_ and\n  `#269 <https://github.com/pytest-dev/pytest-cov/pull/269>`_.\n* Improved ``pytest_cov.embed.cleanup_on_sigterm`` to be reentrant (signal deliveries while signal handling is\n  running won't break stuff).\n* Added ``pytest_cov.embed.cleanup_on_signal`` for customized cleanup.\n* Improved cleanup code and fixed various issues with leftover data files. All contributed in\n  `#265 <https://github.com/pytest-dev/pytest-cov/pull/265>`_ or\n  `#262 <https://github.com/pytest-dev/pytest-cov/pull/262>`_.\n* Improved examples. Now there are two examples for the common project layouts, complete with working coverage\n  configuration. The examples have CI testing. Contributed in\n  `#267 <https://github.com/pytest-dev/pytest-cov/pull/267>`_.\n* Improved help text for CLI options.\n\n2.6.1 (2019-01-07)\n------------------\n\n* Added support for Pytest 4.1. Contributed by Daniel Hahler and Ð¡ÐµÐ¼Ñ‘Ð½ ÐœÐ°Ñ€ÑŒÑÑÐ¸Ð½ in\n  `#253 <https://github.com/pytest-dev/pytest-cov/pull/253>`_ and\n  `#230 <https://github.com/pytest-dev/pytest-cov/pull/230>`_.\n* Various test and docs fixes. Contributed by Daniel Hahler in\n  `#224 <https://github.com/pytest-dev/pytest-cov/pull/224>`_ and\n  `#223 <https://github.com/pytest-dev/pytest-cov/pull/223>`_.\n* Fixed the \"Module already imported\" issue (`#211 <https://github.com/pytest-dev/pytest-cov/issues/211>`_).\n  Contributed by Daniel Hahler in `#228 <https://github.com/pytest-dev/pytest-cov/pull/228>`_.\n\n2.6.0 (2018-09-03)\n------------------\n\n* Dropped support for Python 3 < 3.4, Pytest < 3.5 and Coverage < 4.4.\n* Fixed some documentation formatting. Contributed by Jean Jordaan and Julian.\n* Added an example with ``addopts`` in documentation. Contributed by Samuel Giffard in\n  `#195 <https://github.com/pytest-dev/pytest-cov/pull/195>`_.\n* Fixed ``TypeError: 'NoneType' object is not iterable`` in certain xdist configurations. Contributed by Jeremy Bowman in\n  `#213 <https://github.com/pytest-dev/pytest-cov/pull/213>`_.\n* Added a ``no_cover`` marker and fixture. Fixes\n  `#78 <https://github.com/pytest-dev/pytest-cov/issues/78>`_.\n* Fixed broken ``no_cover`` check when running doctests. Contributed by Terence Honles in\n  `#200 <https://github.com/pytest-dev/pytest-cov/pull/200>`_.\n* Fixed various issues with path normalization in reports (when combining coverage data from parallel mode). Fixes\n  `#130 <https://github.com/pytest-dev/pytest-cov/issues/161>`_.\n  Contributed by Ryan Hiebert & Ionel Cristian MÄƒrieÈ™ in\n  `#178 <https://github.com/pytest-dev/pytest-cov/pull/178>`_.\n* Report generation failures don't raise exceptions anymore. A warning will be logged instead. Fixes\n  `#161 <https://github.com/pytest-dev/pytest-cov/issues/161>`_.\n* Fixed multiprocessing issue on Windows (empty env vars are not passed). Fixes\n  `#165 <https://github.com/pytest-dev/pytest-cov/issues/165>`_.\n\n2.5.1 (2017-05-11)\n------------------\n\n* Fixed xdist breakage (regression in ``2.5.0``).\n  Fixes `#157 <https://github.com/pytest-dev/pytest-cov/issues/157>`_.\n* Allow setting custom ``data_file`` name in ``.coveragerc``.\n  Fixes `#145 <https://github.com/pytest-dev/pytest-cov/issues/145>`_.\n  Contributed by Jannis Leidel & Ionel Cristian MÄƒrieÈ™ in\n  `#156 <https://github.com/pytest-dev/pytest-cov/pull/156>`_.\n\n2.5.0 (2017-05-09)\n------------------\n\n* Always show a summary when ``--cov-fail-under`` is used. Contributed by Francis Niu in `PR#141\n  <https://github.com/pytest-dev/pytest-cov/pull/141>`_.\n* Added ``--cov-branch`` option. Fixes `#85 <https://github.com/pytest-dev/pytest-cov/issues/85>`_.\n* Improve exception handling in subprocess setup. Fixes `#144 <https://github.com/pytest-dev/pytest-cov/issues/144>`_.\n* Fixed handling when ``--cov`` is used multiple times. Fixes `#151 <https://github.com/pytest-dev/pytest-cov/issues/151>`_.\n\n2.4.0 (2016-10-10)\n------------------\n\n* Added a \"disarm\" option: ``--no-cov``. It will disable coverage measurements. Contributed by Zoltan Kozma in\n  `PR#135 <https://github.com/pytest-dev/pytest-cov/pull/135>`_.\n\n  **WARNING: Do not put this in your configuration files, it's meant to be an one-off for situations where you want to\n  disable coverage from command line.**\n* Fixed broken exception handling on ``.pth`` file. See `#136 <https://github.com/pytest-dev/pytest-cov/issues/136>`_.\n\n2.3.1 (2016-08-07)\n------------------\n\n* Fixed regression causing spurious errors when xdist was used. See `#124\n  <https://github.com/pytest-dev/pytest-cov/issues/124>`_.\n* Fixed DeprecationWarning about incorrect `addoption` use. Contributed by Florian Bruhin in `PR#127\n  <https://github.com/pytest-dev/pytest-cov/pull/127>`_.\n* Fixed deprecated use of funcarg fixture API. Contributed by Daniel Hahler in `PR#125\n  <https://github.com/pytest-dev/pytest-cov/pull/125>`_.\n\n2.3.0 (2016-07-05)\n------------------\n\n* Add support for specifying output location for html, xml, and annotate report.\n  Contributed by Patrick Lannigan in `PR#113 <https://github.com/pytest-dev/pytest-cov/pull/113>`_.\n* Fix bug hiding test failure when cov-fail-under failed.\n* For coverage >= 4.0, match the default behaviour of `coverage report` and\n  error if coverage fails to find the source instead of just printing a warning.\n  Contributed by David Szotten in `PR#116 <https://github.com/pytest-dev/pytest-cov/pull/116>`_.\n* Fixed bug occurred when bare ``--cov`` parameter was used with xdist.\n  Contributed by Michael Elovskikh in `PR#120 <https://github.com/pytest-dev/pytest-cov/pull/120>`_.\n* Add support for ``skip_covered`` and added ``--cov-report=term-skip-covered`` command\n  line options. Contributed by Saurabh Kumar in `PR#115 <https://github.com/pytest-dev/pytest-cov/pull/115>`_.\n\n2.2.1 (2016-01-30)\n------------------\n\n* Fixed incorrect merging of coverage data when xdist was used and coverage was ``>= 4.0``.\n\n2.2.0 (2015-10-04)\n------------------\n\n* Added support for changing working directory in tests. Previously changing working\n  directory would disable coverage measurements in suprocesses.\n* Fixed broken handling for ``--cov-report=annotate``.\n\n2.1.0 (2015-08-23)\n------------------\n\n* Added support for `coverage 4.0b2`.\n* Added the ``--cov-append`` command line options. Contributed by Christian Ledermann\n  in `PR#80 <https://github.com/pytest-dev/pytest-cov/pull/80>`_.\n\n2.0.0 (2015-07-28)\n------------------\n\n* Added ``--cov-fail-under``, akin to the new ``fail_under`` option in `coverage-4.0`\n  (automatically activated if there's a ``[report] fail_under = ...`` in ``.coveragerc``).\n* Changed ``--cov-report=term`` to automatically upgrade to ``--cov-report=term-missing``\n  if there's ``[run] show_missing = True`` in ``.coveragerc``.\n* Changed ``--cov`` so it can be used with no path argument (in which case the source\n  settings from ``.coveragerc`` will be used instead).\n* Fixed `.pth` installation to work in all cases (install, easy_install, wheels, develop etc).\n* Fixed `.pth` uninstallation to work for wheel installs.\n* Support for coverage 4.0.\n* Data file suffixing changed to use coverage's ``data_suffix=True`` option (instead of the\n  custom suffixing).\n* Avoid warning about missing coverage data (just like ``coverage.control.process_startup``).\n* Fixed a race condition when running with xdist (all the workers tried to combine the files).\n  It's possible that this issue is not present in `pytest-cov 1.8.X`.\n\n1.8.2 (2014-11-06)\n------------------\n\n* N/A\n",
        "keywords": [
          "cover",
          "coverage",
          "pytest",
          "py.test",
          "distributed",
          "parallel"
        ],
        "home_page": "https://github.com/pytest-dev/pytest-cov",
        "author": "Marc Schlaich",
        "author_email": "marc.schlaich@gmail.com",
        "license": "MIT",
        "license_file": [
          "LICENSE",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: Pytest",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Testing",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "pytest >=4.6",
          "coverage[toml] >=5.2.1",
          "fields ; extra == 'testing'",
          "hunter ; extra == 'testing'",
          "process-tests ; extra == 'testing'",
          "pytest-xdist ; extra == 'testing'",
          "virtualenv ; extra == 'testing'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://pytest-cov.readthedocs.io/",
          "Changelog, https://pytest-cov.readthedocs.io/en/latest/changelog.html",
          "Issue Tracker, https://github.com/pytest-dev/pytest-cov/issues"
        ],
        "provides_extra": [
          "testing"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c2/7c/bd50e62ac330d1c194b3473947ffbe2f99bb0269dbe41824d2534cf3251c/azure_cosmos-4.14.6-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=ea314e85eff9d31db980b7f2e88291579dedc77734bca7e9011d55d371fd0d5f",
          "hashes": {
            "sha256": "ea314e85eff9d31db980b7f2e88291579dedc77734bca7e9011d55d371fd0d5f"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-cosmos",
        "version": "4.14.6",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Cosmos Client Library for Python",
        "description": "# Azure Cosmos DB SQL API client library for Python\n\n## _Disclaimer_\n_Azure SDK Python packages support for Python 2.7 has ended 01 January 2022. For more information and questions, please refer to https://github.com/Azure/azure-sdk-for-python/issues/20691_\n\nAzure Cosmos DB is a globally distributed, multi-model database service that supports document, key-value, wide-column, and graph databases.\n\nUse the Azure Cosmos DB SQL API SDK for Python to manage databases and the JSON documents they contain in this NoSQL database service. High level capabilities are:\n\n* Create Cosmos DB **databases** and modify their settings\n* Create and modify **containers** to store collections of JSON documents\n* Create, read, update, and delete the **items** (JSON documents) in your containers\n* Query the documents in your database using **SQL-like syntax**\n\n[SDK source code][source_code]\n| [Package (PyPI)][cosmos_pypi]\n| [Package (Conda)](https://anaconda.org/microsoft/azure-cosmos/)\n| [API reference documentation][ref_cosmos_sdk]\n| [Product documentation][cosmos_docs]\n| [Samples][cosmos_samples]\n\n> This SDK is used for the [SQL API](https://learn.microsoft.com/azure/cosmos-db/sql-query-getting-started). For all other APIs, please check the [Azure Cosmos DB documentation](https://learn.microsoft.com/azure/cosmos-db/introduction) to evaluate the best SDK for your project.\n\n## Getting started\n\n### Important update on Python 2.x Support\n\nNew releases of this SDK won't support Python 2.x starting January 1st, 2022. Please check the [CHANGELOG](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/cosmos/azure-cosmos/CHANGELOG.md) for more information.\n\n### Prerequisites\n\n* Azure subscription - [Create a free account][azure_sub]\n* Azure [Cosmos DB account][cosmos_account] - SQL API\n* [Python 3.8+][python]\n\nIf you need a Cosmos DB SQL API account, you can create one with this [Azure CLI][azure_cli] command:\n\n```Bash\naz cosmosdb create --resource-group <resource-group-name> --name <cosmos-account-name>\n```\n\n### Install the package\n\n```bash\npip install azure-cosmos\n```\n\n#### Configure a virtual environment (optional)\n\nAlthough not required, you can keep your base system and Azure SDK environments isolated from one another if you use a virtual environment. Execute the following commands to configure and then enter a virtual environment with [venv][venv]:\n\n```Bash\npython3 -m venv azure-cosmosdb-sdk-environment\nsource azure-cosmosdb-sdk-environment/bin/activate\n```\n\n### Authenticate the client\n\nInteraction with Cosmos DB starts with an instance of the [CosmosClient][ref_cosmosclient] class. You need an **account**, its **URI**, and one of its **account keys** to instantiate the client object.\n\nUse the Azure CLI snippet below to populate two environment variables with the database account URI and its primary master key (you can also find these values in the Azure portal). The snippet is formatted for the Bash shell.\n\n```Bash\nRES_GROUP=<resource-group-name>\nACCT_NAME=<cosmos-db-account-name>\n\nexport ACCOUNT_URI=$(az cosmosdb show --resource-group $RES_GROUP --name $ACCT_NAME --query documentEndpoint --output tsv)\nexport ACCOUNT_KEY=$(az cosmosdb list-keys --resource-group $RES_GROUP --name $ACCT_NAME --query primaryMasterKey --output tsv)\n```\n\n### Create the client\n\nOnce you've populated the `ACCOUNT_URI` and `ACCOUNT_KEY` environment variables, you can create the [CosmosClient][ref_cosmosclient].\n\n```python\nfrom azure.cosmos import CosmosClient\n\nimport os\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\n```\n\n### AAD Authentication\n\nYou can also authenticate a client utilizing your service principal's AAD credentials and the azure identity package. \nYou can directly pass in the credentials information to ClientSecretCredential, or use the DefaultAzureCredential:\n```python\nfrom azure.cosmos import CosmosClient\nfrom azure.identity import ClientSecretCredential, DefaultAzureCredential\n\nimport os\nurl = os.environ['ACCOUNT_URI']\ntenant_id = os.environ['TENANT_ID']\nclient_id = os.environ['CLIENT_ID']\nclient_secret = os.environ['CLIENT_SECRET']\n\n# Using ClientSecretCredential\naad_credentials = ClientSecretCredential(\n    tenant_id=tenant_id,\n    client_id=client_id,\n    client_secret=client_secret)\n\n# Using DefaultAzureCredential (recommended)\naad_credentials = DefaultAzureCredential()\n\nclient = CosmosClient(url, aad_credentials)\n```\nAlways ensure that the managed identity you use for AAD authentication has `readMetadata` permissions. <br>\nMore information on how to set up AAD authentication: [Set up RBAC for AAD authentication](https://learn.microsoft.com/azure/cosmos-db/how-to-setup-rbac) <br>\nMore information on allowed operations for AAD authenticated clients: [RBAC Permission Model](https://aka.ms/cosmos-native-rbac)\n\n### Preferred Locations \nTo enable multi-region support in CosmosClient, set the `preferred_locations` parameter. \nBy default, all writes and reads go to the dedicated write region unless specified otherwise.\nThe `preferred_locations` parameter accepts a list of regions for read requests.\nRequests are sent to the first region in the list, and if it fails, they move to the next region.\n\nFor example, to set West US as the read region, and Central US as the backup read region, the code would look like this:\n```python\nfrom azure.cosmos import CosmosClient\n\nimport os\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY, preferred_locations=[\"West US\", \"Central US\"])\n```\nAlso note that if all regions listed in preferred locations fail, read requests are sent to the main write region. \nFor example if the write region is set to East US, then `preferred_locations=[\"West US\", \"Central US\"]`\nis equivalent to `preferred_locations=[\"West US\", \"Central US\", \"East US\"]` since the client will send all requests to the write region if the preferred locations fail.\n\n## Key concepts\n\nOnce you've initialized a [CosmosClient][ref_cosmosclient], you can interact with the primary resource types in Cosmos DB:\n\n* [Database][ref_database]: A Cosmos DB account can contain multiple databases. When you create a database, you specify the API you'd like to use when interacting with its documents: SQL, MongoDB, Gremlin, Cassandra, or Azure Table. Use the [DatabaseProxy][ref_database] object to manage its containers.\n\n* [Container][ref_container]: A container is a collection of JSON documents. You create (insert), read, update, and delete items in a container by using methods on the [ContainerProxy][ref_container] object.\n\n* Item: An Item is the dictionary-like representation of a JSON document stored in a container. Each Item you add to a container must include an `id` key with a value that uniquely identifies the item within the container.\n\nFor more information about these resources, see [Working with Azure Cosmos databases, containers and items][cosmos_resources].\n\n\n## How to use `enable_cross_partition_query`\n\nThe keyword-argument `enable_cross_partition_query` accepts 2 options: `None` (default) or `True`.\n\n## Note on using queries by id\n\nWhen using queries that try to find items based on an **id** value, always make sure you are passing in a string type variable. Azure Cosmos DB only allows string id values and if you use any other datatype, this SDK will return no results and no error messages.\n\n## Note on client consistency levels\n\nAs of release version 4.3.0b3, if a user does not pass in an explicit consistency level to their client initialization,\ntheir client will use their database account's default level. Previously, the default was being set to `Session` consistency.\nIf for some reason you'd like to keep doing this, you can change your client initialization to include the explicit parameter for this like shown:\n```python\nfrom azure.cosmos import CosmosClient\n\nimport os\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY, consistency_level='Session')\n```\n\n## Limitations\n\nCurrently, the features below are **not supported**. For alternatives options, check the **Workarounds** section below.\n\n### Data Plane Limitations:\n\n* Group By queries\n* Queries with COUNT from a DISTINCT subquery: SELECT COUNT (1) FROM (SELECT DISTINCT C.ID FROM C)\n* Direct TCP Mode access\n* Continuation token support for aggregate cross-partition queries like sorting, counting, and distinct.\nStreamable queries like `SELECT * FROM WHERE` *do* support continuation tokens.\n* Change Feed: Processor\n* Change Feed: Read multiple partitions key values\n* Cross-partition ORDER BY for mixed types\n* Enabling diagnostics for async query-type methods\n\n### Control Plane Limitations:\n\n* Get CollectionSizeUsage, DatabaseUsage, and DocumentUsage metrics\n* Get the connection string\n* Get the minimum RU/s of a container\n\n## Workarounds\n\n### Control Plane Limitations Workaround\n\nTypically, you can use [Azure Portal](https://portal.azure.com/), [Azure Cosmos DB Resource Provider REST API](https://learn.microsoft.com/rest/api/cosmos-db-resource-provider), [Azure CLI](https://learn.microsoft.com/cli/azure/azure-cli-reference-for-cosmos-db) or [PowerShell](https://learn.microsoft.com/azure/cosmos-db/manage-with-powershell) for the control plane unsupported limitations.\n\n### Using The Async Client as a Workaround to Bulk\nWhile the SDK supports transactional batch, support for bulk requests is not yet implemented in the Python SDK. You can use the async client along with this [concurrency sample][cosmos_concurrency_sample] we have developed as a reference for a possible workaround. \n>[WARNING]\n> Using the asynchronous client for concurrent operations like shown in this sample will consume a lot of RUs very fast. We **strongly recommend** testing this out against the cosmos emulator first to verify your code works well and avoid incurring charges.\n\n\n\n## Boolean Data Type\n\nWhile the Python language [uses](https://docs.python.org/3/library/stdtypes.html?highlight=boolean#truth-value-testing) \"True\" and \"False\" for boolean types, Cosmos DB [accepts](https://learn.microsoft.com/azure/cosmos-db/sql-query-is-bool) \"true\" and \"false\" only. In other words, the Python language uses Boolean values with the first uppercase letter and all other lowercase letters, while Cosmos DB and its SQL language use only lowercase letters for those same Boolean values. How to deal with this challenge?\n\n* Your JSON documents created with Python must use \"True\" and \"False\", to pass the language validation. The SDK will convert it to \"true\" and \"false\" for you. Meaning that \"true\" and \"false\" is what will be stored in Cosmos DB.\n* If you retrieve those documents with the Cosmos DB Portal's Data Explorer, you will see \"true\" and \"false\".\n* If you retrieve those documents with this Python SDK, \"true\" and \"false\" values will be automatically converted to \"True\" and \"False\".\n\n## SQL Queries x FROM Clause Subitems\n\nThis SDK uses the [query_items](https://learn.microsoft.com/python/api/azure-cosmos/azure.cosmos.containerproxy?preserve-view=true&view=azure-python#query-items-query--parameters-none--partition-key-none--enable-cross-partition-query-none--max-item-count-none--enable-scan-in-query-none--populate-query-metrics-none----kwargs-) method to submit SQL queries to Azure Cosmos DB.\n\nCosmos DB SQL language allows you to [get subitems by using the FROM clause](https://learn.microsoft.com/azure/cosmos-db/sql-query-from#get-subitems-by-using-the-from-clause), to reduce the source to a smaller subset. As an example, you can use `select * from Families.children` instead of `select * from Families`. But please note that:\n\n* For SQL queries using the `query_items` method, this SDK demands that you specify the `partition_key` or use the `enable_cross_partition_query` flag.\n* If you are getting subitems and specifying the `partition_key`, please make sure that your partition key is included in the subitems, which is not true for most of the cases.\n\n## Max Item Count\n\nThis is a parameter of the query_items method, an integer indicating the maximum number of items to be returned per page. The `None` value can be specified to let the service determine the optimal item count. This is the recommended configuration value, and the default behavior of this SDK when it is not set.\n\n## Examples\n\nThe following sections provide several code snippets covering some of the most common Cosmos DB tasks, including:\n\n* [Create a database](#create-a-database \"Create a database\")\n* [Create a container](#create-a-container \"Create a container\")\n* [Create an analytical store enabled container](#create-an-analytical-store-enabled-container \"Create a container\")\n* [Get an existing container](#get-an-existing-container \"Get an existing container\")\n* [Insert data](#insert-data \"Insert data\")\n* [Delete data](#delete-data \"Delete data\")\n* [Query the database](#query-the-database \"Query the database\")\n* [Get database properties](#get-database-properties \"Get database properties\")\n* [Get database and container throughputs](#get-database-and-container-throughputs \"Get database and container throughputs\")\n* [Modify container properties](#modify-container-properties \"Modify container properties\")\n* [Using the asynchronous client](#using-the-asynchronous-client \"Using the asynchronous client\")\n\n### Create a database\n\nAfter authenticating your [CosmosClient][ref_cosmosclient], you can work with any resource in the account. The code snippet below creates a SQL API database, which is the default when no API is specified when [create_database][ref_cosmosclient_create_database] is invoked.\n\n```python\nfrom azure.cosmos import CosmosClient, exceptions\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ntry:\n    database = client.create_database(DATABASE_NAME)\nexcept exceptions.CosmosResourceExistsError:\n    database = client.get_database_client(DATABASE_NAME)\n```\n\n### Create a container\n\nThis example creates a container with default settings. If a container with the same name already exists in the database (generating a `409 Conflict` error), the existing container is obtained instead.\n\n```python\nfrom azure.cosmos import CosmosClient, PartitionKey, exceptions\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\n\ntry:\n    container = database.create_container(id=CONTAINER_NAME, partition_key=PartitionKey(path=\"/productName\"))\nexcept exceptions.CosmosResourceExistsError:\n    container = database.get_container_client(CONTAINER_NAME)\nexcept exceptions.CosmosHttpResponseError:\n    raise\n```\n\n### Create an analytical store enabled container\n\nThis example creates a container with [Analytical Store](https://learn.microsoft.com/azure/cosmos-db/analytical-store-introduction) enabled, for reporting, BI, AI, and Advanced Analytics with [Azure Synapse Link](https://learn.microsoft.com/azure/cosmos-db/synapse-link).\n\nThe options for analytical_storage_ttl are:\n\n+ 0 or Null or not informed: Not enabled.\n+ -1: The data will be stored infinitely.\n+ Any other number: the actual ttl, in seconds.\n\n\n```python\nCONTAINER_NAME = 'products'\ntry:\n    container = database.create_container(id=CONTAINER_NAME, partition_key=PartitionKey(path=\"/productName\"),analytical_storage_ttl=-1)\nexcept exceptions.CosmosResourceExistsError:\n    container = database.get_container_client(CONTAINER_NAME)\nexcept exceptions.CosmosHttpResponseError:\n    raise\n```\n\nThe preceding snippets also handle the [CosmosHttpResponseError][ref_httpfailure] exception if the container creation failed. For more information on error handling and troubleshooting, see the [Troubleshooting](#troubleshooting \"Troubleshooting\") section.\n\n### Get an existing container\n\nRetrieve an existing container from the database:\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n```\n\n### Insert data\n\nTo insert items into a container, pass a dictionary containing your data to [ContainerProxy.upsert_item][ref_container_upsert_item]. Each item you add to a container must include an `id` key with a value that uniquely identifies the item within the container.\n\nThis example inserts several items into the container, each with a unique `id`:\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\nfor i in range(1, 10):\n    container.upsert_item({\n            'id': 'item{0}'.format(i),\n            'productName': 'Widget',\n            'productModel': 'Model {0}'.format(i)\n        }\n    )\n```\n\n### Delete data\n\nTo delete items from a container, use [ContainerProxy.delete_item][ref_container_delete_item]. The SQL API in Cosmos DB does not support the SQL `DELETE` statement.\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\nfor item in container.query_items(\n        query='SELECT * FROM products p WHERE p.productModel = \"Model 2\"',\n        enable_cross_partition_query=True):\n    container.delete_item(item, partition_key='Widget')\n```\n\n> NOTE: If you are using partitioned collection, the value of the `partitionKey` in the example code above, should be set to the value of the partition key for this particular item, not the name of the partition key column in your collection. This holds true for both point reads and deletes.\n\n### Query the database\n\nA Cosmos DB SQL API database supports querying the items in a container with [ContainerProxy.query_items][ref_container_query_items] using SQL-like syntax.\n\nThis example queries a container for items with a specific `id`:\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\n# Enumerate the returned items\nimport json\nfor item in container.query_items(\n        query='SELECT * FROM mycontainer r WHERE r.id=\"item3\"',\n        enable_cross_partition_query=True):\n    print(json.dumps(item, indent=True))\n```\n\n> NOTE: Although you can specify any value for the container name in the `FROM` clause, we recommend you use the container name for consistency.\n\nPerform parameterized queries by passing a dictionary containing the parameters and their values to [ContainerProxy.query_items][ref_container_query_items]:\n\n```python\ndiscontinued_items = container.query_items(\n    query='SELECT * FROM products p WHERE p.productModel = @model',\n    parameters=[\n        dict(name='@model', value='Model 7')\n    ],\n    enable_cross_partition_query=True\n)\nfor item in discontinued_items:\n    print(json.dumps(item, indent=True))\n```\n\nFor more information on querying Cosmos DB databases using the SQL API, see [Query Azure Cosmos DB data with SQL queries][cosmos_sql_queries].\n\n### Get database properties\n\nGet and display the properties of a database:\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\nimport json\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nproperties = database.read()\nprint(json.dumps(properties))\n```\n\n### Get database and container throughputs\n\nGet and display the throughput values of a database and of a container with dedicated throughput:\n\n```python\nfrom azure.cosmos import CosmosClient\nimport os\nimport json\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\n\n# Database\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\ndb_offer = database.get_throughput()\nprint('Found Offer \\'{0}\\' for Database \\'{1}\\' and its throughput is \\'{2}\\''.format(db_offer.properties['id'], database.id, db_offer.properties['content']['offerThroughput']))\n\n# Container with dedicated throughput only. Will return error \"offer not found\" for containers without dedicated throughput\nCONTAINER_NAME = 'testContainer'\ncontainer = database.get_container_client(CONTAINER_NAME)\ncontainer_offer = container.get_throughput()\nprint('Found Offer \\'{0}\\' for Container \\'{1}\\' and its throughput is \\'{2}\\''.format(container_offer.properties['id'], container.id, container_offer.properties['content']['offerThroughput']))\n```\n\n\n### Modify container properties\n\nCertain properties of an existing container can be modified. This example sets the default time to live (TTL) for items in the container to 10 seconds:\n\n```python\nfrom azure.cosmos import CosmosClient, PartitionKey\nimport os\nimport json\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\ndatabase.replace_container(\n    container,\n    partition_key=PartitionKey(path=\"/productName\"),\n    default_ttl=10,\n)\n# Display the new TTL setting for the container\ncontainer_props = container.read()\nprint(json.dumps(container_props['defaultTtl']))\n```\n\nFor more information on TTL, see [Time to Live for Azure Cosmos DB data][cosmos_ttl].\n\n### Using item point operation response headers\n\nResponse headers include metadata information from the executed operations like `etag`, which allows for optimistic concurrency scenarios, or `x-ms-request-charge` which lets you know how many RUs were consumed by the request.\nThis applies to all item point operations in both the sync and async clients - and can be used by referencing the `get_response_headers()` method of any response as such:\n```python\nfrom azure.cosmos import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nDATABASE_NAME = 'testDatabase'\nCONTAINER_NAME = 'products'\nclient = CosmosClient(URL, credential=KEY)\ndatabase = client.get_database_client(DATABASE_NAME)\ncontainer = database.get_container_client(CONTAINER_NAME)\n\noperation_response = container.create_item({\"id\": \"test_item\", \"productName\": \"test_item\"})\noperation_headers = operation_response.get_response_headers()\netag_value = operation_headers['etag']\nrequest_charge = operation_headers['x-ms-request-charge']\n```\n\n### Using the asynchronous client\n\nThe asynchronous cosmos client is a separate client that looks and works in a similar fashion to the existing synchronous client. However, the async client needs to be imported separately and its methods need to be used with the async/await keywords.\nThe Async client needs to be initialized and closed after usage, which can be done manually or with the use of a context manager. The example below shows how to do so manually. We don't recommend doing it this way, since it requires that you manually call __aenter__() before using the client.\n\n```python\nfrom azure.cosmos.aio import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nDATABASE_NAME = 'testDatabase'\nCONTAINER_NAME = 'products'    \n\nasync def create_products():\n    client = CosmosClient(URL, credential=KEY)\n    await client.__aenter__() # this piece is important for the SDK to cache account information\n    database = client.get_database_client(DATABASE_NAME)\n    container = database.get_container_client(CONTAINER_NAME)\n    for i in range(10):\n        await container.upsert_item({\n                'id': 'item{0}'.format(i),\n                'productName': 'Widget',\n                'productModel': 'Model {0}'.format(i)\n            }\n        )\n    await client.close() # the async client must be closed manually if it's not initialized in a with statement\n```\n\nInstead of manually opening and closing the client, it is highly recommended to use the `async with` keywords. This creates a context manager that will initialize and later close the client once you're out of the statement, as well as cache important information the SDK needs. The example below shows how to do so.\n\n```python\nfrom azure.cosmos.aio import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nDATABASE_NAME = 'testDatabase'\nCONTAINER_NAME = 'products'\n\nasync def create_products():\n    async with CosmosClient(URL, credential=KEY) as client: # the with statement will automatically initialize and close the async client\n        database = client.get_database_client(DATABASE_NAME)\n        container = database.get_container_client(CONTAINER_NAME)\n        for i in range(10):\n            await container.upsert_item({\n                    'id': 'item{0}'.format(i),\n                    'productName': 'Widget',\n                    'productModel': 'Model {0}'.format(i)\n                }\n            )\n```\n\n### Queries with the asynchronous client\n\nUnlike the synchronous client, the async client does not have an `enable_cross_partition` flag in the request. Queries without a specified partition key value will attempt to do a cross partition query by default. \n\nQuery results can be iterated, but the query's raw output returns an asynchronous iterator. This means that each object from the iterator is an awaitable object, and does not yet contain the true query result. In order to obtain the query results you can use an async for loop, which awaits each result as you iterate on the object, or manually await each query result as you iterate over the asynchronous iterator.\n\nSince the query results are an asynchronous iterator, they can't be cast into lists directly; instead, if you need to create lists from your results, use an async for loop or Python's list comprehension to populate a list:\n\n```python\nfrom azure.cosmos.aio import CosmosClient\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'products'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\nasync def create_lists():\n    results = container.query_items(\n            query='SELECT * FROM products p WHERE p.productModel = \"Model 2\"')\n\n    # iterates on \"results\" iterator to asynchronously create a complete list of the actual query results\n\n    item_list = []\n    async for item in results:\n        item_list.append(item)\n\n    # Asynchronously creates a complete list of the actual query results. This code performs the same action as the for-loop example above.\n    item_list = [item async for item in results]\n    await client.close()\n```\n\n### Using Integrated Cache\nAn integrated cache is an in-memory cache that helps you ensure manageable costs and low latency as your request volume grows. The integrated cache has two parts: an item cache for point reads and a query cache for queries. The code snippet below shows you how to use this feature with the point read and query cache methods.\n\nThe benefit of using this is that the point reads and queries that hit the integrated cache won't use any RUs. This means you will have a much lower per-operation cost than reads from the backend.\n\n[How to configure the Azure Cosmos DB integrated cache (Preview)][cosmos_configure_integrated_cache]\n\n```python\nimport azure.cosmos.cosmos_client as cosmos_client\nimport os\n\nURL = os.environ['ACCOUNT_URI']\nKEY = os.environ['ACCOUNT_KEY']\nclient = cosmos_client.CosmosClient(URL, credential=KEY)\nDATABASE_NAME = 'testDatabase'\ndatabase = client.get_database_client(DATABASE_NAME)\nCONTAINER_NAME = 'testContainer'\ncontainer = database.get_container_client(CONTAINER_NAME)\n\ndef integrated_cache_snippet():\n    item_id = body['id'] \n    query = 'SELECT * FROM c'\n\n    #item cache\n    container.read_item(item=item_id, partition_key=item_id, max_integrated_cache_staleness_in_ms=30000)\n\n    #query cache   \n    container.query_items(query=query,\n         partition_key=item_id, max_integrated_cache_staleness_in_ms=30000)\n```\nFor more information on Integrated Cache, see [Azure Cosmos DB integrated cache - Overview][cosmos_integrated_cache].\n\n### Using Transactional Batch\nTransactional batch requests allow you to send several operations to be executed at once within the same partition key.\nIf all operations succeed in the order they're described within the transactional batch operation, the transaction will be committed.\nHowever, if any operation fails, the entire transaction is rolled back.\n\nTransactional batches have a limit of 100 operations per batch, and a total size limit of 1.2Mb for the\nbatch operations being passed in.\n\nTransactional Batch operations look very similar to the singular operations apis, and are tuples containing\n(`operation_type_string`, `args_tuple`, `batch_operation_kwargs_dictionary`), with the kwargs dictionary being optional:\n```python\nbatch_operations = [\n        (\"create\", (item_body,), kwargs),\n        (\"replace\", (item_id, item_body), kwargs),\n        (\"read\", (item_id,), kwargs),\n        (\"upsert\", (item_body,), kwargs),\n        (\"patch\", (item_id, operations), kwargs),\n        (\"delete\", (item_id,), kwargs),\n    ]\nbatch_results = container.execute_item_batch(batch_operations=batch_operations, partition_key=partition_key)\n```\nThe batch operation kwargs dictionary is limited, and only takes a total of three different key values.\nIn the case of wanting to use conditional patching within the batch, the use of `filter_predicate` key is available for the\npatch operation, or in case of wanting to use etags with any of the operations, the use of the `if_match_etag`/`if_none_match_etag`\nkeys is available as well.\n```python\nbatch_operations = [\n        (\"replace\", (item_id, item_body), {\"if_match_etag\": etag}),\n        (\"patch\", (item_id, operations), {\"filter_predicate\": filter_predicate, \"if_none_match_etag\": etag}),\n    ]\n```\n\nWe also have some samples showing these transactional batch operations in action with both the [sync][sample_document_mgmt]\nand [async][sample_document_mgmt_async] clients.\n\nIf there is a failure for an operation within the batch, the SDK will raise a `CosmosBatchOperationError` letting you know which operation failed,\nas well as containing the list of failed responses for the failed request.\n\nFor more information on Transactional Batch, see [Azure Cosmos DB Transactional Batch][cosmos_transactional_batch].\n\n### Native Retryable Writes\nWe have added native retryable writes to the SDK, a feature that can be used by customers who don't mind the\nnon-idempotency of these retries and would instead like to ensure that the given operation executed in case of timeouts\nor connectivity issues (status codes 408, 5xx).\n\nThis feature can be enabled either at the client level, to retry all write operations under these conditions, \nor at the per-request level to enable the retries for an individual request.\n\nIf enabled at the client level, the one exception to the rule would be patch requests, since the operations can change\nthe nature of the overall request - replace, set, and copy for example would be idempotent while add, move or remove would\nnot be idempotent unless combined with patch precondition checks. So, for patch we allow opting-in into automatic\nretries only on the request options level.\n\nThe snippet below shows how to enable this feature at the client and request level:\n```python\ncosmos_client = CosmosClient(\n    url=URL,\n    credential=KEY,\n    retry_write=1,  # enables a single native retryable write at the client level\n)\n\ndatabase = cosmos_client.get_database_client(DATABASE_NAME)\ncontainer = database.get_container_client(CONTAINER_NAME)\n\ncontainer.create_item(\n    item_body,\n    retry_write=1  # enables a single native retryable write at the request level\n)\n```\n\n\n### Vector Embeddings and Vector Indexes\nWe have added new capabilities to utilize vector embeddings and vector indexing for users to leverage vector\nsearch utilizing our Cosmos SDK. These two container-level configurations have to be turned on at the account-level\nbefore you can use them.\n\nEach vector embedding should have a path to the relevant vector field in your items being stored, a supported data type\n(float32, int8, uint8), the vector's dimensions, and the distance function being used for that embedding. Vectors indexed \nwith the flat index type can be at most 505 dimensions. Vectors indexed with the quantizedFlat index type can be at most 4,096 dimensions.\nA sample vector embedding policy would look like this:\n```python\nvector_embedding_policy = {\n    \"vectorEmbeddings\": [\n        {\n            \"path\": \"/vector1\",\n            \"dataType\": \"float32\",\n            \"dimensions\": 256,\n            \"distanceFunction\": \"euclidean\"\n        },\n        {\n            \"path\": \"/vector2\",\n            \"dataType\": \"int8\",\n            \"dimensions\": 200,\n            \"distanceFunction\": \"dotproduct\"\n        },\n        {\n            \"path\": \"/vector3\",\n            \"dataType\": \"uint8\",\n            \"dimensions\": 400,\n            \"distanceFunction\": \"cosine\"\n        }\n    ]\n}\n```\n\nSeparately, vector indexes have been added to the already existing indexing_policy and only require two fields per index:\nthe path to the relevant field to be used, and the type of index from the possible options - flat, quantizedFlat, or diskANN.\nA sample indexing policy with vector indexes would look like this:\n```python\nindexing_policy = {\n        \"automatic\": True,\n        \"indexingMode\": \"consistent\",\n        \"compositeIndexes\": [\n            [\n                {\"path\": \"/numberField\", \"order\": \"ascending\"},\n                {\"path\": \"/stringField\", \"order\": \"descending\"}\n            ]\n        ],\n        \"spatialIndexes\": [\n            {\"path\": \"/location/*\", \"types\": [\n                \"Point\",\n                \"Polygon\"]}\n        ],\n        \"vectorIndexes\": [\n            {\"path\": \"/vector1\", \"type\": \"flat\"},\n            {\"path\": \"/vector2\", \"type\": \"quantizedFlat\"},\n            {\"path\": \"/vector3\", \"type\": \"diskANN\"}\n        ]\n    }\n```\n\nFor vector index types of diskANN and quantizedFlat, there are additional options available as well. These are:\n\nquantizationByteSize - the number of bytes used in product quantization of the vectors. A larger value may result in better recall for vector searches at the expense of latency. This applies to index types diskANN and quantizedFlat. The allowed range is between 1 and the minimum between 512 and the vector dimensions. The default value is 64.\n\nindexingSearchListSize - which represents the size of the candidate list of approximate neighbors stored while building the diskANN index as part of the optimization processes. This applies only to index type diskANN. The allowed range is between 25 and 500.\n\nvectorIndexShardKey - a list of strings containing the shard keys used for partitioning vector indexes. The maximum allowed size for this array is 1, meaning that there is only one allowed path. This applies to index types diskANN and quantizedFlat.\n```python\nindexing_policy = {\n        \"automatic\": True,\n        \"indexingMode\": \"consistent\",\n        \"vectorIndexes\": [\n            {\"path\": \"/vector1\", \"type\": \"quantizedFlat\", \"quantizationByteSize\": 8},\n            {\"path\": \"/vector2\", \"type\": \"diskANN\", \"indexingSearchListSize\": 50},\n            {\"path\": \"/vector3\", \"type\": \"diskANN\", \"vectorIndexShardKey\": [\"/country/city\"]}\n        ]\n    }\n```\n\nYou would then pass in the relevant policies to your container creation method to ensure these configurations are used by it.\nThe operation will fail if you pass new vector indexes to your indexing policy but forget to pass in an embedding policy.\n```python\ndatabase.create_container(id=container_id, partition_key=PartitionKey(path=\"/id\"),\n                          indexing_policy=indexing_policy, vector_embedding_policy=vector_embedding_policy)\n```\n***Note: vector embeddings and vector indexes CANNOT be edited by container replace operations. They are only available directly through creation.***\n\n### Vector Search\n\nWith the addition of the vector indexing and vector embedding capabilities, the SDK can now perform order by vector search queries.\nThese queries specify the VectorDistance to use as a metric within the query text. These must always use a TOP or LIMIT clause within the query though,\nsince vector search queries have to look through a lot of data otherwise and may become too expensive or long-running.\nSince these queries are relatively expensive, the SDK sets a default limit of 50000 max items per query - if you'd like to raise that further, you\ncan use the `AZURE_COSMOS_MAX_ITEM_BUFFER_VECTOR_SEARCH` environment variable to do so. However, be advised that queries with too many vector results\nmay have additional latencies associated with searching in the service.\nThe query syntax for these operations looks like this:\n```python\nVectorDistance(<embedding1>, <embedding2>, [,<exact_search>], [,<specification>])\n```\nEmbeddings 1 and 2 are the arrays of values for the relevant embeddings, `exact_search` is an optional boolean indicating whether\nto do an exact search vs. an approximate one (default value of false), and `specification` is an optional Json snippet with embedding\nspecs that can include `dataType`, `dimensions` and `distanceFunction`. The specifications within the query will take precedence\nto any configurations previously set by a vector embedding policy.\nA sample vector search query would look something like this:\n```python\n    query = \"SELECT TOP 10 c.title,VectorDistance(c.embedding, [{}]) AS \" \\\n            \"SimilarityScore FROM c ORDER BY VectorDistance(c.embedding, [{}])\".format(embeddings_string, embeddings_string)\n```\nOr if you'd like to add the optional parameters to the vector distance, you could do this:\n```python\n    query = \"SELECT TOP 10 c.title,VectorDistance(c.embedding, [{}], true, {{'dataType': 'float32' , 'distanceFunction': 'cosine'}}) AS \" \\\n            \"SimilarityScore FROM c ORDER BY VectorDistance(c.embedding, [{}], true, {{'dataType': \" \\\n            \"'float32', 'distanceFunction': 'cosine'}})\".format(embeddings_string, embeddings_string)\n```\nThe `embeddings_string` above would be your string made from your vector embeddings.\nYou can find our sync samples [here][cosmos_index_sample] and our async samples [here][cosmos_index_sample_async] as well to help yourself out.\n\n*Note: For a limited time, if your query operates against a region or emulator that has not yet been updated the client might run into some issues\nnot being able to recognize the new NonStreamingOrderBy capability that makes vector search possible.\nIf this happens, you can set the `AZURE_COSMOS_DISABLE_NON_STREAMING_ORDER_BY` environment variable to `\"True\"` to opt out of this\nfunctionality and continue operating as usual.*\n\n### Public Preview - Full Text Policy and Full Text Indexes\nWe have added new capabilities to utilize full text policies and full text indexing for users to leverage full text search\nutilizing our Cosmos SDK. These two container-level configurations have to be turned on at the account-level\nbefore you can use them.\n\nA full text policy allows the user to define the default language to be used for all full text paths, or to set\na language for each path individually in case the user would like to use full text search on data containing different\nlanguages in different fields.\n\nA sample full text policy would look like this:\n```python\nfull_text_policy = {\n    \"defaultLanguage\": \"en-US\",\n    \"fullTextPaths\": [\n        {\n            \"path\": \"/text1\",\n            \"language\": \"en-US\"\n        },\n        {\n            \"path\": \"/text2\",\n            \"language\": \"en-US\"\n        }\n    ]\n}\n```\nCurrently, the only supported language is `en-US` - using the relevant ISO-639 language code to ISO-3166 country code.\nAny non-supported language or code will return an exception when trying to use it - which will also include the list of supported languages.\nThis list will include more options in the future; for more information on supported languages, please see [here][cosmos_fts].\n\nFull text search indexes have been added to the already existing indexing_policy and only require the path to the\nrelevant field to be used.\nA sample indexing policy with full text search indexes would look like this:\n```python\nindexing_policy = {\n        \"automatic\": True,\n        \"indexingMode\": \"consistent\",\n        \"compositeIndexes\": [\n            [\n                {\"path\": \"/numberField\", \"order\": \"ascending\"},\n                {\"path\": \"/stringField\", \"order\": \"descending\"}\n            ]\n        ],\n        \"fullTextIndexes\": [\n            {\"path\": \"/abstract\"}\n        ]\n    }\n```\nModifying the index in a container is an asynchronous operation that can take a long time to finish. See [here][cosmos_index_policy_change] for more information.\nFor more information on using full text policies and full text indexes, see [here][cosmos_fts].\n\n### Public Preview - Full Text Search and Hybrid Search\n\nWith the addition of the full text indexing and full text policies, the SDK can now perform full text search and hybrid search queries.\nThese queries can utilize the new query functions `FullTextContains()`, `FullTextContainsAll`, and `FullTextContainsAny` to efficiently\nsearch for the given terms within your item fields.\n\nBeyond these, you can also utilize the new `Order By RANK` and `Order By RANK RRF` along with `FullTextScore` to execute the [BM25][BM25] scoring algorithm\nor [Reciprocal Rank Fusion][RRF] (RRF) on your query, finding the items with the highest relevance to the terms you are looking for.\nAll of these mentioned queries would look something like this:\n\n- `SELECT TOP 10 c.id, c.text FROM c WHERE FullTextContains(c.text, 'quantum')`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c WHERE FullTextContainsAll(c.text, 'quantum', 'theory')`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c WHERE FullTextContainsAny(c.text, 'quantum', 'theory')`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c ORDER BY RANK FullTextScore(c.text, ['quantum', 'theory'])`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c ORDER BY RANK RRF(FullTextScore(c.text, ['quantum', 'theory']), FullTextScore(c.text, ['model']))`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c ORDER BY RANK RRF(FullTextScore(c.text, ['quantum', 'theory']), FullTextScore(c.text, ['model']), VectorDistance(c.embedding, {item_embedding}))\"`\n\nYou can also use Weighted Reciprocal Rank Fusion to assign different weights to the different scores being used in the RRF function.\nThis is done by passing in a list of weights to the RRF function in the query. **NOTE: If more weights are given than there are components of the RRF function, or if weights are missing a BAD REQUEST exception will occur.**\n- `SELECT TOP 10 c.id, c.text FROM c ORDER BY RANK RRF(FullTextScore(c.text, ['quantum', 'theory']), FullTextScore(c.text, ['model']), VectorDistance(c.embedding, {item_embedding}), [0.5, 0.3, 0.2])`\n\n\n- `SELECT TOP 10 c.id, c.text FROM c ORDER BY RANK RRF(FullTextScore(c.text, ['quantum', 'theory']), FullTextScore(c.text, ['model']), VectorDistance(c.embedding, {item_embedding}), [-0.5, 0.3, 0.2])`\n\nThese queries must always use a TOP or LIMIT clause within the query since hybrid search queries have to look through a lot of data otherwise and may become too expensive or long-running.\nSince these queries are relatively expensive, the SDK sets a default limit of 1000 max items per query - if you'd like to raise that further, you\ncan use the `AZURE_COSMOS_HYBRID_SEARCH_MAX_ITEMS` environment variable to do so. However, be advised that queries with too many vector results\nmay have additional latencies associated with searching in the service.\n\nYou can find our sync samples [here][cosmos_index_sample] and our async samples [here][cosmos_index_sample_async] as well for additional guidance.\n\n### Public Preview - Throughput Buckets\nWhen multiple workloads share the same Azure Cosmos DB container, resource contention can lead to throttling, increased latency, and potential business impact.\nTo address this, Cosmos DB allows you to allocate throughput buckets, which help manage resource consumption for workloads sharing a Cosmos DB container by limiting the maximum throughput a bucket can consume.\nHowever, throughput isn't reserved for any bucket, it remains shared across all workloads.\n\nUp to five (5) throughput buckets can be configured per container, with an ID ranging from 1-5. Each bucket has a maximum throughput percentage, capping the fraction of the containerâ€™s total throughput that it can consume.\nRequests assigned to a bucket can consume throughput only up to this limit. If the bucket exceeds its configured limit, subsequent requests are throttled. \nThis ensures that no single workload consumes excessive throughput and impacts others.\n\nThroughput bucket configurations can be changed once every 10 minutes, otherwise the request is throttled with an HTTP 429 status code and substatus code 3213.\nAlso, requests with an invalid bucket ID (less than 1 or greater than 5) results in an error, as only bucket IDs 1 to 5 are valid.\n\nSee [here][cosmos_throughput_bucket_configuration] for instructions on configuring throughput buckets through the Azure portal.\nAfter throughput buckets have been configured, you can find our sync samples [here][cosmos_throughput_bucket_sample] and our async samples [here][cosmos_throughput_bucket_sample_async] as well for additional guidance.\n\n### Per Partition Circuit Breaker \nPer partition circuit breaker is a feature that allows the SDK to failover requests on a partition level to another region based on client side statistics on 408 and 5xx error codes. This feature is only applicable for \nreads in single write region accounts and reads and writes for multi-write region accounts. The following are the environment variables to enable per partition circuit breaker and to modify the thresholds for failing over \nrequests to another region:\n- `AZURE_COSMOS_ENABLE_CIRCUIT_BREAKER`: Default is `False`.\n  - Enables the per partition circuit breaker feature.\n- `AZURE_COSMOS_CONSECUTIVE_ERROR_COUNT_TOLERATED_FOR_READ`: Default is `10` consecutive errors.\n  - After a partition has encountered 10 consecutive errors for read requests, the SDK will send requests routed to that partition to another region.\n- `AZURE_COSMOS_CONSECUTIVE_ERROR_COUNT_TOLERATED_FOR_WRITE`: Default is `5` consecutive errors.\n    - After a partition has encountered 5 consecutive errors for write requests, the SDK will send requests routed to that partition to another region.\n- `AZURE_COSMOS_FAILURE_PERCENTAGE_TOLERATED`: Default is a `90` percent failure rate.\n  - After a partition reaches a 90 percent failure rate for all requests, the SDK will send requests routed to that partition to another region.\n\n## Troubleshooting\n\n### General\n\nWhen you interact with Cosmos DB using the Python SDK, exceptions returned by the service correspond to the same HTTP status codes returned for REST API requests:\n\n[HTTP Status Codes for Azure Cosmos DB][cosmos_http_status_codes]\n\nFor example, if you try to create a container using an ID (name) that's already in use in your Cosmos DB database, a `409` error is returned, indicating the conflict. In the following snippet, the error is handled gracefully by catching the exception and displaying additional information about the error.\n\n```python\ntry:\n    database.create_container(id=CONTAINER_NAME, partition_key=PartitionKey(path=\"/productName\"))\nexcept exceptions.CosmosResourceExistsError:\n    print(\"\"\"Error creating container\nHTTP status code 409: The ID (name) provided for the container is already in use.\nThe container name must be unique within the database.\"\"\")\n\n```\n### Logging Diagnostics\n\nThis library uses the standard\n[logging](https://docs.python.org/3.5/library/logging.html) library for logging diagnostics.\nBasic information about HTTP sessions (URLs, headers, etc.) is logged at INFO\nlevel.\n**Note: You must use 'azure.cosmos' for the logger**\nDetailed DEBUG level logging, including request/response bodies and unredacted\nheaders, can be enabled on a client with the `logging_enable` argument:\n```python\nimport sys\nimport logging\nfrom azure.cosmos import CosmosClient\n\n# Create a logger for the 'azure' SDK\nlogger = logging.getLogger('azure.cosmos')\nlogger.setLevel(logging.DEBUG)\n\n# Configure a console output\nhandler = logging.StreamHandler(stream=sys.stdout)\nlogger.addHandler(handler)\n\n# This client will log detailed information about its HTTP sessions, at DEBUG level\nclient = CosmosClient(URL, credential=KEY, logging_enable=True)\n```\n\nSimilarly, `logging_enable` can enable detailed logging for a single operation,\neven when it isn't enabled for the client:\n```python\ndatabase = client.create_database(DATABASE_NAME, logging_enable=True)\n```\nAlternatively, you can log using the CosmosHttpLoggingPolicy, which extends from the azure core HttpLoggingPolicy, by passing in your logger to the `logger` argument.\nBy default, it will use the behaviour from HttpLoggingPolicy. Passing in the `enable_diagnostics_logging` argument will enable the\nCosmosHttpLoggingPolicy, and will have additional information in the response relevant to debugging Cosmos issues.\n```python\nimport logging\nfrom azure.cosmos import CosmosClient\n\n#Create a logger for the 'azure' SDK\nlogger = logging.getLogger('azure.cosmos')\nlogger.setLevel(logging.DEBUG)\n\n# Configure a file output\nhandler = logging.FileHandler(filename=\"azure\")\nlogger.addHandler(handler)\n\n# This client will log diagnostic information from the HTTP session by using the CosmosHttpLoggingPolicy.\n# Since we passed in the logger to the client, it will log information on every request.\nclient = CosmosClient(URL, credential=KEY, logger=logger, enable_diagnostics_logging=True)\n```\nSimilarly, logging can be enabled for a single operation by passing in a logger to the singular request.\nHowever, if you desire to use the CosmosHttpLoggingPolicy to obtain additional information, the `enable_diagnostics_logging` argument needs to be passed in at the client constructor.\n```python\n# This example enables the CosmosHttpLoggingPolicy and uses it with the `logger` passed in to the `create_database` request.\nclient = CosmosClient(URL, credential=KEY, enable_diagnostics_logging=True)\ndatabase = client.create_database(DATABASE_NAME, logger=logger)\n```\n**NOTICE: The Following is a Preview Feature.**\nTo further customize what gets logged, you can use logger filters to filter out the logs you don't want to see. You are able to filter based on the following attributes in the log record of cosmos diagnostics logs:\n- `status_code`\n- `sub_status_code`\n- `duration`\n- `verb`\n- `database_name`\n- `collection_name`\n- `operation_type`\n- `url`\n- `resource_type`\n- `is_request`\n\nYou can take a look at the samples [here][cosmos_diagnostics_filter_sample] or take a quick look at this snippet:\n- Using **filters** from the **logging** library, it is possible to filter the diagnostics logs. Several filterable attributes are made available to the log record of the diagnostics logs when using logging filters.\n```python\n  import logging\n  from azure.cosmos import CosmosClient\n  logger = logging.getLogger('azure.cosmos')\n  logger.setLevel(logging.INFO)\n  file_handler = logging.FileHandler('diagnostics.output')\n  logger.addHandler(file_handler)\n  # Create a filter to filter out logs\n  class CustomFilter(logging.Filter):\n    def filter(self, record):\n        ret = (hasattr(record, 'status_code') and record.status_code > 400\n           and not (record.status_code in [404, 409, 412] and getattr(record, 'sub_status_code', None) in [0, None])\n           and hasattr(record, 'duration') and record.duration > 1000)\n        return ret\n  # Add the filter to the logger\n  logger.addFilter(CustomFilter())\n  client = CosmosClient(endpoint, key,logger=logger, enable_diagnostics_logging=True)\n```\n### Telemetry\nAzure Core provides the ability for our Python SDKs to use OpenTelemetry with them. The only packages that need to be installed\nto use this functionality are the following:\n```bash\npip install azure-core-tracing-opentelemetry\npip install opentelemetry-sdk\n```\nFor more information on this, we recommend taking a look at this [document](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core-tracing-opentelemetry/README.md) \nfrom Azure Core describing how to set it up. We have also added a [sample file][telemetry_sample] to show how it can\nbe used with our SDK. This works the same way regardless of the Cosmos client you are using.\n\n## Next steps\n\nFor more extensive documentation on the Cosmos DB service, see the [Azure Cosmos DB documentation][cosmos_docs] on learn.microsoft.com.\n\n<!-- LINKS -->\n[azure_cli]: https://learn.microsoft.com/cli/azure\n[azure_portal]: https://portal.azure.com\n[azure_sub]: https://azure.microsoft.com/free/\n[cloud_shell]: https://learn.microsoft.com/azure/cloud-shell/overview\n[cosmos_account_create]: https://learn.microsoft.com/azure/cosmos-db/how-to-manage-database-account\n[cosmos_account]: https://learn.microsoft.com/azure/cosmos-db/account-overview\n[cosmos_container]: https://learn.microsoft.com/azure/cosmos-db/databases-containers-items#azure-cosmos-containers\n[cosmos_database]: https://learn.microsoft.com/azure/cosmos-db/databases-containers-items#azure-cosmos-databases\n[cosmos_docs]: https://learn.microsoft.com/azure/cosmos-db/\n[cosmos_samples]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples\n[cosmos_pypi]: https://pypi.org/project/azure-cosmos/\n[cosmos_http_status_codes]: https://learn.microsoft.com/rest/api/cosmos-db/http-status-codes-for-cosmosdb\n[cosmos_item]: https://learn.microsoft.com/azure/cosmos-db/databases-containers-items#azure-cosmos-items\n[cosmos_models]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/azure/cosmos/_models.py\n[cosmos_request_units]: https://learn.microsoft.com/azure/cosmos-db/request-units\n[cosmos_resources]: https://learn.microsoft.com/azure/cosmos-db/databases-containers-items\n[cosmos_sql_queries]: https://learn.microsoft.com/azure/cosmos-db/how-to-sql-query\n[cosmos_ttl]: https://learn.microsoft.com/azure/cosmos-db/time-to-live\n[cosmos_integrated_cache]: https://learn.microsoft.com/azure/cosmos-db/integrated-cache\n[cosmos_configure_integrated_cache]: https://learn.microsoft.com/azure/cosmos-db/how-to-configure-integrated-cache\n[python]: https://www.python.org/downloads/\n[ref_container_delete_item]: https://aka.ms/azsdk-python-cosmos-ref-delete-item\n[ref_container_query_items]: https://aka.ms/azsdk-python-cosmos-ref-query-items\n[ref_container_upsert_item]: https://aka.ms/azsdk-python-cosmos-ref-upsert-item\n[ref_container]: https://aka.ms/azsdk-python-cosmos-ref-container\n[ref_cosmos_sdk]: https://aka.ms/azsdk-python-cosmos-ref\n[ref_cosmosclient_create_database]: https://aka.ms/azsdk-python-cosmos-ref-create-database\n[ref_cosmosclient]: https://aka.ms/azsdk-python-cosmos-ref-cosmos-client\n[ref_database]: https://aka.ms/azsdk-python-cosmos-ref-database\n[ref_httpfailure]: https://aka.ms/azsdk-python-cosmos-ref-http-failure\n[sample_database_mgmt]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/database_management.py\n[sample_document_mgmt]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/document_management.py\n[sample_document_mgmt_async]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/document_management_async.py\n[sample_examples_misc]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/examples.py\n[source_code]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos\n[venv]: https://docs.python.org/3/library/venv.html\n[virtualenv]: https://virtualenv.pypa.io\n[telemetry_sample]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/tracing_open_telemetry.py\n[timeouts_document]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/docs/TimeoutAndRetriesConfig.md\n[cosmos_transactional_batch]: https://learn.microsoft.com/azure/cosmos-db/transactional-batch\n[cosmos_concurrency_sample]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/concurrency_sample.py\n[cosmos_index_sample]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/index_management.py\n[cosmos_index_sample_async]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/index_management_async.py\n[RRF]: https://learn.microsoft.com/azure/search/hybrid-search-ranking\n[BM25]: https://learn.microsoft.com/azure/search/index-similarity-and-scoring\n[cosmos_fts]: https://aka.ms/cosmosfulltextsearch\n[cosmos_index_policy_change]: https://learn.microsoft.com/azure/cosmos-db/index-policy#modifying-the-indexing-policy\n[cosmos_throughput_bucket_sample]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/throughput_bucket_management.py\n[cosmos_throughput_bucket_sample_async]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos/samples/throughput_bucket_management_async.py\n[cosmos_diagnostics_filter_sample]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/cosmos/azure-cosmos/samples/diagnostics_filter_sample.py\n[cosmos_throughput_bucket_configuration]: https://learn.microsoft.com/azure/cosmos-db/nosql/throughput-buckets#configuring-throughput-buckets\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Release History\n\n### 4.14.6 (2026-02-02)\n\n#### Bugs Fixed\n* Fixed async client crash (`AttributeError: 'NoneType' object has no attribute '_WritableLocations'`) during region discovery when `database_account` was `None`. See [PR 44939](https://github.com/Azure/azure-sdk-for-python/pull/44939)\n\n### 4.14.5 (2026-01-15)\n\n#### Bugs Fixed\n* Fixed bug where sdk was encountering a timeout issue caused by infinite recursion during the 410 (Gone) error.See [PR 44659](https://github.com/Azure/azure-sdk-for-python/pull/44649)\n\n### 4.14.4 (2026-01-12)\n\n#### Bugs Fixed\n* Fixed bug where sdk was not properly retrying requests in some edge cases after partition splits.See [PR 44425](https://github.com/Azure/azure-sdk-for-python/pull/44425)\n\n### 4.14.3 (2025-12-08)\n\n#### Bugs Fixed\n* Fixed bug where client timeout/read_timeout values were not properly enforced. See [PR 42652](https://github.com/Azure/azure-sdk-for-python/pull/42652).\n* Fixed bug when passing in None for some options in `query_items` would cause unexpected errors. See [PR 44098](https://github.com/Azure/azure-sdk-for-python/pull/44098)\n\n### 4.14.2 (2025-11-14)\n\n#### Features Added\n* Added merge support. See [PR 42924](https://github.com/Azure/azure-sdk-for-python/pull/42924).\n* Added support for priority-based throttling at the client level for sync and async clients. See [PR 43917](https://github.com/Azure/azure-sdk-for-python/pull/43917)\n\n#### Bugs Fixed\n* Fixed bug where customer provided excluded region was not always being honored during certain transient failures. See [PR 43602](https://github.com/Azure/azure-sdk-for-python/pull/43602)\n* Fixed TypeError bug when `parameters=None` in `query_items`. See [PR 43681](https://github.com/Azure/azure-sdk-for-python/pull/43681)\n\n#### Other Changes\n* Further optimized health checks for sync and async clients. See [PR 43339](https://github.com/Azure/azure-sdk-for-python/pull/43339)\n* Enhanced logging to ensure when a region is marked unavailable we have the proper context. See [PR 43602](https://github.com/Azure/azure-sdk-for-python/pull/43602)\n\n### 4.14.1 (2025-11-04)\n\n#### Bugs Fixed\n* Fixed bug where queries using `feed_range` and `continuation` options would not work as expected. See [PR 43700](https://github.com/Azure/azure-sdk-for-python/pull/43700).\n\n### 4.14.0 (2025-10-13)\nThis version and all future versions will require Python 3.9+.\n\n#### Features Added\n* Added ability to return a tuple of a DatabaseProxy/ContainerProxy with the associated database/container properties when creating or reading databases/containers through `return_properties` parameter. See [PR 41742](https://github.com/Azure/azure-sdk-for-python/pull/41742)\n* Added a new **preview feature** API for Semantic Reranking. See [PR 42991](https://github.com/Azure/azure-sdk-for-python/pull/42991)\n\n#### Breaking Changes\n* Changed `retry_write` from `bool` to `int` to match other retryable options. See [PR 43341](https://github.com/Azure/azure-sdk-for-python/pull/43341).\n\n#### Bugs Fixed\n* Fixed bug where exclusion list was not honored before falling back to global endpoint for multi-write region accounts. See[PR 43297](https://github.com/Azure/azure-sdk-for-python/pull/43297)\n \n#### Other Changes\n* Removed dual endpoint tracking from the sdk. See [PR 40451](https://github.com/Azure/azure-sdk-for-python/pull/40451).\n* Reverted typehints to fix the mismatch issue. See [PR 43124](https://github.com/Azure/azure-sdk-for-python/pull/43124)\n* Corrected type hints for `ConsistencyPolicy` in `DatabaseAccount` class. See [PR 43150](https://github.com/Azure/azure-sdk-for-python/pull/43150)\n\n### 4.14.0b4 (2025-09-11)\n\n#### Bugs Fixed\n* Fixed bug where client provided session token was not respected when client-side session management was disabled. See [PR 42965](https://github.com/Azure/azure-sdk-for-python/pull/42965)\n \n### 4.14.0b3 (2025-09-09)\n\n#### Features Added\n* Added read_items API to provide an efficient method for retrieving multiple items in a single request. See [PR 42167](https://github.com/Azure/azure-sdk-for-python/pull/42167).\n* Added ability to replace a container's indexing policy if a vector embedding policy was present. See [PR 42810](https://github.com/Azure/azure-sdk-for-python/pull/42810).\n\n#### Bugs Fixed\n* Improved the resilience of Database Account Read metadata operation against short-lived network issues by increasing number of retries. See [PR 42525](https://github.com/Azure/azure-sdk-for-python/pull/42525).\n* Fixed bug where during health checks read regions were marked as unavailable for write operations. See [PR 42525](https://github.com/Azure/azure-sdk-for-python/pull/42525).\n* Fixed bug where containers named with spaces or special characters using session consistency would fall back to eventual consistency. See [PR 42608](https://github.com/Azure/azure-sdk-for-python/pull/42608)\n* Fixed bug where `excluded_locations` was not being honored for some metadata calls. See [PR 42266](https://github.com/Azure/azure-sdk-for-python/pull/42266).\n* Fixed bug where Hybrid Search queries using parameters were not working. See [PR 42787](https://github.com/Azure/azure-sdk-for-python/pull/42787)\n* Fixed partition scoping for per partition circuit breaker. See [PR 42751](https://github.com/Azure/azure-sdk-for-python/pull/42751)\n* Fixed bug where `partition_key` set to None was not properly handled for some operations. See [PR 42747](https://github.com/Azure/azure-sdk-for-python/pull/42747)\n\n#### Other Changes\n* Added session token false progress merge logic. See [42393](https://github.com/Azure/azure-sdk-for-python/pull/42393)\n* Added a fallback mechanism to AAD scope override. See [PR 42731](https://github.com/Azure/azure-sdk-for-python/pull/42731).\n\n### 4.14.0b2 (2025-08-12)\n\n#### Features Added\n* Added feed range support in `query_items`. See [PR 41722](https://github.com/Azure/azure-sdk-for-python/pull/41722).\n\n#### Bugs Fixed\n* Fixed session container session token logic. The SDK will now only send the relevant partition-local session tokens for read document requests and write requests when multi-region writes are enabled, as opposed to the entire compound session token for the container for every document request. See [PR 41678](https://github.com/Azure/azure-sdk-for-python/pull/41678).\n* Write requests for single-write region accounts will no longer send session tokens when using session consistency. See [PR 41678](https://github.com/Azure/azure-sdk-for-python/pull/41678).\n* Fixed bug where container cache was not being properly updated resulting in unnecessary extra requests. See [PR 42143](https://github.com/Azure/azure-sdk-for-python/pull/42143).\n* Fixed bug where the Filters on Parent loggers or handlers of Cosmos Diagnostics loggers were not being applied. See [PR 41012](https://github.com/Azure/azure-sdk-for-python/pull/41012)\n\n#### Other Changes\n* Changed to include client id in headers for all requests. See [PR 42104](https://github.com/Azure/azure-sdk-for-python/pull/42104).\n* Added an option to override AAD audience scope through environment variable. See [PR 42228](https://github.com/Azure/azure-sdk-for-python/pull/42228).\n* Diagnostics logging will now log ServiceRequestError Exceptions, ServiceResponseError Exceptions, and Cosmos exceptions with a status code of 500 or greater. See [PR 41012](https://github.com/Azure/azure-sdk-for-python/pull/41012)\n\n### 4.14.0b1 (2025-07-14)\n\n#### Features Added\n* Added option to enable automatic retries for write document operations. See [PR 41272](https://github.com/Azure/azure-sdk-for-python/pull/41272).\n\n#### Breaking Changes\n* Adds cross region retries when no preferred locations are set. This is only a breaking change for customers using bounded staleness consistency. See [PR 39714](https://github.com/Azure/azure-sdk-for-python/pull/39714)\n\n#### Bugs Fixed\n* Fixed bug where replacing manual throughput using `ThroughputProperties` would not work. See [PR 41564](https://github.com/Azure/azure-sdk-for-python/pull/41564)\n* Fixed bug where constantly raising Service Request Error Exceptions would cause the Service Request Retry Policy to indefinitely retry the request during a query or when a request was sent without a request object. See [PR 41804](https://github.com/Azure/azure-sdk-for-python/pull/41804)\n\n### 4.13.0b2 (2025-06-18)\n\n#### Bugs Fixed\n- Fixed issue where key error would occur when getting properties from a container using legacy hash v1 as they may not always contain version property in the partition key definition. See [PR 41639](https://github.com/Azure/azure-sdk-for-python/pull/41639)\n\n### 4.13.0b1 (2025-06-05)\n\n#### Features Added\n* Added ability to set a user agent suffix at the client level. See [PR 40904](https://github.com/Azure/azure-sdk-for-python/pull/40904)\n* Added ability to use request level `excluded_locations` on metadata calls, such as getting container properties. See [PR 40905](https://github.com/Azure/azure-sdk-for-python/pull/40905)\n* Per partition circuit breaker support. It can be enabled through the environment variable `AZURE_COSMOS_ENABLE_CIRCUIT_BREAKER`. See [PR 40302](https://github.com/Azure/azure-sdk-for-python/pull/40302).\n\n#### Bugs Fixed\n* Fixed how resource tokens are parsed for metadata calls in the lifecycle of a document operation. See [PR 40302](https://github.com/Azure/azure-sdk-for-python/pull/40302).\n* Fixed issue where Query Change Feed did not return items if the container uses legacy Hash V1 Partition Keys. This also fixes issues with not being able to change feed query for Specific Partition Key Values for HPK. See [PR 41270](https://github.com/Azure/azure-sdk-for-python/pull/41270/)\n\n#### Other Changes\n* Added Client Generated Activity IDs to all Requests. Cosmos Diagnostics Logs will more clearly show the Activity ID for each request and response. [PR 41013](https://github.com/Azure/azure-sdk-for-python/pull/41013)\n\n### 4.12.0b1 (2025-05-19)\n\n#### Features Added\n* Added ability to use weighted RRF (Reciprocal Rank Fusion) for Hybrid full text search queries. See [PR 40899](https://github.com/Azure/azure-sdk-for-python/pull/40899/files).\n\n#### Bugs Fixed\n* Fixed Diagnostics Error Log Formatting to handle error messages from non-CosmosHttpResponseExceptions. See [PR 40889](https://github.com/Azure/azure-sdk-for-python/pull/40889/files)\n* Fixed bug where `multiple_write_locations` option in client was not being honored. See [PR 40999](https://github.com/Azure/azure-sdk-for-python/pull/40999).\n\n### 4.11.0b1 (2025-04-30)\n\n#### Features Added\n* Added ability to set `throughput_bucket` header at the client level and for all requests. See [PR 40340](https://github.com/Azure/azure-sdk-for-python/pull/40340).\n* Added ability to use Filters from Logging module on Diagnostics Logging based on Http request/response related attributes. See [PR 39897](https://github.com/Azure/azure-sdk-for-python/pull/39897).\n* Added ability to use `excluded_locations` on client level and document API request level. See [PR 40298](https://github.com/Azure/azure-sdk-for-python/pull/40298) \n\n#### Bugs Fixed\n* Fixed bug where change feed requests would not respect the partition key filter. See [PR 40677](https://github.com/Azure/azure-sdk-for-python/pull/40677).\n* Fixed how the environment variables in the sdk are parsed. See [PR 40303](https://github.com/Azure/azure-sdk-for-python/pull/40303).\n* Fixed health check to check the first write region when it is not specified in the preferred regions. See [PR 40588](https://github.com/Azure/azure-sdk-for-python/pull/40588).\n* Fixed `response_hook` not getting called for aggregate queries. See [PR 40696](https://github.com/Azure/azure-sdk-for-python/pull/40696).\n* Fixed bug where writes were being retried for 5xx status codes for patch and replace. See [PR 40672](https://github.com/Azure/azure-sdk-for-python/pull/40672).\n\n#### Other Changes\n* Optimized Diagnostics Logging by reducing time spent on logging. Logged Errors are more readable and formatted. See [PR 39897](https://github.com/Azure/azure-sdk-for-python/pull/39897).\n* Health checks are now done concurrently and for all regions for async apis. See [PR 40588](https://github.com/Azure/azure-sdk-for-python/pull/40588).\n\n\n### 4.10.0b4 (2025-04-01)\n\n#### Bugs Fixed\n* Fixed bug introduced in 4.10.0b3 with explicitly setting `etag` keyword argument as `None` causing exceptions. See [PR 40282](https://github.com/Azure/azure-sdk-for-python/pull/40282).\n\n### 4.10.0b3 (2025-03-27)\n\n#### Bugs Fixed\n* Fixed too many health checks happening when skipping the recommended client startup. See [PR 40203](https://github.com/Azure/azure-sdk-for-python/pull/40203).\n\n#### Other Changes\n* Removed excess keyword arguments from methods that did not use them. See [PR 40008](https://github.com/Azure/azure-sdk-for-python/pull/40008).\n* Removed first `response_hook` call for query methods that would utilize wrong response headers. See [PR 40008](https://github.com/Azure/azure-sdk-for-python/pull/40008).\n\n### 4.10.0b2 (2025-03-17)\n\n#### Bugs Fixed\n* Fixed bug preventing health check in some scenarios. See [PR 39647](https://github.com/Azure/azure-sdk-for-python/pull/39647).\n* Fixed `partition_key` filter for `query_items_change_feed` API. See [PR 39895](https://github.com/Azure/azure-sdk-for-python/pull/39895).\n\n#### Other Changes\n* Moved endpoint health check to the background for async APIs. See [PR 39647](https://github.com/Azure/azure-sdk-for-python/pull/39647).\n\n### 4.10.0b1 (2025-02-13)\n\n#### Features Added\n* Added ability to replace `computed_properties` through `replace_container` method. See [PR 39543](https://github.com/Azure/azure-sdk-for-python/pull/39543).\n\n#### Other Changes\n* Un-marked `computed_properties` keyword as **provisional**. See [PR 39543](https://github.com/Azure/azure-sdk-for-python/pull/39543).\n\n### 4.9.1b4 (2025-02-06)\n\n#### Bugs Fixed\n* Improved retry logic for read requests to failover on other regions in case of timeouts and any error codes >= 500. See [PR 39596](https://github.com/Azure/azure-sdk-for-python/pull/39596).\n* Fixed a regression where read operations were not retrying on timeouts. See [PR 39596](https://github.com/Azure/azure-sdk-for-python/pull/39596)\n* Updated default read timeout for `getDatabaseAccount` calls to 3 seconds. See [PR 39596](https://github.com/Azure/azure-sdk-for-python/pull/39596)\n\n### 4.9.1b3 (2025-02-04)\n\n#### Features Added\n* Improved retry logic by retrying alternative endpoint for writes within a region before performing a cross region retry. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* Added endpoint health check logic during database account calls. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390)\n\n#### Bugs Fixed\n* Fixed unnecessary retries on the wrong region for timout retry policy. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* All client connection errors from aiohttp will be retried. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n\n#### Other Changes\n* Changed defaults for retry delays. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* Changed default connection timeout to be 5 seconds. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* Changed default read timeout to be 65 seconds. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* On database account calls send a client id header for load balancing. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n* Removed aiohttp dependency. See [PR 39390](https://github.com/Azure/azure-sdk-for-python/pull/39390).\n\n### 4.9.1b2 (2025-01-24)\n\n#### Features Added\n* Added new cross-regional retry logic for `ServiceRequestError` and `ServiceResponseError` exceptions. See [PR 39396](https://github.com/Azure/azure-sdk-for-python/pull/39396).\n\n#### Bugs Fixed\n* Fixed `KeyError` being returned by location cache when most preferred location is not present in cached regions. See [PR 39396](https://github.com/Azure/azure-sdk-for-python/pull/39396).\n* Fixed cross-region retries on `CosmosClient` initialization. See [PR 39396](https://github.com/Azure/azure-sdk-for-python/pull/39396).\n\n#### Other Changes\n* This release requires aiohttp version 3.10.11 and above. See [PR 39396](https://github.com/Azure/azure-sdk-for-python/pull/39396).\n\n### 4.9.1b1 (2024-12-13)\n\n#### Features Added\n* Added change feed mode support in `query_items_change_feed`. See [PR 38105](https://github.com/Azure/azure-sdk-for-python/pull/38105).\n* Added a **Preview Feature** for adding Diagnostics Handler to filter what diagnostics get logged. This feature is subject to change significantly. See [PR 38105](https://github.com/Azure/azure-sdk-for-python/pull/38581).\n\n### 4.9.0 (2024-11-18)\n\n#### Features Added\n* Added full text policy and full text indexing policy. See [PR 37891](https://github.com/Azure/azure-sdk-for-python/pull/37891).\n* Added support for full text search and hybrid search queries. See [PR 38275](https://github.com/Azure/azure-sdk-for-python/pull/38275).\n\n### 4.8.0 (2024-11-12)\nThis version and all future versions will support Python 3.13.\n\n#### Features Added\n* Added response headers directly to SDK item point operation responses. See [PR 35791](https://github.com/Azure/azure-sdk-for-python/pull/35791).\n* SDK will now retry all ServiceRequestErrors (failing outgoing requests) before failing. Default number of retries is 3. See [PR 36514](https://github.com/Azure/azure-sdk-for-python/pull/36514).\n* Added Retry Policy for Container Recreate in the Python SDK. See [PR 36043](https://github.com/Azure/azure-sdk-for-python/pull/36043).\n* Added option to disable write payload on writes. See [PR 37365](https://github.com/Azure/azure-sdk-for-python/pull/37365).\n* Added get feed ranges API. See [PR 37687](https://github.com/Azure/azure-sdk-for-python/pull/37687).\n* Added feed range support in `query_items_change_feed`. See [PR 37687](https://github.com/Azure/azure-sdk-for-python/pull/37687).\n* Added **provisional** helper APIs for managing session tokens. See [PR 36971](https://github.com/Azure/azure-sdk-for-python/pull/36971).\n* Added ability to get feed range for a partition key. See [PR 36971](https://github.com/Azure/azure-sdk-for-python/pull/36971).\n\n#### Breaking Changes\n* Item-level point operations will now return `CosmosDict` and `CosmosList` response types. \nResponses will still be able to be used directly as previously, but will now have access to their response headers without need for a response hook. See [PR 35791](https://github.com/Azure/azure-sdk-for-python/pull/35791).\nFor more information on this, see our README section [here](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/cosmos/azure-cosmos/README.md#using-item-operation-response-headers).\n\n#### Bugs Fixed\n* Consolidated Container Properties Cache to be in the Client to cache partition key definition and container rid to avoid unnecessary container reads. See [PR 35731](https://github.com/Azure/azure-sdk-for-python/pull/35731).\n* Fixed bug with client hangs when running into WriteForbidden exceptions. See [PR 36514](https://github.com/Azure/azure-sdk-for-python/pull/36514).\n* Added retry handling logic for DatabaseAccountNotFound exceptions. See [PR 36514](https://github.com/Azure/azure-sdk-for-python/pull/36514).\n* Fixed SDK regex validation that would not allow for item ids to be longer than 255 characters. See [PR 36569](https://github.com/Azure/azure-sdk-for-python/pull/36569).\n* Fixed issue where 'NoneType' object has no attribute error was raised when a session retry happened during a query. See [PR 37578](https://github.com/Azure/azure-sdk-for-python/pull/37578).\n* Fixed issue where passing subpartition partition key values as a tuple in a query would raise an error. See [PR 38136](https://github.com/Azure/azure-sdk-for-python/pull/38136).\n* Batch requests will now be properly considered as Write operation. See [PR 38365](https://github.com/Azure/azure-sdk-for-python/pull/38365).\n\n#### Other Changes\n* Getting offer thoughput when it has not been defined in a container will now give a 404/10004 instead of just a 404. See [PR 36043](https://github.com/Azure/azure-sdk-for-python/pull/36043).\n* Incomplete Partition Key Extractions in documents for Subpartitioning now gives 400/1001 instead of just a 400. See [PR 36043](https://github.com/Azure/azure-sdk-for-python/pull/36043).\n* SDK will now make database account calls every 5 minutes to refresh location cache. See [PR 36514](https://github.com/Azure/azure-sdk-for-python/pull/36514).\n\n### 4.7.0 (2024-05-15)\n\n#### Features Added\n* Adds vector embedding policy and vector indexing policy. See [PR 34882](https://github.com/Azure/azure-sdk-for-python/pull/34882).\n* Adds support for vector search non-streaming order by queries. See [PR 35468](https://github.com/Azure/azure-sdk-for-python/pull/35468).\n* Adds support for using the start time option for change feed query API. See [PR 35090](https://github.com/Azure/azure-sdk-for-python/pull/35090).\n\n#### Bugs Fixed\n* Fixed a bug where change feed query in Async client was not returning all pages due to case-sensitive response headers. See [PR 35090](https://github.com/Azure/azure-sdk-for-python/pull/35090).\n* Fixed a bug when a retryable exception occurs in the first page of a query execution causing query to return 0 results. See [PR 35090](https://github.com/Azure/azure-sdk-for-python/pull/35090).\n\n### 4.6.1 (2024-05-15)\n\n### 4.6.0 (2024-03-14)\n\n#### Features Added\n* GA release of hierarchical partitioning, index metrics and transactional batch.\n\n#### Bugs Fixed\n* Keyword arguments were not being passed down for `create_container_if_not_exists()` methods. See [PR 34286](https://github.com/Azure/azure-sdk-for-python/pull/34286).\n\n#### Other Changes\n* Made several updates to the type hints used throughout the SDK for greater detail. See [PR 33269](https://github.com/Azure/azure-sdk-for-python/pull/33269), [PR 33341](https://github.com/Azure/azure-sdk-for-python/pull/33341), [PR 33738](https://github.com/Azure/azure-sdk-for-python/pull/33738).\n\n### 4.5.2b5 (2024-03-02)\n\n#### Bugs Fixed\n* Fixed bug with async lock not properly releasing on async global endpoint manager. see [PR 34579](https://github.com/Azure/azure-sdk-for-python/pull/34579).\n\n#### Other Changes\n* Marked `computed_properties` keyword as provisional, un-marked `continuation_token_limit` as provisional. See [PR 34207](https://github.com/Azure/azure-sdk-for-python/pull/34207).\n\n### 4.5.2b4 (2024-02-02)\nThis version and all future versions will require Python 3.8+.\n\n#### Features Added\n* Added **preview** support for Computed Properties on Python SDK (Must be enabled on the account level before it can be used). See [PR 33626](https://github.com/Azure/azure-sdk-for-python/pull/33626).\n\n#### Bugs Fixed\n* Made use of `response_hook` thread-safe in the sync client. See [PR 33790](https://github.com/Azure/azure-sdk-for-python/pull/33790).\n* Fixed bug with the session container not being properly maintained. See [33738](https://github.com/Azure/azure-sdk-for-python/pull/33738).\n\n### 4.5.2b3 (2023-11-10)\n\n#### Features Added\n* Added support for capturing Index Metrics in query operations. See [PR 33034](https://github.com/Azure/azure-sdk-for-python/pull/33034).\n\n### 4.5.2b2 (2023-10-31)\n\n#### Features Added\n* Added support for Transactional Batch. See [PR 32508](https://github.com/Azure/azure-sdk-for-python/pull/32508).\n* Added **preview** support for Priority Based Throttling/Priority Based Execution (Must be enabled at the account level before it can be used). See [PR 32441](https://github.com/Azure/azure-sdk-for-python/pull/32441/).\n\n### 4.5.2b1 (2023-10-17)\n\n#### Features Added\n* Added support for Hierarchical Partitioning, also known as Subpartitioning. See [PR 31121](https://github.com/Azure/azure-sdk-for-python/pull/31121).\n\n#### Bugs Fixed\n* Small fix to the `offer_throughput` option in the async client's `create_database_if_not_exists` method, which was previously misspelled as `offerThroughput`.\nSee [PR 32076](https://github.com/Azure/azure-sdk-for-python/pull/32076).\n\n#### Other Changes\n* Marked the outdated `diagnostics.py` file for deprecation since we now recommend the use of our `CosmosHttpLoggingPolicy` for diagnostics.\nFor more on the `CosmosHttpLoggingPolicy` see our [README](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos#logging-diagnostics).\n\n### 4.5.1 (2023-09-12)\n\n#### Bugs Fixed\n* Fixed bug when query with DISTINCT + OFFSET/LIMIT operators returns unexpected result. See [PR 31925](https://github.com/Azure/azure-sdk-for-python/pull/31925).\n\n#### Other Changes\n* Added additional checks for resource creation using specific characters that cause issues. See [PR 31861](https://github.com/Azure/azure-sdk-for-python/pull/31861).\n\n### 4.5.0 (2023-08-09)\n\n#### Features Added\n* Added support for continuation tokens for streamable cross partition queries. See [PR 31189](https://github.com/Azure/azure-sdk-for-python/pull/31189).\n\n#### Bugs Fixed\n* Fixed bug with async `create_database_if_not_exists` method not working when passing `offer_throughput` as an option. See [PR 31478](https://github.com/Azure/azure-sdk-for-python/pull/31478).\n\n#### Other Changes\n* Renamed `response_continuation_token_limit_in_kb` to `continuation_token_limit` for GA. See [PR 31532](https://github.com/Azure/azure-sdk-for-python/pull/31532).\n\n### 4.4.1b1 (2023-07-25)\n\n#### Features Added\n* Added ability to limit continuation token size when querying for items. See [PR 30731](https://github.com/Azure/azure-sdk-for-python/pull/30731)\n\n#### Bugs Fixed\n* Fixed bug with async patch_item method. See [PR 30804](https://github.com/Azure/azure-sdk-for-python/pull/30804).\n\n### 4.4.0 (2023-06-09)\n\n#### Features Added\n- GA release of Patch API and Delete All Items By Partition Key\n\n### 4.4.0b2 (2023-05-22)\n\n#### Features Added\n* Added conditional patching for Patch operations. See [PR 30455](https://github.com/Azure/azure-sdk-for-python/pull/30455).\n\n#### Bugs Fixed\n* Fixed bug with non english locales causing an error with the RFC 1123 Date Format. See [PR 30125](https://github.com/Azure/azure-sdk-for-python/pull/30125).\n\n#### Other Changes\n* Refactoring of our client `connection_timeout` and `request_timeout` configurations. See [PR 30171](https://github.com/Azure/azure-sdk-for-python/pull/30171).\n\n### 4.4.0b1 (2023-04-11)\n\n#### Features Added\n - Added **preview** delete all items by partition key functionality. See [PR 29186](https://github.com/Azure/azure-sdk-for-python/pull/29186). For more information on Partition Key Delete, please see [Azure Cosmos DB Partition Key Delete](https://learn.microsoft.com/azure/cosmos-db/nosql/how-to-delete-by-partition-key?tabs=python-example).\n - Added **preview** partial document update (Patch API) functionality and container methods for patching items with operations. See [PR 29497](https://github.com/Azure/azure-sdk-for-python/pull/29497). For more information on Patch, please see [Azure Cosmos DB Partial Document Update](https://learn.microsoft.com/azure/cosmos-db/partial-document-update).\n\n#### Bugs Fixed\n* Fixed bug in method `create_container_if_not_exists()` of async database client for unexpected kwargs being passed into `read()` method used internally. See [PR 29136](https://github.com/Azure/azure-sdk-for-python/pull/29136).\n* Fixed bug with method `query_items()` of our async container class, where partition key and cross partition headers would both be set when using partition keys. See [PR 29366](https://github.com/Azure/azure-sdk-for-python/pull/29366/).\n* Fixed bug with client not properly surfacing errors for invalid credentials and identities with insufficient permissions. Users running into 'NoneType has no attribute ConsistencyPolicy' errors when initializing their clients will now see proper authentication exceptions. See [PR 29256](https://github.com/Azure/azure-sdk-for-python/pull/29256).\n\n#### Other Changes\n* Removed use of `six` package within the SDK.\n\n### 4.3.1 (2023-02-23)\n\n#### Features Added\n - Added `correlated_activity_id` for query operations.\n - Added cross regional retries for Service Unavailable/Request Timeouts for read/Query Plan operations.\n - GA release of CosmosHttpLoggingPolicy and autoscale feature.\n\n#### Bugs Fixed\n- Bug fix to address queries with VALUE MAX (or any other aggregate) that run into an issue if the query is executed on a container with at least one \"empty\" partition.\n\n### 4.3.1b1 (2022-09-19)\n\n#### Features Added\n- GA release of integrated cache functionality. For more information on integrated cache please see [Azure Cosmos DB integrated cache](https://learn.microsoft.com/azure/cosmos-db/integrated-cache).\n- Added ability to replace analytical ttl on containers. For more information on analytical ttl please see [Azure Cosmos DB analytical store](https://learn.microsoft.com/azure/cosmos-db/analytical-store-introduction).\n- Added `CosmosHttpLoggingPolicy` to replace `HttpLoggingPolicy` for logging HTTP sessions.\n- Added the ability to create containers and databases with autoscale properties for the sync and async clients.\n- Added the ability to update autoscale throughput properties.\n\n#### Bugs Fixed\n- Fixed parsing of args for overloaded `container.read()` method.\n- Fixed `validate_cache_staleness_value()` method to allow max_integrated_cache_staleness to be an integer greater than or equal to 0.\n- Fixed `__aiter__()` method by removing the async keyword.\n\n### 4.3.0 (2022-05-23)\n#### Features Added\n- GA release of Async I/O APIs, including all changes from 4.3.0b1 to 4.3.0b4.\n\n#### Breaking Changes\n- Method signatures have been updated to use keyword arguments instead of positional arguments for most method options in the async client.\n- Bugfix: Automatic Id generation for items was turned on for `upsert_items()` method when no 'id' value was present in document body.\nMethod call will now require an 'id' field to be present in the document body.\n\n#### Other Changes\n- Deprecated offer-named methods in favor of their new throughput-named counterparts (`read_offer` -> `get_throughput`).\n- Marked the GetAuthorizationHeader method for deprecation since it will no longer be public in a future release.\n- Added samples showing how to configure retry options for both the sync and async clients.\n- Deprecated the `connection_retry_policy` and `retry_options` options in the sync client.\n- Added user warning to non-query methods trying to use `populate_query_metrics` options.\n\n### 4.3.0b4 (2022-04-07)\n\n#### Features Added\n- Added support for AAD authentication for the async client.\n- Added support for AAD authentication for the sync client.\n\n#### Other Changes\n- Changed `_set_partition_key` return typehint in async client.\n\n### 4.3.0b3 (2022-03-10)\n\n>[WARNING]\n>The default `Session` consistency bugfix will impact customers whose database accounts have a `Bounded Staleness` or `Strong`\n> consistency level, and were previously not sending `Session` as a consistency_level parameter when initializing\n> their clients.\n> Default consistency level for the sync and async clients is no longer \"Session\" and will instead be set to the \n  consistency level of the user's cosmos account setting on initialization if not passed during client initialization. \n> Please see [Consistency Levels in Azure Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/consistency-levels) \n> for more details on consistency levels, or the README section on this change [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cosmos/azure-cosmos#note-on-client-consistency-levels).\n\n#### Features Added\n- Added new **provisional** `max_integrated_cache_staleness_in_ms` parameter to read item and query items APIs in order\n  to make use of the **preview** CosmosDB integrated cache functionality [See PR #22946](https://github.com/Azure/azure-sdk-for-python/pull/22946).\n  Please see [Azure Cosmos DB integrated cache](https://learn.microsoft.com/azure/cosmos-db/integrated-cache) for more details.\n- Added support for split-proof queries for the async client.\n\n### Bugs fixed\n- Default consistency level for the sync and async clients is no longer `Session` and will instead be set to the \n  consistency level of the user's cosmos account setting on initialization if not passed during client initialization. \n  This change will impact client application in terms of RUs and latency. Users relying on default `Session` consistency\n  will need to pass it explicitly if their account consistency is different than `Session`.\n  Please see [Consistency Levels in Azure Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/consistency-levels) for more details.  \n- Fixed invalid request body being sent when passing in `serverScript` body parameter to replace operations for trigger, sproc and udf resources.\n- Moved `is_system_key` logic in async client.\n- Fixed TypeErrors not being thrown when passing in invalid connection retry policies to the client.\n\n### 4.3.0b2 (2022-01-25)\n\nThis version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.\nWe will also be removing support for Python 3.6 and will only support Python 3.7+ starting December 2022.\n\n#### Features Added\n- Added support for split-proof queries for the sync client.\n\n#### Other Changes\n- Added async user agent for async client.\n\n### 4.3.0b1 (2021-12-14)\n\n#### Features Added\n- Added language native async i/o client.\n\n### 4.2.0 (2020-10-08)\n\n**Bug fixes**\n- Fixed bug where continuation token is not honored when query_iterable is used to get results by page. Issue #13265.\n- Fixed bug where resource tokens not being honored for document reads and deletes. Issue #13634.\n\n**New features**\n- Added support for passing partitionKey while querying changefeed. Issue #11689.\n\n### 4.1.0 (2020-08-10)\n\n- Added deprecation warning for \"lazy\" indexing mode. The backend no longer allows creating containers with this mode and will set them to consistent instead.\n\n**New features**\n- Added the ability to set the analytical storage TTL when creating a new container.\n\n**Bug fixes**\n- Fixed support for dicts as inputs for get_client APIs.\n- Fixed Python 2/3 compatibility in query iterators.\n- Fixed type hint error. Issue #12570 - thanks @sl-sandy.\n- Fixed bug where options headers were not added to upsert_item function. Issue #11791 - thank you @aalapatirvbd.\n- Fixed error raised when a non string ID is used in an item. It now raises TypeError rather than AttributeError. Issue #11793 - thank you @Rabbit994.\n\n\n### 4.0.0 (2020-05-20)\n\n- Stable release.\n- Added HttpLoggingPolicy to pipeline to enable passing in a custom logger for request and response headers.\n\n\n## 4.0.0b6\n\n- Fixed bug in synchronized_request for media APIs.\n- Removed MediaReadMode and MediaRequestTimeout from ConnectionPolicy as media requests are not supported.\n\n\n## 4.0.0b5\n\n- azure.cosmos.errors module deprecated and replaced by azure.cosmos.exceptions\n- The access condition parameters (`access_condition`, `if_match`, `if_none_match`) have been deprecated in favor of separate `match_condition` and `etag` parameters.\n- Fixed bug in routing map provider.\n- Added query Distinct, Offset and Limit support.\n- Default document query execution context now used for\n    - ChangeFeed queries\n    - single partition queries (partitionkey, partitionKeyRangeId is present in options)\n    - Non document queries\n- Errors out for aggregates on multiple partitions, with enable cross partition query set to true, but no \"value\" keyword present\n- Hits query plan endpoint for other scenarios to fetch query plan\n- Added `__repr__` support for Cosmos entity objects.\n- Updated documentation.\n\n\n## 4.0.0b4\n\n- Added support for a `timeout` keyword argument to all operations to specify an absolute timeout in seconds\n  within which the operation must be completed. If the timeout value is exceeded, a `azure.cosmos.errors.CosmosClientTimeoutError` will be raised.\n- Added a new `ConnectionRetryPolicy` to manage retry behaviour during HTTP connection errors.\n- Added new constructor and per-operation configuration keyword arguments:\n    - `retry_total` - Maximum retry attempts.\n    - `retry_backoff_max` - Maximum retry wait time in seconds.\n    - `retry_fixed_interval` - Fixed retry interval in milliseconds.\n    - `retry_read` - Maximum number of socket read retry attempts.\n    - `retry_connect` - Maximum number of connection error retry attempts.\n    - `retry_status` - Maximum number of retry attempts on error status codes.\n    - `retry_on_status_codes` - A list of specific status codes to retry on.\n    - `retry_backoff_factor` - Factor to calculate wait time between retry attempts.\n\n## 4.0.0b3\n\n- Added `create_database_if_not_exists()` and `create_container_if_not_exists` functionalities to CosmosClient and Database respectively.\n\n## 4.0.0b2\n\nVersion 4.0.0b2 is the second iteration in our efforts to build a more Pythonic client library.\n\n**Breaking changes**\n\n- The client connection has been adapted to consume the HTTP pipeline defined in `azure.core.pipeline`.\n- Interactive objects have now been renamed as proxies. This includes:\n    - `Database` -> `DatabaseProxy`\n    - `User` -> `UserProxy`\n    - `Container` -> `ContainerProxy`\n    - `Scripts` -> `ScriptsProxy`\n- The constructor of `CosmosClient` has been updated:\n    - The `auth` parameter has been renamed to `credential` and will now take an authentication type directly. This means the master key value, a dictionary of resource tokens, or a list of permissions can be passed in. However the old dictionary format is still supported.\n    - The `connection_policy` parameter has been made a keyword only parameter, and while it is still supported, each of the individual attributes of the policy can now be passed in as explicit keyword arguments:\n        - `request_timeout`\n        - `media_request_timeout`\n        - `connection_mode`\n        - `media_read_mode`\n        - `proxy_config`\n        - `enable_endpoint_discovery`\n        - `preferred_locations`\n        - `multiple_write_locations`\n- A new classmethod constructor has been added to `CosmosClient` to enable creation via a connection string retrieved from the Azure portal.\n- Some `read_all` operations have been renamed to `list` operations:\n    - `CosmosClient.read_all_databases` -> `CosmosClient.list_databases`\n    - `Container.read_all_conflicts` -> `ContainerProxy.list_conflicts`\n    - `Database.read_all_containers` -> `DatabaseProxy.list_containers`\n    - `Database.read_all_users` -> `DatabaseProxy.list_users`\n    - `User.read_all_permissions` -> `UserProxy.list_permissions`\n- All operations that take `request_options` or `feed_options` parameters, these have been moved to keyword only parameters. In addition, while these options dictionaries are still supported, each of the individual options within the dictionary are now supported as explicit keyword arguments.\n- The error hierarchy is now inherited from `azure.core.AzureError` instead of `CosmosError` which has been removed.\n    - `HTTPFailure` has been renamed to `CosmosHttpResponseError`\n    - `JSONParseFailure` has been removed and replaced by `azure.core.DecodeError`\n    - Added additional errors for specific response codes:\n        - `CosmosResourceNotFoundError` for status 404\n        - `CosmosResourceExistsError` for status 409\n        - `CosmosAccessConditionFailedError` for status 412\n- `CosmosClient` can now be run in a context manager to handle closing the client connection.\n- Iterable responses (e.g. query responses and list responses) are now of type `azure.core.paging.ItemPaged`. The method `fetch_next_block` has been replaced by a secondary iterator, accessed by the `by_page` method.\n\n## 4.0.0b1\n\nVersion 4.0.0b1 is the first preview of our efforts to create a user-friendly and Pythonic client library for Azure Cosmos. For more information about this, and preview releases of other Azure SDK libraries, please visit https://aka.ms/azure-sdk-preview1-python.\n\n**Breaking changes: New API design**\n\n- Operations are now scoped to a particular client:\n    - `CosmosClient`: This client handles account-level operations. This includes managing service properties and listing the databases within an account.\n    - `Database`: This client handles database-level operations. This includes creating and deleting containers, users and stored procedures. It can be accessed from a `CosmosClient` instance by name.\n    - `Container`: This client handles operations for a particular container. This includes querying and inserting items and managing properties.\n    - `User`: This client handles operations for a particular user. This includes adding and deleting permissions and managing user properties.\n    \n    These clients can be accessed by navigating down the client hierarchy using the `get_<child>_client` method. For full details on the new API, please see the [reference documentation](https://aka.ms/azsdk-python-cosmos-ref).\n- Clients are accessed by name rather than by Id. No need to concatenate strings to create links.\n- No more need to import types and methods from individual modules. The public API surface area is available directly in the `azure.cosmos` package.\n- Individual request properties can be provided as keyword arguments rather than constructing a separate `RequestOptions` instance.\n\n## 3.0.2\n\n- Added Support for MultiPolygon Datatype\n- Bug Fix in Session Read Retry Policy\n- Bug Fix for Incorrect padding issues while decoding base 64 strings\n\n## 3.0.1\n\n- Bug fix in LocationCache\n- Bug fix endpoint retry logic\n- Fixed documentation\n\n## 3.0.0\n\n- Multi-region write support added\n- Naming changes\n  - DocumentClient to CosmosClient\n  - Collection to Container\n  - Document to Item\n  - Package name updated to \"azure-cosmos\"\n  - Namespace updated to \"azure.cosmos\"\n\n## 2.3.3\n\n- Added support for proxy\n- Added support for reading change feed\n- Added support for collection quota headers\n- Bugfix for large session tokens issue\n- Bugfix for ReadMedia API\n- Bugfix in partition key range cache\n\n## 2.3.2\n\n- Added support for default retries on connection issues.\n\n## 2.3.1\n\n- Updated documentation to reference Azure Cosmos DB instead of Azure DocumentDB.\n\n## 2.3.0\n\n- This SDK version requires the latest version of Azure Cosmos DB Emulator available for download from https://aka.ms/cosmosdb-emulator.\n\n## 2.2.1\n\n- bugfix for aggregate dict\n- bugfix for trimming slashes in the resource link\n- tests for unicode encoding\n\n## 2.2.0\n\n- Added support for Request Unit per Minute (RU/m) feature.\n- Added support for a new consistency level called ConsistentPrefix.\n\n## 2.1.0\n\n- Added support for aggregation queries (COUNT, MIN, MAX, SUM, and AVG).\n- Added an option for disabling SSL verification when running against DocumentDB Emulator.\n- Removed the restriction of dependent requests module to be exactly 2.10.0.\n- Lowered minimum throughput on partitioned collections from 10,100 RU/s to 2500 RU/s.\n- Added support for enabling script logging during stored procedure execution.\n- REST API version bumped to '2017-01-19' with this release.\n\n## 2.0.1\n\n- Made editorial changes to documentation comments.\n\n## 2.0.0\n\n- Added support for Python 3.5.\n- Added support for connection pooling using the requests module.\n- Added support for session consistency.\n- Added support for TOP/ORDERBY queries for partitioned collections.\n\n## 1.9.0\n\n- Added retry policy support for throttled requests. (Throttled requests receive a request rate too large exception, error code 429.)\n  By default, DocumentDB retries nine times for each request when error code 429 is encountered, honoring the retryAfter time in the response header.\n  A fixed retry interval time can now be set as part of the RetryOptions property on the ConnectionPolicy object if you want to ignore the retryAfter time returned by server between the retries.\n  DocumentDB now waits for a maximum of 30 seconds for each request that is being throttled (irrespective of retry count) and returns the response with error code 429.\n  This time can also be overridden in the RetryOptions property on ConnectionPolicy object.\n\n- DocumentDB now returns x-ms-throttle-retry-count and x-ms-throttle-retry-wait-time-ms as the response headers in every request to denote the throttle retry count\n  and the cumulative time the request waited between the retries.\n\n- Removed the RetryPolicy class and the corresponding property (retry_policy) exposed on the document_client class and instead introduced a RetryOptions class\n  exposing the RetryOptions property on ConnectionPolicy class that can be used to override some of the default retry options.\n\n## 1.8.0\n\n- Added the support for geo-replicated database accounts.\n- Test fixes to move the global host and masterKey into the individual test classes.\n\n## 1.7.0\n\n- Added the support for Time To Live(TTL) feature for documents.\n\n## 1.6.1\n\n- Bug fixes related to server side partitioning to allow special characters in partitionkey path.\n\n## 1.6.0\n\n- Added the support for server side partitioned collections feature.\n\n## 1.5.0\n\n- Added Client-side sharding framework to the SDK. Implemented HashPartionResolver and RangePartitionResolver classes.\n\n## 1.4.2\n\n- Implement Upsert. New UpsertXXX methods added to support Upsert feature.\n- Implement ID Based Routing. No public API changes, all changes internal.\n\n## 1.3.0\n\n- Release skipped to bring version number in alignment with other SDKs\n\n## 1.2.0\n\n- Supports GeoSpatial index.\n- Validates id property for all resources. Ids for resources cannot contain ?, /, #, \\\\, characters or end with a space.\n- Adds new header \"index transformation progress\" to ResourceResponse.\n\n## 1.1.0\n\n- Implements V2 indexing policy\n\n## 1.0.1\n\n- Supports proxy connection\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python",
        "author": "Microsoft Corporation",
        "author_email": "askdocdb@microsoft.com",
        "maintainer": "Microsoft",
        "maintainer_email": "askdocdb@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-core>=1.30.0",
          "typing-extensions>=4.6.0"
        ],
        "requires_python": ">=3.9"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/cf/df/d3f1ddf4bb4cb50ed9b1139cc7b1c54c34a1e7ce8fd1b9a37c0d1551a6bd/opentelemetry_api-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=2edd8463432a7f8443edce90972169b195e7d6a05500cd29e6d13898187c9950",
          "hashes": {
            "sha256": "2edd8463432a7f8443edce90972169b195e7d6a05500cd29e6d13898187c9950"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-api",
        "version": "1.39.1",
        "summary": "OpenTelemetry Python API",
        "description": "OpenTelemetry Python API\n============================================================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-api.svg\n   :target: https://pypi.org/project/opentelemetry-api/\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-api\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "importlib-metadata<8.8.0,>=6.0",
          "typing-extensions>=4.5.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/opentelemetry-api",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7c/98/e91cf858f203d86f4eccdf763dcf01cf03f1dae80c3750f7e635bfa206b6/opentelemetry_sdk-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4d5482c478513ecb0a5d938dcc61394e647066e0cc2676bee9f3af3f3f45f01c",
          "hashes": {
            "sha256": "4d5482c478513ecb0a5d938dcc61394e647066e0cc2676bee9f3af3f3f45f01c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-sdk",
        "version": "1.39.1",
        "summary": "OpenTelemetry Python SDK",
        "description": "OpenTelemetry Python SDK\n============================================================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-sdk.svg\n   :target: https://pypi.org/project/opentelemetry-sdk/\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-sdk\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "opentelemetry-api==1.39.1",
          "opentelemetry-semantic-conventions==0.60b1",
          "typing-extensions>=4.5.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/opentelemetry-sdk",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7a/5e/5958555e09635d09b75de3c4f8b9cae7335ca545d77392ffe7331534c402/opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=9fa8c8b0c110da289809292b0591220d3a7b53c1526a23021e977d68597893fb",
          "hashes": {
            "sha256": "9fa8c8b0c110da289809292b0591220d3a7b53c1526a23021e977d68597893fb"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-semantic-conventions",
        "version": "0.60b1",
        "summary": "OpenTelemetry Semantic Conventions",
        "description": "OpenTelemetry Semantic Conventions\n==================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-semantic-conventions.svg\n   :target: https://pypi.org/project/opentelemetry-semantic-conventions/\n\nThis library contains generated code for the semantic conventions defined by the OpenTelemetry specification.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-semantic-conventions\n\nCode Generation\n---------------\n\nThese files were generated automatically from code in semconv_.\nTo regenerate the code, run ``../scripts/semconv/generate.sh``.\n\nTo build against a new release or specific commit of opentelemetry-specification_,\nupdate the ``SPEC_VERSION`` variable in\n``../scripts/semconv/generate.sh``. Then run the script and commit the changes.\n\n.. _opentelemetry-specification: https://github.com/open-telemetry/opentelemetry-specification\n.. _semconv: https://github.com/open-telemetry/opentelemetry-python/tree/main/scripts/semconv\n\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Semantic Conventions Definitions <https://github.com/open-telemetry/semantic-conventions/blob/main/docs/README.md>`_\n* `generate.sh script <https://github.com/open-telemetry/opentelemetry-python/blob/main/scripts/semconv/generate.sh>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api==1.39.1",
          "typing-extensions>=4.5.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/opentelemetry-semantic-conventions",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/a8/a4/20da314d277121d6534b3a980b29035dcd51e6744bd79075a6ce8fa4eb8d/pytest-8.4.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=872f880de3fc3a5bdc88a11b39c9710c3497a547cfa9320bc3c5e62fbf272e79",
          "hashes": {
            "sha256": "872f880de3fc3a5bdc88a11b39c9710c3497a547cfa9320bc3c5e62fbf272e79"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pytest",
        "version": "8.4.2",
        "dynamic": [
          "license-file"
        ],
        "summary": "pytest: simple powerful testing with Python",
        "description": ".. image:: https://github.com/pytest-dev/pytest/raw/main/doc/en/img/pytest_logo_curves.svg\n   :target: https://docs.pytest.org/en/stable/\n   :align: center\n   :height: 200\n   :alt: pytest\n\n\n------\n\n.. image:: https://img.shields.io/pypi/v/pytest.svg\n    :target: https://pypi.org/project/pytest/\n\n.. image:: https://img.shields.io/conda/vn/conda-forge/pytest.svg\n    :target: https://anaconda.org/conda-forge/pytest\n\n.. image:: https://img.shields.io/pypi/pyversions/pytest.svg\n    :target: https://pypi.org/project/pytest/\n\n.. image:: https://codecov.io/gh/pytest-dev/pytest/branch/main/graph/badge.svg\n    :target: https://codecov.io/gh/pytest-dev/pytest\n    :alt: Code coverage Status\n\n.. image:: https://github.com/pytest-dev/pytest/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/pytest-dev/pytest/actions?query=workflow%3Atest\n\n.. image:: https://results.pre-commit.ci/badge/github/pytest-dev/pytest/main.svg\n   :target: https://results.pre-commit.ci/latest/github/pytest-dev/pytest/main\n   :alt: pre-commit.ci status\n\n.. image:: https://www.codetriage.com/pytest-dev/pytest/badges/users.svg\n    :target: https://www.codetriage.com/pytest-dev/pytest\n\n.. image:: https://readthedocs.org/projects/pytest/badge/?version=latest\n    :target: https://pytest.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://img.shields.io/badge/Discord-pytest--dev-blue\n    :target: https://discord.com/invite/pytest-dev\n    :alt: Discord\n\n.. image:: https://img.shields.io/badge/Libera%20chat-%23pytest-orange\n    :target: https://web.libera.chat/#pytest\n    :alt: Libera chat\n\n\nThe ``pytest`` framework makes it easy to write small tests, yet\nscales to support complex functional testing for applications and libraries.\n\nAn example of a simple test:\n\n.. code-block:: python\n\n    # content of test_sample.py\n    def inc(x):\n        return x + 1\n\n\n    def test_answer():\n        assert inc(3) == 5\n\n\nTo execute it::\n\n    $ pytest\n    ============================= test session starts =============================\n    collected 1 items\n\n    test_sample.py F\n\n    ================================== FAILURES ===================================\n    _________________________________ test_answer _________________________________\n\n        def test_answer():\n    >       assert inc(3) == 5\n    E       assert 4 == 5\n    E        +  where 4 = inc(3)\n\n    test_sample.py:5: AssertionError\n    ========================== 1 failed in 0.04 seconds ===========================\n\n\nDue to ``pytest``'s detailed assertion introspection, only plain ``assert`` statements are used. See `getting-started <https://docs.pytest.org/en/stable/getting-started.html#our-first-test-run>`_ for more examples.\n\n\nFeatures\n--------\n\n- Detailed info on failing `assert statements <https://docs.pytest.org/en/stable/how-to/assert.html>`_ (no need to remember ``self.assert*`` names)\n\n- `Auto-discovery\n  <https://docs.pytest.org/en/stable/explanation/goodpractices.html#python-test-discovery>`_\n  of test modules and functions\n\n- `Modular fixtures <https://docs.pytest.org/en/stable/explanation/fixtures.html>`_ for\n  managing small or parametrized long-lived test resources\n\n- Can run `unittest <https://docs.pytest.org/en/stable/how-to/unittest.html>`_ (or trial)\n  test suites out of the box\n\n- Python 3.9+ or PyPy3\n\n- Rich plugin architecture, with over 1300+ `external plugins <https://docs.pytest.org/en/latest/reference/plugin_list.html>`_ and thriving community\n\n\nDocumentation\n-------------\n\nFor full documentation, including installation, tutorials and PDF documents, please see https://docs.pytest.org/en/stable/.\n\n\nBugs/Requests\n-------------\n\nPlease use the `GitHub issue tracker <https://github.com/pytest-dev/pytest/issues>`_ to submit bugs or request features.\n\n\nChangelog\n---------\n\nConsult the `Changelog <https://docs.pytest.org/en/stable/changelog.html>`__ page for fixes and enhancements of each version.\n\n\nSupport pytest\n--------------\n\n`Open Collective`_ is an online funding platform for open and transparent communities.\nIt provides tools to raise money and share your finances in full transparency.\n\nIt is the platform of choice for individuals and companies that want to make one-time or\nmonthly donations directly to the project.\n\nSee more details in the `pytest collective`_.\n\n.. _Open Collective: https://opencollective.com\n.. _pytest collective: https://opencollective.com/pytest\n\n\npytest for enterprise\n---------------------\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of pytest and thousands of other packages are working with Tidelift to deliver commercial support and\nmaintenance for the open source dependencies you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use.\n\n`Learn more. <https://tidelift.com/subscription/pkg/pypi-pytest?utm_source=pypi-pytest&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_\n\nSecurity\n^^^^^^^^\n\npytest has never been associated with a security vulnerability, but in any case, to report a\nsecurity vulnerability please use the `Tidelift security contact <https://tidelift.com/security>`_.\nTidelift will coordinate the fix and disclosure.\n\n\nLicense\n-------\n\nCopyright Holger Krekel and others, 2004.\n\nDistributed under the terms of the `MIT`_ license, pytest is free and open source software.\n\n.. _`MIT`: https://github.com/pytest-dev/pytest/blob/main/LICENSE\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "test",
          "unittest"
        ],
        "author": "Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin, Others (See AUTHORS)",
        "license": "MIT",
        "license_file": [
          "LICENSE",
          "AUTHORS"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: MacOS",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Testing",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "colorama>=0.4; sys_platform == \"win32\"",
          "exceptiongroup>=1; python_version < \"3.11\"",
          "iniconfig>=1",
          "packaging>=20",
          "pluggy<2,>=1.5",
          "pygments>=2.7.2",
          "tomli>=1; python_version < \"3.11\"",
          "argcomplete; extra == \"dev\"",
          "attrs>=19.2; extra == \"dev\"",
          "hypothesis>=3.56; extra == \"dev\"",
          "mock; extra == \"dev\"",
          "requests; extra == \"dev\"",
          "setuptools; extra == \"dev\"",
          "xmlschema; extra == \"dev\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://docs.pytest.org/en/stable/changelog.html",
          "Contact, https://docs.pytest.org/en/stable/contact.html",
          "Funding, https://docs.pytest.org/en/stable/sponsor.html",
          "Homepage, https://docs.pytest.org/en/latest/",
          "Source, https://github.com/pytest-dev/pytest",
          "Tracker, https://github.com/pytest-dev/pytest/issues"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4e/f1/ab0395f8a79933577cdd996dd2f9aa6014af9535f65dddcf88204682fe62/aiohttp-3.13.3-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=693781c45a4033d31d4187d2436f5ac701e7bbfe5df40d917736108c1cc7436e",
          "hashes": {
            "sha256": "693781c45a4033d31d4187d2436f5ac701e7bbfe5df40d917736108c1cc7436e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "aiohttp",
        "version": "3.13.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Async http client/server framework (asyncio)",
        "description": "==================================\r\nAsync http client/server framework\r\n==================================\r\n\r\n.. image:: https://raw.githubusercontent.com/aio-libs/aiohttp/master/docs/aiohttp-plain.svg\r\n   :height: 64px\r\n   :width: 64px\r\n   :alt: aiohttp logo\r\n\r\n|\r\n\r\n.. image:: https://github.com/aio-libs/aiohttp/workflows/CI/badge.svg\r\n   :target: https://github.com/aio-libs/aiohttp/actions?query=workflow%3ACI\r\n   :alt: GitHub Actions status for master branch\r\n\r\n.. image:: https://codecov.io/gh/aio-libs/aiohttp/branch/master/graph/badge.svg\r\n   :target: https://codecov.io/gh/aio-libs/aiohttp\r\n   :alt: codecov.io status for master branch\r\n\r\n.. image:: https://badge.fury.io/py/aiohttp.svg\r\n   :target: https://pypi.org/project/aiohttp\r\n   :alt: Latest PyPI package version\r\n\r\n.. image:: https://img.shields.io/pypi/dm/aiohttp\r\n   :target: https://pypistats.org/packages/aiohttp\r\n   :alt: Downloads count\r\n\r\n.. image:: https://readthedocs.org/projects/aiohttp/badge/?version=latest\r\n   :target: https://docs.aiohttp.org/\r\n   :alt: Latest Read The Docs\r\n\r\n.. image:: https://img.shields.io/endpoint?url=https://codspeed.io/badge.json\r\n   :target: https://codspeed.io/aio-libs/aiohttp\r\n   :alt: Codspeed.io status for aiohttp\r\n\r\n\r\nKey Features\r\n============\r\n\r\n- Supports both client and server side of HTTP protocol.\r\n- Supports both client and server Web-Sockets out-of-the-box and avoids\r\n  Callback Hell.\r\n- Provides Web-server with middleware and pluggable routing.\r\n\r\n\r\nGetting started\r\n===============\r\n\r\nClient\r\n------\r\n\r\nTo get something from the web:\r\n\r\n.. code-block:: python\r\n\r\n  import aiohttp\r\n  import asyncio\r\n\r\n  async def main():\r\n\r\n      async with aiohttp.ClientSession() as session:\r\n          async with session.get('http://python.org') as response:\r\n\r\n              print(\"Status:\", response.status)\r\n              print(\"Content-type:\", response.headers['content-type'])\r\n\r\n              html = await response.text()\r\n              print(\"Body:\", html[:15], \"...\")\r\n\r\n  asyncio.run(main())\r\n\r\nThis prints:\r\n\r\n.. code-block::\r\n\r\n    Status: 200\r\n    Content-type: text/html; charset=utf-8\r\n    Body: <!doctype html> ...\r\n\r\nComing from `requests <https://requests.readthedocs.io/>`_ ? Read `why we need so many lines <https://aiohttp.readthedocs.io/en/latest/http_request_lifecycle.html>`_.\r\n\r\nServer\r\n------\r\n\r\nAn example using a simple server:\r\n\r\n.. code-block:: python\r\n\r\n    # examples/server_simple.py\r\n    from aiohttp import web\r\n\r\n    async def handle(request):\r\n        name = request.match_info.get('name', \"Anonymous\")\r\n        text = \"Hello, \" + name\r\n        return web.Response(text=text)\r\n\r\n    async def wshandle(request):\r\n        ws = web.WebSocketResponse()\r\n        await ws.prepare(request)\r\n\r\n        async for msg in ws:\r\n            if msg.type == web.WSMsgType.text:\r\n                await ws.send_str(\"Hello, {}\".format(msg.data))\r\n            elif msg.type == web.WSMsgType.binary:\r\n                await ws.send_bytes(msg.data)\r\n            elif msg.type == web.WSMsgType.close:\r\n                break\r\n\r\n        return ws\r\n\r\n\r\n    app = web.Application()\r\n    app.add_routes([web.get('/', handle),\r\n                    web.get('/echo', wshandle),\r\n                    web.get('/{name}', handle)])\r\n\r\n    if __name__ == '__main__':\r\n        web.run_app(app)\r\n\r\n\r\nDocumentation\r\n=============\r\n\r\nhttps://aiohttp.readthedocs.io/\r\n\r\n\r\nDemos\r\n=====\r\n\r\nhttps://github.com/aio-libs/aiohttp-demos\r\n\r\n\r\nExternal links\r\n==============\r\n\r\n* `Third party libraries\r\n  <http://aiohttp.readthedocs.io/en/latest/third_party.html>`_\r\n* `Built with aiohttp\r\n  <http://aiohttp.readthedocs.io/en/latest/built_with.html>`_\r\n* `Powered by aiohttp\r\n  <http://aiohttp.readthedocs.io/en/latest/powered_by.html>`_\r\n\r\nFeel free to make a Pull Request for adding your link to these pages!\r\n\r\n\r\nCommunication channels\r\n======================\r\n\r\n*aio-libs Discussions*: https://github.com/aio-libs/aiohttp/discussions\r\n\r\n*Matrix*: `#aio-libs:matrix.org <https://matrix.to/#/#aio-libs:matrix.org>`_\r\n\r\nWe support `Stack Overflow\r\n<https://stackoverflow.com/questions/tagged/aiohttp>`_.\r\nPlease add *aiohttp* tag to your question there.\r\n\r\nRequirements\r\n============\r\n\r\n- attrs_\r\n- multidict_\r\n- yarl_\r\n- frozenlist_\r\n\r\nOptionally you may install the aiodns_ library (highly recommended for sake of speed).\r\n\r\n.. _aiodns: https://pypi.python.org/pypi/aiodns\r\n.. _attrs: https://github.com/python-attrs/attrs\r\n.. _multidict: https://pypi.python.org/pypi/multidict\r\n.. _frozenlist: https://pypi.org/project/frozenlist/\r\n.. _yarl: https://pypi.python.org/pypi/yarl\r\n.. _async-timeout: https://pypi.python.org/pypi/async_timeout\r\n\r\nLicense\r\n=======\r\n\r\n``aiohttp`` is offered under the Apache 2 license.\r\n\r\n\r\nKeepsafe\r\n========\r\n\r\nThe aiohttp community would like to thank Keepsafe\r\n(https://www.getkeepsafe.com) for its support in the early days of\r\nthe project.\r\n\r\n\r\nSource code\r\n===========\r\n\r\nThe latest developer version is available in a GitHub repository:\r\nhttps://github.com/aio-libs/aiohttp\r\n\r\nBenchmarks\r\n==========\r\n\r\nIf you are interested in efficiency, the AsyncIO community maintains a\r\nlist of benchmarks on the official wiki:\r\nhttps://github.com/python/asyncio/wiki/Benchmarks\r\n\r\n--------\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs:matrix.org\r\n   :alt: Matrix Room â€” #aio-libs:matrix.org\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs-space:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs-space%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs-space:matrix.org\r\n   :alt: Matrix Space â€” #aio-libs-space:matrix.org\r\n\r\n.. image:: https://insights.linuxfoundation.org/api/badge/health-score?project=aiohttp\r\n   :target: https://insights.linuxfoundation.org/project/aiohttp\r\n   :alt: LFX Health Score\r\n",
        "description_content_type": "text/x-rst",
        "maintainer_email": "aiohttp team <team@aiohttp.org>",
        "license": "Apache-2.0 AND MIT",
        "license_file": [
          "LICENSE.txt",
          "vendor/llhttp/LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: AsyncIO",
          "Intended Audience :: Developers",
          "Operating System :: POSIX",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "aiohappyeyeballs>=2.5.0",
          "aiosignal>=1.4.0",
          "async-timeout<6.0,>=4.0; python_version < \"3.11\"",
          "attrs>=17.3.0",
          "frozenlist>=1.1.1",
          "multidict<7.0,>=4.5",
          "propcache>=0.2.0",
          "yarl<2.0,>=1.17.0",
          "aiodns>=3.3.0; extra == \"speedups\"",
          "Brotli>=1.2; platform_python_implementation == \"CPython\" and extra == \"speedups\"",
          "brotlicffi>=1.2; platform_python_implementation != \"CPython\" and extra == \"speedups\"",
          "backports.zstd; (platform_python_implementation == \"CPython\" and python_version < \"3.14\") and extra == \"speedups\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/aio-libs/aiohttp",
          "Chat: Matrix, https://matrix.to/#/#aio-libs:matrix.org",
          "Chat: Matrix Space, https://matrix.to/#/#aio-libs-space:matrix.org",
          "CI: GitHub Actions, https://github.com/aio-libs/aiohttp/actions?query=workflow%3ACI",
          "Coverage: codecov, https://codecov.io/github/aio-libs/aiohttp",
          "Docs: Changelog, https://docs.aiohttp.org/en/stable/changes.html",
          "Docs: RTD, https://docs.aiohttp.org",
          "GitHub: issues, https://github.com/aio-libs/aiohttp/issues",
          "GitHub: repo, https://github.com/aio-libs/aiohttp"
        ],
        "provides_extra": [
          "speedups"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/38/0e/27be9fdef66e72d64c0cdc3cc2823101b80585f8119b5c112c2e8f5f7dab/anyio-4.12.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d405828884fc140aa80a3c667b8beed277f1dfedec42ba031bd6ac3db606ab6c",
          "hashes": {
            "sha256": "d405828884fc140aa80a3c667b8beed277f1dfedec42ba031bd6ac3db606ab6c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "anyio",
        "version": "4.12.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "High-level concurrency and networking framework on top of asyncio or Trio",
        "description": ".. image:: https://github.com/agronholm/anyio/actions/workflows/test.yml/badge.svg\n  :target: https://github.com/agronholm/anyio/actions/workflows/test.yml\n  :alt: Build Status\n.. image:: https://coveralls.io/repos/github/agronholm/anyio/badge.svg?branch=master\n  :target: https://coveralls.io/github/agronholm/anyio?branch=master\n  :alt: Code Coverage\n.. image:: https://readthedocs.org/projects/anyio/badge/?version=latest\n  :target: https://anyio.readthedocs.io/en/latest/?badge=latest\n  :alt: Documentation\n.. image:: https://badges.gitter.im/gitterHQ/gitter.svg\n  :target: https://gitter.im/python-trio/AnyIO\n  :alt: Gitter chat\n\nAnyIO is an asynchronous networking and concurrency library that works on top of either asyncio_ or\nTrio_. It implements Trio-like `structured concurrency`_ (SC) on top of asyncio and works in harmony\nwith the native SC of Trio itself.\n\nApplications and libraries written against AnyIO's API will run unmodified on either asyncio_ or\nTrio_. AnyIO can also be adopted into a library or application incrementally â€“ bit by bit, no full\nrefactoring necessary. It will blend in with the native libraries of your chosen backend.\n\nTo find out why you might want to use AnyIO's APIs instead of asyncio's, you can read about it\n`here <https://anyio.readthedocs.io/en/stable/why.html>`_.\n\nDocumentation\n-------------\n\nView full documentation at: https://anyio.readthedocs.io/\n\nFeatures\n--------\n\nAnyIO offers the following functionality:\n\n* Task groups (nurseries_ in trio terminology)\n* High-level networking (TCP, UDP and UNIX sockets)\n\n  * `Happy eyeballs`_ algorithm for TCP connections (more robust than that of asyncio on Python\n    3.8)\n  * async/await style UDP sockets (unlike asyncio where you still have to use Transports and\n    Protocols)\n\n* A versatile API for byte streams and object streams\n* Inter-task synchronization and communication (locks, conditions, events, semaphores, object\n  streams)\n* Worker threads\n* Subprocesses\n* Subinterpreter support for code parallelization (on Python 3.13 and later)\n* Asynchronous file I/O (using worker threads)\n* Signal handling\n* Asynchronous version of the functools_ module\n\nAnyIO also comes with its own pytest_ plugin which also supports asynchronous fixtures.\nIt even works with the popular Hypothesis_ library.\n\n.. _asyncio: https://docs.python.org/3/library/asyncio.html\n.. _Trio: https://github.com/python-trio/trio\n.. _structured concurrency: https://en.wikipedia.org/wiki/Structured_concurrency\n.. _nurseries: https://trio.readthedocs.io/en/stable/reference-core.html#nurseries-and-spawning\n.. _Happy eyeballs: https://en.wikipedia.org/wiki/Happy_Eyeballs\n.. _pytest: https://docs.pytest.org/en/latest/\n.. _functools: https://docs.python.org/3/library/functools.html\n.. _Hypothesis: https://hypothesis.works/\n",
        "description_content_type": "text/x-rst",
        "author_email": "Alex GrÃ¶nholm <alex.gronholm@nextday.fi>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Framework :: AnyIO",
          "Typing :: Typed",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_dist": [
          "exceptiongroup>=1.0.2; python_version < \"3.11\"",
          "idna>=2.8",
          "typing_extensions>=4.5; python_version < \"3.13\"",
          "trio>=0.32.0; python_version >= \"3.10\" and extra == \"trio\"",
          "trio>=0.31.0; python_version < \"3.10\" and extra == \"trio\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://anyio.readthedocs.io/en/latest/",
          "Changelog, https://anyio.readthedocs.io/en/stable/versionhistory.html",
          "Source code, https://github.com/agronholm/anyio",
          "Issue tracker, https://github.com/agronholm/anyio/issues"
        ],
        "provides_extra": [
          "trio"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4c/b6/4e29b74bb40daa7580310a5ff0df5f121a08ce98340e01a960b668468aab/cloudevents-1.12.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=49196267f5f963d87ae156f93fc0fa32f4af69485f2c8e62e0db8b0b4b8b8921",
          "hashes": {
            "sha256": "49196267f5f963d87ae156f93fc0fa32f4af69485f2c8e62e0db8b0b4b8b8921"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "cloudevents",
        "version": "1.12.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "provides-extra",
          "requires-dist",
          "summary"
        ],
        "summary": "CloudEvents Python SDK",
        "description": "# Python SDK for [CloudEvents](https://github.com/cloudevents/spec)\n\n[![PyPI version](https://badge.fury.io/py/cloudevents.svg)](https://badge.fury.io/py/cloudevents)\n\n## Status\n\nThis SDK is still considered a work in progress, therefore things might (and\nwill) break with every update.\n\nThis SDK current supports the following versions of CloudEvents:\n\n- v1.0\n- v0.3\n\n## Python SDK\n\nPackage **cloudevents** provides primitives to work with CloudEvents specification:\nhttps://github.com/cloudevents/spec.\n\n### Installing\n\nThe CloudEvents SDK can be installed with pip:\n\n```\npip install cloudevents\n```\n\n## Sending CloudEvents\n\nBelow we will provide samples on how to send cloudevents using the popular\n[`requests`](http://docs.python-requests.org) library.\n\n### Binary HTTP CloudEvent\n\n```python\nfrom cloudevents.http import CloudEvent\nfrom cloudevents.conversion import to_binary\nimport requests\n\n# Create a CloudEvent\n# - The CloudEvent \"id\" is generated if omitted. \"specversion\" defaults to \"1.0\".\nattributes = {\n    \"type\": \"com.example.sampletype1\",\n    \"source\": \"https://example.com/event-producer\",\n}\ndata = {\"message\": \"Hello World!\"}\nevent = CloudEvent(attributes, data)\n\n# Creates the HTTP request representation of the CloudEvent in binary content mode\nheaders, body = to_binary(event)\n\n# POST\nrequests.post(\"<some-url>\", data=body, headers=headers)\n```\n\n### Structured HTTP CloudEvent\n\n```python\nfrom cloudevents.conversion import to_structured\nfrom cloudevents.http import CloudEvent\nimport requests\n\n# Create a CloudEvent\n# - The CloudEvent \"id\" is generated if omitted. \"specversion\" defaults to \"1.0\".\nattributes = {\n    \"type\": \"com.example.sampletype2\",\n    \"source\": \"https://example.com/event-producer\",\n}\ndata = {\"message\": \"Hello World!\"}\nevent = CloudEvent(attributes, data)\n\n# Creates the HTTP request representation of the CloudEvent in structured content mode\nheaders, body = to_structured(event)\n\n# POST\nrequests.post(\"<some-url>\", data=body, headers=headers)\n```\n\nYou can find a complete example of turning a CloudEvent into a HTTP request\n[in the samples' directory](samples/http-json-cloudevents/client.py).\n\n## Receiving CloudEvents\n\nThe code below shows how to consume a cloudevent using the popular python web framework\n[flask](https://flask.palletsprojects.com/en/2.2.x/quickstart/):\n\n```python\nfrom flask import Flask, request\n\nfrom cloudevents.http import from_http\n\napp = Flask(__name__)\n\n\n# create an endpoint at http://localhost:/3000/\n@app.route(\"/\", methods=[\"POST\"])\ndef home():\n    # create a CloudEvent\n    event = from_http(request.headers, request.get_data())\n\n    # you can access cloudevent fields as seen below\n    print(\n        f\"Found {event['id']} from {event['source']} with type \"\n        f\"{event['type']} and specversion {event['specversion']}\"\n    )\n\n    return \"\", 204\n\n\nif __name__ == \"__main__\":\n    app.run(port=3000)\n```\n\nYou can find a complete example of turning a CloudEvent into a HTTP request\n[in the samples' directory](samples/http-json-cloudevents/json_sample_server.py).\n\n## SDK versioning\n\nThe goal of this package is to provide support for all released versions of CloudEvents,\nideally while maintaining the same API. It will use semantic versioning\nwith following rules:\n\n- MAJOR version increments when backwards incompatible changes is introduced.\n- MINOR version increments when backwards compatible feature is introduced\n  INCLUDING support for new CloudEvents version.\n- PATCH version increments when a backwards compatible bug fix is introduced.\n\n## Community\n\n- There are bi-weekly calls immediately following the [Serverless/CloudEvents\n  call](https://github.com/cloudevents/spec#meeting-time) at\n  9am PT (US Pacific). Which means they will typically start at 10am PT, but\n  if the other call ends early then the SDK call will start early as well.\n  See the [CloudEvents meeting minutes](https://docs.google.com/document/d/1OVF68rpuPK5shIHILK9JOqlZBbfe91RNzQ7u_P7YCDE/edit#)\n  to determine which week will have the call.\n- Slack: #cloudeventssdk channel under\n  [CNCF's Slack workspace](https://slack.cncf.io/).\n- Email: https://lists.cncf.io/g/cncf-cloudevents-sdk\n- Contact for additional information: Denis Makogon (`@denysmakogon` on slack).\n\nEach SDK may have its own unique processes, tooling and guidelines, common\ngovernance related material can be found in the\n[CloudEvents `docs`](https://github.com/cloudevents/spec/tree/main/docs)\ndirectory. In particular, in there you will find information concerning\nhow SDK projects are\n[managed](https://github.com/cloudevents/spec/blob/main/docs/GOVERNANCE.md),\n[guidelines](https://github.com/cloudevents/spec/blob/main/docs/SDK-maintainer-guidelines.md)\nfor how PR reviews and approval, and our\n[Code of Conduct](https://github.com/cloudevents/spec/blob/main/docs/GOVERNANCE.md#additional-information)\ninformation.\n\nIf there is a security concern with one of the CloudEvents specifications, or\nwith one of the project's SDKs, please send an email to\n[cncf-cloudevents-security@lists.cncf.io](mailto:cncf-cloudevents-security@lists.cncf.io).\n\n## Additional SDK Resources\n\n- [List of current active maintainers](MAINTAINERS.md)\n- [How to contribute to the project](CONTRIBUTING.md)\n- [SDK's License](LICENSE)\n- [SDK's Release process](RELEASING.md)\n\n## Maintenance\n\nWe use [black][black] and [isort][isort] for autoformatting. We set up a [tox][tox]\nenvironment to reformat the codebase.\n\ne.g.\n\n```bash\npip install tox\ntox -e reformat\n```\n\nFor information on releasing version bumps see [RELEASING.md](RELEASING.md)\n\n[black]: https://black.readthedocs.io/\n[isort]: https://pycqa.github.io/isort/\n[tox]: https://tox.wiki/\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "CloudEvents",
          "Eventing",
          "Serverless"
        ],
        "home_page": "https://github.com/cloudevents/sdk-python",
        "author": "The Cloud Events Contributors",
        "author_email": "cncfcloudevents@gmail.com",
        "license": "https://www.apache.org/licenses/LICENSE-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Development Status :: 5 - Production/Stable",
          "Operating System :: OS Independent",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "deprecation<3.0,>=2.0",
          "pydantic<3.0,>=1.0.0; extra == \"pydantic\""
        ],
        "provides_extra": [
          "pydantic"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=a352e7e428770286cc899e2542b6cdaedb2b4953ff269a210103ec58f6198a61",
          "hashes": {
            "sha256": "a352e7e428770286cc899e2542b6cdaedb2b4953ff269a210103ec58f6198a61"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "defusedxml",
        "version": "0.7.1",
        "platform": [
          "all"
        ],
        "summary": "XML bomb protection for Python stdlib modules",
        "description": "===================================================\ndefusedxml -- defusing XML bombs and other exploits\n===================================================\n\n.. image:: https://img.shields.io/pypi/v/defusedxml.svg\n    :target: https://pypi.org/project/defusedxml/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/defusedxml.svg\n    :target: https://pypi.org/project/defusedxml/\n    :alt: Supported Python versions\n\n.. image:: https://travis-ci.org/tiran/defusedxml.svg?branch=master\n    :target: https://travis-ci.org/tiran/defusedxml\n    :alt: Travis CI\n\n.. image:: https://codecov.io/github/tiran/defusedxml/coverage.svg?branch=master\n    :target: https://codecov.io/github/tiran/defusedxml?branch=master\n    :alt: codecov\n\n.. image:: https://img.shields.io/pypi/dm/defusedxml.svg\n    :target: https://pypistats.org/packages/defusedxml\n    :alt: PyPI downloads\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n    :alt: Code style: black\n\n..\n\n    \"It's just XML, what could probably go wrong?\"\n\nChristian Heimes <christian@python.org>\n\nSynopsis\n========\n\nThe results of an attack on a vulnerable XML library can be fairly dramatic.\nWith just a few hundred **Bytes** of XML data an attacker can occupy several\n**Gigabytes** of memory within **seconds**. An attacker can also keep\nCPUs busy for a long time with a small to medium size request. Under some\ncircumstances it is even possible to access local files on your\nserver, to circumvent a firewall, or to abuse services to rebound attacks to\nthird parties.\n\nThe attacks use and abuse less common features of XML and its parsers. The\nmajority of developers are unacquainted with features such as processing\ninstructions and entity expansions that XML inherited from SGML. At best\nthey know about ``<!DOCTYPE>`` from experience with HTML but they are not\naware that a document type definition (DTD) can generate an HTTP request\nor load a file from the file system.\n\nNone of the issues is new. They have been known for a long time. Billion\nlaughs was first reported in 2003. Nevertheless some XML libraries and\napplications are still vulnerable and even heavy users of XML are\nsurprised by these features. It's hard to say whom to blame for the\nsituation. It's too short sighted to shift all blame on XML parsers and\nXML libraries for using insecure default settings. After all they\nproperly implement XML specifications. Application developers must not rely\nthat a library is always configured for security and potential harmful data\nby default.\n\n\n.. contents:: Table of Contents\n   :depth: 2\n\n\nAttack vectors\n==============\n\nbillion laughs / exponential entity expansion\n---------------------------------------------\n\nThe `Billion Laughs`_ attack -- also known as exponential entity expansion --\nuses multiple levels of nested entities. The original example uses 9 levels\nof 10 expansions in each level to expand the string ``lol`` to a string of\n3 * 10 :sup:`9` bytes, hence the name \"billion laughs\". The resulting string\noccupies 3 GB (2.79 GiB) of memory; intermediate strings require additional\nmemory. Because most parsers don't cache the intermediate step for every\nexpansion it is repeated over and over again. It increases the CPU load even\nmore.\n\nAn XML document of just a few hundred bytes can disrupt all services on a\nmachine within seconds.\n\nExample XML::\n\n    <!DOCTYPE xmlbomb [\n    <!ENTITY a \"1234567890\" >\n    <!ENTITY b \"&a;&a;&a;&a;&a;&a;&a;&a;\">\n    <!ENTITY c \"&b;&b;&b;&b;&b;&b;&b;&b;\">\n    <!ENTITY d \"&c;&c;&c;&c;&c;&c;&c;&c;\">\n    ]>\n    <bomb>&d;</bomb>\n\n\nquadratic blowup entity expansion\n---------------------------------\n\nA quadratic blowup attack is similar to a `Billion Laughs`_ attack; it abuses\nentity expansion, too. Instead of nested entities it repeats one large entity\nwith a couple of thousand chars over and over again. The attack isn't as\nefficient as the exponential case but it avoids triggering countermeasures of\nparsers against heavily nested entities. Some parsers limit the depth and\nbreadth of a single entity but not the total amount of expanded text\nthroughout an entire XML document.\n\nA medium-sized XML document with a couple of hundred kilobytes can require a\ncouple of hundred MB to several GB of memory. When the attack is combined\nwith some level of nested expansion an attacker is able to achieve a higher\nratio of success.\n\n::\n\n    <!DOCTYPE bomb [\n    <!ENTITY a \"xxxxxxx... a couple of ten thousand chars\">\n    ]>\n    <bomb>&a;&a;&a;... repeat</bomb>\n\n\nexternal entity expansion (remote)\n----------------------------------\n\nEntity declarations can contain more than just text for replacement. They can\nalso point to external resources by public identifiers or system identifiers.\nSystem identifiers are standard URIs. When the URI is a URL (e.g. a\n``http://`` locator) some parsers download the resource from the remote\nlocation and embed them into the XML document verbatim.\n\nSimple example of a parsed external entity::\n\n    <!DOCTYPE external [\n    <!ENTITY ee SYSTEM \"http://www.python.org/some.xml\">\n    ]>\n    <root>&ee;</root>\n\nThe case of parsed external entities works only for valid XML content. The\nXML standard also supports unparsed external entities with a\n``NData declaration``.\n\nExternal entity expansion opens the door to plenty of exploits. An attacker\ncan abuse a vulnerable XML library and application to rebound and forward\nnetwork requests with the IP address of the server. It highly depends\non the parser and the application what kind of exploit is possible. For\nexample:\n\n* An attacker can circumvent firewalls and gain access to restricted\n  resources as all the requests are made from an internal and trustworthy\n  IP address, not from the outside.\n* An attacker can abuse a service to attack, spy on or DoS your servers but\n  also third party services. The attack is disguised with the IP address of\n  the server and the attacker is able to utilize the high bandwidth of a big\n  machine.\n* An attacker can exhaust additional resources on the machine, e.g. with\n  requests to a service that doesn't respond or responds with very large\n  files.\n* An attacker may gain knowledge, when, how often and from which IP address\n  an XML document is accessed.\n* An attacker could send mail from inside your network if the URL handler\n  supports ``smtp://`` URIs.\n\n\nexternal entity expansion (local file)\n--------------------------------------\n\nExternal entities with references to local files are a sub-case of external\nentity expansion. It's listed as an extra attack because it deserves extra\nattention. Some XML libraries such as lxml disable network access by default\nbut still allow entity expansion with local file access by default. Local\nfiles are either referenced with a ``file://`` URL or by a file path (either\nrelative or absolute).\n\nAn attacker may be able to access and download all files that can be read by\nthe application process. This may include critical configuration files, too.\n\n::\n\n    <!DOCTYPE external [\n    <!ENTITY ee SYSTEM \"file:///PATH/TO/simple.xml\">\n    ]>\n    <root>&ee;</root>\n\n\nDTD retrieval\n-------------\n\nThis case is similar to external entity expansion, too. Some XML libraries\nlike Python's xml.dom.pulldom retrieve document type definitions from remote\nor local locations. Several attack scenarios from the external entity case\napply to this issue as well.\n\n::\n\n    <?xml version=\"1.0\" encoding=\"utf-8\"?>\n    <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n      \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n    <html>\n        <head/>\n        <body>text</body>\n    </html>\n\n\nPython XML Libraries\n====================\n\n.. csv-table:: vulnerabilities and features\n   :header: \"kind\", \"sax\", \"etree\", \"minidom\", \"pulldom\", \"xmlrpc\", \"lxml\", \"genshi\"\n   :widths: 24, 7, 8, 8, 7, 8, 8, 8\n   :stub-columns: 0\n\n   \"billion laughs\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"False (1)\", \"False (5)\"\n   \"quadratic blowup\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"False (5)\"\n   \"external entity expansion (remote)\", \"**True**\", \"False (3)\", \"False (4)\", \"**True**\", \"false\", \"False (1)\", \"False (5)\"\n   \"external entity expansion (local file)\", \"**True**\", \"False (3)\", \"False (4)\", \"**True**\", \"false\", \"**True**\", \"False (5)\"\n   \"DTD retrieval\", \"**True**\", \"False\", \"False\", \"**True**\", \"false\", \"False (1)\", \"False\"\n   \"gzip bomb\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"**partly** (2)\", \"False\"\n   \"xpath support (7)\", \"False\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"False\"\n   \"xsl(t) support (7)\", \"False\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"False\"\n   \"xinclude support (7)\", \"False\", \"**True** (6)\", \"False\", \"False\", \"False\", \"**True** (6)\", \"**True**\"\n   \"C library\", \"expat\", \"expat\", \"expat\", \"expat\", \"expat\", \"libxml2\", \"expat\"\n\n1. Lxml is protected against billion laughs attacks and doesn't do network\n   lookups by default.\n2. libxml2 and lxml are not directly vulnerable to gzip decompression bombs\n   but they don't protect you against them either.\n3. xml.etree doesn't expand entities and raises a ParserError when an entity\n   occurs.\n4. minidom doesn't expand entities and simply returns the unexpanded entity\n   verbatim.\n5. genshi.input of genshi 0.6 doesn't support entity expansion and raises a\n   ParserError when an entity occurs.\n6. Library has (limited) XInclude support but requires an additional step to\n   process inclusion.\n7. These are features but they may introduce exploitable holes, see\n   `Other things to consider`_\n\n\nSettings in standard library\n----------------------------\n\n\nxml.sax.handler Features\n........................\n\nfeature_external_ges (http://xml.org/sax/features/external-general-entities)\n  disables external entity expansion\n\nfeature_external_pes (http://xml.org/sax/features/external-parameter-entities)\n  the option is ignored and doesn't modify any functionality\n\nDOM xml.dom.xmlbuilder.Options\n..............................\n\nexternal_parameter_entities\n  ignored\n\nexternal_general_entities\n  ignored\n\nexternal_dtd_subset\n  ignored\n\nentities\n  unsure\n\n\ndefusedxml\n==========\n\nThe `defusedxml package`_ (`defusedxml on PyPI`_)\ncontains several Python-only workarounds and fixes\nfor denial of service and other vulnerabilities in Python's XML libraries.\nIn order to benefit from the protection you just have to import and use the\nlisted functions / classes from the right defusedxml module instead of the\noriginal module. Merely `defusedxml.xmlrpc`_ is implemented as monkey patch.\n\nInstead of::\n\n   >>> from xml.etree.ElementTree import parse\n   >>> et = parse(xmlfile)\n\nalter code to::\n\n   >>> from defusedxml.ElementTree import parse\n   >>> et = parse(xmlfile)\n\nAdditionally the package has an **untested** function to monkey patch\nall stdlib modules with ``defusedxml.defuse_stdlib()``.\n\nAll functions and parser classes accept three additional keyword arguments.\nThey return either the same objects as the original functions or compatible\nsubclasses.\n\nforbid_dtd (default: False)\n  disallow XML with a ``<!DOCTYPE>`` processing instruction and raise a\n  *DTDForbidden* exception when a DTD processing instruction is found.\n\nforbid_entities (default: True)\n  disallow XML with ``<!ENTITY>`` declarations inside the DTD and raise an\n  *EntitiesForbidden* exception when an entity is declared.\n\nforbid_external (default: True)\n  disallow any access to remote or local resources in external entities\n  or DTD and raising an *ExternalReferenceForbidden* exception when a DTD\n  or entity references an external resource.\n\n\ndefusedxml (package)\n--------------------\n\nDefusedXmlException, DTDForbidden, EntitiesForbidden,\nExternalReferenceForbidden, NotSupportedError\n\ndefuse_stdlib() (*experimental*)\n\n\ndefusedxml.cElementTree\n-----------------------\n\n**NOTE** ``defusedxml.cElementTree`` is deprecated and will be removed in a\nfuture release. Import from ``defusedxml.ElementTree`` instead.\n\nparse(), iterparse(), fromstring(), XMLParser\n\n\ndefusedxml.ElementTree\n-----------------------\n\nparse(), iterparse(), fromstring(), XMLParser\n\n\ndefusedxml.expatreader\n----------------------\n\ncreate_parser(), DefusedExpatParser\n\n\ndefusedxml.sax\n--------------\n\nparse(), parseString(), make_parser()\n\n\ndefusedxml.expatbuilder\n-----------------------\n\nparse(), parseString(), DefusedExpatBuilder, DefusedExpatBuilderNS\n\n\ndefusedxml.minidom\n------------------\n\nparse(), parseString()\n\n\ndefusedxml.pulldom\n------------------\n\nparse(), parseString()\n\n\ndefusedxml.xmlrpc\n-----------------\n\nThe fix is implemented as monkey patch for the stdlib's xmlrpc package (3.x)\nor xmlrpclib module (2.x). The function `monkey_patch()` enables the fixes,\n`unmonkey_patch()` removes the patch and puts the code in its former state.\n\nThe monkey patch protects against XML related attacks as well as\ndecompression bombs and excessively large requests or responses. The default\nsetting is 30 MB for requests, responses and gzip decompression. You can\nmodify the default by changing the module variable `MAX_DATA`. A value of\n`-1` disables the limit.\n\n\ndefusedxml.lxml\n---------------\n\n**DEPRECATED** The module is deprecated and will be removed in a future\nrelease.\n\nThe module acts as an *example* how you could protect code that uses\nlxml.etree. It implements a custom Element class that filters out\nEntity instances, a custom parser factory and a thread local storage for\nparser instances. It also has a check_docinfo() function which inspects\na tree for internal or external DTDs and entity declarations. In order to\ncheck for entities lxml > 3.0 is required.\n\nparse(), fromstring()\nRestrictedElement, GlobalParserTLS, getDefaultParser(), check_docinfo()\n\n\ndefusedexpat\n============\n\nThe `defusedexpat package`_ (`defusedexpat on PyPI`_)\ncomes with binary extensions and a\n`modified expat`_ library instead of the standard `expat parser`_. It's\nbasically a stand-alone version of the patches for Python's standard\nlibrary C extensions.\n\nModifications in expat\n----------------------\n\nnew definitions::\n\n  XML_BOMB_PROTECTION\n  XML_DEFAULT_MAX_ENTITY_INDIRECTIONS\n  XML_DEFAULT_MAX_ENTITY_EXPANSIONS\n  XML_DEFAULT_RESET_DTD\n\nnew XML_FeatureEnum members::\n\n  XML_FEATURE_MAX_ENTITY_INDIRECTIONS\n  XML_FEATURE_MAX_ENTITY_EXPANSIONS\n  XML_FEATURE_IGNORE_DTD\n\nnew XML_Error members::\n\n  XML_ERROR_ENTITY_INDIRECTIONS\n  XML_ERROR_ENTITY_EXPANSION\n\nnew API functions::\n\n  int XML_GetFeature(XML_Parser parser,\n                     enum XML_FeatureEnum feature,\n                     long *value);\n  int XML_SetFeature(XML_Parser parser,\n                     enum XML_FeatureEnum feature,\n                     long value);\n  int XML_GetFeatureDefault(enum XML_FeatureEnum feature,\n                            long *value);\n  int XML_SetFeatureDefault(enum XML_FeatureEnum feature,\n                            long value);\n\nXML_FEATURE_MAX_ENTITY_INDIRECTIONS\n   Limit the amount of indirections that are allowed to occur during the\n   expansion of a nested entity. A counter starts when an entity reference\n   is encountered. It resets after the entity is fully expanded. The limit\n   protects the parser against exponential entity expansion attacks (aka\n   billion laughs attack). When the limit is exceeded the parser stops and\n   fails with `XML_ERROR_ENTITY_INDIRECTIONS`.\n   A value of 0 disables the protection.\n\n   Supported range\n     0 .. UINT_MAX\n   Default\n     40\n\nXML_FEATURE_MAX_ENTITY_EXPANSIONS\n   Limit the total length of all entity expansions throughout the entire\n   document. The lengths of all entities are accumulated in a parser variable.\n   The setting protects against quadratic blowup attacks (lots of expansions\n   of a large entity declaration). When the sum of all entities exceeds\n   the limit, the parser stops and fails with `XML_ERROR_ENTITY_EXPANSION`.\n   A value of 0 disables the protection.\n\n   Supported range\n     0 .. UINT_MAX\n   Default\n     8 MiB\n\nXML_FEATURE_RESET_DTD\n   Reset all DTD information after the <!DOCTYPE> block has been parsed. When\n   the flag is set (default: false) all DTD information after the\n   endDoctypeDeclHandler has been called. The flag can be set inside the\n   endDoctypeDeclHandler. Without DTD information any entity reference in\n   the document body leads to `XML_ERROR_UNDEFINED_ENTITY`.\n\n   Supported range\n     0, 1\n   Default\n     0\n\n\nHow to avoid XML vulnerabilities\n================================\n\nBest practices\n--------------\n\n* Don't allow DTDs\n* Don't expand entities\n* Don't resolve externals\n* Limit parse depth\n* Limit total input size\n* Limit parse time\n* Favor a SAX or iterparse-like parser for potential large data\n* Validate and properly quote arguments to XSL transformations and\n  XPath queries\n* Don't use XPath expression from untrusted sources\n* Don't apply XSL transformations that come untrusted sources\n\n(based on Brad Hill's `Attacking XML Security`_)\n\n\nOther things to consider\n========================\n\nXML, XML parsers and processing libraries have more features and possible\nissue that could lead to DoS vulnerabilities or security exploits in\napplications. I have compiled an incomplete list of theoretical issues that\nneed further research and more attention. The list is deliberately pessimistic\nand a bit paranoid, too. It contains things that might go wrong under daffy\ncircumstances.\n\n\nattribute blowup / hash collision attack\n----------------------------------------\n\nXML parsers may use an algorithm with quadratic runtime O(n :sup:`2`) to\nhandle attributes and namespaces. If it uses hash tables (dictionaries) to\nstore attributes and namespaces the implementation may be vulnerable to\nhash collision attacks, thus reducing the performance to O(n :sup:`2`) again.\nIn either case an attacker is able to forge a denial of service attack with\nan XML document that contains thousands upon thousands of attributes in\na single node.\n\nI haven't researched yet if expat, pyexpat or libxml2 are vulnerable.\n\n\ndecompression bomb\n------------------\n\nThe issue of decompression bombs (aka `ZIP bomb`_) apply to all XML libraries\nthat can parse compressed XML stream like gzipped HTTP streams or LZMA-ed\nfiles. For an attacker it can reduce the amount of transmitted data by three\nmagnitudes or more. Gzip is able to compress 1 GiB zeros to roughly 1 MB,\nlzma is even better::\n\n    $ dd if=/dev/zero bs=1M count=1024 | gzip > zeros.gz\n    $ dd if=/dev/zero bs=1M count=1024 | lzma -z > zeros.xy\n    $ ls -sh zeros.*\n    1020K zeros.gz\n     148K zeros.xy\n\nNone of Python's standard XML libraries decompress streams except for\n``xmlrpclib``. The module is vulnerable <https://bugs.python.org/issue16043>\nto decompression bombs.\n\nlxml can load and process compressed data through libxml2 transparently.\nlibxml2 can handle even very large blobs of compressed data efficiently\nwithout using too much memory. But it doesn't protect applications from\ndecompression bombs. A carefully written SAX or iterparse-like approach can\nbe safe.\n\n\nProcessing Instruction\n----------------------\n\n`PI`_'s like::\n\n  <?xml-stylesheet type=\"text/xsl\" href=\"style.xsl\"?>\n\nmay impose more threats for XML processing. It depends if and how a\nprocessor handles processing instructions. The issue of URL retrieval with\nnetwork or local file access apply to processing instructions, too.\n\n\nOther DTD features\n------------------\n\n`DTD`_ has more features like ``<!NOTATION>``. I haven't researched how\nthese features may be a security threat.\n\n\nXPath\n-----\n\nXPath statements may introduce DoS vulnerabilities. Code should never execute\nqueries from untrusted sources. An attacker may also be able to create an XML\ndocument that makes certain XPath queries costly or resource hungry.\n\n\nXPath injection attacks\n-----------------------\n\nXPath injeciton attacks pretty much work like SQL injection attacks.\nArguments to XPath queries must be quoted and validated properly, especially\nwhen they are taken from the user. The page `Avoid the dangers of XPath injection`_\nlist some ramifications of XPath injections.\n\nPython's standard library doesn't have XPath support. Lxml supports\nparameterized XPath queries which does proper quoting. You just have to use\nits xpath() method correctly::\n\n   # DON'T\n   >>> tree.xpath(\"/tag[@id='%s']\" % value)\n\n   # instead do\n   >>> tree.xpath(\"/tag[@id=$tagid]\", tagid=name)\n\n\nXInclude\n--------\n\n`XML Inclusion`_ is another way to load and include external files::\n\n   <root xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n     <xi:include href=\"filename.txt\" parse=\"text\" />\n   </root>\n\nThis feature should be disabled when XML files from an untrusted source are\nprocessed. Some Python XML libraries and libxml2 support XInclude but don't\nhave an option to sandbox inclusion and limit it to allowed directories.\n\n\nXMLSchema location\n------------------\n\nA validating XML parser may download schema files from the information in a\n``xsi:schemaLocation`` attribute.\n\n::\n\n  <ead xmlns=\"urn:isbn:1-931666-22-9\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"urn:isbn:1-931666-22-9 http://www.loc.gov/ead/ead.xsd\">\n  </ead>\n\n\nXSL Transformation\n------------------\n\nYou should keep in mind that XSLT is a Turing complete language. Never\nprocess XSLT code from unknown or untrusted source! XSLT processors may\nallow you to interact with external resources in ways you can't even imagine.\nSome processors even support extensions that allow read/write access to file\nsystem, access to JRE objects or scripting with Jython.\n\nExample from `Attacking XML Security`_ for Xalan-J::\n\n    <xsl:stylesheet version=\"1.0\"\n     xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n     xmlns:rt=\"http://xml.apache.org/xalan/java/java.lang.Runtime\"\n     xmlns:ob=\"http://xml.apache.org/xalan/java/java.lang.Object\"\n     exclude-result-prefixes= \"rt ob\">\n     <xsl:template match=\"/\">\n       <xsl:variable name=\"runtimeObject\" select=\"rt:getRuntime()\"/>\n       <xsl:variable name=\"command\"\n         select=\"rt:exec($runtimeObject, &apos;c:\\Windows\\system32\\cmd.exe&apos;)\"/>\n       <xsl:variable name=\"commandAsString\" select=\"ob:toString($command)\"/>\n       <xsl:value-of select=\"$commandAsString\"/>\n     </xsl:template>\n    </xsl:stylesheet>\n\n\nRelated CVEs\n============\n\nCVE-2013-1664\n  Unrestricted entity expansion induces DoS vulnerabilities in Python XML\n  libraries (XML bomb)\n\nCVE-2013-1665\n  External entity expansion in Python XML libraries inflicts potential\n  security flaws and DoS vulnerabilities\n\n\nOther languages / frameworks\n=============================\n\nSeveral other programming languages and frameworks are vulnerable as well. A\ncouple of them are affected by the fact that libxml2 up to 2.9.0 has no\nprotection against quadratic blowup attacks. Most of them have potential\ndangerous default settings for entity expansion and external entities, too.\n\nPerl\n----\n\nPerl's XML::Simple is vulnerable to quadratic entity expansion and external\nentity expansion (both local and remote).\n\n\nRuby\n----\n\nRuby's REXML document parser is vulnerable to entity expansion attacks\n(both quadratic and exponential) but it doesn't do external entity\nexpansion by default. In order to counteract entity expansion you have to\ndisable the feature::\n\n  REXML::Document.entity_expansion_limit = 0\n\nlibxml-ruby and hpricot don't expand entities in their default configuration.\n\n\nPHP\n---\n\nPHP's SimpleXML API is vulnerable to quadratic entity expansion and loads\nentities from local and remote resources. The option ``LIBXML_NONET`` disables\nnetwork access but still allows local file access. ``LIBXML_NOENT`` seems to\nhave no effect on entity expansion in PHP 5.4.6.\n\n\nC# / .NET / Mono\n----------------\n\nInformation in `XML DoS and Defenses (MSDN)`_ suggest that .NET is\nvulnerable with its default settings. The article contains code snippets\nhow to create a secure XML reader::\n\n  XmlReaderSettings settings = new XmlReaderSettings();\n  settings.ProhibitDtd = false;\n  settings.MaxCharactersFromEntities = 1024;\n  settings.XmlResolver = null;\n  XmlReader reader = XmlReader.Create(stream, settings);\n\n\nJava\n----\n\nUntested. The documentation of Xerces and its `Xerces SecurityMananger`_\nsounds like Xerces is also vulnerable to billion laugh attacks with its\ndefault settings. It also does entity resolving when an\n``org.xml.sax.EntityResolver`` is configured. I'm not yet sure about the\ndefault setting here.\n\nJava specialists suggest to have a custom builder factory::\n\n  DocumentBuilderFactory builderFactory = DocumentBuilderFactory.newInstance();\n  builderFactory.setXIncludeAware(False);\n  builderFactory.setExpandEntityReferences(False);\n  builderFactory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, True);\n  # either\n  builderFactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", True);\n  # or if you need DTDs\n  builderFactory.setFeature(\"http://xml.org/sax/features/external-general-entities\", False);\n  builderFactory.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", False);\n  builderFactory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", False);\n  builderFactory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-dtd-grammar\", False);\n\n\nTODO\n====\n\n* DOM: Use xml.dom.xmlbuilder options for entity handling\n* SAX: take feature_external_ges and feature_external_pes (?) into account\n* test experimental monkey patching of stdlib modules\n* improve documentation\n\n\nLicense\n=======\n\nCopyright (c) 2013-2017 by Christian Heimes <christian@python.org>\n\nLicensed to PSF under a Contributor Agreement.\n\nSee https://www.python.org/psf/license for licensing details.\n\n\nAcknowledgements\n================\n\nBrett Cannon (Python Core developer)\n  review and code cleanup\n\nAntoine Pitrou (Python Core developer)\n  code review\n\nAaron Patterson, Ben Murphy and Michael Koziarski (Ruby community)\n  Many thanks to Aaron, Ben and Michael from the Ruby community for their\n  report and assistance.\n\nThierry Carrez (OpenStack)\n  Many thanks to Thierry for his report to the Python Security Response\n  Team on behalf of the OpenStack security team.\n\nCarl Meyer (Django)\n  Many thanks to Carl for his report to PSRT on behalf of the Django security\n  team.\n\nDaniel Veillard (libxml2)\n  Many thanks to Daniel for his insight and assistance with libxml2.\n\nsemantics GmbH (https://www.semantics.de/)\n  Many thanks to my employer semantics for letting me work on the issue\n  during working hours as part of semantics's open source initiative.\n\n\nReferences\n==========\n\n* `XML DoS and Defenses (MSDN)`_\n* `Billion Laughs`_ on Wikipedia\n* `ZIP bomb`_ on Wikipedia\n* `Configure SAX parsers for secure processing`_\n* `Testing for XML Injection`_\n\n.. _defusedxml package: https://github.com/tiran/defusedxml\n.. _defusedxml on PyPI: https://pypi.python.org/pypi/defusedxml\n.. _defusedexpat package: https://github.com/tiran/defusedexpat\n.. _defusedexpat on PyPI: https://pypi.python.org/pypi/defusedexpat\n.. _modified expat: https://github.com/tiran/expat\n.. _expat parser: http://expat.sourceforge.net/\n.. _Attacking XML Security: https://www.isecpartners.com/media/12976/iSEC-HILL-Attacking-XML-Security-bh07.pdf\n.. _Billion Laughs: https://en.wikipedia.org/wiki/Billion_laughs\n.. _XML DoS and Defenses (MSDN): https://msdn.microsoft.com/en-us/magazine/ee335713.aspx\n.. _ZIP bomb: https://en.wikipedia.org/wiki/Zip_bomb\n.. _DTD: https://en.wikipedia.org/wiki/Document_Type_Definition\n.. _PI: https://en.wikipedia.org/wiki/Processing_Instruction\n.. _Avoid the dangers of XPath injection: http://www.ibm.com/developerworks/xml/library/x-xpathinjection/index.html\n.. _Configure SAX parsers for secure processing: http://www.ibm.com/developerworks/xml/library/x-tipcfsx/index.html\n.. _Testing for XML Injection: https://www.owasp.org/index.php/Testing_for_XML_Injection_(OWASP-DV-008)\n.. _Xerces SecurityMananger: https://xerces.apache.org/xerces2-j/javadocs/xerces2/org/apache/xerces/util/SecurityManager.html\n.. _XML Inclusion: https://www.w3.org/TR/xinclude/#include_element\n\nChangelog\n=========\n\ndefusedxml 0.7.1\n---------------------\n\n*Release date: 08-Mar-2021*\n\n- Fix regression ``defusedxml.ElementTree.ParseError`` (#63)\n  The ``ParseError`` exception is now the same class object as\n  ``xml.etree.ElementTree.ParseError`` again.\n\n\ndefusedxml 0.7.0\n----------------\n\n*Release date: 4-Mar-2021*\n\n- No changes\n\n\ndefusedxml 0.7.0rc2\n-------------------\n\n*Release date: 12-Jan-2021*\n\n- Re-add and deprecate ``defusedxml.cElementTree``\n- Use GitHub Actions instead of TravisCI\n- Restore ``ElementTree`` attribute of ``xml.etree`` module after patching\n\ndefusedxml 0.7.0rc1\n-------------------\n\n*Release date: 04-May-2020*\n\n- Add support for Python 3.9\n- ``defusedxml.cElementTree`` is not available with Python 3.9.\n- Python 2 is deprecate. Support for Python 2 will be removed in 0.8.0.\n\n\ndefusedxml 0.6.0\n----------------\n\n*Release date: 17-Apr-2019*\n\n- Increase test coverage.\n- Add badges to README.\n\n\ndefusedxml 0.6.0rc1\n-------------------\n\n*Release date: 14-Apr-2019*\n\n- Test on Python 3.7 stable and 3.8-dev\n- Drop support for Python 3.4\n- No longer pass *html* argument to XMLParse. It has been deprecated and\n  ignored for a long time. The DefusedXMLParser still takes a html argument.\n  A deprecation warning is issued when the argument is False and a TypeError\n  when it's True.\n- defusedxml now fails early when pyexpat stdlib module is not available or\n  broken.\n- defusedxml.ElementTree.__all__ now lists ParseError as public attribute.\n- The defusedxml.ElementTree and defusedxml.cElementTree modules had a typo\n  and used XMLParse instead of XMLParser as an alias for DefusedXMLParser.\n  Both the old and fixed name are now available.\n\n\ndefusedxml 0.5.0\n----------------\n\n*Release date: 07-Feb-2017*\n\n- No changes\n\n\ndefusedxml 0.5.0.rc1\n--------------------\n\n*Release date: 28-Jan-2017*\n\n- Add compatibility with Python 3.6\n- Drop support for Python 2.6, 3.1, 3.2, 3.3\n- Fix lxml tests (XMLSyntaxError: Detected an entity reference loop)\n\n\ndefusedxml 0.4.1\n----------------\n\n*Release date: 28-Mar-2013*\n\n- Add more demo exploits, e.g. python_external.py and Xalan XSLT demos.\n- Improved documentation.\n\n\ndefusedxml 0.4\n--------------\n\n*Release date: 25-Feb-2013*\n\n- As per http://seclists.org/oss-sec/2013/q1/340 please REJECT\n  CVE-2013-0278, CVE-2013-0279 and CVE-2013-0280 and use CVE-2013-1664,\n  CVE-2013-1665 for OpenStack/etc.\n- Add missing parser_list argument to sax.make_parser(). The argument is\n  ignored, though. (thanks to Florian Apolloner)\n- Add demo exploit for external entity attack on Python's SAX parser, XML-RPC\n  and WebDAV.\n\n\ndefusedxml 0.3\n--------------\n\n*Release date: 19-Feb-2013*\n\n- Improve documentation\n\n\ndefusedxml 0.2\n--------------\n\n*Release date: 15-Feb-2013*\n\n- Rename ExternalEntitiesForbidden to ExternalReferenceForbidden\n- Rename defusedxml.lxml.check_dtd() to check_docinfo()\n- Unify argument names in callbacks\n- Add arguments and formatted representation to exceptions\n- Add forbid_external argument to all functions and classes\n- More tests\n- LOTS of documentation\n- Add example code for other languages (Ruby, Perl, PHP) and parsers (Genshi)\n- Add protection against XML and gzip attacks to xmlrpclib\n\ndefusedxml 0.1\n--------------\n\n*Release date: 08-Feb-2013*\n\n- Initial and internal release for PSRT review\n\n\n",
        "keywords": [
          "xml",
          "bomb",
          "DoS"
        ],
        "home_page": "https://github.com/tiran/defusedxml",
        "download_url": "https://pypi.python.org/pypi/defusedxml",
        "author": "Christian Heimes",
        "author_email": "christian@python.org",
        "maintainer": "Christian Heimes",
        "maintainer_email": "christian@python.org",
        "license": "PSFL",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Python Software Foundation License",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Text Processing :: Markup :: XML"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=a10811591210e1fb0e768a8c25517cabeabcba6f0bf96564f8ff45189f90b14a",
          "hashes": {
            "sha256": "a10811591210e1fb0e768a8c25517cabeabcba6f0bf96564f8ff45189f90b14a"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "deprecation",
        "version": "2.1.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "A library to handle automated deprecations",
        "description": "deprecation\n===========\n\n.. image:: https://readthedocs.org/projects/deprecation/badge/?version=latest\n   :target: http://deprecation.readthedocs.io/en/latest/\n   :alt: Documentation Status\n\n.. image:: https://travis-ci.org/briancurtin/deprecation.svg?branch=master\n    :target: https://travis-ci.org/briancurtin/deprecation\n\n.. image:: https://codecov.io/gh/briancurtin/deprecation/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/briancurtin/deprecation\n\nThe ``deprecation`` library provides a ``deprecated`` decorator and a\n``fail_if_not_removed`` decorator for your tests. Together, the two\nenable the automation of several things:\n\n1. The docstring of a deprecated method gets the deprecation details\n   appended to the end of it. If you generate your API docs direct\n   from your source, you don't need to worry about writing your own\n   notification. You also don't need to worry about forgetting to\n   write it. It's done for you.\n2. Rather than having code live on forever because you only deprecated\n   it but never actually moved on from it, you can have your tests\n   tell you when it's time to remove the code. The ``@deprecated``\n   decorator can be told when it's time to entirely remove the code,\n   which causes ``@fail_if_not_removed`` to raise an ``AssertionError``,\n   causing either your unittest or py.test tests to fail.\n\nSee http://deprecation.readthedocs.io/ for the full documentation.\n\nInstallation\n============\n\n ::\n\n    pip install deprecation\n\nUsage\n=====\n\n ::\n\n    import deprecation\n\n    @deprecation.deprecated(deprecated_in=\"1.0\", removed_in=\"2.0\",\n                            current_version=__version__,\n                            details=\"Use the bar function instead\")\n    def foo():\n        \"\"\"Do some stuff\"\"\"\n        return 1\n\n...but doesn't Python ignore ``DeprecationWarning``?\n====================================================\n\nYes, by default since 2.7â€”and for good reason [#]_ â€”and this works fine\nwith that.\n\n1. It often makes sense for you to run your tests with a ``-W`` flag or\n   the ``PYTHONWARNINGS`` environment variable so you catch warnings\n   in development and handle them appropriately. The warnings raised by\n   this library show up there, as they're subclasses of the built-in\n   ``DeprecationWarning``. See the `Command Line\n   <https://docs.python.org/2/using/cmdline.html#cmdoption-W>`_\n   and `Environment Variable\n   <https://docs.python.org/2/using/cmdline.html#envvar-PYTHONWARNINGS>`_\n   documentation for more details.\n2. Even if you don't enable those things, the behavior of this library\n   remains the same. The docstrings will still be updated and the tests\n   will still fail when they need to. You'll get the benefits regardless\n   of what Python cares about ``DeprecationWarning``.\n\n----\n\n.. [#] Exposing application users to ``DeprecationWarning``\\s that are\n       emitted by lower-level code needlessly involves end-users in\n       \"how things are done.\" It often leads to users raising issues\n       about warnings they're presented, which on one hand is done\n       rightfully so, as it's been presented to them as some sort of\n       issue to resolve. However, at the same time, the warning could\n       be well known and planned for. From either side, loud\n       ``DeprecationWarning``\\s can be seen as noise that isn't\n       necessary outside of development.\n\n\n",
        "keywords": [
          "deprecation"
        ],
        "home_page": "http://deprecation.readthedocs.io/",
        "author": "Brian Curtin",
        "author_email": "brian@python.org",
        "maintainer": "Brian Curtin",
        "maintainer_email": "brian@python.org",
        "license": "Apache 2",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "packaging"
        ],
        "project_url": [
          "Documentation, http://deprecation.readthedocs.io/en/latest/",
          "Source, https://github.com/briancurtin/deprecation",
          "Bug Tracker, https://github.com/briancurtin/deprecation/issues"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=7bffd925d65168f85027d8da9af6bddab658135b840670a223589bc0c8ef02b2",
          "hashes": {
            "sha256": "7bffd925d65168f85027d8da9af6bddab658135b840670a223589bc0c8ef02b2"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "distro",
        "version": "1.9.0",
        "platform": [
          "All"
        ],
        "summary": "Distro - an OS platform information API",
        "description": "Distro - an OS platform information API\n=======================================\n\n[![CI Status](https://github.com/python-distro/distro/workflows/CI/badge.svg)](https://github.com/python-distro/distro/actions/workflows/ci.yaml)\n[![PyPI version](http://img.shields.io/pypi/v/distro.svg)](https://pypi.python.org/pypi/distro)\n[![Supported Python Versions](https://img.shields.io/pypi/pyversions/distro.svg)](https://img.shields.io/pypi/pyversions/distro.svg)\n[![Code Coverage](https://codecov.io/github/python-distro/distro/coverage.svg?branch=master)](https://codecov.io/github/python-distro/distro?branch=master)\n[![Is Wheel](https://img.shields.io/pypi/wheel/distro.svg?style=flat)](https://pypi.python.org/pypi/distro)\n[![Latest Github Release](https://readthedocs.org/projects/distro/badge/?version=stable)](http://distro.readthedocs.io/en/latest/)\n\n`distro` provides information about the\nOS distribution it runs on, such as a reliable machine-readable ID, or\nversion information.\n\nIt is the recommended replacement for Python's original\n[`platform.linux_distribution`](https://docs.python.org/3.7/library/platform.html#platform.linux_distribution)\nfunction (removed in Python 3.8). It also provides much more functionality\nwhich isn't necessarily Python bound, like a command-line interface.\n\nDistro currently supports Linux and BSD based systems but [Windows and OS X support](https://github.com/python-distro/distro/issues/177) is also planned.\n\nFor Python 2.6 support, see https://github.com/python-distro/distro/tree/python2.6-support\n\n## Installation\n\nInstallation of the latest released version from PyPI:\n\n```shell\npip install distro\n```\n\nInstallation of the latest development version:\n\n```shell\npip install https://github.com/python-distro/distro/archive/master.tar.gz\n```\n\nTo use as a standalone script, download `distro.py` directly:\n\n```shell\ncurl -O https://raw.githubusercontent.com/python-distro/distro/master/src/distro/distro.py\npython distro.py\n```\n\n``distro`` is safe to vendor within projects that do not wish to add\ndependencies.\n\n```shell\ncd myproject\ncurl -O https://raw.githubusercontent.com/python-distro/distro/master/src/distro/distro.py\n```\n\n## Usage\n\n```bash\n$ distro\nName: Antergos Linux\nVersion: 2015.10 (ISO-Rolling)\nCodename: ISO-Rolling\n\n$ distro -j\n{\n    \"codename\": \"ISO-Rolling\",\n    \"id\": \"antergos\",\n    \"like\": \"arch\",\n    \"version\": \"16.9\",\n    \"version_parts\": {\n        \"build_number\": \"\",\n        \"major\": \"16\",\n        \"minor\": \"9\"\n    }\n}\n\n\n$ python\n>>> import distro\n>>> distro.name(pretty=True)\n'CentOS Linux 8'\n>>> distro.id()\n'centos'\n>>> distro.version(best=True)\n'8.4.2105'\n```\n\n\n## Documentation\n\nOn top of the aforementioned API, several more functions are available. For a complete description of the\nAPI, see the [latest API documentation](http://distro.readthedocs.org/en/latest/).\n\n## Background\n\nAn alternative implementation became necessary because Python 3.5 deprecated\nthis function, and Python 3.8 removed it altogether. Its predecessor function\n[`platform.dist`](https://docs.python.org/3.7/library/platform.html#platform.dist)\nwas already deprecated since Python 2.6 and removed in Python 3.8. Still, there\nare many cases in which access to that information is needed. See [Python issue\n1322](https://bugs.python.org/issue1322) for more information.\n\nThe `distro` package implements a robust and inclusive way of retrieving the\ninformation about a distribution based on new standards and old methods,\nnamely from these data sources (from high to low precedence):\n\n* The os-release file `/etc/os-release` if present, with a fall-back on `/usr/lib/os-release` if needed.\n* The output of the `lsb_release` command, if available.\n* The distro release file (`/etc/*(-|_)(release|version)`), if present.\n* The `uname` command for BSD based distrubtions.\n\n\n## Python and Distribution Support\n\n`distro` is supported and tested on Python 3.6+ and PyPy and on any\ndistribution that provides one or more of the data sources covered.\n\nThis package is tested with test data that mimics the exact behavior of the data sources of [a number of Linux distributions](https://github.com/python-distro/distro/tree/master/tests/resources/distros).\n\n\n## Testing\n\n```shell\ngit clone git@github.com:python-distro/distro.git\ncd distro\npip install tox\ntox\n```\n\n\n## Contributions\n\nPull requests are always welcome to deal with specific distributions or just\nfor general merriment.\n\nSee [CONTRIBUTIONS](https://github.com/python-distro/distro/blob/master/CONTRIBUTING.md) for contribution info.\n\nReference implementations for supporting additional distributions and file\nformats can be found here:\n\n* https://github.com/saltstack/salt/blob/develop/salt/grains/core.py#L1172\n* https://github.com/chef/ohai/blob/master/lib/ohai/plugins/linux/platform.rb\n* https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/facts/system/distribution.py\n* https://github.com/puppetlabs/facter/blob/master/lib/src/facts/linux/os_linux.cc\n\n## Package manager distributions\n\n* https://src.fedoraproject.org/rpms/python-distro\n* https://www.archlinux.org/packages/community/any/python-distro/\n* https://launchpad.net/ubuntu/+source/python-distro\n* https://packages.debian.org/stable/python3-distro\n* https://packages.gentoo.org/packages/dev-python/distro\n* https://pkgs.org/download/python3-distro\n* https://slackbuilds.org/repository/14.2/python/python-distro/\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/python-distro/distro",
        "author": "Nir Cohen",
        "author_email": "nir36g@gmail.com",
        "license": "Apache License, Version 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: POSIX :: BSD",
          "Operating System :: POSIX :: BSD :: FreeBSD",
          "Operating System :: POSIX :: BSD :: NetBSD",
          "Operating System :: POSIX :: BSD :: OpenBSD",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: System :: Operating System"
        ],
        "requires_python": ">=3.6"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad",
          "hashes": {
            "sha256": "d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "httpx",
        "version": "0.28.1",
        "summary": "The next generation HTTP client.",
        "description": "<p align=\"center\">\n  <a href=\"https://www.python-httpx.org/\"><img width=\"350\" height=\"208\" src=\"https://raw.githubusercontent.com/encode/httpx/master/docs/img/butterfly.png\" alt='HTTPX'></a>\n</p>\n\n<p align=\"center\"><strong>HTTPX</strong> <em>- A next-generation HTTP client for Python.</em></p>\n\n<p align=\"center\">\n<a href=\"https://github.com/encode/httpx/actions\">\n    <img src=\"https://github.com/encode/httpx/workflows/Test%20Suite/badge.svg\" alt=\"Test Suite\">\n</a>\n<a href=\"https://pypi.org/project/httpx/\">\n    <img src=\"https://badge.fury.io/py/httpx.svg\" alt=\"Package version\">\n</a>\n</p>\n\nHTTPX is a fully featured HTTP client library for Python 3. It includes **an integrated command line client**, has support for both **HTTP/1.1 and HTTP/2**, and provides both **sync and async APIs**.\n\n---\n\nInstall HTTPX using pip:\n\n```shell\n$ pip install httpx\n```\n\nNow, let's get started:\n\n```pycon\n>>> import httpx\n>>> r = httpx.get('https://www.example.org/')\n>>> r\n<Response [200 OK]>\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'text/html; charset=UTF-8'\n>>> r.text\n'<!doctype html>\\n<html>\\n<head>\\n<title>Example Domain</title>...'\n```\n\nOr, using the command-line client.\n\n```shell\n$ pip install 'httpx[cli]'  # The command line client is an optional dependency.\n```\n\nWhich now allows us to use HTTPX directly from the command-line...\n\n<p align=\"center\">\n  <img width=\"700\" src=\"https://raw.githubusercontent.com/encode/httpx/master/docs/img/httpx-help.png\" alt='httpx --help'>\n</p>\n\nSending a request...\n\n<p align=\"center\">\n  <img width=\"700\" src=\"https://raw.githubusercontent.com/encode/httpx/master/docs/img/httpx-request.png\" alt='httpx http://httpbin.org/json'>\n</p>\n\n## Features\n\nHTTPX builds on the well-established usability of `requests`, and gives you:\n\n* A broadly [requests-compatible API](https://www.python-httpx.org/compatibility/).\n* An integrated command-line client.\n* HTTP/1.1 [and HTTP/2 support](https://www.python-httpx.org/http2/).\n* Standard synchronous interface, but with [async support if you need it](https://www.python-httpx.org/async/).\n* Ability to make requests directly to [WSGI applications](https://www.python-httpx.org/advanced/transports/#wsgi-transport) or [ASGI applications](https://www.python-httpx.org/advanced/transports/#asgi-transport).\n* Strict timeouts everywhere.\n* Fully type annotated.\n* 100% test coverage.\n\nPlus all the standard features of `requests`...\n\n* International Domains and URLs\n* Keep-Alive & Connection Pooling\n* Sessions with Cookie Persistence\n* Browser-style SSL Verification\n* Basic/Digest Authentication\n* Elegant Key/Value Cookies\n* Automatic Decompression\n* Automatic Content Decoding\n* Unicode Response Bodies\n* Multipart File Uploads\n* HTTP(S) Proxy Support\n* Connection Timeouts\n* Streaming Downloads\n* .netrc Support\n* Chunked Requests\n\n## Installation\n\nInstall with pip:\n\n```shell\n$ pip install httpx\n```\n\nOr, to include the optional HTTP/2 support, use:\n\n```shell\n$ pip install httpx[http2]\n```\n\nHTTPX requires Python 3.8+.\n\n## Documentation\n\nProject documentation is available at [https://www.python-httpx.org/](https://www.python-httpx.org/).\n\nFor a run-through of all the basics, head over to the [QuickStart](https://www.python-httpx.org/quickstart/).\n\nFor more advanced topics, see the [Advanced Usage](https://www.python-httpx.org/advanced/) section, the [async support](https://www.python-httpx.org/async/) section, or the [HTTP/2](https://www.python-httpx.org/http2/) section.\n\nThe [Developer Interface](https://www.python-httpx.org/api/) provides a comprehensive API reference.\n\nTo find out about tools that integrate with HTTPX, see [Third Party Packages](https://www.python-httpx.org/third_party_packages/).\n\n## Contribute\n\nIf you want to contribute with HTTPX check out the [Contributing Guide](https://www.python-httpx.org/contributing/) to learn how to start.\n\n## Dependencies\n\nThe HTTPX project relies on these excellent libraries:\n\n* `httpcore` - The underlying transport implementation for `httpx`.\n  * `h11` - HTTP/1.1 support.\n* `certifi` - SSL certificates.\n* `idna` - Internationalized domain name support.\n* `sniffio` - Async library autodetection.\n\nAs well as these optional installs:\n\n* `h2` - HTTP/2 support. *(Optional, with `httpx[http2]`)*\n* `socksio` - SOCKS proxy support. *(Optional, with `httpx[socks]`)*\n* `rich` - Rich terminal support. *(Optional, with `httpx[cli]`)*\n* `click` - Command line client support. *(Optional, with `httpx[cli]`)*\n* `brotli` or `brotlicffi` - Decoding for \"brotli\" compressed responses. *(Optional, with `httpx[brotli]`)*\n* `zstandard` - Decoding for \"zstd\" compressed responses. *(Optional, with `httpx[zstd]`)*\n\nA huge amount of credit is due to `requests` for the API layout that\nmuch of this work follows, as well as to `urllib3` for plenty of design\ninspiration around the lower-level networking details.\n\n---\n\n<p align=\"center\"><i>HTTPX is <a href=\"https://github.com/encode/httpx/blob/master/LICENSE.md\">BSD licensed</a> code.<br/>Designed & crafted with care.</i><br/>&mdash; ðŸ¦‹ &mdash;</p>\n\n## Release Information\n\n### Fixed\n\n* Reintroduced supposedly-private `URLTypes` shortcut. (#2673)\n\n\n---\n\n[Full changelog](https://github.com/encode/httpx/blob/master/CHANGELOG.md)\n",
        "description_content_type": "text/markdown",
        "author_email": "Tom Christie <tom@tomchristie.com>",
        "license": "BSD-3-Clause",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Web Environment",
          "Framework :: AsyncIO",
          "Framework :: Trio",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "anyio",
          "certifi",
          "httpcore==1.*",
          "idna",
          "brotli; (platform_python_implementation == 'CPython') and extra == 'brotli'",
          "brotlicffi; (platform_python_implementation != 'CPython') and extra == 'brotli'",
          "click==8.*; extra == 'cli'",
          "pygments==2.*; extra == 'cli'",
          "rich<14,>=10; extra == 'cli'",
          "h2<5,>=3; extra == 'http2'",
          "socksio==1.*; extra == 'socks'",
          "zstandard>=0.18.0; extra == 'zstd'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/encode/httpx/blob/master/CHANGELOG.md",
          "Documentation, https://www.python-httpx.org",
          "Homepage, https://github.com/encode/httpx",
          "Source, https://github.com/encode/httpx"
        ],
        "provides_extra": [
          "brotli",
          "cli",
          "http2",
          "socks",
          "zstd"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=2d400746a40668fc9dec9810239072b40b4484b640a8c38fd654a024c7a1bf55",
          "hashes": {
            "sha256": "2d400746a40668fc9dec9810239072b40b4484b640a8c38fd654a024c7a1bf55"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "httpcore",
        "version": "1.0.9",
        "summary": "A minimal low-level HTTP client.",
        "description": "# HTTP Core\n\n[![Test Suite](https://github.com/encode/httpcore/workflows/Test%20Suite/badge.svg)](https://github.com/encode/httpcore/actions)\n[![Package version](https://badge.fury.io/py/httpcore.svg)](https://pypi.org/project/httpcore/)\n\n> *Do one thing, and do it well.*\n\nThe HTTP Core package provides a minimal low-level HTTP client, which does\none thing only. Sending HTTP requests.\n\nIt does not provide any high level model abstractions over the API,\ndoes not handle redirects, multipart uploads, building authentication headers,\ntransparent HTTP caching, URL parsing, session cookie handling,\ncontent or charset decoding, handling JSON, environment based configuration\ndefaults, or any of that Jazz.\n\nSome things HTTP Core does do:\n\n* Sending HTTP requests.\n* Thread-safe / task-safe connection pooling.\n* HTTP(S) proxy & SOCKS proxy support.\n* Supports HTTP/1.1 and HTTP/2.\n* Provides both sync and async interfaces.\n* Async backend support for `asyncio` and `trio`.\n\n## Requirements\n\nPython 3.8+\n\n## Installation\n\nFor HTTP/1.1 only support, install with:\n\n```shell\n$ pip install httpcore\n```\n\nThere are also a number of optional extras available...\n\n```shell\n$ pip install httpcore['asyncio,trio,http2,socks']\n```\n\n## Sending requests\n\nSend an HTTP request:\n\n```python\nimport httpcore\n\nresponse = httpcore.request(\"GET\", \"https://www.example.com/\")\n\nprint(response)\n# <Response [200]>\nprint(response.status)\n# 200\nprint(response.headers)\n# [(b'Accept-Ranges', b'bytes'), (b'Age', b'557328'), (b'Cache-Control', b'max-age=604800'), ...]\nprint(response.content)\n# b'<!doctype html>\\n<html>\\n<head>\\n<title>Example Domain</title>\\n\\n<meta charset=\"utf-8\"/>\\n ...'\n```\n\nThe top-level `httpcore.request()` function is provided for convenience. In practice whenever you're working with `httpcore` you'll want to use the connection pooling functionality that it provides.\n\n```python\nimport httpcore\n\nhttp = httpcore.ConnectionPool()\nresponse = http.request(\"GET\", \"https://www.example.com/\")\n```\n\nOnce you're ready to get going, [head over to the documentation](https://www.encode.io/httpcore/).\n\n## Motivation\n\nYou *probably* don't want to be using HTTP Core directly. It might make sense if\nyou're writing something like a proxy service in Python, and you just want\nsomething at the lowest possible level, but more typically you'll want to use\na higher level client library, such as `httpx`.\n\nThe motivation for `httpcore` is:\n\n* To provide a reusable low-level client library, that other packages can then build on top of.\n* To provide a *really clear interface split* between the networking code and client logic,\n  so that each is easier to understand and reason about in isolation.\n\n## Dependencies\n\nThe `httpcore` package has the following dependencies...\n\n* `h11`\n* `certifi`\n\nAnd the following optional extras...\n\n* `anyio` - Required by `pip install httpcore['asyncio']`.\n* `trio` - Required by `pip install httpcore['trio']`.\n* `h2` - Required by `pip install httpcore['http2']`.\n* `socksio` - Required by `pip install httpcore['socks']`.\n\n## Versioning\n\nWe use [SEMVER for our versioning policy](https://semver.org/).\n\nFor changes between package versions please see our [project changelog](CHANGELOG.md).\n\nWe recommend pinning your requirements either the most current major version, or a more specific version range:\n\n```python\npip install 'httpcore==1.*'\n```\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## Version 1.0.9 (April 24th, 2025)\n\n- Resolve https://github.com/advisories/GHSA-vqfr-h8mv-ghfj with h11 dependency update. (#1008)\n\n## Version 1.0.8 (April 11th, 2025)\n\n- Fix `AttributeError` when importing on Python 3.14. (#1005)\n\n## Version 1.0.7 (November 15th, 2024)\n\n- Support `proxy=â€¦` configuration on `ConnectionPool()`. (#974)\n\n## Version 1.0.6 (October 1st, 2024)\n\n- Relax `trio` dependency pinning. (#956)\n- Handle `trio` raising `NotImplementedError` on unsupported platforms. (#955)\n- Handle mapping `ssl.SSLError` to `httpcore.ConnectError`. (#918)\n\n## 1.0.5 (March 27th, 2024)\n\n- Handle `EndOfStream` exception for anyio backend. (#899)\n- Allow trio `0.25.*` series in package dependancies. (#903)\n\n## 1.0.4 (February 21st, 2024)\n\n- Add `target` request extension. (#888)\n- Fix support for connection `Upgrade` and `CONNECT` when some data in the stream has been read. (#882)\n\n## 1.0.3 (February 13th, 2024)\n\n- Fix support for async cancellations. (#880)\n- Fix trace extension when used with socks proxy. (#849)\n- Fix SSL context for connections using the \"wss\" scheme (#869)\n\n## 1.0.2 (November 10th, 2023)\n\n- Fix `float(\"inf\")` timeouts in `Event.wait` function. (#846)\n\n## 1.0.1 (November 3rd, 2023)\n\n- Fix pool timeout to account for the total time spent retrying. (#823)\n- Raise a neater RuntimeError when the correct async deps are not installed. (#826)\n- Add support for synchronous TLS-in-TLS streams. (#840)\n\n## 1.0.0 (October 6th, 2023)\n\nFrom version 1.0 our async support is now optional, as the package has minimal dependencies by default.\n\nFor async support use either `pip install 'httpcore[asyncio]'` or `pip install 'httpcore[trio]'`.\n\nThe project versioning policy is now explicitly governed by SEMVER. See https://semver.org/.\n\n- Async support becomes fully optional. (#809)\n- Add support for Python 3.12. (#807)\n\n## 0.18.0 (September 8th, 2023)\n\n- Add support for HTTPS proxies. (#745, #786)\n- Drop Python 3.7 support. (#727)\n- Handle `sni_hostname` extension with SOCKS proxy. (#774)\n- Handle HTTP/1.1 half-closed connections gracefully. (#641)\n- Change the type of `Extensions` from `Mapping[Str, Any]` to `MutableMapping[Str, Any]`. (#762)\n\n## 0.17.3 (July 5th, 2023)\n\n- Support async cancellations, ensuring that the connection pool is left in a clean state when cancellations occur. (#726)\n- The networking backend interface has [been added to the public API](https://www.encode.io/httpcore/network-backends). Some classes which were previously private implementation detail are now part of the top-level public API. (#699)\n- Graceful handling of HTTP/2 GoAway frames, with requests being transparently retried on a new connection. (#730)\n- Add exceptions when a synchronous `trace callback` is passed to an asynchronous request or an asynchronous `trace callback` is passed to a synchronous request. (#717)\n- Drop Python 3.7 support. (#727)\n\n## 0.17.2 (May 23th, 2023)\n\n- Add `socket_options` argument to `ConnectionPool` and `HTTProxy` classes. (#668)\n- Improve logging with per-module logger names. (#690)\n- Add `sni_hostname` request extension. (#696)\n- Resolve race condition during import of `anyio` package. (#692)\n- Enable TCP_NODELAY for all synchronous sockets. (#651)\n\n## 0.17.1 (May 17th, 2023)\n\n- If 'retries' is set, then allow retries if an SSL handshake error occurs. (#669)\n- Improve correctness of tracebacks on network exceptions, by raising properly chained exceptions. (#678)\n- Prevent connection-hanging behaviour when HTTP/2 connections are closed by a server-sent 'GoAway' frame. (#679)\n- Fix edge-case exception when removing requests from the connection pool. (#680)\n- Fix pool timeout edge-case. (#688)\n\n## 0.17.0 (March 16th, 2023)\n\n- Add DEBUG level logging. (#648)\n- Respect HTTP/2 max concurrent streams when settings updates are sent by server. (#652)\n- Increase the allowable HTTP header size to 100kB. (#647)\n- Add `retries` option to SOCKS proxy classes. (#643)\n\n## 0.16.3 (December 20th, 2022)\n\n- Allow `ws` and `wss` schemes. Allows us to properly support websocket upgrade connections. (#625)\n- Forwarding HTTP proxies use a connection-per-remote-host. Required by some proxy implementations. (#637)\n- Don't raise `RuntimeError` when closing a connection pool with active connections. Removes some error cases when cancellations are used. (#631)\n- Lazy import `anyio`, so that it's no longer a hard dependancy, and isn't imported if unused. (#639)\n\n## 0.16.2 (November 25th, 2022)\n\n- Revert 'Fix async cancellation behaviour', which introduced race conditions. (#627)\n- Raise `RuntimeError` if attempting to us UNIX domain sockets on Windows. (#619)\n\n## 0.16.1 (November 17th, 2022)\n\n- Fix HTTP/1.1 interim informational responses, such as \"100 Continue\". (#605)\n\n## 0.16.0 (October 11th, 2022)\n\n- Support HTTP/1.1 informational responses. (#581)\n- Fix async cancellation behaviour. (#580)\n- Support `h11` 0.14. (#579)\n\n## 0.15.0 (May 17th, 2022)\n\n- Drop Python 3.6 support (#535)\n- Ensure HTTP proxy CONNECT requests include `timeout` configuration. (#506)\n- Switch to explicit `typing.Optional` for type hints. (#513)\n- For `trio` map OSError exceptions to `ConnectError`. (#543)\n\n## 0.14.7 (February 4th, 2022)\n\n- Requests which raise a PoolTimeout need to be removed from the pool queue. (#502)\n- Fix AttributeError that happened when Socks5Connection were terminated. (#501)\n\n## 0.14.6 (February 1st, 2022)\n\n- Fix SOCKS support for `http://` URLs. (#492)\n- Resolve race condition around exceptions during streaming a response. (#491)\n\n## 0.14.5 (January 18th, 2022)\n\n- SOCKS proxy support. (#478)\n- Add proxy_auth argument to HTTPProxy. (#481)\n- Improve error message on 'RemoteProtocolError' exception when server disconnects without sending a response. (#479)\n\n## 0.14.4 (January 5th, 2022)\n\n- Support HTTP/2 on HTTPS tunnelling proxies. (#468)\n- Fix proxy headers missing on HTTP forwarding. (#456)\n- Only instantiate SSL context if required. (#457)\n- More robust HTTP/2 handling. (#253, #439, #440, #441)\n\n## 0.14.3 (November 17th, 2021)\n\n- Fix race condition when removing closed connections from the pool. (#437)\n\n## 0.14.2 (November 16th, 2021)\n\n- Failed connections no longer remain in the pool. (Pull #433)\n\n## 0.14.1 (November 12th, 2021)\n\n- `max_connections` becomes optional. (Pull #429)\n- `certifi` is now included in the install dependancies. (Pull #428)\n- `h2` is now strictly optional. (Pull #428)\n\n## 0.14.0 (November 11th, 2021)\n\nThe 0.14 release is a complete reworking of `httpcore`, comprehensively addressing some underlying issues in the connection pooling, as well as substantially redesigning the API to be more user friendly.\n\nSome of the lower-level API design also makes the components more easily testable in isolation, and the package now has 100% test coverage.\n\nSee [discussion #419](https://github.com/encode/httpcore/discussions/419) for a little more background.\n\nThere's some other neat bits in there too, such as the \"trace\" extension, which gives a hook into inspecting the internal events that occur during the request/response cycle. This extension is needed for the HTTPX cli, in order to...\n\n* Log the point at which the connection is established, and the IP/port on which it is made.\n* Determine if the outgoing request should log as HTTP/1.1 or HTTP/2, rather than having to assume it's HTTP/2 if the --http2 flag was passed. (Which may not actually be true.)\n* Log SSL version info / certificate info.\n\nNote that `curio` support is not currently available in 0.14.0. If you're using `httpcore` with `curio` please get in touch, so we can assess if we ought to prioritize it as a feature or not.\n\n## 0.13.7 (September 13th, 2021)\n\n- Fix broken error messaging when URL scheme is missing, or a non HTTP(S) scheme is used. (Pull #403)\n\n## 0.13.6 (June 15th, 2021)\n\n### Fixed\n\n- Close sockets when read or write timeouts occur. (Pull #365)\n\n## 0.13.5 (June 14th, 2021)\n\n### Fixed\n\n- Resolved niggles with AnyIO EOF behaviours. (Pull #358, #362)\n\n## 0.13.4 (June 9th, 2021)\n\n### Added\n\n- Improved error messaging when URL scheme is missing, or a non HTTP(S) scheme is used. (Pull #354)\n\n### Fixed\n\n- Switched to `anyio` as the default backend implementation when running with `asyncio`. Resolves some awkward [TLS timeout issues](https://github.com/encode/httpx/discussions/1511).\n\n## 0.13.3 (May 6th, 2021)\n\n### Added\n\n- Support HTTP/2 prior knowledge, using `httpcore.SyncConnectionPool(http1=False)`. (Pull #333)\n\n### Fixed\n\n- Handle cases where environment does not provide `select.poll` support. (Pull #331)\n\n## 0.13.2 (April 29th, 2021)\n\n### Added\n\n- Improve error message for specific case of `RemoteProtocolError` where server disconnects without sending a response. (Pull #313)\n\n## 0.13.1 (April 28th, 2021)\n\n### Fixed\n\n- More resiliant testing for closed connections. (Pull #311)\n- Don't raise exceptions on ungraceful connection closes. (Pull #310)\n\n## 0.13.0 (April 21st, 2021)\n\nThe 0.13 release updates the core API in order to match the HTTPX Transport API,\nintroduced in HTTPX 0.18 onwards.\n\nAn example of making requests with the new interface is:\n\n```python\nwith httpcore.SyncConnectionPool() as http:\n    status_code, headers, stream, extensions = http.handle_request(\n        method=b'GET',\n        url=(b'https', b'example.org', 443, b'/'),\n        headers=[(b'host', b'example.org'), (b'user-agent', b'httpcore')]\n        stream=httpcore.ByteStream(b''),\n        extensions={}\n    )\n    body = stream.read()\n    print(status_code, body)\n```\n\n### Changed\n\n- The `.request()` method is now `handle_request()`. (Pull #296)\n- The `.arequest()` method is now `.handle_async_request()`. (Pull #296)\n- The `headers` argument is no longer optional. (Pull #296)\n- The `stream` argument is no longer optional. (Pull #296)\n- The `ext` argument is now named `extensions`, and is no longer optional. (Pull #296)\n- The `\"reason\"` extension keyword is now named `\"reason_phrase\"`. (Pull #296)\n- The `\"reason_phrase\"` and `\"http_version\"` extensions now use byte strings for their values. (Pull #296)\n- The `httpcore.PlainByteStream()` class becomes `httpcore.ByteStream()`. (Pull #296)\n\n### Added\n\n- Streams now support a `.read()` interface. (Pull #296)\n\n### Fixed\n\n- Task cancellation no longer leaks connections from the connection pool. (Pull #305)\n\n## 0.12.3 (December 7th, 2020)\n\n### Fixed\n\n- Abort SSL connections on close rather than waiting for remote EOF when using `asyncio`.  (Pull #167)\n- Fix exception raised in case of connect timeouts when using the `anyio` backend. (Pull #236)\n- Fix `Host` header precedence for `:authority` in HTTP/2. (Pull #241, #243)\n- Handle extra edge case when detecting for socket readability when using `asyncio`. (Pull #242, #244)\n- Fix `asyncio` SSL warning when using proxy tunneling. (Pull #249)\n\n## 0.12.2 (November 20th, 2020)\n\n### Fixed\n\n- Properly wrap connect errors on the asyncio backend. (Pull #235)\n- Fix `ImportError` occurring on Python 3.9 when using the HTTP/1.1 sync client in a multithreaded context. (Pull #237)\n\n## 0.12.1 (November 7th, 2020)\n\n### Added\n\n- Add connect retries. (Pull #221)\n\n### Fixed\n\n- Tweak detection of dropped connections, resolving an issue with open files limits on Linux. (Pull #185)\n- Avoid leaking connections when establishing an HTTP tunnel to a proxy has failed. (Pull #223)\n- Properly wrap OS errors when using `trio`. (Pull #225)\n\n## 0.12.0 (October 6th, 2020)\n\n### Changed\n\n- HTTP header casing is now preserved, rather than always sent in lowercase. (#216 and python-hyper/h11#104)\n\n### Added\n\n- Add Python 3.9 to officially supported versions.\n\n### Fixed\n\n- Gracefully handle a stdlib asyncio bug when a connection is closed while it is in a paused-for-reading state. (#201)\n\n## 0.11.1 (September 28nd, 2020)\n\n### Fixed\n\n- Add await to async semaphore release() coroutine (#197)\n- Drop incorrect curio classifier (#192)\n\n## 0.11.0 (September 22nd, 2020)\n\nThe Transport API with 0.11.0 has a couple of significant changes.\n\nFirstly we've moved changed the request interface in order to allow extensions, which will later enable us to support features\nsuch as trailing headers, HTTP/2 server push, and CONNECT/Upgrade connections.\n\nThe interface changes from:\n\n```python\ndef request(method, url, headers, stream, timeout):\n    return (http_version, status_code, reason, headers, stream)\n```\n\nTo instead including an optional dictionary of extensions on the request and response:\n\n```python\ndef request(method, url, headers, stream, ext):\n    return (status_code, headers, stream, ext)\n```\n\nHaving an open-ended extensions point will allow us to add later support for various optional features, that wouldn't otherwise be supported without these API changes.\n\nIn particular:\n\n* Trailing headers support.\n* HTTP/2 Server Push\n* sendfile.\n* Exposing raw connection on CONNECT, Upgrade, HTTP/2 bi-di streaming.\n* Exposing debug information out of the API, including template name, template context.\n\nCurrently extensions are limited to:\n\n* request: `timeout` - Optional. Timeout dictionary.\n* response: `http_version` - Optional. Include the HTTP version used on the response.\n* response: `reason` - Optional. Include the reason phrase used on the response. Only valid with HTTP/1.*.\n\nSee https://github.com/encode/httpx/issues/1274#issuecomment-694884553 for the history behind this.\n\nSecondly, the async version of `request` is now namespaced as `arequest`.\n\nThis allows concrete transports to support both sync and async implementations on the same class.\n\n### Added\n\n- Add curio support. (Pull #168)\n- Add anyio support, with `backend=\"anyio\"`. (Pull #169)\n\n### Changed\n\n- Update the Transport API to use 'ext' for optional extensions. (Pull #190)\n- Update the Transport API to use `.request` and `.arequest` so implementations can support both sync and async. (Pull #189)\n\n## 0.10.2 (August 20th, 2020)\n\n### Added\n\n- Added Unix Domain Socket support. (Pull #139)\n\n### Fixed\n\n- Always include the port on proxy CONNECT requests. (Pull #154)\n- Fix `max_keepalive_connections` configuration. (Pull #153)\n- Fixes behaviour in HTTP/1.1 where server disconnects can be used to signal the end of the response body. (Pull #164)\n\n## 0.10.1 (August 7th, 2020)\n\n- Include `max_keepalive_connections` on `AsyncHTTPProxy`/`SyncHTTPProxy` classes.\n\n## 0.10.0 (August 7th, 2020)\n\nThe most notable change in the 0.10.0 release is that HTTP/2 support is now fully optional.\n\nUse either `pip install httpcore` for HTTP/1.1 support only, or `pip install httpcore[http2]` for HTTP/1.1 and HTTP/2 support.\n\n### Added\n\n- HTTP/2 support becomes optional. (Pull #121, #130)\n- Add `local_address=...` support. (Pull #100, #134)\n- Add `PlainByteStream`, `IteratorByteStream`, `AsyncIteratorByteStream`. The `AsyncByteSteam` and `SyncByteStream` classes are now pure interface classes. (#133)\n- Add `LocalProtocolError`, `RemoteProtocolError` exceptions. (Pull #129)\n- Add `UnsupportedProtocol` exception. (Pull #128)\n- Add `.get_connection_info()` method. (Pull #102, #137)\n- Add better TRACE logs. (Pull #101)\n\n### Changed\n\n- `max_keepalive` is deprecated in favour of `max_keepalive_connections`. (Pull #140)\n\n### Fixed\n\n- Improve handling of server disconnects. (Pull #112)\n\n## 0.9.1 (May 27th, 2020)\n\n### Fixed\n\n- Proper host resolution for sync case, including IPv6 support. (Pull #97)\n- Close outstanding connections when connection pool is closed. (Pull #98)\n\n## 0.9.0 (May 21th, 2020)\n\n### Changed\n\n- URL port becomes an `Optional[int]` instead of `int`. (Pull #92)\n\n### Fixed\n\n- Honor HTTP/2 max concurrent streams settings. (Pull #89, #90)\n- Remove incorrect debug log. (Pull #83)\n\n## 0.8.4 (May 11th, 2020)\n\n### Added\n\n- Logging via HTTPCORE_LOG_LEVEL and HTTPX_LOG_LEVEL environment variables\nand TRACE level logging. (Pull #79)\n\n### Fixed\n\n- Reuse of connections on HTTP/2 in close concurrency situations. (Pull #81)\n\n## 0.8.3 (May 6rd, 2020)\n\n### Fixed\n\n- Include `Host` and `Accept` headers on proxy \"CONNECT\" requests.\n- De-duplicate any headers also contained in proxy_headers.\n- HTTP/2 flag not being passed down to proxy connections.\n\n## 0.8.2 (May 3rd, 2020)\n\n### Fixed\n\n- Fix connections using proxy forwarding requests not being added to the\nconnection pool properly. (Pull #70)\n\n## 0.8.1 (April 30th, 2020)\n\n### Changed\n\n- Allow inherintance of both `httpcore.AsyncByteStream`, `httpcore.SyncByteStream` without type conflicts.\n\n## 0.8.0 (April 30th, 2020)\n\n### Fixed\n\n- Fixed tunnel proxy support.\n\n###Â Added\n\n- New `TimeoutException` base class.\n\n## 0.7.0 (March 5th, 2020)\n\n- First integration with HTTPX.\n",
        "description_content_type": "text/markdown",
        "author_email": "Tom Christie <tom@tomchristie.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Environment :: Web Environment",
          "Framework :: AsyncIO",
          "Framework :: Trio",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "certifi",
          "h11>=0.16",
          "anyio<5.0,>=4.0; extra == 'asyncio'",
          "h2<5,>=3; extra == 'http2'",
          "socksio==1.*; extra == 'socks'",
          "trio<1.0,>=0.22.0; extra == 'trio'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://www.encode.io/httpcore",
          "Homepage, https://www.encode.io/httpcore/",
          "Source, https://github.com/encode/httpcore"
        ],
        "provides_extra": [
          "asyncio",
          "http2",
          "socks",
          "trio"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/fa/5e/f8e9a1d23b9c20a551a8a02ea3637b4642e22c2626e3a13a9a29cdea99eb/importlib_metadata-8.7.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5a1f80bf1daa489495071efbb095d75a634cf28a8bc299581244063b53176151",
          "hashes": {
            "sha256": "5a1f80bf1daa489495071efbb095d75a634cf28a8bc299581244063b53176151"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "importlib_metadata",
        "version": "8.7.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "Read metadata from Python packages",
        "description": ".. image:: https://img.shields.io/pypi/v/importlib_metadata.svg\n   :target: https://pypi.org/project/importlib_metadata\n\n.. image:: https://img.shields.io/pypi/pyversions/importlib_metadata.svg\n\n.. image:: https://github.com/python/importlib_metadata/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/python/importlib_metadata/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://readthedocs.org/projects/importlib-metadata/badge/?version=latest\n   :target: https://importlib-metadata.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2025-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/importlib-metadata\n   :target: https://tidelift.com/subscription/pkg/pypi-importlib-metadata?utm_source=pypi-importlib-metadata&utm_medium=readme\n\nLibrary to access the metadata for a Python package.\n\nThis package supplies third-party access to the functionality of\n`importlib.metadata <https://docs.python.org/3/library/importlib.metadata.html>`_\nincluding improvements added to subsequent Python versions.\n\n\nCompatibility\n=============\n\nNew features are introduced in this third-party library and later merged\ninto CPython. The following table indicates which versions of this library\nwere contributed to different versions in the standard library:\n\n.. list-table::\n   :header-rows: 1\n\n   * - importlib_metadata\n     - stdlib\n   * - 7.0\n     - 3.13\n   * - 6.5\n     - 3.12\n   * - 4.13\n     - 3.11\n   * - 4.6\n     - 3.10\n   * - 1.4\n     - 3.8\n\n\nUsage\n=====\n\nSee the `online documentation <https://importlib-metadata.readthedocs.io/>`_\nfor usage details.\n\n`Finder authors\n<https://docs.python.org/3/reference/import.html#finders-and-loaders>`_ can\nalso add support for custom package installers.  See the above documentation\nfor details.\n\n\nCaveats\n=======\n\nThis project primarily supports third-party packages installed by PyPA\ntools (or other conforming packages). It does not support:\n\n- Packages in the stdlib.\n- Packages installed without metadata.\n\nProject details\n===============\n\n * Project home: https://github.com/python/importlib_metadata\n * Report bugs at: https://github.com/python/importlib_metadata/issues\n * Code hosting: https://github.com/python/importlib_metadata\n * Documentation: https://importlib-metadata.readthedocs.io/\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-importlib-metadata?utm_source=pypi-importlib-metadata&utm_medium=referral&utm_campaign=github>`_.\n",
        "description_content_type": "text/x-rst",
        "author_email": "\"Jason R. Coombs\" <jaraco@jaraco.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "zipp>=3.20",
          "pytest!=8.1.*,>=6; extra == \"test\"",
          "packaging; extra == \"test\"",
          "pyfakefs; extra == \"test\"",
          "flufl.flake8; extra == \"test\"",
          "pytest-perf>=0.9.2; extra == \"test\"",
          "jaraco.test>=5.4; extra == \"test\"",
          "sphinx>=3.5; extra == \"doc\"",
          "jaraco.packaging>=9.3; extra == \"doc\"",
          "rst.linker>=1.9; extra == \"doc\"",
          "furo; extra == \"doc\"",
          "sphinx-lint; extra == \"doc\"",
          "jaraco.tidelift>=1.4; extra == \"doc\"",
          "ipython; extra == \"perf\"",
          "pytest-checkdocs>=2.4; extra == \"check\"",
          "pytest-ruff>=0.2.1; sys_platform != \"cygwin\" and extra == \"check\"",
          "pytest-cov; extra == \"cover\"",
          "pytest-enabler>=3.4; extra == \"enabler\"",
          "pytest-mypy>=1.0.1; extra == \"type\"",
          "mypy<1.19; platform_python_implementation == \"PyPy\" and extra == \"type\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source, https://github.com/python/importlib_metadata"
        ],
        "provides_extra": [
          "test",
          "doc",
          "perf",
          "check",
          "cover",
          "enabler",
          "type"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=85ece4451f492d0c13c5dd7c13a64681a86afae63a5f347908daf103ce6d2f67",
          "hashes": {
            "sha256": "85ece4451f492d0c13c5dd7c13a64681a86afae63a5f347908daf103ce6d2f67"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "Jinja2",
        "version": "3.1.6",
        "summary": "A very fast and expressive template engine.",
        "description": "# Jinja\n\nJinja is a fast, expressive, extensible templating engine. Special\nplaceholders in the template allow writing code similar to Python\nsyntax. Then the template is passed data to render the final document.\n\nIt includes:\n\n-   Template inheritance and inclusion.\n-   Define and import macros within templates.\n-   HTML templates can use autoescaping to prevent XSS from untrusted\n    user input.\n-   A sandboxed environment can safely render untrusted templates.\n-   AsyncIO support for generating templates and calling async\n    functions.\n-   I18N support with Babel.\n-   Templates are compiled to optimized Python code just-in-time and\n    cached, or can be compiled ahead-of-time.\n-   Exceptions point to the correct line in templates to make debugging\n    easier.\n-   Extensible filters, tests, functions, and even syntax.\n\nJinja's philosophy is that while application logic belongs in Python if\npossible, it shouldn't make the template designer's job difficult by\nrestricting functionality too much.\n\n\n## In A Nutshell\n\n```jinja\n{% extends \"base.html\" %}\n{% block title %}Members{% endblock %}\n{% block content %}\n  <ul>\n  {% for user in users %}\n    <li><a href=\"{{ user.url }}\">{{ user.username }}</a></li>\n  {% endfor %}\n  </ul>\n{% endblock %}\n```\n\n## Donate\n\nThe Pallets organization develops and supports Jinja and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n## Contributing\n\nSee our [detailed contributing documentation][contrib] for many ways to\ncontribute, including reporting issues, requesting features, asking or answering\nquestions, and making PRs.\n\n[contrib]: https://palletsprojects.com/contributing/\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "MarkupSafe>=2.0",
          "Babel>=2.7 ; extra == \"i18n\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changes, https://jinja.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://jinja.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/jinja/"
        ],
        "provides_extra": [
          "i18n"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/25/65/3bd1a972c9a08ecd22eb3b08a95d1941ebe6938aea620c246cf426ae09c2/jiter-0.13.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=8d76029f077379374cf0dbc78dbe45b38dec4a2eb78b08b5194ce836b2517afc",
          "hashes": {
            "sha256": "8d76029f077379374cf0dbc78dbe45b38dec4a2eb78b08b5194ce836b2517afc"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "jiter",
        "version": "0.13.0",
        "summary": "Fast iterable JSON parser.",
        "description": "# jiter\r\n\r\n[![CI](https://github.com/pydantic/jiter/workflows/CI/badge.svg?event=push)](https://github.com/pydantic/jiter/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\r\n[![pypi](https://img.shields.io/pypi/v/jiter.svg)](https://pypi.python.org/pypi/jiter)\r\n[![versions](https://img.shields.io/pypi/pyversions/jiter.svg)](https://github.com/pydantic/jiter)\r\n[![license](https://img.shields.io/github/license/pydantic/jiter.svg)](https://github.com/pydantic/jiter/blob/main/LICENSE)\r\n\r\nThis is a standalone version of the JSON parser used in `pydantic-core`. The recommendation is to only use this package directly if you do not use `pydantic`.\r\n\r\nThe API is extremely minimal:\r\n\r\n```python\r\ndef from_json(\r\n    json_data: bytes,\r\n    /,\r\n    *,\r\n    allow_inf_nan: bool = True,\r\n    cache_mode: Literal[True, False, \"all\", \"keys\", \"none\"] = \"all\",\r\n    partial_mode: Literal[True, False, \"off\", \"on\", \"trailing-strings\"] = False,\r\n    catch_duplicate_keys: bool = False,\r\n    float_mode: Literal[\"float\", \"decimal\", \"lossless-float\"] = \"float\",\r\n) -> Any:\r\n    \"\"\"\r\n    Parse input bytes into a JSON object.\r\n\r\n    Arguments:\r\n        json_data: The JSON data to parse\r\n        allow_inf_nan: Whether to allow infinity (`Infinity` an `-Infinity`) and `NaN` values to float fields.\r\n            Defaults to True.\r\n        cache_mode: cache Python strings to improve performance at the cost of some memory usage\r\n            - True / 'all' - cache all strings\r\n            - 'keys' - cache only object keys\r\n            - False / 'none' - cache nothing\r\n        partial_mode: How to handle incomplete strings:\r\n            - False / 'off' - raise an exception if the input is incomplete\r\n            - True / 'on' - allow incomplete JSON but discard the last string if it is incomplete\r\n            - 'trailing-strings' - allow incomplete JSON, and include the last incomplete string in the output\r\n        catch_duplicate_keys: if True, raise an exception if objects contain the same key multiple times\r\n        float_mode: How to return floats: as a `float`, `Decimal` or `LosslessFloat`\r\n\r\n    Returns:\r\n        Python object built from the JSON input.\r\n    \"\"\"\r\n\r\ndef cache_clear() -> None:\r\n    \"\"\"\r\n    Reset the string cache.\r\n    \"\"\"\r\n\r\ndef cache_usage() -> int:\r\n    \"\"\"\r\n    get the size of the string cache.\r\n\r\n    Returns:\r\n        Size of the string cache in bytes.\r\n    \"\"\"\r\n```\r\n## Examples\r\n\r\nThe main function provided by Jiter is `from_json()`, which accepts a bytes object containing JSON and returns a Python dictionary, list or other value.\r\n\r\n```python\r\nimport jiter\r\n\r\njson_data = b'{\"name\": \"John\", \"age\": 30}'\r\nparsed_data = jiter.from_json(json_data)\r\nprint(parsed_data)  # Output: {'name': 'John', 'age': 30}\r\n```\r\n\r\n### Handling Partial JSON\r\n\r\nIncomplete JSON objects can be parsed using the `partial_mode=` parameter.\r\n\r\n```python\r\nimport jiter\r\n\r\npartial_json = b'{\"name\": \"John\", \"age\": 30, \"city\": \"New Yor'\r\n\r\n# Raise error on incomplete JSON\r\ntry:\r\n    jiter.from_json(partial_json, partial_mode=False)\r\nexcept ValueError as e:\r\n    print(f\"Error: {e}\")\r\n\r\n# Parse incomplete JSON, discarding incomplete last field\r\nresult = jiter.from_json(partial_json, partial_mode=True)\r\nprint(result)  # Output: {'name': 'John', 'age': 30}\r\n\r\n# Parse incomplete JSON, including incomplete last field\r\nresult = jiter.from_json(partial_json, partial_mode='trailing-strings')\r\nprint(result)  # Output: {'name': 'John', 'age': 30, 'city': 'New Yor'}\r\n```\r\n\r\n### Catching Duplicate Keys\r\n\r\nThe `catch_duplicate_keys=True` option can be used to raise a `ValueError` if an object contains duplicate keys.\r\n\r\n```python\r\nimport jiter\r\n\r\njson_with_dupes = b'{\"foo\": 1, \"foo\": 2}'\r\n\r\n# Default behavior (last value wins)\r\nresult = jiter.from_json(json_with_dupes)\r\nprint(result)  # Output: {'foo': 2}\r\n\r\n# Catch duplicate keys\r\ntry:\r\n    jiter.from_json(json_with_dupes, catch_duplicate_keys=True)\r\nexcept ValueError as e:\r\n    print(f\"Error: {e}\")\r\n```\r\n\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
        "home_page": "https://github.com/pydantic/jiter/",
        "author_email": "Samuel Colvin <s@muelcolvin.com>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: GraalPy",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: MIT License",
          "Operating System :: Unix",
          "Operating System :: POSIX :: Linux",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Topic :: File Formats :: JSON",
          "Framework :: Pydantic :: 2"
        ],
        "requires_python": ">=3.9"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b2/35/e994121b0e90e46134673422dd564623f93304614f5d11886b1b3e06f503/multidict-6.7.1-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=960c83bf01a95b12b08fd54324a4eb1d5b52c88932b5cba5d6e712bb3ed12eb5",
          "hashes": {
            "sha256": "960c83bf01a95b12b08fd54324a4eb1d5b52c88932b5cba5d6e712bb3ed12eb5"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "multidict",
        "version": "6.7.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "multidict implementation",
        "description": "=========\r\nmultidict\r\n=========\r\n\r\n.. image:: https://github.com/aio-libs/multidict/actions/workflows/ci-cd.yml/badge.svg\r\n   :target: https://github.com/aio-libs/multidict/actions\r\n   :alt: GitHub status for master branch\r\n\r\n.. image:: https://codecov.io/gh/aio-libs/multidict/branch/master/graph/badge.svg?flag=pytest\r\n   :target: https://codecov.io/gh/aio-libs/multidict?flags[]=pytest\r\n   :alt: Coverage metrics\r\n\r\n.. image:: https://img.shields.io/pypi/v/multidict.svg\r\n   :target: https://pypi.org/project/multidict\r\n   :alt: PyPI\r\n\r\n.. image:: https://readthedocs.org/projects/multidict/badge/?version=latest\r\n   :target: https://multidict.aio-libs.org\r\n   :alt: Read The Docs build status badge\r\n\r\n.. image:: https://img.shields.io/endpoint?url=https://codspeed.io/badge.json\r\n   :target: https://codspeed.io/aio-libs/multidict\r\n   :alt: CodSpeed\r\n\r\n.. image:: https://img.shields.io/pypi/pyversions/multidict.svg\r\n   :target: https://pypi.org/project/multidict\r\n   :alt: Python versions\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs:matrix.org\r\n   :alt: Matrix Room â€” #aio-libs:matrix.org\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs-space:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs-space%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs-space:matrix.org\r\n   :alt: Matrix Space â€” #aio-libs-space:matrix.org\r\n\r\nMultidict is dict-like collection of *key-value pairs* where key\r\nmight occur more than once in the container.\r\n\r\nIntroduction\r\n------------\r\n\r\n*HTTP Headers* and *URL query string* require specific data structure:\r\n*multidict*. It behaves mostly like a regular ``dict`` but it may have\r\nseveral *values* for the same *key* and *preserves insertion ordering*.\r\n\r\nThe *key* is ``str`` (or ``istr`` for case-insensitive dictionaries).\r\n\r\n``multidict`` has four multidict classes:\r\n``MultiDict``, ``MultiDictProxy``, ``CIMultiDict``\r\nand ``CIMultiDictProxy``.\r\n\r\nImmutable proxies (``MultiDictProxy`` and\r\n``CIMultiDictProxy``) provide a dynamic view for the\r\nproxied multidict, the view reflects underlying collection changes. They\r\nimplement the ``collections.abc.Mapping`` interface.\r\n\r\nRegular mutable (``MultiDict`` and ``CIMultiDict``) classes\r\nimplement ``collections.abc.MutableMapping`` and allows them to change\r\ntheir own content.\r\n\r\n\r\n*Case insensitive* (``CIMultiDict`` and\r\n``CIMultiDictProxy``) assume the *keys* are case\r\ninsensitive, e.g.::\r\n\r\n   >>> dct = CIMultiDict(key='val')\r\n   >>> 'Key' in dct\r\n   True\r\n   >>> dct['Key']\r\n   'val'\r\n\r\n*Keys* should be ``str`` or ``istr`` instances.\r\n\r\nThe library has optional C Extensions for speed.\r\n\r\n\r\nLicense\r\n-------\r\n\r\nApache 2\r\n\r\nLibrary Installation\r\n--------------------\r\n\r\n.. code-block:: bash\r\n\r\n   $ pip install multidict\r\n\r\nThe library is Python 3 only!\r\n\r\nPyPI contains binary wheels for Linux, Windows and MacOS.  If you want to install\r\n``multidict`` on another operating system (or *Alpine Linux* inside a Docker) the\r\ntarball will be used to compile the library from source.  It requires a C compiler and\r\nPython headers to be installed.\r\n\r\nTo skip the compilation, please use the `MULTIDICT_NO_EXTENSIONS` environment variable,\r\ne.g.:\r\n\r\n.. code-block:: bash\r\n\r\n   $ MULTIDICT_NO_EXTENSIONS=1 pip install multidict\r\n\r\nPlease note, the pure Python (uncompiled) version is about 20-50 times slower depending on\r\nthe usage scenario!!!\r\n\r\nFor extension development, set the ``MULTIDICT_DEBUG_BUILD`` environment variable to compile\r\nthe extensions in debug mode:\r\n\r\n.. code-block:: console\r\n\r\n   $ MULTIDICT_DEBUG_BUILD=1 pip install multidict\r\n\r\nChangelog\r\n---------\r\nSee `RTD page <http://multidict.aio-libs.org/en/latest/changes>`_.\r\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/aio-libs/multidict",
        "author": "Andrew Svetlov",
        "author_email": "andrew.svetlov@gmail.com",
        "license": "Apache License 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_dist": [
          "typing-extensions>=4.1.0; python_version < \"3.11\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat: Matrix, https://matrix.to/#/#aio-libs:matrix.org",
          "Chat: Matrix Space, https://matrix.to/#/#aio-libs-space:matrix.org",
          "CI: GitHub, https://github.com/aio-libs/multidict/actions",
          "Code of Conduct, https://github.com/aio-libs/.github/blob/master/CODE_OF_CONDUCT.md",
          "Coverage: codecov, https://codecov.io/github/aio-libs/multidict",
          "Docs: Changelog, https://multidict.aio-libs.org/en/latest/changes/",
          "Docs: RTD, https://multidict.aio-libs.org",
          "GitHub: issues, https://github.com/aio-libs/multidict/issues",
          "GitHub: repo, https://github.com/aio-libs/multidict"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=87af6efd6b5e897c81050477ef65c62e2b2f35d51703cae01aff2905b1852e1c",
          "hashes": {
            "sha256": "87af6efd6b5e897c81050477ef65c62e2b2f35d51703cae01aff2905b1852e1c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "nest-asyncio",
        "version": "1.6.0",
        "summary": "Patch asyncio to allow nested event loops",
        "description": "|Build| |Status| |PyPiVersion| |License| |Downloads|\n\nIntroduction\n------------\n\nBy design asyncio `does not allow <https://github.com/python/cpython/issues/66435>`_\nits event loop to be nested. This presents a practical problem:\nWhen in an environment where the event loop is\nalready running it's impossible to run tasks and wait\nfor the result. Trying to do so will give the error\n\"``RuntimeError: This event loop is already running``\".\n\nThe issue pops up in various environments, such as web servers,\nGUI applications and in Jupyter notebooks.\n\nThis module patches asyncio to allow nested use of ``asyncio.run`` and\n``loop.run_until_complete``.\n\nInstallation\n------------\n\n.. code-block::\n\n    pip3 install nest_asyncio\n\nPython 3.5 or higher is required.\n\nUsage\n-----\n\n.. code-block:: python\n\n    import nest_asyncio\n    nest_asyncio.apply()\n\nOptionally the specific loop that needs patching can be given\nas argument to ``apply``, otherwise the current event loop is used.\nAn event loop can be patched whether it is already running\nor not. Only event loops from asyncio can be patched;\nLoops from other projects, such as uvloop or quamash,\ngenerally can't be patched.\n\n\n.. |Build| image:: https://github.com/erdewit/nest_asyncio/actions/workflows/test.yml/badge.svg?branche=master\n   :alt: Build\n   :target: https://github.com/erdewit/nest_asyncio/actions\n\n.. |PyPiVersion| image:: https://img.shields.io/pypi/v/nest_asyncio.svg\n   :alt: PyPi\n   :target: https://pypi.python.org/pypi/nest_asyncio\n\n.. |Status| image:: https://img.shields.io/badge/status-stable-green.svg\n   :alt:\n\n.. |License| image:: https://img.shields.io/badge/license-BSD-blue.svg\n   :alt:\n\n.. |Downloads| image:: https://static.pepy.tech/badge/nest-asyncio/month\n   :alt: Number of downloads\n   :target: https://pepy.tech/project/nest-asyncio\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "asyncio",
          "nested",
          "eventloop"
        ],
        "home_page": "https://github.com/erdewit/nest_asyncio",
        "author": "Ewald R. de Wit",
        "author_email": "ewald.de.wit@gmail.com",
        "license": "BSD",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3 :: Only",
          "Framework :: AsyncIO"
        ],
        "requires_python": ">=3.5"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/27/6f/83ead0e2e30a90445ee4fc0135f43741aebc30cca5b43f20968b603e30b6/openapi_core-0.19.5-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=ef7210e83a59394f46ce282639d8d26ad6fc8094aa904c9c16eb1bac8908911f",
          "hashes": {
            "sha256": "ef7210e83a59394f46ce282639d8d26ad6fc8094aa904c9c16eb1bac8908911f"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "openapi-core",
        "version": "0.19.5",
        "summary": "client-side and server-side support for the OpenAPI Specification v3",
        "description": "# openapi-core\n\n<a href=\"https://pypi.python.org/pypi/openapi-core\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/v/openapi-core.svg\" alt=\"Package version\">\n</a>\n<a href=\"https://travis-ci.org/python-openapi/openapi-core\" target=\"_blank\">\n    <img src=\"https://travis-ci.org/python-openapi/openapi-core.svg?branch=master\" alt=\"Continuous Integration\">\n</a>\n<a href=\"https://codecov.io/github/python-openapi/openapi-core?branch=master\" target=\"_blank\">\n    <img src=\"https://img.shields.io/codecov/c/github/python-openapi/openapi-core/master.svg?style=flat\" alt=\"Tests coverage\">\n</a>\n<a href=\"https://pypi.python.org/pypi/openapi-core\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/pyversions/openapi-core.svg\" alt=\"Python versions\">\n</a>\n<a href=\"https://pypi.python.org/pypi/openapi-core\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/format/openapi-core.svg\" alt=\"Package format\">\n</a>\n<a href=\"https://pypi.python.org/pypi/openapi-core\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/status/openapi-core.svg\" alt=\"Development status\">\n</a>\n\n## About\n\nOpenapi-core is a Python library that provides client-side and server-side support\nfor the [OpenAPI v3.0](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md)\nand [OpenAPI v3.1](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md) specifications.\n\n\n## Key features\n\n- **Validation** and **unmarshalling** of request and response data (including webhooks)\n- **Integration** with popular libraries (Requests, Werkzeug) and frameworks (Django, Falcon, Flask, Starlette)\n- Customization with media type **deserializers** and format **unmarshallers**\n- **Security** data providers (API keys, Cookie, Basic, and Bearer HTTP authentications)\n\n\n## Documentation\n\nCheck documentation to see more details about the features. All documentation is in the \"docs\" directory and online at [openapi-core.readthedocs.io](https://openapi-core.readthedocs.io)\n\n\n## Installation\n\nRecommended way (via pip):\n\n``` console\npip install openapi-core\n```\n\nAlternatively you can download the code and install from the repository:\n\n``` console\npip install -e git+https://github.com/python-openapi/openapi-core.git#egg=openapi_core\n```\n\n\n## First steps\n\nFirst, create your OpenAPI object.\n\n``` python\nfrom openapi_core import OpenAPI\n\nopenapi = OpenAPI.from_file_path('openapi.json')\n```\n\nNow you can use it to validate and unmarshal against requests and/or responses. \n\n``` python\n# raises an error if the request is invalid\nresult = openapi.unmarshal_request(request)\n```\n\nRetrieve validated and unmarshalled request data.\n\n``` python\n# get parameters\npath_params = result.parameters.path\nquery_params = result.parameters.query\ncookies_params = result.parameters.cookies\nheaders_params = result.parameters.headers\n# get body\nbody = result.body\n# get security data\nsecurity = result.security\n```\n\nThe request object should implement the OpenAPI Request protocol. Check [Integrations](https://openapi-core.readthedocs.io/en/latest/integrations.html) to find officially supported implementations.\n\nFor more details read about the [Unmarshalling](https://openapi-core.readthedocs.io/en/latest/unmarshalling.html) process.\n\nIf you just want to validate your request/response data without unmarshalling, read about [Validation](https://openapi-core.readthedocs.io/en/latest/validation.html) instead.\n\n\n## Related projects\n\n- [openapi-spec-validator](https://github.com/python-openapi/openapi-spec-validator)\n  : A Python library that validates OpenAPI Specs against the OpenAPI 2.0 (aka Swagger), OpenAPI 3.0, and OpenAPI 3.1 specification. The validator aims to check for full compliance with the Specification.\n- [openapi-schema-validator](https://github.com/python-openapi/openapi-schema-validator)\n  : A Python library that validates schema against the OpenAPI Schema Specification v3.0 and OpenAPI Schema Specification v3.1.\n- [bottle-openapi-3](https://github.com/cope-systems/bottle-openapi-3)\n  : OpenAPI 3.0 Support for the Bottle Web Framework\n- [pyramid_openapi3](https://github.com/niteoweb/pyramid_openapi3)\n  : Pyramid addon for OpenAPI3 validation of requests and responses.\n- [tornado-openapi3](https://github.com/correl/tornado-openapi3)\n  : Tornado OpenAPI 3 request and response validation library.\n\n## License\n\nThe project is under the terms of the BSD 3-Clause License.\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "openapi",
          "swagger",
          "schema"
        ],
        "author": "Artur Maciag",
        "author_email": "maciag.artur@gmail.com",
        "license": "BSD-3-Clause",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "aiohttp (>=3.0) ; extra == \"aiohttp\"",
          "aioitertools (>=0.11,<0.13) ; extra == \"starlette\"",
          "django (>=3.0) ; extra == \"django\"",
          "falcon (>=3.0) ; extra == \"falcon\"",
          "fastapi (>=0.111,<0.116) ; extra == \"fastapi\"",
          "flask ; extra == \"flask\"",
          "isodate",
          "jsonschema (>=4.18.0,<5.0.0)",
          "jsonschema-path (>=0.3.1,<0.4.0)",
          "more-itertools",
          "multidict (>=6.0.4,<7.0.0) ; extra == \"aiohttp\"",
          "openapi-schema-validator (>=0.6.0,<0.7.0)",
          "openapi-spec-validator (>=0.7.1,<0.8.0)",
          "parse",
          "requests ; extra == \"requests\"",
          "starlette (>=0.26.1,<0.45.0) ; extra == \"starlette\"",
          "typing-extensions (>=4.8.0,<5.0.0)",
          "werkzeug (<3.1.2)"
        ],
        "requires_python": ">=3.8.0,<4.0.0",
        "project_url": [
          "Documentation, https://openapi-core.readthedocs.io",
          "Repository, https://github.com/python-openapi/openapi-core"
        ],
        "provides_extra": [
          "aiohttp",
          "django",
          "falcon",
          "fastapi",
          "flask",
          "requests",
          "starlette"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/69/90/f63fb5873511e014207a475e2bb4e8b2e570d655b00ac19a9a0ca0a385ee/jsonschema-4.26.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d489f15263b8d200f8387e64b4c3a75f06629559fb73deb8fdfb525f2dab50ce",
          "hashes": {
            "sha256": "d489f15263b8d200f8387e64b4c3a75f06629559fb73deb8fdfb525f2dab50ce"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "jsonschema",
        "version": "4.26.0",
        "summary": "An implementation of JSON Schema validation for Python",
        "description": "==========\njsonschema\n==========\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |Precommit| |Zenodo|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema.svg\n   :alt: PyPI version\n   :target: https://pypi.org/project/jsonschema/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema.svg\n   :alt: Supported Python versions\n   :target: https://pypi.org/project/jsonschema/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/python-jsonschema/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://python-jsonschema.readthedocs.io/en/stable/\n\n.. |Precommit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/jsonschema/main.svg\n   :alt: pre-commit.ci status\n   :target: https://results.pre-commit.ci/latest/github/python-jsonschema/jsonschema/main\n\n.. |Zenodo| image:: https://zenodo.org/badge/3072629.svg\n   :alt: Zenodo DOI\n   :target: https://zenodo.org/badge/latestdoi/3072629\n\n\n``jsonschema`` is an implementation of the `JSON Schema <https://json-schema.org>`_ specification for Python.\n\n.. code:: python\n\n    >>> from jsonschema import validate\n\n    >>> # A sample schema, like what we'd get from json.load()\n    >>> schema = {\n    ...     \"type\" : \"object\",\n    ...     \"properties\" : {\n    ...         \"price\" : {\"type\" : \"number\"},\n    ...         \"name\" : {\"type\" : \"string\"},\n    ...     },\n    ... }\n\n    >>> # If no exception is raised by validate(), the instance is valid.\n    >>> validate(instance={\"name\" : \"Eggs\", \"price\" : 34.99}, schema=schema)\n\n    >>> validate(\n    ...     instance={\"name\" : \"Eggs\", \"price\" : \"Invalid\"}, schema=schema,\n    ... )                                   # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    ValidationError: 'Invalid' is not of type 'number'\n\nIt can also be used from the command line by installing `check-jsonschema <https://github.com/python-jsonschema/check-jsonschema>`_.\n\nFeatures\n--------\n\n* Full support for `Draft 2020-12 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft202012Validator>`_, `Draft 2019-09 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft201909Validator>`_, `Draft 7 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft7Validator>`_, `Draft 6 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft6Validator>`_, `Draft 4 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft4Validator>`_ and `Draft 3 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft3Validator>`_\n\n* `Lazy validation <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/protocols/#jsonschema.protocols.Validator.iter_errors>`_ that can iteratively report *all* validation errors.\n\n* `Programmatic querying <https://python-jsonschema.readthedocs.io/en/latest/errors/>`_ of which properties or items failed validation.\n\n\nInstallation\n------------\n\n``jsonschema`` is available on `PyPI <https://pypi.org/project/jsonschema/>`_. You can install using `pip <https://pip.pypa.io/en/stable/>`_:\n\n.. code:: bash\n\n    $ pip install jsonschema\n\n\nExtras\n======\n\nTwo extras are available when installing the package, both currently related to ``format`` validation:\n\n    * ``format``\n    * ``format-nongpl``\n\nThey can be used when installing in order to include additional dependencies, e.g.:\n\n.. code:: bash\n\n    $ pip install jsonschema'[format]'\n\nBe aware that the mere presence of these dependencies â€“ or even the specification of ``format`` checks in a schema â€“ do *not* activate format checks (as per the specification).\nPlease read the `format validation documentation <https://python-jsonschema.readthedocs.io/en/latest/validate/#validating-formats>`_ for further details.\n\nAbout\n-----\n\nI'm Julian Berman.\n\n``jsonschema`` is on `GitHub <https://github.com/python-jsonschema/jsonschema>`_.\n\nGet in touch, via GitHub or otherwise, if you've got something to contribute, it'd be most welcome!\n\nIf you feel overwhelmingly grateful, you can also `sponsor me <https://github.com/sponsors/Julian/>`_.\n\nAnd for companies who appreciate ``jsonschema`` and its continued support and growth, ``jsonschema`` is also now supportable via `TideLift <https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=readme>`_.\n\n\nRelease Information\n-------------------\n\nv4.26.0\n=======\n\n* Decrease import time by delaying importing of ``urllib.request`` (#1416).\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author_email": "Julian Berman <Julian+jsonschema@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "jsonschema-specifications>=2023.03.6",
          "referencing>=0.28.4",
          "rpds-py>=0.25.0",
          "fqdn; extra == 'format'",
          "idna; extra == 'format'",
          "isoduration; extra == 'format'",
          "jsonpointer>1.13; extra == 'format'",
          "rfc3339-validator; extra == 'format'",
          "rfc3987; extra == 'format'",
          "uri-template; extra == 'format'",
          "webcolors>=1.11; extra == 'format'",
          "fqdn; extra == 'format-nongpl'",
          "idna; extra == 'format-nongpl'",
          "isoduration; extra == 'format-nongpl'",
          "jsonpointer>1.13; extra == 'format-nongpl'",
          "rfc3339-validator; extra == 'format-nongpl'",
          "rfc3986-validator>0.1.0; extra == 'format-nongpl'",
          "rfc3987-syntax>=1.1.0; extra == 'format-nongpl'",
          "uri-template; extra == 'format-nongpl'",
          "webcolors>=24.6.0; extra == 'format-nongpl'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/python-jsonschema/jsonschema",
          "Documentation, https://python-jsonschema.readthedocs.io/",
          "Issues, https://github.com/python-jsonschema/jsonschema/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://github.com/python-jsonschema/jsonschema/blob/main/CHANGELOG.rst",
          "Source, https://github.com/python-jsonschema/jsonschema"
        ],
        "provides_extra": [
          "format",
          "format-nongpl"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/cb/58/3485da8cb93d2f393bce453adeef16896751f14ba3e2024bc21dc9597646/jsonschema_path-0.3.4-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f502191fdc2b22050f9a81c9237be9d27145b9001c55842bece5e94e382e52f8",
          "hashes": {
            "sha256": "f502191fdc2b22050f9a81c9237be9d27145b9001c55842bece5e94e382e52f8"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "jsonschema-path",
        "version": "0.3.4",
        "summary": "JSONSchema Spec with object-oriented paths",
        "description": "***************\nJSONSchema Path\n***************\n\n.. image:: https://img.shields.io/pypi/v/jsonschema-path.svg\n     :target: https://pypi.python.org/pypi/jsonschema-path\n.. image:: https://travis-ci.org/p1c2u/jsonschema-path.svg?branch=master\n     :target: https://travis-ci.org/p1c2u/jsonschema-path\n.. image:: https://img.shields.io/codecov/c/github/p1c2u/jsonschema-path/master.svg?style=flat\n     :target: https://codecov.io/github/p1c2u/jsonschema-path?branch=master\n.. image:: https://img.shields.io/pypi/pyversions/jsonschema-path.svg\n     :target: https://pypi.python.org/pypi/jsonschema-path\n.. image:: https://img.shields.io/pypi/format/jsonschema-path.svg\n     :target: https://pypi.python.org/pypi/jsonschema-path\n.. image:: https://img.shields.io/pypi/status/jsonschema-path.svg\n     :target: https://pypi.python.org/pypi/jsonschema-path\n\nAbout\n#####\n\nObject-oriented JSONSchema\n\nKey features\n############\n\n* Traverse schema like paths\n* Access schema on demand with separate dereferencing accessor layer\n\nInstallation\n############\n\n.. code-block:: console\n\n   pip install jsonschema-path\n\nAlternatively you can download the code and install from the repository:\n\n.. code-block:: console\n\n   pip install -e git+https://github.com/p1c2u/jsonschema-path.git#egg=jsonschema_path\n\n\nUsage\n#####\n\n.. code-block:: python\n\n   >>> from jsonschema_path import SchemaPath\n   \n   >>> d = {\n   ...     \"properties\": {\n   ...        \"info\": {\n   ...            \"$ref\": \"#/$defs/Info\",\n   ...        },\n   ...     },\n   ...     \"$defs\": {\n   ...         \"Info\": {\n   ...             \"properties\": {\n   ...                 \"title\": {\n   ...                     \"$ref\": \"http://example.com\",\n   ...                 },\n   ...                 \"version\": {\n   ...                     \"type\": \"string\",\n   ...                     \"default\": \"1.0\",\n   ...                 },\n   ...             },\n   ...         },\n   ...     },\n   ... }\n   \n   >>> path = SchemaPath.from_dict(d)\n   \n   >>> # Stat keys\n   >>> \"properties\" in path\n   True\n   \n   >>> # Concatenate paths with /\n   >>> info_path = path / \"properties\" / \"info\"\n   \n   >>> # Stat keys with implicit dereferencing\n   >>> \"properties\" in info_path\n   True\n   \n   >>> # Concatenate paths with implicit dereferencing\n   >>> version_path = info_path / \"properties\" / \"version\"\n   \n   >>> # Open content with implicit dereferencing\n   >>> with version_path.open() as contents:\n   ...     print(contents)\n   {'type': 'string', 'default': '1.0'}\n\n\nRelated projects\n################\n\n* `openapi-core <https://github.com/p1c2u/openapi-core>`__\n   Python library that adds client-side and server-side support for the OpenAPI.\n* `openapi-spec-validator <https://github.com/p1c2u/openapi-spec-validator>`__\n   Python library that validates OpenAPI Specs against the OpenAPI 2.0 (aka Swagger) and OpenAPI 3.0 specification\n* `openapi-schema-validator <https://github.com/p1c2u/openapi-schema-validator>`__\n   Python library that validates schema against the OpenAPI Schema Specification v3.0.\n\nLicense\n#######\n\nCopyright (c) 2017-2022, Artur Maciag, All rights reserved. Apache-2.0\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "jsonschema",
          "swagger",
          "spec"
        ],
        "author": "Artur Maciag",
        "author_email": "maciag.artur@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "PyYAML (>=5.1)",
          "pathable (>=0.4.1,<0.5.0)",
          "referencing (<0.37.0)",
          "requests (>=2.31.0,<3.0.0)"
        ],
        "requires_python": ">=3.8.0,<4.0.0",
        "project_url": [
          "Repository, https://github.com/p1c2u/jsonschema-path"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/21/c6/ad0fba32775ae749016829dace42ed80f4407b171da41313d1a3a5f102e4/openapi_schema_validator-0.6.3-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f3b9870f4e556b5a62a1c39da72a6b4b16f3ad9c73dc80084b1b11e74ba148a3",
          "hashes": {
            "sha256": "f3b9870f4e556b5a62a1c39da72a6b4b16f3ad9c73dc80084b1b11e74ba148a3"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "openapi-schema-validator",
        "version": "0.6.3",
        "summary": "OpenAPI schema validation for Python",
        "description": "************************\nopenapi-schema-validator\n************************\n\n.. image:: https://img.shields.io/pypi/v/openapi-schema-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-schema-validator\n.. image:: https://travis-ci.org/python-openapi/openapi-schema-validator.svg?branch=master\n     :target: https://travis-ci.org/python-openapi/openapi-schema-validator\n.. image:: https://img.shields.io/codecov/c/github/python-openapi/openapi-schema-validator/master.svg?style=flat\n     :target: https://codecov.io/github/python-openapi/openapi-schema-validator?branch=master\n.. image:: https://img.shields.io/pypi/pyversions/openapi-schema-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-schema-validator\n.. image:: https://img.shields.io/pypi/format/openapi-schema-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-schema-validator\n.. image:: https://img.shields.io/pypi/status/openapi-schema-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-schema-validator\n\nAbout\n#####\n\nOpenapi-schema-validator is a Python library that validates schema against:\n\n* `OpenAPI Schema Specification v3.0 <https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md#schemaObject>`__ which is an extended subset of the `JSON Schema Specification Wright Draft 00 <http://json-schema.org/>`__.\n* `OpenAPI Schema Specification v3.1 <https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.1.0.md#schemaObject>`__ which is an extended superset of the `JSON Schema Specification Draft 2020-12 <http://json-schema.org/>`__.\n\n\nDocumentation\n#############\n\nCheck documentation to see more details about the features. All documentation is in the \"docs\" directory and online at `openapi-schema-validator.readthedocs.io <https://openapi-schema-validator.readthedocs.io>`__\n\n\nInstallation\n############\n\nRecommended way (via pip):\n\n.. code-block:: console\n\n   pip install openapi-schema-validator\n\nAlternatively you can download the code and install from the repository:\n\n.. code-block:: console\n\n   pip install -e git+https://github.com/python-openapi/openapi-schema-validator.git#egg=openapi_schema_validator\n\n\nUsage\n#####\n\nTo validate an OpenAPI v3.1 schema:\n\n.. code-block:: python\n\n   from openapi_schema_validator import validate\n\n   # A sample schema\n   schema = {\n       \"type\": \"object\",\n       \"required\": [\n          \"name\"\n       ],\n       \"properties\": {\n           \"name\": {\n               \"type\": \"string\"\n           },\n           \"age\": {\n               \"type\": [\"integer\", \"null\"],\n               \"format\": \"int32\",\n               \"minimum\": 0,\n           },\n           \"birth-date\": {\n               \"type\": \"string\",\n               \"format\": \"date\",\n           },\n           \"address\": {\n                \"type\": 'array',\n                \"prefixItems\": [\n                    { \"type\": \"number\" },\n                    { \"type\": \"string\" },\n                    { \"enum\": [\"Street\", \"Avenue\", \"Boulevard\"] },\n                    { \"enum\": [\"NW\", \"NE\", \"SW\", \"SE\"] }\n                ],\n                \"items\": False,\n            }\n       },\n       \"additionalProperties\": False,\n   }\n\n   # If no exception is raised by validate(), the instance is valid.\n   validate({\"name\": \"John\", \"age\": 23, \"address\": [1600, \"Pennsylvania\", \"Avenue\"]}, schema)\n\n   validate({\"name\": \"John\", \"city\": \"London\"}, schema)\n\n   Traceback (most recent call last):\n       ...\n   ValidationError: Additional properties are not allowed ('city' was unexpected)\n\nBy default, the latest OpenAPI schema syntax is expected.\n\nFor more details read about `Validation <https://openapi-schema-validator.readthedocs.io/en/latest/validation.html>`__.\n\nRelated projects\n################\n* `openapi-core <https://github.com/python-openapi/openapi-core>`__\n   Python library that adds client-side and server-side support for the OpenAPI.\n* `openapi-spec-validator <https://github.com/python-openapi/openapi-spec-validator>`__\n   Python library that validates OpenAPI Specs against the OpenAPI 2.0 (aka Swagger) and OpenAPI 3.0 specification\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "openapi",
          "swagger",
          "schema"
        ],
        "home_page": "https://github.com/python-openapi/openapi-schema-validator",
        "author": "Artur Maciag",
        "author_email": "maciag.artur@gmail.com",
        "license": "BSD-3-Clause",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "jsonschema (>=4.19.1,<5.0.0)",
          "jsonschema-specifications (>=2023.5.2)",
          "rfc3339-validator"
        ],
        "requires_python": ">=3.8.0,<4.0.0",
        "project_url": [
          "Repository, https://github.com/python-openapi/openapi-schema-validator"
        ],
        "provides_extra": [
          "docs"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/27/dd/b3fd642260cb17532f66cc1e8250f3507d1e580483e209dc1e9d13bd980d/openapi_spec_validator-0.7.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4bbdc0894ec85f1d1bea1d6d9c8b2c3c8d7ccaa13577ef40da9c006c9fd0eb60",
          "hashes": {
            "sha256": "4bbdc0894ec85f1d1bea1d6d9c8b2c3c8d7ccaa13577ef40da9c006c9fd0eb60"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "openapi-spec-validator",
        "version": "0.7.2",
        "summary": "OpenAPI 2.0 (aka Swagger) and OpenAPI 3 spec validator",
        "description": "**********************\nOpenAPI Spec validator\n**********************\n\n.. image:: https://img.shields.io/docker/v/pythonopenapi/openapi-spec-validator.svg?color=%23086DD7&label=docker%20hub&sort=semver\n     :target: https://hub.docker.com/r/pythonopenapi/openapi-spec-validator\n.. image:: https://img.shields.io/pypi/v/openapi-spec-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-spec-validator\n.. image:: https://travis-ci.org/python-openapi/openapi-spec-validator.svg?branch=master\n     :target: https://travis-ci.org/python-openapi/openapi-spec-validator\n.. image:: https://img.shields.io/codecov/c/github/python-openapi/openapi-spec-validator/master.svg?style=flat\n     :target: https://codecov.io/github/python-openapi/openapi-spec-validator?branch=master\n.. image:: https://img.shields.io/pypi/pyversions/openapi-spec-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-spec-validator\n.. image:: https://img.shields.io/pypi/format/openapi-spec-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-spec-validator\n.. image:: https://img.shields.io/pypi/status/openapi-spec-validator.svg\n     :target: https://pypi.python.org/pypi/openapi-spec-validator\n\nAbout\n#####\n\nOpenAPI Spec Validator is a CLI, pre-commit hook and python package that validates OpenAPI Specs\nagainst the `OpenAPI 2.0 (aka Swagger)\n<https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md>`__,\n`OpenAPI 3.0 <https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md>`__\nand `OpenAPI 3.1 <https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md>`__\nspecification. The validator aims to check for full compliance with the Specification.\n\n\nDocumentation\n#############\n\nCheck documentation to see more details about the features. All documentation is in the \"docs\" directory and online at `openapi-spec-validator.readthedocs.io <https://openapi-spec-validator.readthedocs.io>`__\n\n\nInstallation\n############\n\n.. code-block:: console\n\n    pip install openapi-spec-validator\n\nAlternatively you can download the code and install from the repository:\n\n.. code-block:: bash\n\n   pip install -e git+https://github.com/python-openapi/openapi-spec-validator.git#egg=openapi_spec_validator\n\n\nUsage\n#####\n\nCLI (Command Line Interface)\n****************************\n\nStraight forward way:\n\n.. code-block:: bash\n\n    openapi-spec-validator openapi.yaml\n\npipes way:\n\n.. code-block:: bash\n\n    cat openapi.yaml | openapi-spec-validator -\n\ndocker way:\n\n.. code-block:: bash\n\n    docker run -v path/to/openapi.yaml:/openapi.yaml --rm pythonopenapi/openapi-spec-validator /openapi.yaml\n\nor more pythonic way:\n\n.. code-block:: bash\n\n    python -m openapi_spec_validator openapi.yaml\n\nFor more details, read about `CLI (Command Line Interface) <https://openapi-spec-validator.readthedocs.io/en/latest/cli.html>`__.\n\npre-commit hook\n***************\n\n.. code-block:: yaml\n\n   repos:\n   -   repo: https://github.com/python-openapi/openapi-spec-validator\n       rev: 0.5.5 # The version to use or 'master' for latest\n       hooks:\n       -   id: openapi-spec-validator\n\nFor more details, read about `pre-commit hook <https://openapi-spec-validator.readthedocs.io/en/latest/hook.html>`__.\n\nPython package\n**************\n\n.. code:: python\n\n    from openapi_spec_validator import validate\n    from openapi_spec_validator.readers import read_from_filename\n\n    spec_dict, base_uri = read_from_filename('openapi.yaml')\n\n    # If no exception is raised by validate(), the spec is valid.\n    validate(spec_dict)\n\n    validate({'openapi': '3.1.0'})\n\n    Traceback (most recent call last):\n        ...\n    OpenAPIValidationError: 'info' is a required property\n\nFor more details, read about `Python package <https://openapi-spec-validator.readthedocs.io/en/latest/python.html>`__.\n\nRelated projects\n################\n\n* `openapi-core <https://github.com/python-openapi/openapi-core>`__\n   Python library that adds client-side and server-side support for the OpenAPI v3.0 and OpenAPI v3.1 specification.\n* `openapi-schema-validator <https://github.com/python-openapi/openapi-schema-validator>`__\n   Python library that validates schema against the OpenAPI Schema Specification v3.0 and OpenAPI Schema Specification v3.1.\n\nLicense\n#######\n\nCopyright (c) 2017-2023, Artur Maciag, All rights reserved. Apache v2\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "openapi",
          "swagger",
          "schema"
        ],
        "author": "Artur Maciag",
        "author_email": "maciag.artur@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "importlib-resources (>=5.8,<7.0) ; python_version < \"3.9\"",
          "jsonschema (>=4.18.0,<5.0.0)",
          "jsonschema-path (>=0.3.1,<0.4.0)",
          "lazy-object-proxy (>=1.7.1,<2.0.0)",
          "openapi-schema-validator (>=0.6.0,<0.7.0)"
        ],
        "requires_python": ">=3.8.0,<4.0.0",
        "project_url": [
          "Repository, https://github.com/python-openapi/openapi-spec-validator"
        ],
        "provides_extra": [
          "docs"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c0/67/8ec9abe15c4f8a4bcc6e65160a2c667240d025cbb6591b879bea55625263/lazy_object_proxy-1.12.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=7b22c2bbfb155706b928ac4d74c1a63ac8552a55ba7fff4445155523ea4067e1",
          "hashes": {
            "sha256": "7b22c2bbfb155706b928ac4d74c1a63ac8552a55ba7fff4445155523ea4067e1"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "lazy-object-proxy",
        "version": "1.12.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "A fast and thorough lazy object proxy.",
        "description": "========\r\nOverview\r\n========\r\n\r\n.. start-badges\r\n\r\n.. list-table::\r\n    :stub-columns: 1\r\n\r\n    * - docs\r\n      - |docs|\r\n    * - tests\r\n      - |github-actions| |coveralls| |codecov|\r\n    * - package\r\n      - |version| |wheel| |supported-versions| |supported-implementations| |commits-since|\r\n.. |docs| image:: https://readthedocs.org/projects/python-lazy-object-proxy/badge/?style=flat\r\n    :target: https://readthedocs.org/projects/python-lazy-object-proxy/\r\n    :alt: Documentation Status\r\n\r\n.. |github-actions| image:: https://github.com/ionelmc/python-lazy-object-proxy/actions/workflows/github-actions.yml/badge.svg\r\n    :alt: GitHub Actions Build Status\r\n    :target: https://github.com/ionelmc/python-lazy-object-proxy/actions\r\n\r\n.. |coveralls| image:: https://coveralls.io/repos/github/ionelmc/python-lazy-object-proxy/badge.svg?branch=master\r\n    :alt: Coverage Status\r\n    :target: https://coveralls.io/github/ionelmc/python-lazy-object-proxy?branch=master\r\n\r\n.. |codecov| image:: https://codecov.io/gh/ionelmc/python-lazy-object-proxy/branch/master/graphs/badge.svg?branch=master\r\n    :alt: Coverage Status\r\n    :target: https://app.codecov.io/github/ionelmc/python-lazy-object-proxy\r\n\r\n.. |version| image:: https://img.shields.io/pypi/v/lazy-object-proxy.svg\r\n    :alt: PyPI Package latest release\r\n    :target: https://pypi.org/project/lazy-object-proxy\r\n\r\n.. |wheel| image:: https://img.shields.io/pypi/wheel/lazy-object-proxy.svg\r\n    :alt: PyPI Wheel\r\n    :target: https://pypi.org/project/lazy-object-proxy\r\n\r\n.. |supported-versions| image:: https://img.shields.io/pypi/pyversions/lazy-object-proxy.svg\r\n    :alt: Supported versions\r\n    :target: https://pypi.org/project/lazy-object-proxy\r\n\r\n.. |supported-implementations| image:: https://img.shields.io/pypi/implementation/lazy-object-proxy.svg\r\n    :alt: Supported implementations\r\n    :target: https://pypi.org/project/lazy-object-proxy\r\n\r\n.. |commits-since| image:: https://img.shields.io/github/commits-since/ionelmc/python-lazy-object-proxy/v1.12.0.svg\r\n    :alt: Commits since latest release\r\n    :target: https://github.com/ionelmc/python-lazy-object-proxy/compare/v1.12.0...master\r\n\r\n\r\n\r\n.. end-badges\r\n\r\nA fast and thorough lazy object proxy.\r\n\r\n* Free software: BSD 2-Clause License\r\n\r\nNote that this is based on `wrapt`_'s ObjectProxy with one big change: it calls a function the first time the proxy object is\r\nused, while `wrapt.ObjectProxy` just forwards the method calls to the target object.\r\n\r\nIn other words, you use `lazy-object-proxy` when you only have the object way later and you use `wrapt.ObjectProxy` when you\r\nwant to override few methods (by subclassing) and forward everything else to the target object.\r\n\r\nExample::\r\n\r\n    import lazy_object_proxy\r\n\r\n    def expensive_func():\r\n        from time import sleep\r\n        print('starting calculation')\r\n        # just as example for a very slow computation\r\n        sleep(2)\r\n        print('finished calculation')\r\n        # return the result of the calculation\r\n        return 10\r\n\r\n    obj = lazy_object_proxy.Proxy(expensive_func)\r\n    # function is called only when object is actually used\r\n    print(obj)  # now expensive_func is called\r\n\r\n    print(obj)  # the result without calling the expensive_func\r\n\r\nInstallation\r\n============\r\n\r\n::\r\n\r\n    pip install lazy-object-proxy\r\n\r\nYou can also install the in-development version with::\r\n\r\n    pip install https://github.com/ionelmc/python-lazy-object-proxy/archive/master.zip\r\n\r\n\r\nDocumentation\r\n=============\r\n\r\n\r\nhttps://python-lazy-object-proxy.readthedocs.io/\r\n\r\n\r\nDevelopment\r\n===========\r\n\r\nTo run all the tests run::\r\n\r\n    tox\r\n\r\nAcknowledgements\r\n================\r\n\r\nThis project is based on some code from `wrapt`_ as you can see in the git history.\r\n\r\n.. _wrapt: https://github.com/GrahamDumpleton/wrapt\r\n",
        "description_content_type": "text/x-rst",
        "author_email": "Ionel Cristian MÄƒrieÈ™ <contact@ionelmc.ro>",
        "license_expression": "BSD-2-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: Unix",
          "Operating System :: POSIX",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Sources, https://github.com/ionelmc/python-lazy-object-proxy",
          "Documentation, https://python-lazy-object-proxy.readthedocs.io/",
          "Changelog, https://python-lazy-object-proxy.readthedocs.io/en/latest/changelog.html",
          "Issue Tracker, https://github.com/ionelmc/python-lazy-object-proxy/issues"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7d/eb/b6260b31b1a96386c0a880edebe26f89669098acea8e0318bff6adb378fd/pathable-0.4.4-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5ae9e94793b6ef5a4cbe0a7ce9dbbefc1eec38df253763fd0aeeacf2762dbbc2",
          "hashes": {
            "sha256": "5ae9e94793b6ef5a4cbe0a7ce9dbbefc1eec38df253763fd0aeeacf2762dbbc2"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "pathable",
        "version": "0.4.4",
        "summary": "Object-oriented paths",
        "description": "********\npathable\n********\n\n\nAbout\n#####\n\nObject-oriented paths\n\nKey features\n************\n\n* Traverse resources like paths\n* Access resources on demand with separate accessor layer\n\nUsage\n#####\n\n.. code-block:: python\n\n   from pathable import DictPath\n   \n   d = {\n       \"parts\": {\n           \"part1\": {\n               \"name\": \"Part One\",\n           },\n           \"part2\": {\n               \"name\": \"Part Two\",\n           },\n       },\n   }\n   \n   dp = DictPath(d)\n   \n   # Concatenate paths with /\n   parts = dp / \"parts\"\n   \n   # Stat path keys\n   \"part2\" in parts\n   \n   # Open path dict\n   with parts.open() as parts_dict:\n       print(parts_dict)\n\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "dict",
          "dictionary",
          "list",
          "lookup",
          "path",
          "pathable"
        ],
        "home_page": "https://github.com/p1c2u/pathable",
        "author": "Artur Maciag",
        "author_email": "maciag.artur@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.7.0,<4.0.0",
        "project_url": [
          "Repository, https://github.com/p1c2u/pathable"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/54/20/4d324d65cc6d9205fabedc306948156824eb9f0ee1633355a8f7ec5c66bf/pluggy-1.6.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=e920276dd6813095e9377c0bc5566d94c932c33b27a3e3945d8389c374dd4746",
          "hashes": {
            "sha256": "e920276dd6813095e9377c0bc5566d94c932c33b27a3e3945d8389c374dd4746"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pluggy",
        "version": "1.6.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "plugin and hook calling mechanisms for python",
        "description": "====================================================\npluggy - A minimalist production ready plugin system\n====================================================\n\n|pypi| |conda-forge| |versions| |github-actions| |gitter| |black| |codecov|\n\nThis is the core framework used by the `pytest`_, `tox`_, and `devpi`_ projects.\n\nPlease `read the docs`_ to learn more!\n\nA definitive example\n====================\n.. code-block:: python\n\n    import pluggy\n\n    hookspec = pluggy.HookspecMarker(\"myproject\")\n    hookimpl = pluggy.HookimplMarker(\"myproject\")\n\n\n    class MySpec:\n        \"\"\"A hook specification namespace.\"\"\"\n\n        @hookspec\n        def myhook(self, arg1, arg2):\n            \"\"\"My special little hook that you can customize.\"\"\"\n\n\n    class Plugin_1:\n        \"\"\"A hook implementation namespace.\"\"\"\n\n        @hookimpl\n        def myhook(self, arg1, arg2):\n            print(\"inside Plugin_1.myhook()\")\n            return arg1 + arg2\n\n\n    class Plugin_2:\n        \"\"\"A 2nd hook implementation namespace.\"\"\"\n\n        @hookimpl\n        def myhook(self, arg1, arg2):\n            print(\"inside Plugin_2.myhook()\")\n            return arg1 - arg2\n\n\n    # create a manager and add the spec\n    pm = pluggy.PluginManager(\"myproject\")\n    pm.add_hookspecs(MySpec)\n\n    # register plugins\n    pm.register(Plugin_1())\n    pm.register(Plugin_2())\n\n    # call our ``myhook`` hook\n    results = pm.hook.myhook(arg1=1, arg2=2)\n    print(results)\n\n\nRunning this directly gets us::\n\n    $ python docs/examples/toy-example.py\n    inside Plugin_2.myhook()\n    inside Plugin_1.myhook()\n    [-1, 3]\n\n\n.. badges\n\n.. |pypi| image:: https://img.shields.io/pypi/v/pluggy.svg\n    :target: https://pypi.org/pypi/pluggy\n\n.. |versions| image:: https://img.shields.io/pypi/pyversions/pluggy.svg\n    :target: https://pypi.org/pypi/pluggy\n\n.. |github-actions| image:: https://github.com/pytest-dev/pluggy/workflows/main/badge.svg\n    :target: https://github.com/pytest-dev/pluggy/actions\n\n.. |conda-forge| image:: https://img.shields.io/conda/vn/conda-forge/pluggy.svg\n    :target: https://anaconda.org/conda-forge/pytest\n\n.. |gitter| image:: https://badges.gitter.im/pytest-dev/pluggy.svg\n    :alt: Join the chat at https://gitter.im/pytest-dev/pluggy\n    :target: https://gitter.im/pytest-dev/pluggy?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\n.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/ambv/black\n\n.. |codecov| image:: https://codecov.io/gh/pytest-dev/pluggy/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/pytest-dev/pluggy\n    :alt: Code coverage Status\n\n.. links\n.. _pytest:\n    http://pytest.org\n.. _tox:\n    https://tox.readthedocs.org\n.. _devpi:\n    http://doc.devpi.net\n.. _read the docs:\n   https://pluggy.readthedocs.io/en/latest/\n\n\nSupport pluggy\n--------------\n\n`Open Collective`_ is an online funding platform for open and transparent communities.\nIt provides tools to raise money and share your finances in full transparency.\n\nIt is the platform of choice for individuals and companies that want to make one-time or\nmonthly donations directly to the project.\n\n``pluggy`` is part of the ``pytest-dev`` project, see more details in the `pytest collective`_.\n\n.. _Open Collective: https://opencollective.com\n.. _pytest collective: https://opencollective.com/pytest\n",
        "description_content_type": "text/x-rst",
        "author_email": "Holger Krekel <holger@merlinux.eu>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS :: MacOS X",
          "Topic :: Software Development :: Testing",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "pre-commit; extra == \"dev\"",
          "tox; extra == \"dev\"",
          "pytest; extra == \"testing\"",
          "pytest-benchmark; extra == \"testing\"",
          "coverage; extra == \"testing\""
        ],
        "requires_python": ">=3.9",
        "provides_extra": [
          "dev",
          "testing"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/a9/a8/fc509e514c708f43102542cdcbc2f42dc49f7a159f90f56d072371629731/prance-25.4.8.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d3c362036d625b12aeee495621cb1555fd50b2af3632af3d825176bfb50e073b",
          "hashes": {
            "sha256": "d3c362036d625b12aeee495621cb1555fd50b2af3632af3d825176bfb50e073b"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "prance",
        "version": "25.4.8.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Resolving Swagger/OpenAPI 2.0 and 3.0.0 Parser",
        "description": "|License| |PyPI| |Python Versions| |Package Format| |Package Status|\n\n|Logo|\n\nPrance provides parsers for `Swagger/OpenAPI\n2.0 and 3.0 <http://swagger.io/specification/>`__ API specifications in Python.\nIt uses `openapi\\_spec\\_validator <https://github.com/p1c2u/openapi-spec-validator>`__,\n`swagger\\_spec\\_validator <https://github.com/Yelp/swagger_spec_validator>`__ or\n`flex <https://github.com/pipermerriam/flex>`__\nto validate specifications, but additionally resolves `JSON\nreferences <https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03>`__\nin accordance with the OpenAPI spec.\n\nMostly the latter involves handling non-URI references; OpenAPI is fine\nwith providing relative file paths, whereas JSON references require URIs\nat this point in time.\n\nUsage\n=====\n\nInstallation\n------------\n\nPrance is available from PyPI, and can be installed via pip:\n\n.. code:: bash\n\n    $ pip install prance\n\nNote that this will install the code, but additional subpackages must be specified\nto unlock various pieces of functionality. At minimum, a parsing backend must be\ninstalled. For the CLI functionality, you need further dependencies.\n\nThe recommended installation installs the CLI, uses ICU and installs one validation\nbackend:\n\n.. code:: bash\n\n    $ pip install prance[osv,icu,cli]\n\nMake sure you have `ICU Unicode Library <http://site.icu-project.org/home>`__ installed,\nas well as Python dev library before running the commands above. If not, use the\nfollowing commands:\n\n.. code:: bash\n\n    $ sudo apt-get install libicu-dev python3-dev # Ubuntu/Debian\n    $ sudo dnf install libicu-devel python3-devel # Fedora\n\n\nCommand Line Interface\n----------------------\n\nAfter installing prance, a CLI is available for validating (and resolving\nexternal references in) specs:\n\n.. code:: bash\n\n    # Validates with resolving\n    $ prance validate path/to/swagger.yml\n\n    # Validates without resolving\n    $ prance validate --no-resolve path/to/swagger.yml\n\n    # Fetch URL, validate and resolve.\n    $ prance validate http://petstore.swagger.io/v2/swagger.json\n    Processing \"http://petstore.swagger.io/v2/swagger.json\"...\n     -> Resolving external references.\n    Validates OK as Swagger/OpenAPI 2.0!\n\nValidation is not the only feature of prance. One of the side effects of\nresolving is that from a spec with references, one can create a fully resolved\noutput spec. In the past, this was done via options to the ``validate`` command,\nbut now there's a specific command just for this purpose:\n\n.. code:: bash\n\n    # Compile spec\n    $ prance compile path/to/input.yml path/to/output.yml\n\n\nLastly, with the arrival of OpenAPI 3.0.0, it becomes useful for tooling to\nconvert older specs to the new standard. Instead of re-inventing the wheel,\nprance just provides a CLI command for passing specs to the web API of\n`swagger2openapi <https://github.com/Mermade/swagger2openapi>`__ - a working\ninternet connection is therefore required for this command:\n\n.. code:: bash\n\n    # Convert spec\n    $ prance convert path/to/swagger.yml path/to/openapi.yml\n\n\nCode\n----\n\nMost likely you have spec file and want to parse it:\n\n.. code:: python\n\n    from prance import ResolvingParser\n    parser = ResolvingParser('path/to/my/swagger.yaml')\n    parser.specification  # contains fully resolved specs as a dict\n\nPrance also includes a non-resolving parser that does not follow JSON\nreferences, in case you prefer that.\n\n.. code:: python\n\n    from prance import BaseParser\n    parser = BaseParser('path/to/my/swagger.yaml')\n    parser.specification  # contains specs as a dict still containing JSON references\n\nOn Windows, the code reacts correctly if you pass posix-like paths\n(``/c:/swagger``) or if the path is relative.  If you pass absolute\nwindows path (like ``c:\\swagger.yaml``), you can use\n``prance.util.fs.abspath`` to convert them.\n\nURLs can also be parsed:\n\n.. code:: python\n\n    parser = ResolvingParser('http://petstore.swagger.io/v2/swagger.json')\n\nLargely, that's it. There is a whole slew of utility code that you may\nor may not find useful, too. Look at the `full documentation\n<https://prance.readthedocs.io/en/latest/#api-modules>`__ for details.\n\n\nCompatibility\n-------------\n\n*Python Versions*\n\nVersion 0.16.2 is the last version supporting Python 2. It was released on\nNov 12th, 2019. Python 2 reaches end of life at the end of 2019. If you wish\nfor updates to the Python 2 supported packages, please contact the maintainer\ndirectly.\n\nUntil fairly recently, we also tested with `PyPy <https://www.pypy.org/>`__.\nUnfortunately, Travis isn't very good at supporting this. So in the absence\nof spare time, they're disabled. `Issue 50 <https://github.com/jfinkhaeuser/prance/issues/50>`__\ntracks progress on that.\n\nSimilarly, but less critically, Python 3.4 is no longer receiving a lot of\nlove from CI vendors, so automated builds on that version are no longer\nsupported.\n\n*Backends*\n\nDifferent validation backends support different features.\n\n+------------------------+----------------+-----------------+-------------+-------------------------------------------------------+----------------+-----------------------------------------------------------------------------------+\n| Backend                | Python Version | OpenAPI Version | Strict Mode | Notes                                                 | Available From | Link                                                                              |\n+========================+================+=================+=============+=======================================================+================+===================================================================================+\n| swagger-spec-validator | 2 and 3        | 2.0 only        | yes         | Slow; does not accept integer keys (see strict mode). | prance 0.1     | `swagger\\_spec\\_validator <https://github.com/Yelp/swagger_spec_validator>`__     |\n+------------------------+----------------+-----------------+-------------+-------------------------------------------------------+----------------+-----------------------------------------------------------------------------------+\n| flex                   | 2 and 3        | 2.0 only        | n/a         | Fastest; unfortunately deprecated.                    | prance 0.8     | `flex <https://github.com/pipermerriam/flex>`__                                   |\n+------------------------+----------------+-----------------+-------------+-------------------------------------------------------+----------------+-----------------------------------------------------------------------------------+\n| openapi-spec-validator | 2 and 3        | 2.0 and 3.0     | yes         | Slow; does not accept integer keys (see strict mode). | prance 0.11    | `openapi\\_spec\\_validator <https://github.com/p1c2u/openapi-spec-validator>`__    |\n+------------------------+----------------+-----------------+-------------+-------------------------------------------------------+----------------+-----------------------------------------------------------------------------------+\n\nYou can select the backend in the constructor of the parser(s):\n\n.. code:: python\n\n    parser = ResolvingParser('http://petstore.swagger.io/v2/swagger.json', backend = 'openapi-spec-validator')\n\n\nNo backend is included in the dependencies; they are detected at run-time. If you install them,\nthey can be used:\n\n.. code:: bash\n\n    $ pip install openapi-spec-validator\n    $ pip install prance\n    $ prance validate --backend=openapi-spec-validator path/to/spec.yml\n\n*A note on flex usage:* While flex is the fastest validation backend, unfortunately it is no longer\nmaintained and there are issues with its dependencies. For one thing, it depends on a version of `PyYAML`\nthat contains security flaws. For another, it depends explicitly on older versions of `click`.\n\nIf you use the flex subpackage, therefore, you do so at your own risk.\n\n*Compatibility*\n\nSee `COMPATIBILITY.rst <https://github.com/jfinkhaeuser/prance/blob/master/COMPATIBILITY.rst>`__\nfor a list of known issues.\n\n\nPartial Reference Resolution\n----------------------------\n\nIt's possible to instruct the parser to only resolve some kinds of references.\nThis allows e.g. resolving references from external URLs, whilst keeping local\nreferences (i.e. to local files, or file internal) intact.\n\n.. code:: python\n\n    from prance import ResolvingParser\n    from prance.util.resolver import RESOLVE_HTTP\n\n    parser = ResolvingParser('/path/to/spec', resolve_types = RESOLVE_HTTP)\n\n\nMultiple types can be specified by OR-ing constants together:\n\n.. code:: python\n\n    from prance import ResolvingParser\n    from prance.util.resolver import RESOLVE_HTTP, RESOLVE_FILES\n\n    parser = ResolvingParser('/path/to/spec', resolve_types = RESOLVE_HTTP | RESOLVE_FILES)\n\n\nExtensions\n----------\n\nPrance includes the ability to reference outside swagger definitions\nin outside Python packages. Such a package must already be importable\n(i.e. installed), and be accessible via the\n`ResourceManager API <https://setuptools.readthedocs.io/en/latest/pkg_resources.html#resourcemanager-api>`__\n(some more info `here <https://setuptools.readthedocs.io/en/latest/setuptools.html#including-data-files>`__).\n\nFor example, you might create a package ``common_swag`` with the file\n``base.yaml`` containing the definition\n\n.. code:: yaml\n\n    definitions:\n      Severity:\n        type: string\n        enum:\n        - INFO\n        - WARN\n        - ERROR\n        - FATAL\n\nIn the ``setup.py`` for ``common_swag`` you would add lines such as\n\n.. code:: python\n\n    packages=find_packages('src'),\n    package_dir={'': 'src'},\n    package_data={\n        '': '*.yaml'\n    }\n\nThen, having installed ``common_swag`` into some application, you could\nnow write\n\n.. code:: yaml\n\n    definitions:\n      Message:\n        type: object\n        properties:\n          severity:\n            $ref: 'python://common_swag/base.yaml#/definitions/Severity'\n          code:\n            type: string\n          summary:\n            type: string\n          description:\n            type: string\n        required:\n        - severity\n        - summary\n\nContributing\n============\n\nSee `CONTRIBUTING.md <https://github.com/jfinkhaeuser/prance/blob/master/CONTRIBUTING.md>`__ for details.\n\nProfessional support is available through `finkhaeuser consulting <https://finkhaeuser.de>`__.\n\nLicense\n=======\n\nLicensed under MIT. See the `LICENSE.txt <https://github.com/RonnyPfannschmidt/prance/blob/master/LICENSE.txt>`__ file for details.\n\n\"Prancing unicorn\" logo image Copyright (c) Jens Finkhaeuser.\nMade by `Moreven B <http://morevenb.com/>`__. Use of the logo is permitted under\nthe `Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license <https://creativecommons.org/licenses/by-nc-sa/4.0/>`__.\n\n\n.. |License| image:: https://img.shields.io/pypi/l/prance.svg\n   :target: https://pypi.python.org/pypi/prance/\n.. |PyPI| image:: https://img.shields.io/pypi/v/prance.svg\n   :target: https://pypi.python.org/pypi/prance/\n.. |Package Format| image:: https://img.shields.io/pypi/format/prance.svg\n   :target: https://pypi.python.org/pypi/prance/\n.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/prance.svg\n   :target: https://pypi.python.org/pypi/prance/\n.. |Package Status| image:: https://img.shields.io/pypi/status/prance.svg\n   :target: https://pypi.python.org/pypi/prance/\n.. |Logo| image:: https://raw.githubusercontent.com/RonnyPfannschmidt/prance/master/docs/images/prance_logo_256.png\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "swagger",
          "openapi",
          "parsing"
        ],
        "home_page": "https://github.com/RonnyPfannschmidt/prance",
        "author": "Jens Finkhaeuser",
        "author_email": "jens@finkhaeuser.de",
        "maintainer": "Ronny Pfannschmidt",
        "maintainer_email": "opensource@ronnypfannschmidt.de",
        "license": "MITNFA",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Plugins",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "chardet>=5.2",
          "ruamel.yaml>=0.18.10",
          "requests>=2.32.3",
          "packaging>=24.2",
          "tox>=4.23.2; extra == \"dev\"",
          "bumpversion>=0.6.0; extra == \"dev\"",
          "pytest>=8.3.5; extra == \"dev\"",
          "pytest-cov>=6.0; extra == \"dev\"",
          "sphinx>=8.1.3; extra == \"dev\"",
          "towncrier>=24.8; extra == \"dev\"",
          "PyICU~=2.14; extra == \"icu\"",
          "swagger-spec-validator~=3.0.4; extra == \"ssv\"",
          "openapi-spec-validator~=0.7.1; extra == \"osv\"",
          "flex~=6.14.1; extra == \"flex\"",
          "click>=8.1.8; extra == \"cli\""
        ],
        "requires_python": ">=3.10",
        "provides_extra": [
          "dev",
          "icu",
          "ssv",
          "osv",
          "flex",
          "cli"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/ee/52/9aa428633ef5aba4b096b2b2f8d046ece613cecab28b4ceed54126d25ea5/pybars4-0.9.13.tar.gz",
        "archive_info": {
          "hash": "sha256=425817da20d4ad320bc9b8e77a60cab1bb9d3c677df3dce224925c3310fcd635",
          "hashes": {
            "sha256": "425817da20d4ad320bc9b8e77a60cab1bb9d3c677df3dce224925c3310fcd635"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pybars4",
        "version": "0.9.13",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license-file",
          "requires-dist",
          "summary"
        ],
        "summary": "Handlebars.js templating for Python 3",
        "description": "Documentation is maintained at https://github.com/up9inc/pybars4#readme\r\n",
        "home_page": "https://github.com/up9inc/pybars4",
        "author": "wbond, mjumbewu, undera, mehmet",
        "author_email": "will@wbond.net, mjumbewu@gmail.com, andrey@up9.com, mehmet@up9.com",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4"
        ],
        "requires_dist": [
          "PyMeta3>=0.5.1"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/bd/1f/73c53fcbfb0b5a78f91176df41945ca466e71e9d9d836e5c522abda39ee7/pydantic-2.11.10-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=802a655709d49bd004c31e865ef37da30b540786a46bfce02333e0e24b5fe29a",
          "hashes": {
            "sha256": "802a655709d49bd004c31e865ef37da30b540786a46bfce02333e0e24b5fe29a"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pydantic",
        "version": "2.11.10",
        "summary": "Data validation using Python type hints",
        "description": "# Pydantic\n[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic)\n[![pypi](https://img.shields.io/pypi/v/pydantic.svg)](https://pypi.python.org/pypi/pydantic)\n[![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)](https://anaconda.org/conda-forge/pydantic)\n[![downloads](https://static.pepy.tech/badge/pydantic/month)](https://pepy.tech/project/pydantic)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic.svg)](https://github.com/pydantic/pydantic)\n[![license](https://img.shields.io/github/license/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/blob/main/LICENSE)\n[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://docs.pydantic.dev/latest/contributing/#badges)\n[![llms.txt](https://img.shields.io/badge/llms.txt-green)](https://docs.pydantic.dev/latest/llms.txt)\n\n\nData validation using Python type hints.\n\nFast and extensible, Pydantic plays nicely with your linters/IDE/brain.\nDefine how data should be in pure, canonical Python 3.9+; validate it with Pydantic.\n\n## Pydantic Logfire :fire:\n\nWe've recently launched Pydantic Logfire to help you monitor your applications.\n[Learn more](https://pydantic.dev/articles/logfire-announcement)\n\n## Pydantic V1.10 vs. V2\n\nPydantic V2 is a ground-up rewrite that offers many new features, performance improvements, and some breaking changes compared to Pydantic V1.\n\nIf you're using Pydantic V1 you may want to look at the\n[pydantic V1.10 Documentation](https://docs.pydantic.dev/) or,\n[`1.10.X-fixes` git branch](https://github.com/pydantic/pydantic/tree/1.10.X-fixes). Pydantic V2 also ships with the latest version of Pydantic V1 built in so that you can incrementally upgrade your code base and projects: `from pydantic import v1 as pydantic_v1`.\n\n## Help\n\nSee [documentation](https://docs.pydantic.dev/) for more details.\n\n## Installation\n\nInstall using `pip install -U pydantic` or `conda install pydantic -c conda-forge`.\nFor more installation options to make Pydantic even faster,\nsee the [Install](https://docs.pydantic.dev/install/) section in the documentation.\n\n## A Simple Example\n\n```python\nfrom datetime import datetime\nfrom typing import Optional\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n    friends: list[int] = []\n\nexternal_data = {'id': '123', 'signup_ts': '2017-06-01 12:22', 'friends': [1, '2', b'3']}\nuser = User(**external_data)\nprint(user)\n#> User id=123 name='John Doe' signup_ts=datetime.datetime(2017, 6, 1, 12, 22) friends=[1, 2, 3]\nprint(user.id)\n#> 123\n```\n\n## Contributing\n\nFor guidance on setting up a development environment and how to make a\ncontribution to Pydantic, see\n[Contributing to Pydantic](https://docs.pydantic.dev/contributing/).\n\n## Reporting a Security Vulnerability\n\nSee our [security policy](https://github.com/pydantic/pydantic/security/policy).\n\n## Changelog\n\n## v2.11.10 (2025-10-04)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.10)\n\n### What's Changed\n\n#### Fixes\n\n* Backport v1.10.24 changes by [@Viicos](https://github.com/Viicos)\n\n## v2.11.9 (2025-09-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.9)\n\n### What's Changed\n\n#### Fixes\n\n* Backport v1.10.23 changes by [@Viicos](https://github.com/Viicos)\n\n## v2.11.8 (2025-09-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.8)\n\n### What's Changed\n\n#### Fixes\n\n* Fix mypy plugin for mypy 1.18 by [@cdce8p](https://github.com/cdce8p) in [#12209](https://github.com/pydantic/pydantic/pull/12209)\n\n## v2.11.7 (2025-06-14)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.7)\n\n### What's Changed\n\n#### Fixes\n\n* Copy `FieldInfo` instance if necessary during `FieldInfo` build by [@Viicos](https://github.com/Viicos) in [#11898](https://github.com/pydantic/pydantic/pull/11898)\n\n## v2.11.6 (2025-06-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.6)\n\n### What's Changed\n\n#### Fixes\n\n* Rebuild dataclass fields before schema generation by [@Viicos](https://github.com/Viicos) in [#11949](https://github.com/pydantic/pydantic/pull/11949)\n* Always store the original field assignment on `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11946](https://github.com/pydantic/pydantic/pull/11946)\n\n## v2.11.5 (2025-05-22)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.5)\n\n### What's Changed\n\n#### Fixes\n\n* Check if `FieldInfo` is complete after applying type variable map by [@Viicos](https://github.com/Viicos) in [#11855](https://github.com/pydantic/pydantic/pull/11855)\n* Do not delete mock validator/serializer in `model_rebuild()` by [@Viicos](https://github.com/Viicos) in [#11890](https://github.com/pydantic/pydantic/pull/11890)\n* Do not duplicate metadata on model rebuild by [@Viicos](https://github.com/Viicos) in [#11902](https://github.com/pydantic/pydantic/pull/11902)\n\n## v2.11.4 (2025-04-29)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.4)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `mkdocs-llmstxt` to v0.2.0 by [@Viicos](https://github.com/Viicos) in [#11725](https://github.com/pydantic/pydantic/pull/11725)\n\n#### Changes\n\n* Allow config and bases to be specified together in `create_model()` by [@Viicos](https://github.com/Viicos) in [#11714](https://github.com/pydantic/pydantic/pull/11714).\n  This change was backported as it was previously possible (although not meant to be supported)\n  to provide `model_config` as a field, which would make it possible to provide both configuration\n  and bases.\n\n#### Fixes\n\n* Remove generics cache workaround by [@Viicos](https://github.com/Viicos) in [#11755](https://github.com/pydantic/pydantic/pull/11755)\n* Remove coercion of decimal constraints by [@Viicos](https://github.com/Viicos) in [#11772](https://github.com/pydantic/pydantic/pull/11772)\n* Fix crash when expanding root type in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11735](https://github.com/pydantic/pydantic/pull/11735)\n* Fix issue with recursive generic models by [@Viicos](https://github.com/Viicos) in [#11775](https://github.com/pydantic/pydantic/pull/11775)\n* Traverse `function-before` schemas during schema gathering by [@Viicos](https://github.com/Viicos) in [#11801](https://github.com/pydantic/pydantic/pull/11801)\n\n## v2.11.3 (2025-04-08)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.3)\n\n### What's Changed\n\n#### Packaging\n\n* Update V1 copy to v1.10.21 by [@Viicos](https://github.com/Viicos) in [#11706](https://github.com/pydantic/pydantic/pull/11706)\n\n#### Fixes\n\n* Preserve field description when rebuilding model fields by [@Viicos](https://github.com/Viicos) in [#11698](https://github.com/pydantic/pydantic/pull/11698)\n\n## v2.11.2 (2025-04-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.2)\n\n### What's Changed\n\n#### Fixes\n\n* Bump `pydantic-core` to v2.33.1 by [@Viicos](https://github.com/Viicos) in [#11678](https://github.com/pydantic/pydantic/pull/11678)\n* Make sure `__pydantic_private__` exists before setting private attributes by [@Viicos](https://github.com/Viicos) in [#11666](https://github.com/pydantic/pydantic/pull/11666)\n* Do not override `FieldInfo._complete` when using field from parent class by [@Viicos](https://github.com/Viicos) in [#11668](https://github.com/pydantic/pydantic/pull/11668)\n* Provide the available definitions when applying discriminated unions by [@Viicos](https://github.com/Viicos) in [#11670](https://github.com/pydantic/pydantic/pull/11670)\n* Do not expand root type in the mypy plugin for variables by [@Viicos](https://github.com/Viicos) in [#11676](https://github.com/pydantic/pydantic/pull/11676)\n* Mention the attribute name in model fields deprecation message by [@Viicos](https://github.com/Viicos) in [#11674](https://github.com/pydantic/pydantic/pull/11674)\n* Properly validate parameterized mappings by [@Viicos](https://github.com/Viicos) in [#11658](https://github.com/pydantic/pydantic/pull/11658)\n\n## v2.11.1 (2025-03-28)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.1)\n\n### What's Changed\n\n#### Fixes\n\n* Do not override `'definitions-ref'` schemas containing serialization schemas or metadata by [@Viicos](https://github.com/Viicos) in [#11644](https://github.com/pydantic/pydantic/pull/11644)\n\n## v2.11.0 (2025-03-27)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nSee the [blog post](https://pydantic.dev/articles/pydantic-v2-11-release) for more details.\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.33.0 by [@Viicos](https://github.com/Viicos) in [#11631](https://github.com/pydantic/pydantic/pull/11631)\n\n#### New Features\n\n* Add `encoded_string()` method to the URL types by [@YassinNouh21](https://github.com/YassinNouh21) in [#11580](https://github.com/pydantic/pydantic/pull/11580)\n* Add support for `defer_build` with `@validate_call` decorator by [@Viicos](https://github.com/Viicos) in [#11584](https://github.com/pydantic/pydantic/pull/11584)\n* Allow `@with_config` decorator to be used with keyword arguments by [@Viicos](https://github.com/Viicos) in [#11608](https://github.com/pydantic/pydantic/pull/11608)\n* Simplify customization of default value inclusion in JSON Schema generation by [@Viicos](https://github.com/Viicos) in [#11634](https://github.com/pydantic/pydantic/pull/11634)\n* Add `generate_arguments_schema()` function by [@Viicos](https://github.com/Viicos) in [#11572](https://github.com/pydantic/pydantic/pull/11572)\n\n#### Fixes\n\n* Allow generic typed dictionaries to be used for unpacked variadic keyword parameters by [@Viicos](https://github.com/Viicos) in [#11571](https://github.com/pydantic/pydantic/pull/11571)\n* Fix runtime error when computing model string representation involving cached properties and self-referenced models by [@Viicos](https://github.com/Viicos) in [#11579](https://github.com/pydantic/pydantic/pull/11579)\n* Preserve other steps when using the ellipsis in the pipeline API by [@Viicos](https://github.com/Viicos) in [#11626](https://github.com/pydantic/pydantic/pull/11626)\n* Fix deferred discriminator application logic by [@Viicos](https://github.com/Viicos) in [#11591](https://github.com/pydantic/pydantic/pull/11591)\n\n### New Contributors\n\n* [@cmenon12](https://github.com/cmenon12) made their first contribution in [#11562](https://github.com/pydantic/pydantic/pull/11562)\n* [@Jeukoh](https://github.com/Jeukoh) made their first contribution in [#11611](https://github.com/pydantic/pydantic/pull/11611)\n\n## v2.11.0b2 (2025-03-17)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b2)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.32.0 by [@Viicos](https://github.com/Viicos) in [#11567](https://github.com/pydantic/pydantic/pull/11567)\n\n#### New Features\n\n* Add experimental support for free threading by [@Viicos](https://github.com/Viicos) in [#11516](https://github.com/pydantic/pydantic/pull/11516)\n\n#### Fixes\n\n* Fix `NotRequired` qualifier not taken into account in stringified annotation by [@Viicos](https://github.com/Viicos) in [#11559](https://github.com/pydantic/pydantic/pull/11559)\n\n### New Contributors\n\n* [@joren485](https://github.com/joren485) made their first contribution in [#11547](https://github.com/pydantic/pydantic/pull/11547)\n\n## v2.11.0b1 (2025-03-06)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b1)\n\n### What's Changed\n\n#### Packaging\n\n* Add a `check_pydantic_core_version()` function by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11324\n* Remove `greenlet` development dependency by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11351\n* Use the `typing-inspection` library by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11479\n* Bump `pydantic-core` to `v2.31.1` by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11526\n\n#### New Features\n\n* Support unsubstituted type variables with both a default and a bound or constraints by [@FyZzyss](https://github.com/FyZzyss) in https://github.com/pydantic/pydantic/pull/10789\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11034\n* Raise a better error when a generic alias is used inside `type[]` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11088\n* Properly support PEP 695 generics syntax by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11189\n* Properly support type variable defaults by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11332\n* Add support for validating v6, v7, v8 UUIDs by [@astei](https://github.com/astei) in https://github.com/pydantic/pydantic/pull/11436\n* Improve alias configuration APIs by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11468\n\n#### Changes\n\n* Rework `create_model` field definitions format by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11032\n* Raise a deprecation warning when a field is annotated as final with a default value by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11168\n* Deprecate accessing `model_fields` and `model_computed_fields` on instances by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11169\n* **Breaking Change:** Move core schema generation logic for path types inside the `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/10846\n* Remove Python 3.8 Support by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11258\n* Optimize calls to `get_type_ref` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10863\n* Disable `pydantic-core` core schema validation by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11271\n\n#### Performance\n\n* Only evaluate `FieldInfo` annotations if required during schema building by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10769\n* Improve `__setattr__` performance of Pydantic models by caching setter functions by [@MarkusSintonen](https://github.com/MarkusSintonen) in https://github.com/pydantic/pydantic/pull/10868\n* Improve annotation application performance by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11186\n* Improve performance of `_typing_extra` module by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11255\n* Refactor and optimize schema cleaning logic by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11244\n* Create a single dictionary when creating a `CoreConfig` instance by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11384\n* Bump `pydantic-core` and thus use `SchemaValidator` and `SchemaSerializer` caching by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11402\n* Reuse cached core schemas for parametrized generic Pydantic models by [@MarkusSintonen](https://github.com/MarkusSintonen) in https://github.com/pydantic/pydantic/pull/11434\n\n#### Fixes\n\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/10872\n* Use the correct frame when instantiating a parametrized `TypeAdapter` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10893\n* Infer final fields with a default value as class variables in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11121\n* Recursively unpack `Literal` values if using PEP 695 type aliases by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11114\n* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11116\n* Remove unused `_extract_get_pydantic_json_schema()` parameter by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11155\n* Improve discriminated union error message for invalid union variants by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11161\n* Unpack PEP 695 type aliases if using the `Annotated` form by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11109\n* Add missing stacklevel in `deprecated_instance_property` warning by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11200\n* Copy `WithJsonSchema` schema to avoid sharing mutated data by [@thejcannon](https://github.com/thejcannon) in https://github.com/pydantic/pydantic/pull/11014\n* Do not cache parametrized models when in the process of parametrizing another model by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10704\n* Add discriminated union related metadata entries to the `CoreMetadata` definition by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11216\n* Consolidate schema definitions logic in the `_Definitions` class by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11208\n* Support initializing root model fields with values of the `root` type in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11212\n* Fix various issues with dataclasses and `use_attribute_docstrings` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11246\n* Only compute normalized decimal places if necessary in `decimal_places_validator` by [@misrasaurabh1](https://github.com/misrasaurabh1) in https://github.com/pydantic/pydantic/pull/11281\n* Add support for `validation_alias` in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11295\n* Fix JSON Schema reference collection with `\"examples\"` keys by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11305\n* Do not transform model serializer functions as class methods in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11298\n* Simplify `GenerateJsonSchema.literal_schema()` implementation by [@misrasaurabh1](https://github.com/misrasaurabh1) in https://github.com/pydantic/pydantic/pull/11321\n* Add additional allowed schemes for `ClickHouseDsn` by [@Maze21127](https://github.com/Maze21127) in https://github.com/pydantic/pydantic/pull/11319\n* Coerce decimal constraints to `Decimal` instances by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11350\n* Use the correct JSON Schema mode when handling function schemas by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11367\n* Improve exception message when encountering recursion errors during type evaluation by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11356\n* Always include `additionalProperties: True` for arbitrary dictionary schemas by [@austinyu](https://github.com/austinyu) in https://github.com/pydantic/pydantic/pull/11392\n* Expose `fallback` parameter in serialization methods by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11398\n* Fix path serialization behavior by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11416\n* Do not reuse validators and serializers during model rebuild by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11429\n* Collect model fields when rebuilding a model by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11388\n* Allow cached properties to be altered on frozen models by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11432\n* Fix tuple serialization for `Sequence` types by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11435\n* Fix: do not check for `__get_validators__` on classes where `__get_pydantic_core_schema__` is also defined by [@tlambert03](https://github.com/tlambert03) in https://github.com/pydantic/pydantic/pull/11444\n* Allow callable instances to be used as serializers by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11451\n* Improve error thrown when overriding field with a property by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11459\n* Fix JSON Schema generation with referenceable core schemas holding JSON metadata by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11475\n* Support strict specification on union member types by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11481\n* Implicitly set `validate_by_name` to `True` when `validate_by_alias` is `False` by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11503\n* Change type of `Any` when synthesizing `BaseSettings.__init__` signature in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11497\n* Support type variable defaults referencing other type variables by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11520\n* Fix `ValueError` on year zero by [@davidhewitt](https://github.com/davidhewitt) in https://github.com/pydantic/pydantic-core/pull/1583\n* `dataclass` `InitVar` shouldn't be required on serialization by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic-core/pull/1602\n\n## New Contributors\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in https://github.com/pydantic/pydantic/pull/10789\n* [@tamird](https://github.com/tamird) made their first contribution in https://github.com/pydantic/pydantic/pull/10948\n* [@felixxm](https://github.com/felixxm) made their first contribution in https://github.com/pydantic/pydantic/pull/11077\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in https://github.com/pydantic/pydantic/pull/11082\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in https://github.com/pydantic/pydantic/pull/11111\n* [@mdaffad](https://github.com/mdaffad) made their first contribution in https://github.com/pydantic/pydantic/pull/11177\n* [@thejcannon](https://github.com/thejcannon) made their first contribution in https://github.com/pydantic/pydantic/pull/11014\n* [@thomasfrimannkoren](https://github.com/thomasfrimannkoren) made their first contribution in https://github.com/pydantic/pydantic/pull/11251\n* [@usernameMAI](https://github.com/usernameMAI) made their first contribution in https://github.com/pydantic/pydantic/pull/11275\n* [@ananiavito](https://github.com/ananiavito) made their first contribution in https://github.com/pydantic/pydantic/pull/11302\n* [@pawamoy](https://github.com/pawamoy) made their first contribution in https://github.com/pydantic/pydantic/pull/11311\n* [@Maze21127](https://github.com/Maze21127) made their first contribution in https://github.com/pydantic/pydantic/pull/11319\n* [@kauabh](https://github.com/kauabh) made their first contribution in https://github.com/pydantic/pydantic/pull/11369\n* [@jaceklaskowski](https://github.com/jaceklaskowski) made their first contribution in https://github.com/pydantic/pydantic/pull/11353\n* [@tmpbeing](https://github.com/tmpbeing) made their first contribution in https://github.com/pydantic/pydantic/pull/11375\n* [@petyosi](https://github.com/petyosi) made their first contribution in https://github.com/pydantic/pydantic/pull/11405\n* [@austinyu](https://github.com/austinyu) made their first contribution in https://github.com/pydantic/pydantic/pull/11392\n* [@mikeedjones](https://github.com/mikeedjones) made their first contribution in https://github.com/pydantic/pydantic/pull/11402\n* [@astei](https://github.com/astei) made their first contribution in https://github.com/pydantic/pydantic/pull/11436\n* [@dsayling](https://github.com/dsayling) made their first contribution in https://github.com/pydantic/pydantic/pull/11522\n* [@sobolevn](https://github.com/sobolevn) made their first contribution in https://github.com/pydantic/pydantic-core/pull/1645\n\n## v2.11.0a2 (2025-02-10)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a2)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nThis is another early alpha release, meant to collect early feedback from users having issues with core schema builds.\n\n#### Packaging\n\n* Bump `ruff` from 0.9.2 to 0.9.5 by [@Viicos](https://github.com/Viicos) in [#11407](https://github.com/pydantic/pydantic/pull/11407)\n* Bump `pydantic-core` to v2.29.0 by [@mikeedjones](https://github.com/mikeedjones) in [#11402](https://github.com/pydantic/pydantic/pull/11402)\n* Use locally-built rust with symbols & pgo by [@davidhewitt](https://github.com/davidhewitt) in [#11403](https://github.com/pydantic/pydantic/pull/11403)\n\n\n#### Performance\n\n* Create a single dictionary when creating a `CoreConfig` instance by [@sydney-runkle](https://github.com/sydney-runkle) in [#11384](https://github.com/pydantic/pydantic/pull/11384)\n\n#### Fixes\n\n* Use the correct JSON Schema mode when handling function schemas by [@Viicos](https://github.com/Viicos) in [#11367](https://github.com/pydantic/pydantic/pull/11367)\n* Fix JSON Schema reference logic with `examples` keys by [@Viicos](https://github.com/Viicos) in [#11366](https://github.com/pydantic/pydantic/pull/11366)\n* Improve exception message when encountering recursion errors during type evaluation by [@Viicos](https://github.com/Viicos) in [#11356](https://github.com/pydantic/pydantic/pull/11356)\n* Always include `additionalProperties: True` for arbitrary dictionary schemas by [@austinyu](https://github.com/austinyu) in [#11392](https://github.com/pydantic/pydantic/pull/11392)\n* Expose `fallback` parameter in serialization methods by [@Viicos](https://github.com/Viicos) in [#11398](https://github.com/pydantic/pydantic/pull/11398)\n* Fix path serialization behavior by [@sydney-runkle](https://github.com/sydney-runkle) in [#11416](https://github.com/pydantic/pydantic/pull/11416)\n\n### New Contributors\n\n* [@kauabh](https://github.com/kauabh) made their first contribution in [#11369](https://github.com/pydantic/pydantic/pull/11369)\n* [@jaceklaskowski](https://github.com/jaceklaskowski) made their first contribution in [#11353](https://github.com/pydantic/pydantic/pull/11353)\n* [@tmpbeing](https://github.com/tmpbeing) made their first contribution in [#11375](https://github.com/pydantic/pydantic/pull/11375)\n* [@petyosi](https://github.com/petyosi) made their first contribution in [#11405](https://github.com/pydantic/pydantic/pull/11405)\n* [@austinyu](https://github.com/austinyu) made their first contribution in [#11392](https://github.com/pydantic/pydantic/pull/11392)\n* [@mikeedjones](https://github.com/mikeedjones) made their first contribution in [#11402](https://github.com/pydantic/pydantic/pull/11402)\n\n## v2.11.0a1 (2025-01-30)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a1)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nThis is an early alpha release, meant to collect early feedback from users having issues with core schema builds.\n\n#### Packaging\n\n* Bump dawidd6/action-download-artifact from 6 to 7 by [@dependabot](https://github.com/dependabot) in [#11018](https://github.com/pydantic/pydantic/pull/11018)\n* Re-enable memray related tests on Python 3.12+ by [@Viicos](https://github.com/Viicos) in [#11191](https://github.com/pydantic/pydantic/pull/11191)\n* Bump astral-sh/setup-uv to 5 by [@dependabot](https://github.com/dependabot) in [#11205](https://github.com/pydantic/pydantic/pull/11205)\n* Bump `ruff` to v0.9.0 by [@sydney-runkle](https://github.com/sydney-runkle) in [#11254](https://github.com/pydantic/pydantic/pull/11254)\n* Regular `uv.lock` deps update by [@sydney-runkle](https://github.com/sydney-runkle) in [#11333](https://github.com/pydantic/pydantic/pull/11333)\n* Add a `check_pydantic_core_version()` function by [@Viicos](https://github.com/Viicos) in [#11324](https://github.com/pydantic/pydantic/pull/11324)\n* Remove `greenlet` development dependency by [@Viicos](https://github.com/Viicos) in [#11351](https://github.com/pydantic/pydantic/pull/11351)\n* Bump `pydantic-core` to v2.28.0 by [@Viicos](https://github.com/Viicos) in [#11364](https://github.com/pydantic/pydantic/pull/11364)\n\n#### New Features\n\n* Support unsubstituted type variables with both a default and a bound or constraints by [@FyZzyss](https://github.com/FyZzyss) in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11034](https://github.com/pydantic/pydantic/pull/11034)\n* Raise a better error when a generic alias is used inside `type[]` by [@Viicos](https://github.com/Viicos) in [#11088](https://github.com/pydantic/pydantic/pull/11088)\n* Properly support PEP 695 generics syntax by [@Viicos](https://github.com/Viicos) in [#11189](https://github.com/pydantic/pydantic/pull/11189)\n* Properly support type variable defaults by [@Viicos](https://github.com/Viicos) in [#11332](https://github.com/pydantic/pydantic/pull/11332)\n\n#### Changes\n\n* Rework `create_model` field definitions format by [@Viicos](https://github.com/Viicos) in [#11032](https://github.com/pydantic/pydantic/pull/11032)\n* Raise a deprecation warning when a field is annotated as final with a default value by [@Viicos](https://github.com/Viicos) in [#11168](https://github.com/pydantic/pydantic/pull/11168)\n* Deprecate accessing `model_fields` and `model_computed_fields` on instances by [@Viicos](https://github.com/Viicos) in [#11169](https://github.com/pydantic/pydantic/pull/11169)\n* Move core schema generation logic for path types inside the `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in [#10846](https://github.com/pydantic/pydantic/pull/10846)\n* Move `deque` schema gen to `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in [#11239](https://github.com/pydantic/pydantic/pull/11239)\n* Move `Mapping` schema gen to `GenerateSchema` to complete removal of `prepare_annotations_for_known_type` workaround by [@sydney-runkle](https://github.com/sydney-runkle) in [#11247](https://github.com/pydantic/pydantic/pull/11247)\n* Remove Python 3.8 Support by [@sydney-runkle](https://github.com/sydney-runkle) in [#11258](https://github.com/pydantic/pydantic/pull/11258)\n* Disable `pydantic-core` core schema validation by [@sydney-runkle](https://github.com/sydney-runkle) in [#11271](https://github.com/pydantic/pydantic/pull/11271)\n\n#### Performance\n\n* Only evaluate `FieldInfo` annotations if required during schema building by [@Viicos](https://github.com/Viicos) in [#10769](https://github.com/pydantic/pydantic/pull/10769)\n* Optimize calls to `get_type_ref` by [@Viicos](https://github.com/Viicos) in [#10863](https://github.com/pydantic/pydantic/pull/10863)\n* Improve `__setattr__` performance of Pydantic models by caching setter functions by [@MarkusSintonen](https://github.com/MarkusSintonen) in [#10868](https://github.com/pydantic/pydantic/pull/10868)\n* Improve annotation application performance by [@Viicos](https://github.com/Viicos) in [#11186](https://github.com/pydantic/pydantic/pull/11186)\n* Improve performance of `_typing_extra` module by [@Viicos](https://github.com/Viicos) in [#11255](https://github.com/pydantic/pydantic/pull/11255)\n* Refactor and optimize schema cleaning logic by [@Viicos](https://github.com/Viicos) and [@MarkusSintonen](https://github.com/MarkusSintonen) in [#11244](https://github.com/pydantic/pydantic/pull/11244)\n\n#### Fixes\n\n* Add validation tests for `_internal/_validators.py` by [@tkasuz](https://github.com/tkasuz) in [#10763](https://github.com/pydantic/pydantic/pull/10763)\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in [#10872](https://github.com/pydantic/pydantic/pull/10872)\n* Revert \"ci: use locally built pydantic-core with debug symbols by [@sydney-runkle](https://github.com/sydney-runkle) in [#10942](https://github.com/pydantic/pydantic/pull/10942)\n* Re-enable all FastAPI tests by [@tamird](https://github.com/tamird) in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* Fix typo in HISTORY.md. by [@felixxm](https://github.com/felixxm) in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* Infer final fields with a default value as class variables in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11121](https://github.com/pydantic/pydantic/pull/11121)\n* Recursively unpack `Literal` values if using PEP 695 type aliases by [@Viicos](https://github.com/Viicos) in [#11114](https://github.com/pydantic/pydantic/pull/11114)\n* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by [@Viicos](https://github.com/Viicos) in [#11116](https://github.com/pydantic/pydantic/pull/11116)\n* Remove unused `_extract_get_pydantic_json_schema()` parameter by [@Viicos](https://github.com/Viicos) in [#11155](https://github.com/pydantic/pydantic/pull/11155)\n* Add FastAPI and SQLModel to third-party tests by [@sydney-runkle](https://github.com/sydney-runkle) in [#11044](https://github.com/pydantic/pydantic/pull/11044)\n* Fix conditional expressions syntax for third-party tests by [@Viicos](https://github.com/Viicos) in [#11162](https://github.com/pydantic/pydantic/pull/11162)\n* Move FastAPI tests to third-party workflow by [@Viicos](https://github.com/Viicos) in [#11164](https://github.com/pydantic/pydantic/pull/11164)\n* Improve discriminated union error message for invalid union variants by [@Viicos](https://github.com/Viicos) in [#11161](https://github.com/pydantic/pydantic/pull/11161)\n* Unpack PEP 695 type aliases if using the `Annotated` form by [@Viicos](https://github.com/Viicos) in [#11109](https://github.com/pydantic/pydantic/pull/11109)\n* Include `openapi-python-client` check in issue creation for third-party failures, use `main` branch by [@sydney-runkle](https://github.com/sydney-runkle) in [#11182](https://github.com/pydantic/pydantic/pull/11182)\n* Add pandera third-party tests by [@Viicos](https://github.com/Viicos) in [#11193](https://github.com/pydantic/pydantic/pull/11193)\n* Add ODMantic third-party tests by [@sydney-runkle](https://github.com/sydney-runkle) in [#11197](https://github.com/pydantic/pydantic/pull/11197)\n* Add missing stacklevel in `deprecated_instance_property` warning by [@Viicos](https://github.com/Viicos) in [#11200](https://github.com/pydantic/pydantic/pull/11200)\n* Copy `WithJsonSchema` schema to avoid sharing mutated data by [@thejcannon](https://github.com/thejcannon) in [#11014](https://github.com/pydantic/pydantic/pull/11014)\n* Do not cache parametrized models when in the process of parametrizing another model by [@Viicos](https://github.com/Viicos) in [#10704](https://github.com/pydantic/pydantic/pull/10704)\n* Re-enable Beanie third-party tests by [@Viicos](https://github.com/Viicos) in [#11214](https://github.com/pydantic/pydantic/pull/11214)\n* Add discriminated union related metadata entries to the `CoreMetadata` definition by [@Viicos](https://github.com/Viicos) in [#11216](https://github.com/pydantic/pydantic/pull/11216)\n* Consolidate schema definitions logic in the `_Definitions` class by [@Viicos](https://github.com/Viicos) in [#11208](https://github.com/pydantic/pydantic/pull/11208)\n* Support initializing root model fields with values of the `root` type in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11212](https://github.com/pydantic/pydantic/pull/11212)\n* Fix various issues with dataclasses and `use_attribute_docstrings` by [@Viicos](https://github.com/Viicos) in [#11246](https://github.com/pydantic/pydantic/pull/11246)\n* Only compute normalized decimal places if necessary in `decimal_places_validator` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#11281](https://github.com/pydantic/pydantic/pull/11281)\n* Fix two misplaced sentences in validation errors documentation by [@ananiavito](https://github.com/ananiavito) in [#11302](https://github.com/pydantic/pydantic/pull/11302)\n* Fix mkdocstrings inventory example in documentation by [@pawamoy](https://github.com/pawamoy) in [#11311](https://github.com/pydantic/pydantic/pull/11311)\n* Add support for `validation_alias` in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11295](https://github.com/pydantic/pydantic/pull/11295)\n* Do not transform model serializer functions as class methods in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11298](https://github.com/pydantic/pydantic/pull/11298)\n* Simplify `GenerateJsonSchema.literal_schema()` implementation by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#11321](https://github.com/pydantic/pydantic/pull/11321)\n* Add additional allowed schemes for `ClickHouseDsn` by [@Maze21127](https://github.com/Maze21127) in [#11319](https://github.com/pydantic/pydantic/pull/11319)\n* Coerce decimal constraints to `Decimal` instances by [@Viicos](https://github.com/Viicos) in [#11350](https://github.com/pydantic/pydantic/pull/11350)\n* Fix `ValueError` on year zero by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1583](https://github.com/pydantic/pydantic-core/pull/1583)\n\n### New Contributors\n\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* [@tamird](https://github.com/tamird) made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* [@felixxm](https://github.com/felixxm) made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n* [@mdaffad](https://github.com/mdaffad) made their first contribution in [#11177](https://github.com/pydantic/pydantic/pull/11177)\n* [@thejcannon](https://github.com/thejcannon) made their first contribution in [#11014](https://github.com/pydantic/pydantic/pull/11014)\n* [@thomasfrimannkoren](https://github.com/thomasfrimannkoren) made their first contribution in [#11251](https://github.com/pydantic/pydantic/pull/11251)\n* [@usernameMAI](https://github.com/usernameMAI) made their first contribution in [#11275](https://github.com/pydantic/pydantic/pull/11275)\n* [@ananiavito](https://github.com/ananiavito) made their first contribution in [#11302](https://github.com/pydantic/pydantic/pull/11302)\n* [@pawamoy](https://github.com/pawamoy) made their first contribution in [#11311](https://github.com/pydantic/pydantic/pull/11311)\n* [@Maze21127](https://github.com/Maze21127) made their first contribution in [#11319](https://github.com/pydantic/pydantic/pull/11319)\n\n## v2.10.6 (2025-01-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.6)\n\n### What's Changed\n\n#### Fixes\n\n* Fix JSON Schema reference collection with `'examples'` keys by [@Viicos](https://github.com/Viicos) in [#11325](https://github.com/pydantic/pydantic/pull/11325)\n* Fix url python serialization by [@sydney-runkle](https://github.com/sydney-runkle) in [#11331](https://github.com/pydantic/pydantic/pull/11331)\n\n## v2.10.5 (2025-01-08)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.5)\n\n### What's Changed\n\n#### Fixes\n\n* Remove custom MRO implementation of Pydantic models by [@Viicos](https://github.com/Viicos) in [#11184](https://github.com/pydantic/pydantic/pull/11184)\n* Fix URL serialization for unions by [@sydney-runkle](https://github.com/sydney-runkle) in [#11233](https://github.com/pydantic/pydantic/pull/11233)\n\n## v2.10.4 (2024-12-18)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.4)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.27.2 by [@davidhewitt](https://github.com/davidhewitt) in [#11138](https://github.com/pydantic/pydantic/pull/11138)\n\n#### Fixes\n\n* Fix for comparison of `AnyUrl` objects by [@alexprabhat99](https://github.com/alexprabhat99) in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* Properly fetch PEP 695 type params for functions, do not fetch annotations from signature by [@Viicos](https://github.com/Viicos) in [#11093](https://github.com/pydantic/pydantic/pull/11093)\n* Include JSON Schema input core schema in function schemas by [@Viicos](https://github.com/Viicos) in [#11085](https://github.com/pydantic/pydantic/pull/11085)\n* Add `len` to `_BaseUrl` to avoid TypeError by [@Kharianne](https://github.com/Kharianne) in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n* Make sure the type reference is removed from the seen references by [@Viicos](https://github.com/Viicos) in [#11143](https://github.com/pydantic/pydantic/pull/11143)\n\n### New Contributors\n\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* [@tamird](https://github.com/tamird) made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* [@felixxm](https://github.com/felixxm) made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n\n## v2.10.3 (2024-12-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.3)\n\n### What's Changed\n\n#### Fixes\n\n* Set fields when `defer_build` is set on Pydantic dataclasses by [@Viicos](https://github.com/Viicos) in [#10984](https://github.com/pydantic/pydantic/pull/10984)\n* Do not resolve the JSON Schema reference for `dict` core schema keys by [@Viicos](https://github.com/Viicos) in [#10989](https://github.com/pydantic/pydantic/pull/10989)\n* Use the globals of the function when evaluating the return type for `PlainSerializer` and `WrapSerializer` functions by [@Viicos](https://github.com/Viicos) in [#11008](https://github.com/pydantic/pydantic/pull/11008)\n* Fix host required enforcement for urls to be compatible with v2.9 behavior by [@sydney-runkle](https://github.com/sydney-runkle) in [#11027](https://github.com/pydantic/pydantic/pull/11027)\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11034](https://github.com/pydantic/pydantic/pull/11034)\n* Fix url json schema in `serialization` mode by [@sydney-runkle](https://github.com/sydney-runkle) in [#11035](https://github.com/pydantic/pydantic/pull/11035)\n\n## v2.10.2 (2024-11-25)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.2)\n\n### What's Changed\n\n#### Fixes\n\n* Only evaluate FieldInfo annotations if required during schema building by [@Viicos](https://github.com/Viicos) in [#10769](https://github.com/pydantic/pydantic/pull/10769)\n* Do not evaluate annotations for private fields by [@Viicos](https://github.com/Viicos) in [#10962](https://github.com/pydantic/pydantic/pull/10962)\n* Support serialization as any for `Secret` types and `Url` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10947](https://github.com/pydantic/pydantic/pull/10947)\n* Fix type hint of `Field.default` to be compatible with Python 3.8 and 3.9 by [@Viicos](https://github.com/Viicos) in [#10972](https://github.com/pydantic/pydantic/pull/10972)\n* Add hashing support for URL types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10975](https://github.com/pydantic/pydantic/pull/10975)\n* Hide `BaseModel.__replace__` definition from type checkers by [@Viicos](https://github.com/Viicos) in [#10979](https://github.com/pydantic/pydantic/pull/10979)\n\n## v2.10.1 (2024-11-21)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.1)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` version to `v2.27.1` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10938](https://github.com/pydantic/pydantic/pull/10938)\n\n#### Fixes\n\n* Use the correct frame when instantiating a parametrized `TypeAdapter` by [@Viicos](https://github.com/Viicos) in [#10893](https://github.com/pydantic/pydantic/pull/10893)\n* Relax check for validated data in `default_factory` utils by [@sydney-runkle](https://github.com/sydney-runkle) in [#10909](https://github.com/pydantic/pydantic/pull/10909)\n* Fix type checking issue with `model_fields` and `model_computed_fields` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10911](https://github.com/pydantic/pydantic/pull/10911)\n* Use the parent configuration during schema generation for stdlib `dataclass`es by [@sydney-runkle](https://github.com/sydney-runkle) in [#10928](https://github.com/pydantic/pydantic/pull/10928)\n* Use the `globals` of the function when evaluating the return type of serializers and `computed_field`s by [@Viicos](https://github.com/Viicos) in [#10929](https://github.com/pydantic/pydantic/pull/10929)\n* Fix URL constraint application by [@sydney-runkle](https://github.com/sydney-runkle) in [#10922](https://github.com/pydantic/pydantic/pull/10922)\n* Fix URL equality with different validation methods by [@sydney-runkle](https://github.com/sydney-runkle) in [#10934](https://github.com/pydantic/pydantic/pull/10934)\n* Fix JSON schema title when specified as `''` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10936](https://github.com/pydantic/pydantic/pull/10936)\n* Fix `python` mode serialization for `complex` inference by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic-core#1549](https://github.com/pydantic/pydantic-core/pull/1549)\n\n### New Contributors\n\n## v2.10.0 (2024-11-20)\n\nThe code released in v2.10.0 is practically identical to that of v2.10.0b2.\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0)\n\nSee the [v2.10 release blog post](https://pydantic.dev/articles/pydantic-v2-10-release) for the highlights!\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to `v2.27.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10825](https://github.com/pydantic/pydantic/pull/10825)\n* Replaced pdm with uv by [@frfahim](https://github.com/frfahim) in [#10727](https://github.com/pydantic/pydantic/pull/10727)\n\n#### New Features\n\n* Support `fractions.Fraction` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10318](https://github.com/pydantic/pydantic/pull/10318)\n* Support `Hashable` for json validation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10324](https://github.com/pydantic/pydantic/pull/10324)\n* Add a `SocketPath` type for `linux` systems by [@theunkn0wn1](https://github.com/theunkn0wn1) in [#10378](https://github.com/pydantic/pydantic/pull/10378)\n* Allow arbitrary refs in JSON schema `examples` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10417](https://github.com/pydantic/pydantic/pull/10417)\n* Support `defer_build` for Pydantic dataclasses by [@Viicos](https://github.com/Viicos) in [#10313](https://github.com/pydantic/pydantic/pull/10313)\n* Adding v1 / v2 incompatibility warning for nested v1 model by [@sydney-runkle](https://github.com/sydney-runkle) in [#10431](https://github.com/pydantic/pydantic/pull/10431)\n* Add support for unpacked `TypedDict` to type hint variadic keyword arguments with `@validate_call` by [@Viicos](https://github.com/Viicos) in [#10416](https://github.com/pydantic/pydantic/pull/10416)\n* Support compiled patterns in `protected_namespaces` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10522](https://github.com/pydantic/pydantic/pull/10522)\n* Add support for `propertyNames` in JSON schema by [@FlorianSW](https://github.com/FlorianSW) in [#10478](https://github.com/pydantic/pydantic/pull/10478)\n* Adding `__replace__` protocol for Python 3.13+ support by [@sydney-runkle](https://github.com/sydney-runkle) in [#10596](https://github.com/pydantic/pydantic/pull/10596)\n* Expose public `sort` method for JSON schema generation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10595](https://github.com/pydantic/pydantic/pull/10595)\n* Add runtime validation of `@validate_call` callable argument by [@kc0506](https://github.com/kc0506) in [#10627](https://github.com/pydantic/pydantic/pull/10627)\n* Add `experimental_allow_partial` support by [@samuelcolvin](https://github.com/samuelcolvin) in [#10748](https://github.com/pydantic/pydantic/pull/10748)\n* Support default factories taking validated data as an argument by [@Viicos](https://github.com/Viicos) in [#10678](https://github.com/pydantic/pydantic/pull/10678)\n* Allow subclassing `ValidationError` and `PydanticCustomError` by [@Youssefares](https://github.com/Youssefares) in [pydantic/pydantic-core#1413](https://github.com/pydantic/pydantic-core/pull/1413)\n* Add `trailing-strings` support to `experimental_allow_partial` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10825](https://github.com/pydantic/pydantic/pull/10825)\n* Add `rebuild()` method for `TypeAdapter` and simplify `defer_build` patterns by [@sydney-runkle](https://github.com/sydney-runkle) in [#10537](https://github.com/pydantic/pydantic/pull/10537)\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in [#10872](https://github.com/pydantic/pydantic/pull/10872)\n\n#### Changes\n\n* Don't allow customization of `SchemaGenerator` until interface is more stable by [@sydney-runkle](https://github.com/sydney-runkle) in [#10303](https://github.com/pydantic/pydantic/pull/10303)\n* Cleanly `defer_build` on `TypeAdapters`, removing experimental flag by [@sydney-runkle](https://github.com/sydney-runkle) in [#10329](https://github.com/pydantic/pydantic/pull/10329)\n* Fix `mro` of generic subclass  by [@kc0506](https://github.com/kc0506) in [#10100](https://github.com/pydantic/pydantic/pull/10100)\n* Strip whitespaces on JSON Schema title generation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10404](https://github.com/pydantic/pydantic/pull/10404)\n* Use `b64decode` and `b64encode` for `Base64Bytes` type by [@sydney-runkle](https://github.com/sydney-runkle) in [#10486](https://github.com/pydantic/pydantic/pull/10486)\n* Relax protected namespace config default by [@sydney-runkle](https://github.com/sydney-runkle) in [#10441](https://github.com/pydantic/pydantic/pull/10441)\n* Revalidate parametrized generics if instance's origin is subclass of OG class by [@sydney-runkle](https://github.com/sydney-runkle) in [#10666](https://github.com/pydantic/pydantic/pull/10666)\n* Warn if configuration is specified on the `@dataclass` decorator and with the `__pydantic_config__` attribute by [@sydney-runkle](https://github.com/sydney-runkle) in [#10406](https://github.com/pydantic/pydantic/pull/10406)\n* Recommend against using `Ellipsis` (...) with `Field` by [@Viicos](https://github.com/Viicos) in [#10661](https://github.com/pydantic/pydantic/pull/10661)\n* Migrate to subclassing instead of annotated approach for pydantic url types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10662](https://github.com/pydantic/pydantic/pull/10662)\n* Change JSON schema generation of `Literal`s and `Enums` by [@Viicos](https://github.com/Viicos) in [#10692](https://github.com/pydantic/pydantic/pull/10692)\n* Simplify unions involving `Any` or `Never` when replacing type variables by [@Viicos](https://github.com/Viicos) in [#10338](https://github.com/pydantic/pydantic/pull/10338)\n* Do not require padding when decoding `base64` bytes by [@bschoenmaeckers](https://github.com/bschoenmaeckers) in [pydantic/pydantic-core#1448](https://github.com/pydantic/pydantic-core/pull/1448)\n* Support dates all the way to 1BC by [@changhc](https://github.com/changhc) in [pydantic/speedate#77](https://github.com/pydantic/speedate/pull/77)\n\n#### Performance\n\n* Schema cleaning: skip unnecessary copies during schema walking by [@Viicos](https://github.com/Viicos) in [#10286](https://github.com/pydantic/pydantic/pull/10286)\n* Refactor namespace logic for annotations evaluation by [@Viicos](https://github.com/Viicos) in [#10530](https://github.com/pydantic/pydantic/pull/10530)\n* Improve email regexp on edge cases by [@AlekseyLobanov](https://github.com/AlekseyLobanov) in [#10601](https://github.com/pydantic/pydantic/pull/10601)\n* `CoreMetadata` refactor with an emphasis on documentation, schema build time performance, and reducing complexity by [@sydney-runkle](https://github.com/sydney-runkle) in [#10675](https://github.com/pydantic/pydantic/pull/10675)\n\n#### Fixes\n\n* Remove guarding check on `computed_field` with `field_serializer` by [@nix010](https://github.com/nix010) in [#10390](https://github.com/pydantic/pydantic/pull/10390)\n* Fix `Predicate` issue in `v2.9.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10321](https://github.com/pydantic/pydantic/pull/10321)\n* Fixing `annotated-types` bound by [@sydney-runkle](https://github.com/sydney-runkle) in [#10327](https://github.com/pydantic/pydantic/pull/10327)\n* Turn `tzdata` install requirement into optional `timezone` dependency by [@jakob-keller](https://github.com/jakob-keller) in [#10331](https://github.com/pydantic/pydantic/pull/10331)\n* Use correct types namespace when building `namedtuple` core schemas by [@Viicos](https://github.com/Viicos) in [#10337](https://github.com/pydantic/pydantic/pull/10337)\n* Fix evaluation of stringified annotations during namespace inspection by [@Viicos](https://github.com/Viicos) in [#10347](https://github.com/pydantic/pydantic/pull/10347)\n* Fix `IncEx` type alias definition by [@Viicos](https://github.com/Viicos) in [#10339](https://github.com/pydantic/pydantic/pull/10339)\n* Do not error when trying to evaluate annotations of private attributes by [@Viicos](https://github.com/Viicos) in [#10358](https://github.com/pydantic/pydantic/pull/10358)\n* Fix nested type statement by [@kc0506](https://github.com/kc0506) in [#10369](https://github.com/pydantic/pydantic/pull/10369)\n* Improve typing of `ModelMetaclass.mro` by [@Viicos](https://github.com/Viicos) in [#10372](https://github.com/pydantic/pydantic/pull/10372)\n* Fix class access of deprecated `computed_field`s by [@Viicos](https://github.com/Viicos) in [#10391](https://github.com/pydantic/pydantic/pull/10391)\n* Make sure `inspect.iscoroutinefunction` works on coroutines decorated with `@validate_call` by [@MovisLi](https://github.com/MovisLi) in [#10374](https://github.com/pydantic/pydantic/pull/10374)\n* Fix `NameError` when using `validate_call` with PEP 695 on a class by [@kc0506](https://github.com/kc0506) in [#10380](https://github.com/pydantic/pydantic/pull/10380)\n* Fix `ZoneInfo` with various invalid types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10408](https://github.com/pydantic/pydantic/pull/10408)\n* Fix `PydanticUserError` on empty `model_config` with annotations by [@cdwilson](https://github.com/cdwilson) in [#10412](https://github.com/pydantic/pydantic/pull/10412)\n* Fix variance issue in `_IncEx` type alias, only allow `True` by [@Viicos](https://github.com/Viicos) in [#10414](https://github.com/pydantic/pydantic/pull/10414)\n* Fix serialization schema generation when using `PlainValidator` by [@Viicos](https://github.com/Viicos) in [#10427](https://github.com/pydantic/pydantic/pull/10427)\n* Fix schema generation error when serialization schema holds references by [@Viicos](https://github.com/Viicos) in [#10444](https://github.com/pydantic/pydantic/pull/10444)\n* Inline references if possible when generating schema for `json_schema_input_type` by [@Viicos](https://github.com/Viicos) in [#10439](https://github.com/pydantic/pydantic/pull/10439)\n* Fix recursive arguments in `Representation` by [@Viicos](https://github.com/Viicos) in [#10480](https://github.com/pydantic/pydantic/pull/10480)\n* Fix representation for builtin function types by [@kschwab](https://github.com/kschwab) in [#10479](https://github.com/pydantic/pydantic/pull/10479)\n* Add python validators for decimal constraints (`max_digits` and `decimal_places`) by [@sydney-runkle](https://github.com/sydney-runkle) in [#10506](https://github.com/pydantic/pydantic/pull/10506)\n* Only fetch `__pydantic_core_schema__` from the current class during schema generation by [@Viicos](https://github.com/Viicos) in [#10518](https://github.com/pydantic/pydantic/pull/10518)\n* Fix `stacklevel` on deprecation warnings for `BaseModel` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10520](https://github.com/pydantic/pydantic/pull/10520)\n* Fix warning `stacklevel` in `BaseModel.__init__` by [@Viicos](https://github.com/Viicos) in [#10526](https://github.com/pydantic/pydantic/pull/10526)\n* Improve error handling for in-evaluable refs for discriminator application by [@sydney-runkle](https://github.com/sydney-runkle) in [#10440](https://github.com/pydantic/pydantic/pull/10440)\n* Change the signature of `ConfigWrapper.core_config` to take the title directly by [@Viicos](https://github.com/Viicos) in [#10562](https://github.com/pydantic/pydantic/pull/10562)\n* Do not use the previous config from the stack for dataclasses without config by [@Viicos](https://github.com/Viicos) in [#10576](https://github.com/pydantic/pydantic/pull/10576)\n* Fix serialization for IP types with `mode='python'` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10594](https://github.com/pydantic/pydantic/pull/10594)\n* Support constraint application for `Base64Etc` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10584](https://github.com/pydantic/pydantic/pull/10584)\n* Fix `validate_call` ignoring `Field` in `Annotated` by [@kc0506](https://github.com/kc0506) in [#10610](https://github.com/pydantic/pydantic/pull/10610)\n* Raise an error when `Self` is invalid by [@kc0506](https://github.com/kc0506) in [#10609](https://github.com/pydantic/pydantic/pull/10609)\n* Using `core_schema.InvalidSchema` instead of metadata injection + checks by [@sydney-runkle](https://github.com/sydney-runkle) in [#10523](https://github.com/pydantic/pydantic/pull/10523)\n* Tweak type alias logic by [@kc0506](https://github.com/kc0506) in [#10643](https://github.com/pydantic/pydantic/pull/10643)\n* Support usage of `type` with `typing.Self` and type aliases by [@kc0506](https://github.com/kc0506) in [#10621](https://github.com/pydantic/pydantic/pull/10621)\n* Use overloads for `Field` and `PrivateAttr` functions by [@Viicos](https://github.com/Viicos) in [#10651](https://github.com/pydantic/pydantic/pull/10651)\n* Clean up the `mypy` plugin implementation by [@Viicos](https://github.com/Viicos) in [#10669](https://github.com/pydantic/pydantic/pull/10669)\n* Properly check for `typing_extensions` variant of `TypeAliasType` by [@Daraan](https://github.com/Daraan) in [#10713](https://github.com/pydantic/pydantic/pull/10713)\n* Allow any mapping in `BaseModel.model_copy()` by [@Viicos](https://github.com/Viicos) in [#10751](https://github.com/pydantic/pydantic/pull/10751)\n* Fix `isinstance` behavior for urls by [@sydney-runkle](https://github.com/sydney-runkle) in [#10766](https://github.com/pydantic/pydantic/pull/10766)\n* Ensure `cached_property` can be set on Pydantic models by [@Viicos](https://github.com/Viicos) in [#10774](https://github.com/pydantic/pydantic/pull/10774)\n* Fix equality checks for primitives in literals by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1459](https://github.com/pydantic/pydantic-core/pull/1459)\n* Properly enforce `host_required` for URLs by [@Viicos](https://github.com/Viicos) in [pydantic/pydantic-core#1488](https://github.com/pydantic/pydantic-core/pull/1488)\n* Fix when `coerce_numbers_to_str` enabled and string has invalid Unicode character by [@andrey-berenda](https://github.com/andrey-berenda) in [pydantic/pydantic-core#1515](https://github.com/pydantic/pydantic-core/pull/1515)\n* Fix serializing `complex` values in `Enum`s by [@changhc](https://github.com/changhc) in [pydantic/pydantic-core#1524](https://github.com/pydantic/pydantic-core/pull/1524)\n* Refactor `_typing_extra` module by [@Viicos](https://github.com/Viicos) in [#10725](https://github.com/pydantic/pydantic/pull/10725)\n* Support intuitive equality for urls by [@sydney-runkle](https://github.com/sydney-runkle) in [#10798](https://github.com/pydantic/pydantic/pull/10798)\n* Add `bytearray` to `TypeAdapter.validate_json` signature by [@samuelcolvin](https://github.com/samuelcolvin) in [#10802](https://github.com/pydantic/pydantic/pull/10802)\n* Ensure class access of method descriptors is performed when used as a default with `Field` by [@Viicos](https://github.com/Viicos) in [#10816](https://github.com/pydantic/pydantic/pull/10816)\n* Fix circular import with `validate_call` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10807](https://github.com/pydantic/pydantic/pull/10807)\n* Fix error when using type aliases referencing other type aliases by [@Viicos](https://github.com/Viicos) in [#10809](https://github.com/pydantic/pydantic/pull/10809)\n* Fix `IncEx` type alias to be compatible with mypy by [@Viicos](https://github.com/Viicos) in [#10813](https://github.com/pydantic/pydantic/pull/10813)\n* Make `__signature__` a lazy property, do not deepcopy defaults by [@Viicos](https://github.com/Viicos) in [#10818](https://github.com/pydantic/pydantic/pull/10818)\n* Make `__signature__` lazy for dataclasses, too by [@sydney-runkle](https://github.com/sydney-runkle) in [#10832](https://github.com/pydantic/pydantic/pull/10832)\n* Subclass all single host url classes from `AnyUrl` to preserve behavior from v2.9 by [@sydney-runkle](https://github.com/sydney-runkle) in [#10856](https://github.com/pydantic/pydantic/pull/10856)\n\n### New Contributors\n\n* [@jakob-keller](https://github.com/jakob-keller) made their first contribution in [#10331](https://github.com/pydantic/pydantic/pull/10331)\n* [@MovisLi](https://github.com/MovisLi) made their first contribution in [#10374](https://github.com/pydantic/pydantic/pull/10374)\n* [@joaopalmeiro](https://github.com/joaopalmeiro) made their first contribution in [#10405](https://github.com/pydantic/pydantic/pull/10405)\n* [@theunkn0wn1](https://github.com/theunkn0wn1) made their first contribution in [#10378](https://github.com/pydantic/pydantic/pull/10378)\n* [@cdwilson](https://github.com/cdwilson) made their first contribution in [#10412](https://github.com/pydantic/pydantic/pull/10412)\n* [@dlax](https://github.com/dlax) made their first contribution in [#10421](https://github.com/pydantic/pydantic/pull/10421)\n* [@kschwab](https://github.com/kschwab) made their first contribution in [#10479](https://github.com/pydantic/pydantic/pull/10479)\n* [@santibreo](https://github.com/santibreo) made their first contribution in [#10453](https://github.com/pydantic/pydantic/pull/10453)\n* [@FlorianSW](https://github.com/FlorianSW) made their first contribution in [#10478](https://github.com/pydantic/pydantic/pull/10478)\n* [@tkasuz](https://github.com/tkasuz) made their first contribution in [#10555](https://github.com/pydantic/pydantic/pull/10555)\n* [@AlekseyLobanov](https://github.com/AlekseyLobanov) made their first contribution in [#10601](https://github.com/pydantic/pydantic/pull/10601)\n* [@NiclasvanEyk](https://github.com/NiclasvanEyk) made their first contribution in [#10667](https://github.com/pydantic/pydantic/pull/10667)\n* [@mschoettle](https://github.com/mschoettle) made their first contribution in [#10677](https://github.com/pydantic/pydantic/pull/10677)\n* [@Daraan](https://github.com/Daraan) made their first contribution in [#10713](https://github.com/pydantic/pydantic/pull/10713)\n* [@k4nar](https://github.com/k4nar) made their first contribution in [#10736](https://github.com/pydantic/pydantic/pull/10736)\n* [@UriyaHarpeness](https://github.com/UriyaHarpeness) made their first contribution in [#10740](https://github.com/pydantic/pydantic/pull/10740)\n* [@frfahim](https://github.com/frfahim) made their first contribution in [#10727](https://github.com/pydantic/pydantic/pull/10727)\n\n## v2.10.0b2 (2024-11-13)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b2) for details.\n\n## v2.10.0b1 (2024-11-06)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b1) for details.\n\n\n... see [here](https://docs.pydantic.dev/changelog/#v0322-2019-08-17) for earlier changes.\n",
        "description_content_type": "text/markdown",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Terrence Dorsey <terry@pydantic.dev>, David Montague <david@pydantic.dev>, Serge Matveenko <lig@countzero.co>, Marcelo Trylesinski <marcelotryle@gmail.com>, Sydney Runkle <sydneymarierunkle@gmail.com>, David Hewitt <mail@davidhewitt.io>, Alex Hall <alex.mojaki@gmail.com>, Victorien Plot <contact@vctrn.dev>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: Hypothesis",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "annotated-types>=0.6.0",
          "pydantic-core==2.33.2",
          "typing-extensions>=4.12.2",
          "typing-inspection>=0.4.0",
          "email-validator>=2.0.0; extra == 'email'",
          "tzdata; (python_version >= '3.9' and platform_system == 'Windows') and extra == 'timezone'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic",
          "Documentation, https://docs.pydantic.dev",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic",
          "Changelog, https://docs.pydantic.dev/latest/changelog/"
        ],
        "provides_extra": [
          "email",
          "timezone"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/a0/75/4a0a9bac998d78d889def5e4ef2b065acba8cae8c93696906c3a91f310ca/pydantic_core-2.33.2-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=c083a3bdd5a93dfe480f1125926afcdbf2917ae714bdb80b36d34318b2bec5d9",
          "hashes": {
            "sha256": "c083a3bdd5a93dfe480f1125926afcdbf2917ae714bdb80b36d34318b2bec5d9"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pydantic_core",
        "version": "2.33.2",
        "summary": "Core functionality for Pydantic validation and serialization",
        "description": "# pydantic-core\r\n\r\n[![CI](https://github.com/pydantic/pydantic-core/workflows/ci/badge.svg?event=push)](https://github.com/pydantic/pydantic-core/actions?query=event%3Apush+branch%3Amain+workflow%3Aci)\r\n[![Coverage](https://codecov.io/gh/pydantic/pydantic-core/branch/main/graph/badge.svg)](https://codecov.io/gh/pydantic/pydantic-core)\r\n[![pypi](https://img.shields.io/pypi/v/pydantic-core.svg)](https://pypi.python.org/pypi/pydantic-core)\r\n[![versions](https://img.shields.io/pypi/pyversions/pydantic-core.svg)](https://github.com/pydantic/pydantic-core)\r\n[![license](https://img.shields.io/github/license/pydantic/pydantic-core.svg)](https://github.com/pydantic/pydantic-core/blob/main/LICENSE)\r\n\r\nThis package provides the core functionality for [pydantic](https://docs.pydantic.dev) validation and serialization.\r\n\r\nPydantic-core is currently around 17x faster than pydantic V1.\r\nSee [`tests/benchmarks/`](./tests/benchmarks/) for details.\r\n\r\n## Example of direct usage\r\n\r\n_NOTE: You should not need to use pydantic-core directly; instead, use pydantic, which in turn uses pydantic-core._\r\n\r\n```py\r\nfrom pydantic_core import SchemaValidator, ValidationError\r\n\r\n\r\nv = SchemaValidator(\r\n    {\r\n        'type': 'typed-dict',\r\n        'fields': {\r\n            'name': {\r\n                'type': 'typed-dict-field',\r\n                'schema': {\r\n                    'type': 'str',\r\n                },\r\n            },\r\n            'age': {\r\n                'type': 'typed-dict-field',\r\n                'schema': {\r\n                    'type': 'int',\r\n                    'ge': 18,\r\n                },\r\n            },\r\n            'is_developer': {\r\n                'type': 'typed-dict-field',\r\n                'schema': {\r\n                    'type': 'default',\r\n                    'schema': {'type': 'bool'},\r\n                    'default': True,\r\n                },\r\n            },\r\n        },\r\n    }\r\n)\r\n\r\nr1 = v.validate_python({'name': 'Samuel', 'age': 35})\r\nassert r1 == {'name': 'Samuel', 'age': 35, 'is_developer': True}\r\n\r\n# pydantic-core can also validate JSON directly\r\nr2 = v.validate_json('{\"name\": \"Samuel\", \"age\": 35}')\r\nassert r1 == r2\r\n\r\ntry:\r\n    v.validate_python({'name': 'Samuel', 'age': 11})\r\nexcept ValidationError as e:\r\n    print(e)\r\n    \"\"\"\r\n    1 validation error for model\r\n    age\r\n      Input should be greater than or equal to 18\r\n      [type=greater_than_equal, context={ge: 18}, input_value=11, input_type=int]\r\n    \"\"\"\r\n```\r\n\r\n## Getting Started\r\n\r\nYou'll need rust stable [installed](https://rustup.rs/), or rust nightly if you want to generate accurate coverage.\r\n\r\nWith rust and python 3.9+ installed, compiling pydantic-core should be possible with roughly the following:\r\n\r\n```bash\r\n# clone this repo or your fork\r\ngit clone git@github.com:pydantic/pydantic-core.git\r\ncd pydantic-core\r\n# create a new virtual env\r\npython3 -m venv env\r\nsource env/bin/activate\r\n# install dependencies and install pydantic-core\r\nmake install\r\n```\r\n\r\nThat should be it, the example shown above should now run.\r\n\r\nYou might find it useful to look at [`python/pydantic_core/_pydantic_core.pyi`](./python/pydantic_core/_pydantic_core.pyi) and\r\n[`python/pydantic_core/core_schema.py`](./python/pydantic_core/core_schema.py) for more information on the python API,\r\nbeyond that, [`tests/`](./tests) provide a large number of examples of usage.\r\n\r\nIf you want to contribute to pydantic-core, you'll want to use some other make commands:\r\n* `make build-dev` to build the package during development\r\n* `make build-prod` to perform an optimised build for benchmarking\r\n* `make test` to run the tests\r\n* `make testcov` to run the tests and generate a coverage report\r\n* `make lint` to run the linter\r\n* `make format` to format python and rust code\r\n* `make` to run `format build-dev lint test`\r\n\r\n## Profiling\r\n\r\nIt's possible to profile the code using the [`flamegraph` utility from `flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph). (Tested on Linux.) You can install this with `cargo install flamegraph`.\r\n\r\nRun `make build-profiling` to install a release build with debugging symbols included (needed for profiling).\r\n\r\nOnce that is built, you can profile pytest benchmarks with (e.g.):\r\n\r\n```bash\r\nflamegraph -- pytest tests/benchmarks/test_micro_benchmarks.py -k test_list_of_ints_core_py --benchmark-enable\r\n```\r\nThe `flamegraph` command will produce an interactive SVG at `flamegraph.svg`.\r\n\r\n## Releasing\r\n\r\n1. Bump package version locally. Do not just edit `Cargo.toml` on Github, you need both `Cargo.toml` and `Cargo.lock` to be updated.\r\n2. Make a PR for the version bump and merge it.\r\n3. Go to https://github.com/pydantic/pydantic-core/releases and click \"Draft a new release\"\r\n4. In the \"Choose a tag\" dropdown enter the new tag `v<the.new.version>` and select \"Create new tag on publish\" when the option appears.\r\n5. Enter the release title in the form \"v<the.new.version> <YYYY-MM-DD>\"\r\n6. Click Generate release notes button\r\n7. Click Publish release\r\n8. Go to https://github.com/pydantic/pydantic-core/actions and ensure that all build for release are done successfully.\r\n9. Go to https://pypi.org/project/pydantic-core/ and ensure that the latest release is published.\r\n10. Done ðŸŽ‰\r\n\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
        "home_page": "https://github.com/pydantic/pydantic-core",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, David Montague <david@pydantic.dev>, David Hewitt <mail@davidhewitt.dev>, Sydney Runkle <sydneymarierunkle@gmail.com>, Victorien Plot <contact@vctrn.dev>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Rust",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.6.0,!=4.7.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic-core",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic-core"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c1/60/5d4751ba3f4a40a6891f24eec885f51afd78d208498268c734e256fb13c4/pydantic_settings-2.12.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=fddb9fd99a5b18da837b29710391e945b1e30c135477f484084ee513adb93809",
          "hashes": {
            "sha256": "fddb9fd99a5b18da837b29710391e945b1e30c135477f484084ee513adb93809"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pydantic-settings",
        "version": "2.12.0",
        "summary": "Settings management using Pydantic",
        "description": "# pydantic-settings\n\n[![CI](https://github.com/pydantic/pydantic-settings/actions/workflows/ci.yml/badge.svg?event=push)](https://github.com/pydantic/pydantic-settings/actions/workflows/ci.yml?query=branch%3Amain)\n[![Coverage](https://codecov.io/gh/pydantic/pydantic-settings/branch/main/graph/badge.svg)](https://codecov.io/gh/pydantic/pydantic-settings)\n[![pypi](https://img.shields.io/pypi/v/pydantic-settings.svg)](https://pypi.python.org/pypi/pydantic-settings)\n[![license](https://img.shields.io/github/license/pydantic/pydantic-settings.svg)](https://github.com/pydantic/pydantic-settings/blob/main/LICENSE)\n[![downloads](https://static.pepy.tech/badge/pydantic-settings/month)](https://pepy.tech/project/pydantic-settings)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic-settings.svg)](https://github.com/pydantic/pydantic-settings)\n\nSettings management using Pydantic.\n\nSee [documentation](https://docs.pydantic.dev/latest/concepts/pydantic_settings/) for more details.\n",
        "description_content_type": "text/markdown",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Framework :: Pydantic",
          "Framework :: Pydantic :: 2",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Unix",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "pydantic>=2.7.0",
          "python-dotenv>=0.21.0",
          "typing-inspection>=0.4.0",
          "boto3-stubs[secretsmanager]; extra == 'aws-secrets-manager'",
          "boto3>=1.35.0; extra == 'aws-secrets-manager'",
          "azure-identity>=1.16.0; extra == 'azure-key-vault'",
          "azure-keyvault-secrets>=4.8.0; extra == 'azure-key-vault'",
          "google-cloud-secret-manager>=2.23.1; extra == 'gcp-secret-manager'",
          "tomli>=2.0.1; extra == 'toml'",
          "pyyaml>=6.0.1; extra == 'yaml'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic-settings",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic-settings",
          "Changelog, https://github.com/pydantic/pydantic-settings/releases",
          "Documentation, https://docs.pydantic.dev/dev-v2/concepts/pydantic_settings/"
        ],
        "provides_extra": [
          "aws-secrets-manager",
          "azure-key-vault",
          "gcp-secret-manager",
          "toml",
          "yaml"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=e8699adbbf8b5c7de96d8ffa0eb5c158b3beafce084968e2ea8bb08c6794dcd0",
          "hashes": {
            "sha256": "e8699adbbf8b5c7de96d8ffa0eb5c158b3beafce084968e2ea8bb08c6794dcd0"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "referencing",
        "version": "0.36.2",
        "summary": "JSON Referencing + Python",
        "description": "===============\n``referencing``\n===============\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |pre-commit|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/referencing.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/referencing/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/referencing.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/referencing/\n\n.. |CI| image:: https://github.com/python-jsonschema/referencing/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/referencing/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://referencing.readthedocs.io/en/stable/\n\n.. |pre-commit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/referencing/main.svg\n  :alt: pre-commit.ci status\n  :target: https://results.pre-commit.ci/latest/github/python-jsonschema/referencing/main\n\n\nAn implementation-agnostic implementation of JSON reference resolution.\n\nSee `the documentation <https://referencing.readthedocs.io/>`_ for more details.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "asyncapi",
          "json",
          "jsonschema",
          "openapi",
          "referencing"
        ],
        "author_email": "Julian Berman <Julian+referencing@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "rpds-py>=0.7.0",
          "typing-extensions>=4.4.0; python_version < '3.13'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://referencing.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/referencing",
          "Issues, https://github.com/python-jsonschema/referencing/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-referencing?utm_source=pypi-referencing&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://referencing.readthedocs.io/en/stable/changes/",
          "Source, https://github.com/python-jsonschema/referencing"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6",
          "hashes": {
            "sha256": "2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "requests",
        "version": "2.32.5",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Python HTTP for Humans.",
        "description": "# Requests\n\n**Requests** is a simple, yet elegant, HTTP library.\n\n```python\n>>> import requests\n>>> r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\n'{\"authenticated\": true, ...'\n>>> r.json()\n{'authenticated': True, ...}\n```\n\nRequests allows you to send HTTP/1.1 requests extremely easily. Thereâ€™s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data â€” but nowadays, just use the `json` method!\n\nRequests is one of the most downloaded Python packages today, pulling in around `30M downloads / week`â€” according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `1,000,000+` repositories. You may certainly put your trust in this code.\n\n[![Downloads](https://static.pepy.tech/badge/requests/month)](https://pepy.tech/project/requests)\n[![Supported Versions](https://img.shields.io/pypi/pyversions/requests.svg)](https://pypi.org/project/requests)\n[![Contributors](https://img.shields.io/github/contributors/psf/requests.svg)](https://github.com/psf/requests/graphs/contributors)\n\n## Installing Requests and Supported Versions\n\nRequests is available on PyPI:\n\n```console\n$ python -m pip install requests\n```\n\nRequests officially supports Python 3.9+.\n\n## Supported Features & Bestâ€“Practices\n\nRequests is ready for the demands of building robust and reliable HTTPâ€“speaking applications, for the needs of today.\n\n- Keep-Alive & Connection Pooling\n- International Domains and URLs\n- Sessions with Cookie Persistence\n- Browser-style TLS/SSL Verification\n- Basic & Digest Authentication\n- Familiar `dict`â€“like Cookies\n- Automatic Content Decompression and Decoding\n- Multi-part File Uploads\n- SOCKS Proxy Support\n- Connection Timeouts\n- Streaming Downloads\n- Automatic honoring of `.netrc`\n- Chunked HTTP Requests\n\n## API Reference and User Guide available on [Read the Docs](https://requests.readthedocs.io)\n\n[![Read the Docs](https://raw.githubusercontent.com/psf/requests/main/ext/ss.png)](https://requests.readthedocs.io)\n\n## Cloning the repository\n\nWhen cloning the Requests repository, you may need to add the `-c\nfetch.fsck.badTimezone=ignore` flag to avoid an error about a bad commit timestamp (see\n[this issue](https://github.com/psf/requests/issues/2690) for more background):\n\n```shell\ngit clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git\n```\n\nYou can also apply this setting to your global Git config:\n\n```shell\ngit config --global fetch.fsck.badTimezone ignore\n```\n\n---\n\n[![Kenneth Reitz](https://raw.githubusercontent.com/psf/requests/main/ext/kr.png)](https://kennethreitz.org) [![Python Software Foundation](https://raw.githubusercontent.com/psf/requests/main/ext/psf.png)](https://www.python.org/psf)\n",
        "description_content_type": "text/markdown",
        "home_page": "https://requests.readthedocs.io",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "charset_normalizer<4,>=2",
          "idna<4,>=2.5",
          "urllib3<3,>=1.21.1",
          "certifi>=2017.4.17",
          "PySocks!=1.5.7,>=1.5.6; extra == \"socks\"",
          "chardet<6,>=3.0.2; extra == \"use-chardet-on-py3\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://requests.readthedocs.io",
          "Source, https://github.com/psf/requests"
        ],
        "provides_extra": [
          "security",
          "socks",
          "use-chardet-on-py3"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c4/26/b9924fa27db384bdcd97ab83b4f0a8058d96ad9626ead570674d5e737d90/charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=b435cba5f4f750aa6c0a0d92c541fb79f69a387c91e61f1795227e4ed9cece14",
          "hashes": {
            "sha256": "b435cba5f4f750aa6c0a0d92c541fb79f69a387c91e61f1795227e4ed9cece14"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "charset-normalizer",
        "version": "3.4.4",
        "dynamic": [
          "license-file"
        ],
        "summary": "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet.",
        "description": "<h1 align=\"center\">Charset Detection, for Everyone ðŸ‘‹</h1>\r\n\r\n<p align=\"center\">\r\n  <sup>The Real First Universal Charset Detector</sup><br>\r\n  <a href=\"https://pypi.org/project/charset-normalizer\">\r\n    <img src=\"https://img.shields.io/pypi/pyversions/charset_normalizer.svg?orange=blue\" />\r\n  </a>\r\n  <a href=\"https://pepy.tech/project/charset-normalizer/\">\r\n    <img alt=\"Download Count Total\" src=\"https://static.pepy.tech/badge/charset-normalizer/month\" />\r\n  </a>\r\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/7297\">\r\n    <img src=\"https://bestpractices.coreinfrastructure.org/projects/7297/badge\">\r\n  </a>\r\n</p>\r\n<p align=\"center\">\r\n  <sup><i>Featured Packages</i></sup><br>\r\n  <a href=\"https://github.com/jawah/niquests\">\r\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Niquests-Most_Advanced_HTTP_Client-cyan\">\r\n  </a>\r\n  <a href=\"https://github.com/jawah/wassima\">\r\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Wassima-Certifi_Replacement-cyan\">\r\n  </a>\r\n</p>\r\n<p align=\"center\">\r\n  <sup><i>In other language (unofficial port - by the community)</i></sup><br>\r\n  <a href=\"https://github.com/nickspring/charset-normalizer-rs\">\r\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Rust-red\">\r\n  </a>\r\n</p>\r\n\r\n> A library that helps you read text from an unknown charset encoding.<br /> Motivated by `chardet`,\r\n> I'm trying to resolve the issue by taking a new approach.\r\n> All IANA character set names for which the Python core library provides codecs are supported.\r\n\r\n<p align=\"center\">\r\n  >>>>> <a href=\"https://charsetnormalizerweb.ousret.now.sh\" target=\"_blank\">ðŸ‘‰ Try Me Online Now, Then Adopt Me ðŸ‘ˆ </a> <<<<<\r\n</p>\r\n\r\nThis project offers you an alternative to **Universal Charset Encoding Detector**, also known as **Chardet**.\r\n\r\n| Feature                                          | [Chardet](https://github.com/chardet/chardet) |                                         Charset Normalizer                                         | [cChardet](https://github.com/PyYoshi/cChardet) |\r\n|--------------------------------------------------|:---------------------------------------------:|:--------------------------------------------------------------------------------------------------:|:-----------------------------------------------:|\r\n| `Fast`                                           |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\r\n| `Universal**`                                    |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\r\n| `Reliable` **without** distinguishable standards |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\r\n| `Reliable` **with** distinguishable standards    |                       âœ…                       |                                                 âœ…                                                  |                        âœ…                        |\r\n| `License`                                        |           LGPL-2.1<br>_restrictive_           |                                                MIT                                                 |            MPL-1.1<br>_restrictive_             |\r\n| `Native Python`                                  |                       âœ…                       |                                                 âœ…                                                  |                        âŒ                        |\r\n| `Detect spoken language`                         |                       âŒ                       |                                                 âœ…                                                  |                       N/A                       |\r\n| `UnicodeDecodeError Safety`                      |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\r\n| `Whl Size (min)`                                 |                   193.6 kB                    |                                               42 kB                                                |                     ~200 kB                     |\r\n| `Supported Encoding`                             |                      33                       | ðŸŽ‰ [99](https://charset-normalizer.readthedocs.io/en/latest/user/support.html#supported-encodings) |                       40                        |\r\n\r\n<p align=\"center\">\r\n<img src=\"https://i.imgflip.com/373iay.gif\" alt=\"Reading Normalized Text\" width=\"226\"/><img src=\"https://media.tenor.com/images/c0180f70732a18b4965448d33adba3d0/tenor.gif\" alt=\"Cat Reading Text\" width=\"200\"/>\r\n</p>\r\n\r\n*\\*\\* : They are clearly using specific code for a specific encoding even if covering most of used one*<br>\r\n\r\n## âš¡ Performance\r\n\r\nThis package offer better performance than its counterpart Chardet. Here are some numbers.\r\n\r\n| Package                                       | Accuracy | Mean per file (ms) | File per sec (est) |\r\n|-----------------------------------------------|:--------:|:------------------:|:------------------:|\r\n| [chardet](https://github.com/chardet/chardet) |   86 %   |       63 ms        |    16 file/sec     |\r\n| charset-normalizer                            | **98 %** |     **10 ms**      |    100 file/sec    |\r\n\r\n| Package                                       | 99th percentile | 95th percentile | 50th percentile |\r\n|-----------------------------------------------|:---------------:|:---------------:|:---------------:|\r\n| [chardet](https://github.com/chardet/chardet) |     265 ms      |      71 ms      |      7 ms       |\r\n| charset-normalizer                            |     100 ms      |      50 ms      |      5 ms       |\r\n\r\n_updated as of december 2024 using CPython 3.12_\r\n\r\nChardet's performance on larger file (1MB+) are very poor. Expect huge difference on large payload.\r\n\r\n> Stats are generated using 400+ files using default parameters. More details on used files, see GHA workflows.\r\n> And yes, these results might change at any time. The dataset can be updated to include more files.\r\n> The actual delays heavily depends on your CPU capabilities. The factors should remain the same.\r\n> Keep in mind that the stats are generous and that Chardet accuracy vs our is measured using Chardet initial capability\r\n> (e.g. Supported Encoding) Challenge-them if you want.\r\n\r\n## âœ¨ Installation\r\n\r\nUsing pip:\r\n\r\n```sh\r\npip install charset-normalizer -U\r\n```\r\n\r\n## ðŸš€ Basic Usage\r\n\r\n### CLI\r\nThis package comes with a CLI.\r\n\r\n```\r\nusage: normalizer [-h] [-v] [-a] [-n] [-m] [-r] [-f] [-t THRESHOLD]\r\n                  file [file ...]\r\n\r\nThe Real First Universal Charset Detector. Discover originating encoding used\r\non text file. Normalize text to unicode.\r\n\r\npositional arguments:\r\n  files                 File(s) to be analysed\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  -v, --verbose         Display complementary information about file if any.\r\n                        Stdout will contain logs about the detection process.\r\n  -a, --with-alternative\r\n                        Output complementary possibilities if any. Top-level\r\n                        JSON WILL be a list.\r\n  -n, --normalize       Permit to normalize input file. If not set, program\r\n                        does not write anything.\r\n  -m, --minimal         Only output the charset detected to STDOUT. Disabling\r\n                        JSON output.\r\n  -r, --replace         Replace file when trying to normalize it instead of\r\n                        creating a new one.\r\n  -f, --force           Replace file without asking if you are sure, use this\r\n                        flag with caution.\r\n  -t THRESHOLD, --threshold THRESHOLD\r\n                        Define a custom maximum amount of chaos allowed in\r\n                        decoded content. 0. <= chaos <= 1.\r\n  --version             Show version information and exit.\r\n```\r\n\r\n```bash\r\nnormalizer ./data/sample.1.fr.srt\r\n```\r\n\r\nor\r\n\r\n```bash\r\npython -m charset_normalizer ./data/sample.1.fr.srt\r\n```\r\n\r\nðŸŽ‰ Since version 1.4.0 the CLI produce easily usable stdout result in JSON format.\r\n\r\n```json\r\n{\r\n    \"path\": \"/home/default/projects/charset_normalizer/data/sample.1.fr.srt\",\r\n    \"encoding\": \"cp1252\",\r\n    \"encoding_aliases\": [\r\n        \"1252\",\r\n        \"windows_1252\"\r\n    ],\r\n    \"alternative_encodings\": [\r\n        \"cp1254\",\r\n        \"cp1256\",\r\n        \"cp1258\",\r\n        \"iso8859_14\",\r\n        \"iso8859_15\",\r\n        \"iso8859_16\",\r\n        \"iso8859_3\",\r\n        \"iso8859_9\",\r\n        \"latin_1\",\r\n        \"mbcs\"\r\n    ],\r\n    \"language\": \"French\",\r\n    \"alphabets\": [\r\n        \"Basic Latin\",\r\n        \"Latin-1 Supplement\"\r\n    ],\r\n    \"has_sig_or_bom\": false,\r\n    \"chaos\": 0.149,\r\n    \"coherence\": 97.152,\r\n    \"unicode_path\": null,\r\n    \"is_preferred\": true\r\n}\r\n```\r\n\r\n### Python\r\n*Just print out normalized text*\r\n```python\r\nfrom charset_normalizer import from_path\r\n\r\nresults = from_path('./my_subtitle.srt')\r\n\r\nprint(str(results.best()))\r\n```\r\n\r\n*Upgrade your code without effort*\r\n```python\r\nfrom charset_normalizer import detect\r\n```\r\n\r\nThe above code will behave the same as **chardet**. We ensure that we offer the best (reasonable) BC result possible.\r\n\r\nSee the docs for advanced usage : [readthedocs.io](https://charset-normalizer.readthedocs.io/en/latest/)\r\n\r\n## ðŸ˜‡ Why\r\n\r\nWhen I started using Chardet, I noticed that it was not suited to my expectations, and I wanted to propose a\r\nreliable alternative using a completely different method. Also! I never back down on a good challenge!\r\n\r\nI **don't care** about the **originating charset** encoding, because **two different tables** can\r\nproduce **two identical rendered string.**\r\nWhat I want is to get readable text, the best I can.\r\n\r\nIn a way, **I'm brute forcing text decoding.** How cool is that ? ðŸ˜Ž\r\n\r\nDon't confuse package **ftfy** with charset-normalizer or chardet. ftfy goal is to repair Unicode string whereas charset-normalizer to convert raw file in unknown encoding to unicode.\r\n\r\n## ðŸ° How\r\n\r\n  - Discard all charset encoding table that could not fit the binary content.\r\n  - Measure noise, or the mess once opened (by chunks) with a corresponding charset encoding.\r\n  - Extract matches with the lowest mess detected.\r\n  - Additionally, we measure coherence / probe for a language.\r\n\r\n**Wait a minute**, what is noise/mess and coherence according to **YOU ?**\r\n\r\n*Noise :* I opened hundred of text files, **written by humans**, with the wrong encoding table. **I observed**, then\r\n**I established** some ground rules about **what is obvious** when **it seems like** a mess (aka. defining noise in rendered text).\r\n I know that my interpretation of what is noise is probably incomplete, feel free to contribute in order to\r\n improve or rewrite it.\r\n\r\n*Coherence :* For each language there is on earth, we have computed ranked letter appearance occurrences (the best we can). So I thought\r\nthat intel is worth something here. So I use those records against decoded text to check if I can detect intelligent design.\r\n\r\n## âš¡ Known limitations\r\n\r\n  - Language detection is unreliable when text contains two or more languages sharing identical letters. (eg. HTML (english tags) + Turkish content (Sharing Latin characters))\r\n  - Every charset detector heavily depends on sufficient content. In common cases, do not bother run detection on very tiny content.\r\n\r\n## âš ï¸ About Python EOLs\r\n\r\n**If you are running:**\r\n\r\n- Python >=2.7,<3.5: Unsupported\r\n- Python 3.5: charset-normalizer < 2.1\r\n- Python 3.6: charset-normalizer < 3.1\r\n- Python 3.7: charset-normalizer < 4.0\r\n\r\nUpgrade your Python interpreter as soon as possible.\r\n\r\n## ðŸ‘¤ Contributing\r\n\r\nContributions, issues and feature requests are very much welcome.<br />\r\nFeel free to check [issues page](https://github.com/ousret/charset_normalizer/issues) if you want to contribute.\r\n\r\n## ðŸ“ License\r\n\r\nCopyright Â© [Ahmed TAHRI @Ousret](https://github.com/Ousret).<br />\r\nThis project is [MIT](https://github.com/Ousret/charset_normalizer/blob/master/LICENSE) licensed.\r\n\r\nCharacters frequencies used in this project Â© 2012 [Denny VrandeÄiÄ‡](http://simia.net/letters/)\r\n\r\n## ðŸ’¼ For Enterprise\r\n\r\nProfessional support for charset-normalizer is available as part of the [Tidelift\r\nSubscription][1]. Tidelift gives software development teams a single source for\r\npurchasing and maintaining their software, with professional grade assurances\r\nfrom the experts who know it best, while seamlessly integrating with existing\r\ntools.\r\n\r\n[1]: https://tidelift.com/subscription/pkg/pypi-charset-normalizer?utm_source=pypi-charset-normalizer&utm_medium=readme\r\n\r\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/7297/badge)](https://www.bestpractices.dev/projects/7297)\r\n\r\n# Changelog\r\nAll notable changes to charset-normalizer will be documented in this file. This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\r\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\r\n\r\n## [3.4.4](https://github.com/Ousret/charset_normalizer/compare/3.4.2...3.4.4) (2025-10-13)\r\n\r\n### Changed\r\n- Bound `setuptools` to a specific constraint `setuptools>=68,<=81`.\r\n- Raised upper bound of mypyc for the optional pre-built extension to v1.18.2\r\n\r\n### Removed\r\n- `setuptools-scm` as a build dependency.\r\n\r\n### Misc\r\n- Enforced hashes in `dev-requirements.txt` and created `ci-requirements.txt` for security purposes.\r\n- Additional pre-built wheels for riscv64, s390x, and armv7l architectures.\r\n- Restore ` multiple.intoto.jsonl` in GitHub releases in addition to individual attestation file per wheel.\r\n\r\n## [3.4.3](https://github.com/Ousret/charset_normalizer/compare/3.4.2...3.4.3) (2025-08-09)\r\n\r\n### Changed\r\n- mypy(c) is no longer a required dependency at build time if `CHARSET_NORMALIZER_USE_MYPYC` isn't set to `1`. (#595) (#583)\r\n- automatically lower confidence on small bytes samples that are not Unicode in `detect` output legacy function. (#391)\r\n\r\n### Added\r\n- Custom build backend to overcome inability to mark mypy as an optional dependency in the build phase.\r\n- Support for Python 3.14\r\n\r\n### Fixed\r\n- sdist archive contained useless directories.\r\n- automatically fallback on valid UTF-16 or UTF-32 even if the md says it's noisy. (#633)\r\n\r\n### Misc\r\n- SBOM are automatically published to the relevant GitHub release to comply with regulatory changes.\r\n  Each published wheel comes with its SBOM. We choose CycloneDX as the format.\r\n- Prebuilt optimized wheel are no longer distributed by default for CPython 3.7 due to a change in cibuildwheel.\r\n\r\n## [3.4.2](https://github.com/Ousret/charset_normalizer/compare/3.4.1...3.4.2) (2025-05-02)\r\n\r\n### Fixed\r\n- Addressed the DeprecationWarning in our CLI regarding `argparse.FileType` by backporting the target class into the package. (#591)\r\n- Improved the overall reliability of the detector with CJK Ideographs. (#605) (#587)\r\n\r\n### Changed\r\n- Optional mypyc compilation upgraded to version 1.15 for Python >= 3.8\r\n\r\n## [3.4.1](https://github.com/Ousret/charset_normalizer/compare/3.4.0...3.4.1) (2024-12-24)\r\n\r\n### Changed\r\n- Project metadata are now stored using `pyproject.toml` instead of `setup.cfg` using setuptools as the build backend.\r\n- Enforce annotation delayed loading for a simpler and consistent types in the project.\r\n- Optional mypyc compilation upgraded to version 1.14 for Python >= 3.8\r\n\r\n### Added\r\n- pre-commit configuration.\r\n- noxfile.\r\n\r\n### Removed\r\n- `build-requirements.txt` as per using `pyproject.toml` native build configuration.\r\n- `bin/integration.py` and `bin/serve.py` in favor of downstream integration test (see noxfile).\r\n- `setup.cfg` in favor of `pyproject.toml` metadata configuration.\r\n- Unused `utils.range_scan` function.\r\n\r\n### Fixed\r\n- Converting content to Unicode bytes may insert `utf_8` instead of preferred `utf-8`. (#572)\r\n- Deprecation warning \"'count' is passed as positional argument\" when converting to Unicode bytes on Python 3.13+\r\n\r\n## [3.4.0](https://github.com/Ousret/charset_normalizer/compare/3.3.2...3.4.0) (2024-10-08)\r\n\r\n### Added\r\n- Argument `--no-preemptive` in the CLI to prevent the detector to search for hints.\r\n- Support for Python 3.13 (#512)\r\n\r\n### Fixed\r\n- Relax the TypeError exception thrown when trying to compare a CharsetMatch with anything else than a CharsetMatch.\r\n- Improved the general reliability of the detector based on user feedbacks. (#520) (#509) (#498) (#407) (#537)\r\n- Declared charset in content (preemptive detection) not changed when converting to utf-8 bytes. (#381)\r\n\r\n## [3.3.2](https://github.com/Ousret/charset_normalizer/compare/3.3.1...3.3.2) (2023-10-31)\r\n\r\n### Fixed\r\n- Unintentional memory usage regression when using large payload that match several encoding (#376)\r\n- Regression on some detection case showcased in the documentation (#371)\r\n\r\n### Added\r\n- Noise (md) probe that identify malformed arabic representation due to the presence of letters in isolated form (credit to my wife)\r\n\r\n## [3.3.1](https://github.com/Ousret/charset_normalizer/compare/3.3.0...3.3.1) (2023-10-22)\r\n\r\n### Changed\r\n- Optional mypyc compilation upgraded to version 1.6.1 for Python >= 3.8\r\n- Improved the general detection reliability based on reports from the community\r\n\r\n## [3.3.0](https://github.com/Ousret/charset_normalizer/compare/3.2.0...3.3.0) (2023-09-30)\r\n\r\n### Added\r\n- Allow to execute the CLI (e.g. normalizer) through `python -m charset_normalizer.cli` or `python -m charset_normalizer`\r\n- Support for 9 forgotten encoding that are supported by Python but unlisted in `encoding.aliases` as they have no alias (#323)\r\n\r\n### Removed\r\n- (internal) Redundant utils.is_ascii function and unused function is_private_use_only\r\n- (internal) charset_normalizer.assets is moved inside charset_normalizer.constant\r\n\r\n### Changed\r\n- (internal) Unicode code blocks in constants are updated using the latest v15.0.0 definition to improve detection\r\n- Optional mypyc compilation upgraded to version 1.5.1 for Python >= 3.8\r\n\r\n### Fixed\r\n- Unable to properly sort CharsetMatch when both chaos/noise and coherence were close due to an unreachable condition in \\_\\_lt\\_\\_ (#350)\r\n\r\n## [3.2.0](https://github.com/Ousret/charset_normalizer/compare/3.1.0...3.2.0) (2023-06-07)\r\n\r\n### Changed\r\n- Typehint for function `from_path` no longer enforce `PathLike` as its first argument\r\n- Minor improvement over the global detection reliability\r\n\r\n### Added\r\n- Introduce function `is_binary` that relies on main capabilities, and optimized to detect binaries\r\n- Propagate `enable_fallback` argument throughout `from_bytes`, `from_path`, and `from_fp` that allow a deeper control over the detection (default True)\r\n- Explicit support for Python 3.12\r\n\r\n### Fixed\r\n- Edge case detection failure where a file would contain 'very-long' camel cased word (Issue #289)\r\n\r\n## [3.1.0](https://github.com/Ousret/charset_normalizer/compare/3.0.1...3.1.0) (2023-03-06)\r\n\r\n### Added\r\n- Argument `should_rename_legacy` for legacy function `detect` and disregard any new arguments without errors (PR #262)\r\n\r\n### Removed\r\n- Support for Python 3.6 (PR #260)\r\n\r\n### Changed\r\n- Optional speedup provided by mypy/c 1.0.1\r\n\r\n## [3.0.1](https://github.com/Ousret/charset_normalizer/compare/3.0.0...3.0.1) (2022-11-18)\r\n\r\n### Fixed\r\n- Multi-bytes cutter/chunk generator did not always cut correctly (PR #233)\r\n\r\n### Changed\r\n- Speedup provided by mypy/c 0.990 on Python >= 3.7\r\n\r\n## [3.0.0](https://github.com/Ousret/charset_normalizer/compare/2.1.1...3.0.0) (2022-10-20)\r\n\r\n### Added\r\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\r\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\r\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\r\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\r\n\r\n### Changed\r\n- Build with static metadata using 'build' frontend\r\n- Make the language detection stricter\r\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\r\n\r\n### Fixed\r\n- CLI with opt --normalize fail when using full path for files\r\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\r\n- Sphinx warnings when generating the documentation\r\n\r\n### Removed\r\n- Coherence detector no longer return 'Simple English' instead return 'English'\r\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\r\n- Breaking: Method `first()` and `best()` from CharsetMatch\r\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\r\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\r\n- Breaking: Top-level function `normalize`\r\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\r\n- Support for the backport `unicodedata2`\r\n\r\n## [3.0.0rc1](https://github.com/Ousret/charset_normalizer/compare/3.0.0b2...3.0.0rc1) (2022-10-18)\r\n\r\n### Added\r\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\r\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\r\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\r\n\r\n### Changed\r\n- Build with static metadata using 'build' frontend\r\n- Make the language detection stricter\r\n\r\n### Fixed\r\n- CLI with opt --normalize fail when using full path for files\r\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\r\n\r\n### Removed\r\n- Coherence detector no longer return 'Simple English' instead return 'English'\r\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\r\n\r\n## [3.0.0b2](https://github.com/Ousret/charset_normalizer/compare/3.0.0b1...3.0.0b2) (2022-08-21)\r\n\r\n### Added\r\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\r\n\r\n### Removed\r\n- Breaking: Method `first()` and `best()` from CharsetMatch\r\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\r\n\r\n### Fixed\r\n- Sphinx warnings when generating the documentation\r\n\r\n## [3.0.0b1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...3.0.0b1) (2022-08-15)\r\n\r\n### Changed\r\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\r\n\r\n### Removed\r\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\r\n- Breaking: Top-level function `normalize`\r\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\r\n- Support for the backport `unicodedata2`\r\n\r\n## [2.1.1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...2.1.1) (2022-08-19)\r\n\r\n### Deprecated\r\n- Function `normalize` scheduled for removal in 3.0\r\n\r\n### Changed\r\n- Removed useless call to decode in fn is_unprintable (#206)\r\n\r\n### Fixed\r\n- Third-party library (i18n xgettext) crashing not recognizing utf_8 (PEP 263) with underscore from [@aleksandernovikov](https://github.com/aleksandernovikov) (#204)\r\n\r\n## [2.1.0](https://github.com/Ousret/charset_normalizer/compare/2.0.12...2.1.0) (2022-06-19)\r\n\r\n### Added\r\n- Output the Unicode table version when running the CLI with `--version` (PR #194)\r\n\r\n### Changed\r\n- Re-use decoded buffer for single byte character sets from [@nijel](https://github.com/nijel) (PR #175)\r\n- Fixing some performance bottlenecks from [@deedy5](https://github.com/deedy5) (PR #183)\r\n\r\n### Fixed\r\n- Workaround potential bug in cpython with Zero Width No-Break Space located in Arabic Presentation Forms-B, Unicode 1.1 not acknowledged as space (PR #175)\r\n- CLI default threshold aligned with the API threshold from [@oleksandr-kuzmenko](https://github.com/oleksandr-kuzmenko) (PR #181)\r\n\r\n### Removed\r\n- Support for Python 3.5 (PR #192)\r\n\r\n### Deprecated\r\n- Use of backport unicodedata from `unicodedata2` as Python is quickly catching up, scheduled for removal in 3.0 (PR #194)\r\n\r\n## [2.0.12](https://github.com/Ousret/charset_normalizer/compare/2.0.11...2.0.12) (2022-02-12)\r\n\r\n### Fixed\r\n- ASCII miss-detection on rare cases (PR #170)\r\n\r\n## [2.0.11](https://github.com/Ousret/charset_normalizer/compare/2.0.10...2.0.11) (2022-01-30)\r\n\r\n### Added\r\n- Explicit support for Python 3.11 (PR #164)\r\n\r\n### Changed\r\n- The logging behavior have been completely reviewed, now using only TRACE and DEBUG levels (PR #163 #165)\r\n\r\n## [2.0.10](https://github.com/Ousret/charset_normalizer/compare/2.0.9...2.0.10) (2022-01-04)\r\n\r\n### Fixed\r\n- Fallback match entries might lead to UnicodeDecodeError for large bytes sequence (PR #154)\r\n\r\n### Changed\r\n- Skipping the language-detection (CD) on ASCII (PR #155)\r\n\r\n## [2.0.9](https://github.com/Ousret/charset_normalizer/compare/2.0.8...2.0.9) (2021-12-03)\r\n\r\n### Changed\r\n- Moderating the logging impact (since 2.0.8) for specific environments (PR #147)\r\n\r\n### Fixed\r\n- Wrong logging level applied when setting kwarg `explain` to True (PR #146)\r\n\r\n## [2.0.8](https://github.com/Ousret/charset_normalizer/compare/2.0.7...2.0.8) (2021-11-24)\r\n### Changed\r\n- Improvement over Vietnamese detection (PR #126)\r\n- MD improvement on trailing data and long foreign (non-pure latin) data (PR #124)\r\n- Efficiency improvements in cd/alphabet_languages from [@adbar](https://github.com/adbar) (PR #122)\r\n- call sum() without an intermediary list following PEP 289 recommendations from [@adbar](https://github.com/adbar) (PR #129)\r\n- Code style as refactored by Sourcery-AI (PR #131)\r\n- Minor adjustment on the MD around european words (PR #133)\r\n- Remove and replace SRTs from assets / tests (PR #139)\r\n- Initialize the library logger with a `NullHandler` by default from [@nmaynes](https://github.com/nmaynes) (PR #135)\r\n- Setting kwarg `explain` to True will add provisionally (bounded to function lifespan) a specific stream handler (PR #135)\r\n\r\n### Fixed\r\n- Fix large (misleading) sequence giving UnicodeDecodeError (PR #137)\r\n- Avoid using too insignificant chunk (PR #137)\r\n\r\n### Added\r\n- Add and expose function `set_logging_handler` to configure a specific StreamHandler from [@nmaynes](https://github.com/nmaynes) (PR #135)\r\n- Add `CHANGELOG.md` entries, format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/) (PR #141)\r\n\r\n## [2.0.7](https://github.com/Ousret/charset_normalizer/compare/2.0.6...2.0.7) (2021-10-11)\r\n### Added\r\n- Add support for Kazakh (Cyrillic) language detection (PR #109)\r\n\r\n### Changed\r\n- Further, improve inferring the language from a given single-byte code page (PR #112)\r\n- Vainly trying to leverage PEP263 when PEP3120 is not supported (PR #116)\r\n- Refactoring for potential performance improvements in loops from [@adbar](https://github.com/adbar) (PR #113)\r\n- Various detection improvement (MD+CD) (PR #117)\r\n\r\n### Removed\r\n- Remove redundant logging entry about detected language(s) (PR #115)\r\n\r\n### Fixed\r\n- Fix a minor inconsistency between Python 3.5 and other versions regarding language detection (PR #117 #102)\r\n\r\n## [2.0.6](https://github.com/Ousret/charset_normalizer/compare/2.0.5...2.0.6) (2021-09-18)\r\n### Fixed\r\n- Unforeseen regression with the loss of the backward-compatibility with some older minor of Python 3.5.x (PR #100)\r\n- Fix CLI crash when using --minimal output in certain cases (PR #103)\r\n\r\n### Changed\r\n- Minor improvement to the detection efficiency (less than 1%) (PR #106 #101)\r\n\r\n## [2.0.5](https://github.com/Ousret/charset_normalizer/compare/2.0.4...2.0.5) (2021-09-14)\r\n### Changed\r\n- The project now comply with: flake8, mypy, isort and black to ensure a better overall quality (PR #81)\r\n- The BC-support with v1.x was improved, the old staticmethods are restored (PR #82)\r\n- The Unicode detection is slightly improved (PR #93)\r\n- Add syntax sugar \\_\\_bool\\_\\_ for results CharsetMatches list-container (PR #91)\r\n\r\n### Removed\r\n- The project no longer raise warning on tiny content given for detection, will be simply logged as warning instead (PR #92)\r\n\r\n### Fixed\r\n- In some rare case, the chunks extractor could cut in the middle of a multi-byte character and could mislead the mess detection (PR #95)\r\n- Some rare 'space' characters could trip up the UnprintablePlugin/Mess detection (PR #96)\r\n- The MANIFEST.in was not exhaustive (PR #78)\r\n\r\n## [2.0.4](https://github.com/Ousret/charset_normalizer/compare/2.0.3...2.0.4) (2021-07-30)\r\n### Fixed\r\n- The CLI no longer raise an unexpected exception when no encoding has been found (PR #70)\r\n- Fix accessing the 'alphabets' property when the payload contains surrogate characters (PR #68)\r\n- The logger could mislead (explain=True) on detected languages and the impact of one MBCS match (PR #72)\r\n- Submatch factoring could be wrong in rare edge cases (PR #72)\r\n- Multiple files given to the CLI were ignored when publishing results to STDOUT. (After the first path) (PR #72)\r\n- Fix line endings from CRLF to LF for certain project files (PR #67)\r\n\r\n### Changed\r\n- Adjust the MD to lower the sensitivity, thus improving the global detection reliability (PR #69 #76)\r\n- Allow fallback on specified encoding if any (PR #71)\r\n\r\n## [2.0.3](https://github.com/Ousret/charset_normalizer/compare/2.0.2...2.0.3) (2021-07-16)\r\n### Changed\r\n- Part of the detection mechanism has been improved to be less sensitive, resulting in more accurate detection results. Especially ASCII. (PR #63)\r\n- According to the community wishes, the detection will fall back on ASCII or UTF-8 in a last-resort case. (PR #64)\r\n\r\n## [2.0.2](https://github.com/Ousret/charset_normalizer/compare/2.0.1...2.0.2) (2021-07-15)\r\n### Fixed\r\n- Empty/Too small JSON payload miss-detection fixed. Report from [@tseaver](https://github.com/tseaver) (PR #59)\r\n\r\n### Changed\r\n- Don't inject unicodedata2 into sys.modules from [@akx](https://github.com/akx) (PR #57)\r\n\r\n## [2.0.1](https://github.com/Ousret/charset_normalizer/compare/2.0.0...2.0.1) (2021-07-13)\r\n### Fixed\r\n- Make it work where there isn't a filesystem available, dropping assets frequencies.json. Report from [@sethmlarson](https://github.com/sethmlarson). (PR #55)\r\n- Using explain=False permanently disable the verbose output in the current runtime (PR #47)\r\n- One log entry (language target preemptive) was not show in logs when using explain=True (PR #47)\r\n- Fix undesired exception (ValueError) on getitem of instance CharsetMatches (PR #52)\r\n\r\n### Changed\r\n- Public function normalize default args values were not aligned with from_bytes (PR #53)\r\n\r\n### Added\r\n- You may now use charset aliases in cp_isolation and cp_exclusion arguments (PR #47)\r\n\r\n## [2.0.0](https://github.com/Ousret/charset_normalizer/compare/1.4.1...2.0.0) (2021-07-02)\r\n### Changed\r\n- 4x to 5 times faster than the previous 1.4.0 release. At least 2x faster than Chardet.\r\n- Accent has been made on UTF-8 detection, should perform rather instantaneous.\r\n- The backward compatibility with Chardet has been greatly improved. The legacy detect function returns an identical charset name whenever possible.\r\n- The detection mechanism has been slightly improved, now Turkish content is detected correctly (most of the time)\r\n- The program has been rewritten to ease the readability and maintainability. (+Using static typing)+\r\n- utf_7 detection has been reinstated.\r\n\r\n### Removed\r\n- This package no longer require anything when used with Python 3.5 (Dropped cached_property)\r\n- Removed support for these languages: Catalan, Esperanto, Kazakh, Baque, VolapÃ¼k, Azeri, Galician, Nynorsk, Macedonian, and Serbocroatian.\r\n- The exception hook on UnicodeDecodeError has been removed.\r\n\r\n### Deprecated\r\n- Methods coherence_non_latin, w_counter, chaos_secondary_pass of the class CharsetMatch are now deprecated and scheduled for removal in v3.0\r\n\r\n### Fixed\r\n- The CLI output used the relative path of the file(s). Should be absolute.\r\n\r\n## [1.4.1](https://github.com/Ousret/charset_normalizer/compare/1.4.0...1.4.1) (2021-05-28)\r\n### Fixed\r\n- Logger configuration/usage no longer conflict with others (PR #44)\r\n\r\n## [1.4.0](https://github.com/Ousret/charset_normalizer/compare/1.3.9...1.4.0) (2021-05-21)\r\n### Removed\r\n- Using standard logging instead of using the package loguru.\r\n- Dropping nose test framework in favor of the maintained pytest.\r\n- Choose to not use dragonmapper package to help with gibberish Chinese/CJK text.\r\n- Require cached_property only for Python 3.5 due to constraint. Dropping for every other interpreter version.\r\n- Stop support for UTF-7 that does not contain a SIG.\r\n- Dropping PrettyTable, replaced with pure JSON output in CLI.\r\n\r\n### Fixed\r\n- BOM marker in a CharsetNormalizerMatch instance could be False in rare cases even if obviously present. Due to the sub-match factoring process.\r\n- Not searching properly for the BOM when trying utf32/16 parent codec.\r\n\r\n### Changed\r\n- Improving the package final size by compressing frequencies.json.\r\n- Huge improvement over the larges payload.\r\n\r\n### Added\r\n- CLI now produces JSON consumable output.\r\n- Return ASCII if given sequences fit. Given reasonable confidence.\r\n\r\n## [1.3.9](https://github.com/Ousret/charset_normalizer/compare/1.3.8...1.3.9) (2021-05-13)\r\n\r\n### Fixed\r\n- In some very rare cases, you may end up getting encode/decode errors due to a bad bytes payload (PR #40)\r\n\r\n## [1.3.8](https://github.com/Ousret/charset_normalizer/compare/1.3.7...1.3.8) (2021-05-12)\r\n\r\n### Fixed\r\n- Empty given payload for detection may cause an exception if trying to access the `alphabets` property. (PR #39)\r\n\r\n## [1.3.7](https://github.com/Ousret/charset_normalizer/compare/1.3.6...1.3.7) (2021-05-12)\r\n\r\n### Fixed\r\n- The legacy detect function should return UTF-8-SIG if sig is present in the payload. (PR #38)\r\n\r\n## [1.3.6](https://github.com/Ousret/charset_normalizer/compare/1.3.5...1.3.6) (2021-02-09)\r\n\r\n### Changed\r\n- Amend the previous release to allow prettytable 2.0 (PR #35)\r\n\r\n## [1.3.5](https://github.com/Ousret/charset_normalizer/compare/1.3.4...1.3.5) (2021-02-08)\r\n\r\n### Fixed\r\n- Fix error while using the package with a python pre-release interpreter (PR #33)\r\n\r\n### Changed\r\n- Dependencies refactoring, constraints revised.\r\n\r\n### Added\r\n- Add python 3.9 and 3.10 to the supported interpreters\r\n\r\nMIT License\r\n\r\nCopyright (c) 2025 TAHRI Ahmed R.\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all\r\ncopies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\nSOFTWARE.\r\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "encoding",
          "charset",
          "charset-detector",
          "detector",
          "normalization",
          "unicode",
          "chardet",
          "detect"
        ],
        "author_email": "\"Ahmed R. TAHRI\" <tahri.ahmed@proton.me>",
        "maintainer_email": "\"Ahmed R. TAHRI\" <tahri.ahmed@proton.me>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Linguistic",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changelog, https://github.com/jawah/charset_normalizer/blob/master/CHANGELOG.md",
          "Documentation, https://charset-normalizer.readthedocs.io/",
          "Code, https://github.com/jawah/charset_normalizer",
          "Issue tracker, https://github.com/jawah/charset_normalizer/issues"
        ],
        "provides_extra": [
          "unicode-backport"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=771a87f49d9defaf64091e6e6fe9c18d4833f140bd19464795bc32d966ca37ea",
          "hashes": {
            "sha256": "771a87f49d9defaf64091e6e6fe9c18d4833f140bd19464795bc32d966ca37ea"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "idna",
        "version": "3.11",
        "summary": "Internationalized Domain Names in Applications (IDNA)",
        "description": "Internationalized Domain Names in Applications (IDNA)\n=====================================================\n\nSupport for `Internationalized Domain Names in\nApplications (IDNA) <https://tools.ietf.org/html/rfc5891>`_\nand `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_.\n\nThe latest versions of these standards supplied here provide\nmore comprehensive language coverage and reduce the potential of\nallowing domains with known security vulnerabilities. This library\nis a suitable replacement for the â€œencodings.idnaâ€\nmodule that comes with the Python standard library, but which\nonly supports an older superseded IDNA specification from 2003.\n\nBasic functions are simply executed:\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\n\nInstallation\n------------\n\nThis package is available for installation from PyPI via the\ntypical mechanisms, such as:\n\n.. code-block:: bash\n\n    $ python3 -m pip install idna\n\n\nUsage\n-----\n\nFor typical usage, the ``encode`` and ``decode`` functions will take a\ndomain name argument and perform a conversion to ASCII compatible encoding\n(known as A-labels), or to Unicode strings (known as U-labels)\nrespectively.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\nConversions can be applied at a per-label basis using the ``ulabel`` or\n``alabel`` functions if necessary:\n\n.. code-block:: pycon\n\n    >>> idna.alabel('æµ‹è¯•')\n    b'xn--0zwm56d'\n\n\nCompatibility Mapping (UTS #46)\n+++++++++++++++++++++++++++++++\n\nThis library provides support for `Unicode IDNA Compatibility\nProcessing <https://unicode.org/reports/tr46/>`_ which normalizes input from\ndifferent potential ways a user may input a domain prior to performing the IDNA\nconversion operations. This functionality, known as a \n`mapping <https://tools.ietf.org/html/rfc5895>`_, is considered by the\nspecification to be a local user-interface issue distinct from IDNA\nconversion functionality.\n\nFor example, â€œKÃ¶nigsgÃ¤ÃŸchenâ€ is not a permissible label as *LATIN\nCAPITAL LETTER K* is not allowed (nor are capital letters in general).\nUTS 46 will convert this into lower case prior to applying the IDNA\nconversion.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen')\n    ...\n    idna.core.InvalidCodepoint: Codepoint U+004B at position 1 of 'KÃ¶nigsgÃ¤ÃŸchen' not allowed\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen', uts46=True)\n    b'xn--knigsgchen-b4a3dun'\n    >>> print(idna.decode('xn--knigsgchen-b4a3dun'))\n    kÃ¶nigsgÃ¤ÃŸchen\n\n\nExceptions\n----------\n\nAll errors raised during the conversion following the specification\nshould raise an exception derived from the ``idna.IDNAError`` base\nclass.\n\nMore specific exceptions that may be generated as ``idna.IDNABidiError``\nwhen the error reflects an illegal combination of left-to-right and\nright-to-left characters in a label; ``idna.InvalidCodepoint`` when\na specific codepoint is an illegal character in an IDN label (i.e.\nINVALID); and ``idna.InvalidCodepointContext`` when the codepoint is\nillegal based on its position in the string (i.e. it is CONTEXTO or CONTEXTJ\nbut the contextual requirements are not satisfied.)\n\nBuilding and Diagnostics\n------------------------\n\nThe IDNA and UTS 46 functionality relies upon pre-calculated lookup\ntables for performance. These tables are derived from computing against\neligibility criteria in the respective standards using the command-line\nscript ``tools/idna-data``.\n\nThis tool will fetch relevant codepoint data from the Unicode repository\nand perform the required calculations to identify eligibility. There are\nthree main modes:\n\n* ``idna-data make-libdata``. Generates ``idnadata.py`` and\n  ``uts46data.py``, the pre-calculated lookup tables used for IDNA and\n  UTS 46 conversions. Implementers who wish to track this library against\n  a different Unicode version may use this tool to manually generate a\n  different version of the ``idnadata.py`` and ``uts46data.py`` files.\n\n* ``idna-data make-table``. Generate a table of the IDNA disposition\n  (e.g. PVALID, CONTEXTJ, CONTEXTO) in the format found in Appendix\n  B.1 of RFC 5892 and the pre-computed tables published by `IANA\n  <https://www.iana.org/>`_.\n\n* ``idna-data U+0061``. Prints debugging output on the various\n  properties associated with an individual Unicode codepoint (in this\n  case, U+0061), that are used to assess the IDNA and UTS 46 status of a\n  codepoint. This is helpful in debugging or analysis.\n\nThe tool accepts a number of arguments, described using ``idna-data\n-h``. Most notably, the ``--version`` argument allows the specification\nof the version of Unicode to be used in computing the table data. For\nexample, ``idna-data --version 9.0.0 make-libdata`` will generate\nlibrary data against Unicode 9.0.0.\n\n\nAdditional Notes\n----------------\n\n* **Packages**. The latest tagged release version is published in the\n  `Python Package Index <https://pypi.org/project/idna/>`_.\n\n* **Version support**. This library supports Python 3.8 and higher.\n  As this library serves as a low-level toolkit for a variety of\n  applications, many of which strive for broad compatibility with older\n  Python versions, there is no rush to remove older interpreter support.\n  Support for older versions are likely to be removed from new releases\n  as automated tests can no longer easily be run, i.e. once the Python\n  version is officially end-of-life.\n\n* **Testing**. The library has a test suite based on each rule of the\n  IDNA specification, as well as tests that are provided as part of the\n  Unicode Technical Standard 46, `Unicode IDNA Compatibility Processing\n  <https://unicode.org/reports/tr46/>`_.\n\n* **Emoji**. It is an occasional request to support emoji domains in\n  this library. Encoding of symbols like emoji is expressly prohibited by\n  the technical standard IDNA 2008 and emoji domains are broadly phased\n  out across the domain industry due to associated security risks. For\n  now, applications that need to support these non-compliant labels\n  may wish to consider trying the encode/decode operation in this library\n  first, and then falling back to using `encodings.idna`. See `the Github\n  project <https://github.com/kjd/idna/issues/18>`_ for more discussion.\n\n* **Transitional processing**. Unicode 16.0.0 removed transitional\n  processing so the `transitional` argument for the encode() method\n  no longer has any effect and will be removed at a later date.\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Kim Davies <kim+pypi@gumleaf.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: Name Service (DNS)",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "ruff >= 0.6.2 ; extra == \"all\"",
          "mypy >= 1.11.2 ; extra == \"all\"",
          "pytest >= 8.3.2 ; extra == \"all\"",
          "flake8 >= 7.1.1 ; extra == \"all\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/kjd/idna/blob/master/HISTORY.rst",
          "Issue tracker, https://github.com/kjd/idna/issues",
          "Source, https://github.com/kjd/idna"
        ],
        "provides_extra": [
          "all"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548",
          "hashes": {
            "sha256": "f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "typing_extensions",
        "version": "4.15.0",
        "summary": "Backported and Experimental Type Hints for Python 3.9+",
        "description": "# Typing Extensions\n\n[![Chat at https://gitter.im/python/typing](https://badges.gitter.im/python/typing.svg)](https://gitter.im/python/typing)\n\n[Documentation](https://typing-extensions.readthedocs.io/en/latest/#) â€“\n[PyPI](https://pypi.org/project/typing-extensions/)\n\n## Overview\n\nThe `typing_extensions` module serves two related purposes:\n\n- Enable use of new type system features on older Python versions. For example,\n  `typing.TypeGuard` is new in Python 3.10, but `typing_extensions` allows\n  users on previous Python versions to use it too.\n- Enable experimentation with new type system PEPs before they are accepted and\n  added to the `typing` module.\n\n`typing_extensions` is treated specially by static type checkers such as\nmypy and pyright. Objects defined in `typing_extensions` are treated the same\nway as equivalent forms in `typing`.\n\n`typing_extensions` uses\n[Semantic Versioning](https://semver.org/). The\nmajor version will be incremented only for backwards-incompatible changes.\nTherefore, it's safe to depend\non `typing_extensions` like this: `typing_extensions ~=x.y`,\nwhere `x.y` is the first version that includes all features you need.\n[This](https://packaging.python.org/en/latest/specifications/version-specifiers/#compatible-release)\nis equivalent to `typing_extensions >=x.y, <(x+1)`. Do not depend on `~= x.y.z`\nunless you really know what you're doing; that defeats the purpose of\nsemantic versioning.\n\n## Included items\n\nSee [the documentation](https://typing-extensions.readthedocs.io/en/latest/#) for a\ncomplete listing of module contents.\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/python/typing_extensions/blob/main/CONTRIBUTING.md)\nfor how to contribute to `typing_extensions`.\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "annotations",
          "backport",
          "checker",
          "checking",
          "function",
          "hinting",
          "hints",
          "type",
          "typechecking",
          "typehinting",
          "typehints",
          "typing"
        ],
        "author_email": "\"Guido van Rossum, Jukka Lehtosalo, Åukasz Langa, Michael Lee\" <levkivskyi@gmail.com>",
        "license_expression": "PSF-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Bug Tracker, https://github.com/python/typing_extensions/issues",
          "Changes, https://github.com/python/typing_extensions/blob/main/CHANGELOG.md",
          "Documentation, https://typing-extensions.readthedocs.io/",
          "Home, https://github.com/python/typing_extensions",
          "Q & A, https://github.com/python/typing/discussions",
          "Repository, https://github.com/python/typing_extensions"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/39/08/aaaad47bc4e9dc8c725e68f9d04865dbcb2052843ff09c97b08904852d84/urllib3-2.6.3-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=bf272323e553dfb2e87d9bfd225ca7b0f467b919d7bbd355436d3fd37cb0acd4",
          "hashes": {
            "sha256": "bf272323e553dfb2e87d9bfd225ca7b0f467b919d7bbd355436d3fd37cb0acd4"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "urllib3",
        "version": "2.6.3",
        "summary": "HTTP library with thread-safe connection pooling, file post, and more.",
        "description": "<h1 align=\"center\">\n\n![urllib3](https://github.com/urllib3/urllib3/raw/main/docs/_static/banner_github.svg)\n\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"Python Versions\" src=\"https://img.shields.io/pypi/pyversions/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://discord.gg/urllib3\"><img alt=\"Join our Discord\" src=\"https://img.shields.io/discord/756342717725933608?color=%237289da&label=discord\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions?query=workflow%3ACI\"><img alt=\"Coverage Status\" src=\"https://img.shields.io/badge/coverage-100%25-success\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml?query=branch%3Amain\"><img alt=\"Build Status on GitHub\" src=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml/badge.svg?branch:main&workflow:CI\" /></a>\n  <a href=\"https://urllib3.readthedocs.io\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/urllib3/badge/?version=latest\" /></a><br>\n  <a href=\"https://deps.dev/pypi/urllib3\"><img alt=\"OpenSSF Scorecard\" src=\"https://api.securityscorecards.dev/projects/github.com/urllib3/urllib3/badge\" /></a>\n  <a href=\"https://slsa.dev\"><img alt=\"SLSA 3\" src=\"https://slsa.dev/images/gh-badge-level3.svg\" /></a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/6227\"><img alt=\"CII Best Practices\" src=\"https://bestpractices.coreinfrastructure.org/projects/6227/badge\" /></a>\n</p>\n\nurllib3 is a powerful, *user-friendly* HTTP client for Python.\nurllib3 brings many critical features that are missing from the Python\nstandard libraries:\n\n- Thread safety.\n- Connection pooling.\n- Client-side SSL/TLS verification.\n- File uploads with multipart encoding.\n- Helpers for retrying requests and dealing with HTTP redirects.\n- Support for gzip, deflate, brotli, and zstd encoding.\n- Proxy support for HTTP and SOCKS.\n- 100% test coverage.\n\n... and many more features, but most importantly: Our maintainers have a 15+\nyear track record of maintaining urllib3 with the highest code standards and\nattention to security and safety.\n\n[Much of the Python ecosystem already uses urllib3](https://urllib3.readthedocs.io/en/stable/#who-uses)\nand you should too.\n\n\n## Installing\n\nurllib3 can be installed with [pip](https://pip.pypa.io):\n\n```bash\n$ python -m pip install urllib3\n```\n\nAlternatively, you can grab the latest source code from [GitHub](https://github.com/urllib3/urllib3):\n\n```bash\n$ git clone https://github.com/urllib3/urllib3.git\n$ cd urllib3\n$ pip install .\n```\n\n## Getting Started\n\nurllib3 is easy to use:\n\n```python3\n>>> import urllib3\n>>> resp = urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\")\n>>> resp.status\n200\n>>> resp.data\nb\"User-agent: *\\nDisallow: /deny\\n\"\n```\n\nurllib3 has usage and reference documentation at [urllib3.readthedocs.io](https://urllib3.readthedocs.io).\n\n\n## Community\n\nurllib3 has a [community Discord channel](https://discord.gg/urllib3) for asking questions and\ncollaborating with other contributors. Drop by and say hello ðŸ‘‹\n\n\n## Contributing\n\nurllib3 happily accepts contributions. Please see our\n[contributing documentation](https://urllib3.readthedocs.io/en/latest/contributing.html)\nfor some tips on getting started.\n\n\n## Security Disclosures\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure with maintainers.\n\n\n## Maintainers\n\nMeet our maintainers since 2008:\n\n- Current Lead: [@illia-v](https://github.com/illia-v) (Illia Volochii)\n- [@sethmlarson](https://github.com/sethmlarson) (Seth M. Larson)\n- [@pquentin](https://github.com/pquentin) (Quentin Pradet)\n- [@theacodes](https://github.com/theacodes) (Thea Flowers)\n- [@haikuginger](https://github.com/haikuginger) (Jess Shapiro)\n- [@lukasa](https://github.com/lukasa) (Cory Benfield)\n- [@sigmavirus24](https://github.com/sigmavirus24) (Ian Stapleton Cordasco)\n- [@shazow](https://github.com/shazow) (Andrey Petrov)\n\nðŸ‘‹\n\n\n## Sponsorship\n\nIf your company benefits from this library, please consider [sponsoring its\ndevelopment](https://urllib3.readthedocs.io/en/latest/sponsors.html).\n\n\n## For Enterprise\n\nProfessional support for urllib3 is available as part of the [Tidelift\nSubscription][1]. Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-urllib3?utm_source=pypi-urllib3&utm_medium=referral&utm_campaign=readme\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "filepost",
          "http",
          "httplib",
          "https",
          "pooling",
          "ssl",
          "threadsafe",
          "urllib"
        ],
        "author_email": "Andrey Petrov <andrey.petrov@shazow.net>",
        "maintainer_email": "Seth Michael Larson <sethmichaellarson@gmail.com>, Quentin Pradet <quentin@pradet.me>, Illia Volochii <illia.volochii@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Free Threading :: 2 - Beta",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "brotli>=1.2.0; (platform_python_implementation == 'CPython') and extra == 'brotli'",
          "brotlicffi>=1.2.0.0; (platform_python_implementation != 'CPython') and extra == 'brotli'",
          "h2<5,>=4; extra == 'h2'",
          "pysocks!=1.5.7,<2.0,>=1.5.6; extra == 'socks'",
          "backports-zstd>=1.0.0; (python_version < '3.14') and extra == 'zstd'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://github.com/urllib3/urllib3/blob/main/CHANGES.rst",
          "Documentation, https://urllib3.readthedocs.io",
          "Code, https://github.com/urllib3/urllib3",
          "Issue tracker, https://github.com/urllib3/urllib3/issues"
        ],
        "provides_extra": [
          "brotli",
          "h2",
          "socks",
          "zstd"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/1b/6c/c65773d6cab416a64d191d6ee8a8b1c68a09970ea6909d16965d26bfed1e/websockets-15.0.1-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=e09473f095a819042ecb2ab9465aee615bd9c2028e4ef7d933600a8401c79561",
          "hashes": {
            "sha256": "e09473f095a819042ecb2ab9465aee615bd9c2028e4ef7d933600a8401c79561"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.2",
        "name": "websockets",
        "version": "15.0.1",
        "dynamic": [
          "description",
          "description-content-type"
        ],
        "summary": "An implementation of the WebSocket Protocol (RFC 6455 & 7692)",
        "description": ".. image:: logo/horizontal.svg\r\n   :width: 480px\r\n   :alt: websockets\r\n\r\n|licence| |version| |pyversions| |tests| |docs| |openssf|\r\n\r\n.. |licence| image:: https://img.shields.io/pypi/l/websockets.svg\r\n    :target: https://pypi.python.org/pypi/websockets\r\n\r\n.. |version| image:: https://img.shields.io/pypi/v/websockets.svg\r\n    :target: https://pypi.python.org/pypi/websockets\r\n\r\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/websockets.svg\r\n    :target: https://pypi.python.org/pypi/websockets\r\n\r\n.. |tests| image:: https://img.shields.io/github/checks-status/python-websockets/websockets/main?label=tests\r\n   :target: https://github.com/python-websockets/websockets/actions/workflows/tests.yml\r\n\r\n.. |docs| image:: https://img.shields.io/readthedocs/websockets.svg\r\n   :target: https://websockets.readthedocs.io/\r\n\r\n.. |openssf| image:: https://bestpractices.coreinfrastructure.org/projects/6475/badge\r\n   :target: https://bestpractices.coreinfrastructure.org/projects/6475\r\n\r\nWhat is ``websockets``?\r\n-----------------------\r\n\r\nwebsockets is a library for building WebSocket_ servers and clients in Python\r\nwith a focus on correctness, simplicity, robustness, and performance.\r\n\r\n.. _WebSocket: https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API\r\n\r\nBuilt on top of ``asyncio``, Python's standard asynchronous I/O framework, the\r\ndefault implementation provides an elegant coroutine-based API.\r\n\r\nAn implementation on top of ``threading`` and a Sans-I/O implementation are also\r\navailable.\r\n\r\n`Documentation is available on Read the Docs. <https://websockets.readthedocs.io/>`_\r\n\r\n.. copy-pasted because GitHub doesn't support the include directive\r\n\r\nHere's an echo server with the ``asyncio`` API:\r\n\r\n.. code:: python\r\n\r\n    #!/usr/bin/env python\r\n\r\n    import asyncio\r\n    from websockets.asyncio.server import serve\r\n\r\n    async def echo(websocket):\r\n        async for message in websocket:\r\n            await websocket.send(message)\r\n\r\n    async def main():\r\n        async with serve(echo, \"localhost\", 8765) as server:\r\n            await server.serve_forever()\r\n\r\n    asyncio.run(main())\r\n\r\nHere's how a client sends and receives messages with the ``threading`` API:\r\n\r\n.. code:: python\r\n\r\n    #!/usr/bin/env python\r\n\r\n    from websockets.sync.client import connect\r\n\r\n    def hello():\r\n        with connect(\"ws://localhost:8765\") as websocket:\r\n            websocket.send(\"Hello world!\")\r\n            message = websocket.recv()\r\n            print(f\"Received: {message}\")\r\n\r\n    hello()\r\n\r\n\r\nDoes that look good?\r\n\r\n`Get started with the tutorial! <https://websockets.readthedocs.io/en/stable/intro/index.html>`_\r\n\r\nWhy should I use ``websockets``?\r\n--------------------------------\r\n\r\nThe development of ``websockets`` is shaped by four principles:\r\n\r\n1. **Correctness**: ``websockets`` is heavily tested for compliance with\r\n   :rfc:`6455`. Continuous integration fails under 100% branch coverage.\r\n\r\n2. **Simplicity**: all you need to understand is ``msg = await ws.recv()`` and\r\n   ``await ws.send(msg)``. ``websockets`` takes care of managing connections\r\n   so you can focus on your application.\r\n\r\n3. **Robustness**: ``websockets`` is built for production. For example, it was\r\n   the only library to `handle backpressure correctly`_ before the issue\r\n   became widely known in the Python community.\r\n\r\n4. **Performance**: memory usage is optimized and configurable. A C extension\r\n   accelerates expensive operations. It's pre-compiled for Linux, macOS and\r\n   Windows and packaged in the wheel format for each system and Python version.\r\n\r\nDocumentation is a first class concern in the project. Head over to `Read the\r\nDocs`_ and see for yourself.\r\n\r\n.. _Read the Docs: https://websockets.readthedocs.io/\r\n.. _handle backpressure correctly: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#websocket-servers\r\n\r\nWhy shouldn't I use ``websockets``?\r\n-----------------------------------\r\n\r\n* If you prefer callbacks over coroutines: ``websockets`` was created to\r\n  provide the best coroutine-based API to manage WebSocket connections in\r\n  Python. Pick another library for a callback-based API.\r\n\r\n* If you're looking for a mixed HTTP / WebSocket library: ``websockets`` aims\r\n  at being an excellent implementation of :rfc:`6455`: The WebSocket Protocol\r\n  and :rfc:`7692`: Compression Extensions for WebSocket. Its support for HTTP\r\n  is minimal â€” just enough for an HTTP health check.\r\n\r\n  If you want to do both in the same server, look at HTTP + WebSocket servers\r\n  that build on top of ``websockets`` to support WebSocket connections, like\r\n  uvicorn_ or Sanic_.\r\n\r\n.. _uvicorn: https://www.uvicorn.org/\r\n.. _Sanic: https://sanic.dev/en/\r\n\r\nWhat else?\r\n----------\r\n\r\nBug reports, patches and suggestions are welcome!\r\n\r\nTo report a security vulnerability, please use the `Tidelift security\r\ncontact`_. Tidelift will coordinate the fix and disclosure.\r\n\r\n.. _Tidelift security contact: https://tidelift.com/security\r\n\r\nFor anything else, please open an issue_ or send a `pull request`_.\r\n\r\n.. _issue: https://github.com/python-websockets/websockets/issues/new\r\n.. _pull request: https://github.com/python-websockets/websockets/compare/\r\n\r\nParticipants must uphold the `Contributor Covenant code of conduct`_.\r\n\r\n.. _Contributor Covenant code of conduct: https://github.com/python-websockets/websockets/blob/main/CODE_OF_CONDUCT.md\r\n\r\n``websockets`` is released under the `BSD license`_.\r\n\r\n.. _BSD license: https://github.com/python-websockets/websockets/blob/main/LICENSE\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "WebSocket"
        ],
        "author_email": "Aymeric Augustin <aymeric.augustin@m4x.org>",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/python-websockets/websockets",
          "Changelog, https://websockets.readthedocs.io/en/stable/project/changelog.html",
          "Documentation, https://websockets.readthedocs.io/",
          "Funding, https://tidelift.com/subscription/pkg/pypi-websockets?utm_source=pypi-websockets&utm_medium=referral&utm_campaign=readme",
          "Tracker, https://github.com/python-websockets/websockets/issues"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/ee/ea/c67e1dee1ba208ed22c06d1d547ae5e293374bfc43e0eb0ef5e262b68561/werkzeug-3.1.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=a71124d1ef06008baafa3d266c02f56e1836a5984afd6dd6c9230669d60d9fb5",
          "hashes": {
            "sha256": "a71124d1ef06008baafa3d266c02f56e1836a5984afd6dd6c9230669d60d9fb5"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "Werkzeug",
        "version": "3.1.1",
        "summary": "The comprehensive WSGI web application library.",
        "description": "# Werkzeug\n\n*werkzeug* German noun: \"tool\". Etymology: *werk* (\"work\"), *zeug* (\"stuff\")\n\nWerkzeug is a comprehensive [WSGI][] web application library. It began as\na simple collection of various utilities for WSGI applications and has\nbecome one of the most advanced WSGI utility libraries.\n\nIt includes:\n\n-   An interactive debugger that allows inspecting stack traces and\n    source code in the browser with an interactive interpreter for any\n    frame in the stack.\n-   A full-featured request object with objects to interact with\n    headers, query args, form data, files, and cookies.\n-   A response object that can wrap other WSGI applications and handle\n    streaming data.\n-   A routing system for matching URLs to endpoints and generating URLs\n    for endpoints, with an extensible system for capturing variables\n    from URLs.\n-   HTTP utilities to handle entity tags, cache control, dates, user\n    agents, cookies, files, and more.\n-   A threaded WSGI server for use while developing applications\n    locally.\n-   A test client for simulating HTTP requests during testing without\n    requiring running a server.\n\nWerkzeug doesn't enforce any dependencies. It is up to the developer to\nchoose a template engine, database adapter, and even how to handle\nrequests. It can be used to build all sorts of end user applications\nsuch as blogs, wikis, or bulletin boards.\n\n[Flask][] wraps Werkzeug, using it to handle the details of WSGI while\nproviding more structure and patterns for defining powerful\napplications.\n\n[WSGI]: https://wsgi.readthedocs.io/en/latest/\n[Flask]: https://www.palletsprojects.com/p/flask/\n\n\n## A Simple Example\n\n```python\n# save this as app.py\nfrom werkzeug.wrappers import Request, Response\n\n@Request.application\ndef application(request: Request) -> Response:\n    return Response(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    from werkzeug.serving import run_simple\n    run_simple(\"127.0.0.1\", 5000, application)\n```\n\n```\n$ python -m app\n  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Werkzeug and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n[please donate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Internet :: WWW/HTTP :: WSGI",
          "Topic :: Internet :: WWW/HTTP :: WSGI :: Application",
          "Topic :: Internet :: WWW/HTTP :: WSGI :: Middleware",
          "Topic :: Software Development :: Libraries :: Application Frameworks",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "MarkupSafe>=2.1.1",
          "watchdog>=2.3 ; extra == \"watchdog\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changes, https://werkzeug.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://werkzeug.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Issue Tracker, https://github.com/pallets/werkzeug/issues/",
          "Source Code, https://github.com/pallets/werkzeug/"
        ],
        "provides_extra": [
          "watchdog"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/9a/ee/450914ae11b419eadd067c6183ae08381cfdfcb9798b90b2b713bbebddda/yarl-1.22.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=47743b82b76d89a1d20b83e60d5c20314cbd5ba2befc9cda8f28300c4a08ed4d",
          "hashes": {
            "sha256": "47743b82b76d89a1d20b83e60d5c20314cbd5ba2befc9cda8f28300c4a08ed4d"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "yarl",
        "version": "1.22.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Yet another URL library",
        "description": "yarl\r\n====\r\n\r\nThe module provides handy URL class for URL parsing and changing.\r\n\r\n.. image:: https://github.com/aio-libs/yarl/workflows/CI/badge.svg\r\n   :target: https://github.com/aio-libs/yarl/actions?query=workflow%3ACI\r\n   :align: right\r\n\r\n.. image:: https://codecov.io/gh/aio-libs/yarl/graph/badge.svg?flag=pytest\r\n   :target: https://app.codecov.io/gh/aio-libs/yarl?flags[]=pytest\r\n   :alt: Codecov coverage for the pytest-driven measurements\r\n\r\n.. image:: https://img.shields.io/endpoint?url=https://codspeed.io/badge.json\r\n   :target: https://codspeed.io/aio-libs/yarl\r\n\r\n.. image:: https://badge.fury.io/py/yarl.svg\r\n   :target: https://badge.fury.io/py/yarl\r\n\r\n.. image:: https://readthedocs.org/projects/yarl/badge/?version=latest\r\n   :target: https://yarl.aio-libs.org\r\n\r\n.. image:: https://img.shields.io/pypi/pyversions/yarl.svg\r\n   :target: https://pypi.python.org/pypi/yarl\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs:matrix.org\r\n   :alt: Matrix Room â€” #aio-libs:matrix.org\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs-space:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs-space%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs-space:matrix.org\r\n   :alt: Matrix Space â€” #aio-libs-space:matrix.org\r\n\r\n\r\nIntroduction\r\n------------\r\n\r\nUrl is constructed from ``str``:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> from yarl import URL\r\n   >>> url = URL('https://www.python.org/~guido?arg=1#frag')\r\n   >>> url\r\n   URL('https://www.python.org/~guido?arg=1#frag')\r\n\r\nAll url parts: *scheme*, *user*, *password*, *host*, *port*, *path*,\r\n*query* and *fragment* are accessible by properties:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> url.scheme\r\n   'https'\r\n   >>> url.host\r\n   'www.python.org'\r\n   >>> url.path\r\n   '/~guido'\r\n   >>> url.query_string\r\n   'arg=1'\r\n   >>> url.query\r\n   <MultiDictProxy('arg': '1')>\r\n   >>> url.fragment\r\n   'frag'\r\n\r\nAll url manipulations produce a new url object:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> url = URL('https://www.python.org')\r\n   >>> url / 'foo' / 'bar'\r\n   URL('https://www.python.org/foo/bar')\r\n   >>> url / 'foo' % {'bar': 'baz'}\r\n   URL('https://www.python.org/foo?bar=baz')\r\n\r\nStrings passed to constructor and modification methods are\r\nautomatically encoded giving canonical representation as result:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> url = URL('https://www.python.org/ÑˆÐ»ÑÑ…')\r\n   >>> url\r\n   URL('https://www.python.org/%D1%88%D0%BB%D1%8F%D1%85')\r\n\r\nRegular properties are *percent-decoded*, use ``raw_`` versions for\r\ngetting *encoded* strings:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> url.path\r\n   '/ÑˆÐ»ÑÑ…'\r\n\r\n   >>> url.raw_path\r\n   '/%D1%88%D0%BB%D1%8F%D1%85'\r\n\r\nHuman readable representation of URL is available as ``.human_repr()``:\r\n\r\n.. code-block:: pycon\r\n\r\n   >>> url.human_repr()\r\n   'https://www.python.org/ÑˆÐ»ÑÑ…'\r\n\r\nFor full documentation please read https://yarl.aio-libs.org.\r\n\r\n\r\nInstallation\r\n------------\r\n\r\n::\r\n\r\n   $ pip install yarl\r\n\r\nThe library is Python 3 only!\r\n\r\nPyPI contains binary wheels for Linux, Windows and MacOS.  If you want to install\r\n``yarl`` on another operating system where wheels are not provided,\r\nthe tarball will be used to compile the library from\r\nthe source code. It requires a C compiler and and Python headers installed.\r\n\r\nTo skip the compilation you must explicitly opt-in by using a PEP 517\r\nconfiguration setting ``pure-python``, or setting the ``YARL_NO_EXTENSIONS``\r\nenvironment variable to a non-empty value, e.g.:\r\n\r\n.. code-block:: console\r\n\r\n   $ pip install yarl --config-settings=pure-python=false\r\n\r\nPlease note that the pure-Python (uncompiled) version is much slower. However,\r\nPyPy always uses a pure-Python implementation, and, as such, it is unaffected\r\nby this variable.\r\n\r\nDependencies\r\n------------\r\n\r\nYARL requires multidict_ and propcache_ libraries.\r\n\r\n\r\nAPI documentation\r\n------------------\r\n\r\nThe documentation is located at https://yarl.aio-libs.org.\r\n\r\n\r\nWhy isn't boolean supported by the URL query API?\r\n-------------------------------------------------\r\n\r\nThere is no standard for boolean representation of boolean values.\r\n\r\nSome systems prefer ``true``/``false``, others like ``yes``/``no``, ``on``/``off``,\r\n``Y``/``N``, ``1``/``0``, etc.\r\n\r\n``yarl`` cannot make an unambiguous decision on how to serialize ``bool`` values because\r\nit is specific to how the end-user's application is built and would be different for\r\ndifferent apps.  The library doesn't accept booleans in the API; a user should convert\r\nbools into strings using own preferred translation protocol.\r\n\r\n\r\nComparison with other URL libraries\r\n------------------------------------\r\n\r\n* furl (https://pypi.python.org/pypi/furl)\r\n\r\n  The library has rich functionality but the ``furl`` object is mutable.\r\n\r\n  I'm afraid to pass this object into foreign code: who knows if the\r\n  code will modify my url in a terrible way while I just want to send URL\r\n  with handy helpers for accessing URL properties.\r\n\r\n  ``furl`` has other non-obvious tricky things but the main objection\r\n  is mutability.\r\n\r\n* URLObject (https://pypi.python.org/pypi/URLObject)\r\n\r\n  URLObject is immutable, that's pretty good.\r\n\r\n  Every URL change generates a new URL object.\r\n\r\n  But the library doesn't do any decode/encode transformations leaving the\r\n  end user to cope with these gory details.\r\n\r\n\r\nSource code\r\n-----------\r\n\r\nThe project is hosted on GitHub_\r\n\r\nPlease file an issue on the `bug tracker\r\n<https://github.com/aio-libs/yarl/issues>`_ if you have found a bug\r\nor have some suggestion in order to improve the library.\r\n\r\nDiscussion list\r\n---------------\r\n\r\n*aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs\r\n\r\nFeel free to post your questions and ideas here.\r\n\r\n\r\nAuthors and License\r\n-------------------\r\n\r\nThe ``yarl`` package is written by Andrew Svetlov.\r\n\r\nIt's *Apache 2* licensed and freely available.\r\n\r\n\r\n.. _GitHub: https://github.com/aio-libs/yarl\r\n\r\n.. _multidict: https://github.com/aio-libs/multidict\r\n\r\n.. _propcache: https://github.com/aio-libs/propcache\r\n\r\n=========\r\nChangelog\r\n=========\r\n\r\n..\r\n    You should *NOT* be adding new change log entries to this file, this\r\n    file is managed by towncrier. You *may* edit previous change logs to\r\n    fix problems like typo corrections or such.\r\n    To add a new change log entry, please see\r\n    https://pip.pypa.io/en/latest/development/#adding-a-news-entry\r\n    we named the news folder \"changes\".\r\n\r\n    WARNING: Don't drop the next directive!\r\n\r\n.. towncrier release notes start\r\n\r\n1.22.0\r\n======\r\n\r\n*(2025-10-05)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added arm64 Windows wheel builds\r\n  -- by `@finnagin <https://github.com/sponsors/finnagin>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1516 <https://github.com/aio-libs/yarl/issues/1516>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.21.0\r\n======\r\n\r\n*(2025-10-05)*\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- The ``reusable-cibuildwheel.yml`` workflow has been refactored to\r\n  be more generic and ``ci-cd.yml`` now holds all the configuration\r\n  toggles -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1535 <https://github.com/aio-libs/yarl/issues/1535>`__.\r\n\r\n- When building wheels, the source distribution is now passed directly\r\n  to the ``cibuildwheel`` invocation -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1536 <https://github.com/aio-libs/yarl/issues/1536>`__.\r\n\r\n- Added CI for Python 3.14 -- by `@kumaraditya303 <https://github.com/sponsors/kumaraditya303>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1560 <https://github.com/aio-libs/yarl/issues/1560>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.20.1\r\n======\r\n\r\n*(2025-06-09)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Started raising a ``ValueError`` exception raised for corrupted\r\n  IPv6 URL values.\r\n\r\n  These fixes the issue where exception ``IndexError`` was\r\n  leaking from the internal code because of not being handled and\r\n  transformed into a user-facing error. The problem was happening\r\n  under the following conditions: empty IPv6 URL, brackets in\r\n  reverse order.\r\n\r\n  -- by `@MaelPic <https://github.com/sponsors/MaelPic>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1512 <https://github.com/aio-libs/yarl/issues/1512>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Updated to use Cython 3.1 universally across the build path -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1514 <https://github.com/aio-libs/yarl/issues/1514>`__.\r\n\r\n- Made Cython line tracing opt-in via the ``with-cython-tracing`` build config setting -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Previously, line tracing was enabled by default in ``pyproject.toml``, which caused build issues for some users and made wheels nearly twice as slow.\r\n  Now line tracing is only enabled when explicitly requested via ``pip install . --config-setting=with-cython-tracing=true`` or by setting the ``YARL_CYTHON_TRACING`` environment variable.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1521 <https://github.com/aio-libs/yarl/issues/1521>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.20.0\r\n======\r\n\r\n*(2025-04-16)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Implemented support for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1456 <https://github.com/aio-libs/yarl/issues/1456>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Started building wheels for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1456 <https://github.com/aio-libs/yarl/issues/1456>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.19.0\r\n======\r\n\r\n*(2025-04-05)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed entire name being re-encoded when using ``yarl.URL.with_suffix()`` -- by `@NTFSvolume <https://github.com/sponsors/NTFSvolume>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1468 <https://github.com/aio-libs/yarl/issues/1468>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Started building armv7l wheels for manylinux -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1495 <https://github.com/aio-libs/yarl/issues/1495>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- GitHub Actions CI/CD is now configured to manage caching pip-ecosystem\r\n  dependencies using `re-actors/cache-python-deps`_ -- an action by\r\n  `@webknjaz <https://github.com/sponsors/webknjaz>`__ that takes into account ABI stability and the exact\r\n  version of Python runtime.\r\n\r\n  .. _`re-actors/cache-python-deps`:\r\n     https://github.com/marketplace/actions/cache-python-deps\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1471 <https://github.com/aio-libs/yarl/issues/1471>`__.\r\n\r\n- Increased minimum `propcache`_ version to 0.2.1 to fix failing tests -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  .. _`propcache`:\r\n     https://github.com/aio-libs/propcache\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1479 <https://github.com/aio-libs/yarl/issues/1479>`__.\r\n\r\n- Added all hidden folders to pytest's ``norecursedirs`` to prevent it\r\n  from trying to collect tests there -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1480 <https://github.com/aio-libs/yarl/issues/1480>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved accuracy of type annotations -- by `@Dreamsorcerer <https://github.com/sponsors/Dreamsorcerer>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1484 <https://github.com/aio-libs/yarl/issues/1484>`__.\r\n\r\n- Improved performance of parsing query strings -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1493 <https://github.com/aio-libs/yarl/issues/1493>`__, `#1497 <https://github.com/aio-libs/yarl/issues/1497>`__.\r\n\r\n- Improved performance of the C unquoter -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1496 <https://github.com/aio-libs/yarl/issues/1496>`__, `#1498 <https://github.com/aio-libs/yarl/issues/1498>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.18.3\r\n======\r\n\r\n*(2024-12-01)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed uppercase ASCII hosts being rejected by ``URL.build()()`` and ``yarl.URL.with_host()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#954 <https://github.com/aio-libs/yarl/issues/954>`__, `#1442 <https://github.com/aio-libs/yarl/issues/1442>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performances of multiple path properties on cache miss -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1443 <https://github.com/aio-libs/yarl/issues/1443>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.18.2\r\n======\r\n\r\n*(2024-11-29)*\r\n\r\n\r\nNo significant changes.\r\n\r\n\r\n----\r\n\r\n\r\n1.18.1\r\n======\r\n\r\n*(2024-11-29)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved cache performance when ``~yarl.URL`` objects are constructed from ``yarl.URL.build()`` with ``encoded=True`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1432 <https://github.com/aio-libs/yarl/issues/1432>`__.\r\n\r\n- Improved cache performance for operations that produce a new ``~yarl.URL`` object -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1434 <https://github.com/aio-libs/yarl/issues/1434>`__, `#1436 <https://github.com/aio-libs/yarl/issues/1436>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.18.0\r\n======\r\n\r\n*(2024-11-21)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``keep_query`` and ``keep_fragment`` flags in the ``yarl.URL.with_path()``, ``yarl.URL.with_name()`` and ``yarl.URL.with_suffix()`` methods, allowing users to optionally retain the query string and fragment in the resulting URL when replacing the path -- by `@paul-nameless <https://github.com/sponsors/paul-nameless>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#111 <https://github.com/aio-libs/yarl/issues/111>`__, `#1421 <https://github.com/aio-libs/yarl/issues/1421>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Started running downstream ``aiohttp`` tests in CI -- by `@Cycloctane <https://github.com/sponsors/Cycloctane>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1415 <https://github.com/aio-libs/yarl/issues/1415>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of converting ``~yarl.URL`` to a string -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1422 <https://github.com/aio-libs/yarl/issues/1422>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.17.2\r\n======\r\n\r\n*(2024-11-17)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1411 <https://github.com/aio-libs/yarl/issues/1411>`__, `#1412 <https://github.com/aio-libs/yarl/issues/1412>`__.\r\n\r\n- Fixed a bug causing ``~yarl.URL.port`` to return the default port when the given port was zero\r\n  -- by `@gmacon <https://github.com/sponsors/gmacon>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1413 <https://github.com/aio-libs/yarl/issues/1413>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Make error messages include details of incorrect type when ``port`` is not int in ``yarl.URL.build()``.\r\n  -- by `@Cycloctane <https://github.com/sponsors/Cycloctane>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1414 <https://github.com/aio-libs/yarl/issues/1414>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1411 <https://github.com/aio-libs/yarl/issues/1411>`__, `#1412 <https://github.com/aio-libs/yarl/issues/1412>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of the ``yarl.URL.joinpath()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1418 <https://github.com/aio-libs/yarl/issues/1418>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.17.1\r\n======\r\n\r\n*(2024-10-30)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of many ``~yarl.URL`` methods -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1396 <https://github.com/aio-libs/yarl/issues/1396>`__, `#1397 <https://github.com/aio-libs/yarl/issues/1397>`__, `#1398 <https://github.com/aio-libs/yarl/issues/1398>`__.\r\n\r\n- Improved performance of passing a `dict` or `str` to ``yarl.URL.extend_query()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1401 <https://github.com/aio-libs/yarl/issues/1401>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.17.0\r\n======\r\n\r\n*(2024-10-28)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``~yarl.URL.host_port_subcomponent`` which returns the ``3986#section-3.2.2`` host and ``3986#section-3.2.3`` port subcomponent -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1375 <https://github.com/aio-libs/yarl/issues/1375>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.16.0\r\n======\r\n\r\n*(2024-10-21)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed blocking I/O to load Python code when creating a new ``~yarl.URL`` with non-ascii characters in the network location part -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1342 <https://github.com/aio-libs/yarl/issues/1342>`__.\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Migrated to using a single cache for encoding hosts -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Passing ``ip_address_size`` and ``host_validate_size`` to ``yarl.cache_configure()`` is deprecated in favor of the new ``encode_host_size`` parameter and will be removed in a future release. For backwards compatibility, the old parameters affect the ``encode_host`` cache size.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1348 <https://github.com/aio-libs/yarl/issues/1348>`__, `#1357 <https://github.com/aio-libs/yarl/issues/1357>`__, `#1363 <https://github.com/aio-libs/yarl/issues/1363>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of constructing ``~yarl.URL`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1336 <https://github.com/aio-libs/yarl/issues/1336>`__.\r\n\r\n- Improved performance of calling ``yarl.URL.build()`` and constructing unencoded ``~yarl.URL`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1345 <https://github.com/aio-libs/yarl/issues/1345>`__.\r\n\r\n- Reworked the internal encoding cache to improve performance on cache hit -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1369 <https://github.com/aio-libs/yarl/issues/1369>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.5\r\n======\r\n\r\n*(2024-10-18)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of the ``yarl.URL.joinpath()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1304 <https://github.com/aio-libs/yarl/issues/1304>`__.\r\n\r\n- Improved performance of the ``yarl.URL.extend_query()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1305 <https://github.com/aio-libs/yarl/issues/1305>`__.\r\n\r\n- Improved performance of the ``yarl.URL.origin()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1306 <https://github.com/aio-libs/yarl/issues/1306>`__.\r\n\r\n- Improved performance of the ``yarl.URL.with_path()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1307 <https://github.com/aio-libs/yarl/issues/1307>`__.\r\n\r\n- Improved performance of the ``yarl.URL.with_query()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1308 <https://github.com/aio-libs/yarl/issues/1308>`__, `#1328 <https://github.com/aio-libs/yarl/issues/1328>`__.\r\n\r\n- Improved performance of the ``yarl.URL.update_query()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1309 <https://github.com/aio-libs/yarl/issues/1309>`__, `#1327 <https://github.com/aio-libs/yarl/issues/1327>`__.\r\n\r\n- Improved performance of the ``yarl.URL.join()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1313 <https://github.com/aio-libs/yarl/issues/1313>`__.\r\n\r\n- Improved performance of ``~yarl.URL`` equality checks -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1315 <https://github.com/aio-libs/yarl/issues/1315>`__.\r\n\r\n- Improved performance of ``~yarl.URL`` methods that modify the network location -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1316 <https://github.com/aio-libs/yarl/issues/1316>`__.\r\n\r\n- Improved performance of the ``yarl.URL.with_fragment()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1317 <https://github.com/aio-libs/yarl/issues/1317>`__.\r\n\r\n- Improved performance of calculating the hash of ``~yarl.URL`` objects -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1318 <https://github.com/aio-libs/yarl/issues/1318>`__.\r\n\r\n- Improved performance of the ``yarl.URL.relative()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1319 <https://github.com/aio-libs/yarl/issues/1319>`__.\r\n\r\n- Improved performance of the ``yarl.URL.with_name()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1320 <https://github.com/aio-libs/yarl/issues/1320>`__.\r\n\r\n- Improved performance of ``~yarl.URL.parent`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1321 <https://github.com/aio-libs/yarl/issues/1321>`__.\r\n\r\n- Improved performance of the ``yarl.URL.with_scheme()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1322 <https://github.com/aio-libs/yarl/issues/1322>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.4\r\n======\r\n\r\n*(2024-10-16)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of the quoter when all characters are safe -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1288 <https://github.com/aio-libs/yarl/issues/1288>`__.\r\n\r\n- Improved performance of unquoting strings -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1292 <https://github.com/aio-libs/yarl/issues/1292>`__, `#1293 <https://github.com/aio-libs/yarl/issues/1293>`__.\r\n\r\n- Improved performance of calling ``yarl.URL.build()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1297 <https://github.com/aio-libs/yarl/issues/1297>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.3\r\n======\r\n\r\n*(2024-10-15)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed ``yarl.URL.build()`` failing to validate paths must start with a ``/`` when passing ``authority`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  The validation only worked correctly when passing ``host``.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1265 <https://github.com/aio-libs/yarl/issues/1265>`__.\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Removed support for Python 3.8 as it has reached end of life -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1203 <https://github.com/aio-libs/yarl/issues/1203>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of constructing ``~yarl.URL`` when the net location is only the host -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1271 <https://github.com/aio-libs/yarl/issues/1271>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.2\r\n======\r\n\r\n*(2024-10-13)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of converting ``~yarl.URL`` to a string -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1234 <https://github.com/aio-libs/yarl/issues/1234>`__.\r\n\r\n- Improved performance of ``yarl.URL.joinpath()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1248 <https://github.com/aio-libs/yarl/issues/1248>`__, `#1250 <https://github.com/aio-libs/yarl/issues/1250>`__.\r\n\r\n- Improved performance of constructing query strings from ``~multidict.MultiDict`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1256 <https://github.com/aio-libs/yarl/issues/1256>`__.\r\n\r\n- Improved performance of constructing query strings with ``int`` values -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1259 <https://github.com/aio-libs/yarl/issues/1259>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.1\r\n======\r\n\r\n*(2024-10-12)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of calling ``yarl.URL.build()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1222 <https://github.com/aio-libs/yarl/issues/1222>`__.\r\n\r\n- Improved performance of all ``~yarl.URL`` methods that create new ``~yarl.URL`` objects -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1226 <https://github.com/aio-libs/yarl/issues/1226>`__.\r\n\r\n- Improved performance of ``~yarl.URL`` methods that modify the network location -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1229 <https://github.com/aio-libs/yarl/issues/1229>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.15.0\r\n======\r\n\r\n*(2024-10-11)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed validation with ``yarl.URL.with_scheme()`` when passed scheme is not lowercase -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1189 <https://github.com/aio-libs/yarl/issues/1189>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Started building ``armv7l`` wheels -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1204 <https://github.com/aio-libs/yarl/issues/1204>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of constructing unencoded ``~yarl.URL`` objects -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1188 <https://github.com/aio-libs/yarl/issues/1188>`__.\r\n\r\n- Added a cache for parsing hosts to reduce overhead of encoding ``~yarl.URL`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1190 <https://github.com/aio-libs/yarl/issues/1190>`__.\r\n\r\n- Improved performance of constructing query strings from ``~collections.abc.Mapping`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1193 <https://github.com/aio-libs/yarl/issues/1193>`__.\r\n\r\n- Improved performance of converting ``~yarl.URL`` objects to strings -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1198 <https://github.com/aio-libs/yarl/issues/1198>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.14.0\r\n======\r\n\r\n*(2024-10-08)*\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Switched to using the ``propcache`` package for property caching\r\n  -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  The ``propcache`` package is derived from the property caching\r\n  code in ``yarl`` and has been broken out to avoid maintaining it for multiple\r\n  projects.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1169 <https://github.com/aio-libs/yarl/issues/1169>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Started testing with Hypothesis -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__ and `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Special thanks to `@Zac-HD <https://github.com/sponsors/Zac-HD>`__ for helping us get started with this framework.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#860 <https://github.com/aio-libs/yarl/issues/860>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of ``yarl.URL.is_default_port()`` when no explicit port is set -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1168 <https://github.com/aio-libs/yarl/issues/1168>`__.\r\n\r\n- Improved performance of converting ``~yarl.URL`` to a string when no explicit port is set -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1170 <https://github.com/aio-libs/yarl/issues/1170>`__.\r\n\r\n- Improved performance of the ``yarl.URL.origin()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1175 <https://github.com/aio-libs/yarl/issues/1175>`__.\r\n\r\n- Improved performance of encoding hosts -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1176 <https://github.com/aio-libs/yarl/issues/1176>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.13.1\r\n======\r\n\r\n*(2024-09-27)*\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of calling ``yarl.URL.build()`` with ``authority`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1163 <https://github.com/aio-libs/yarl/issues/1163>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.13.0\r\n======\r\n\r\n*(2024-09-26)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Started rejecting ASCII hostnames with invalid characters. For host strings that\r\n  look like authority strings, the exception message includes advice on what to do\r\n  instead -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#880 <https://github.com/aio-libs/yarl/issues/880>`__, `#954 <https://github.com/aio-libs/yarl/issues/954>`__.\r\n\r\n- Fixed IPv6 addresses missing brackets when the ``~yarl.URL`` was converted to a string -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1157 <https://github.com/aio-libs/yarl/issues/1157>`__, `#1158 <https://github.com/aio-libs/yarl/issues/1158>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``~yarl.URL.host_subcomponent`` which returns the ``3986#section-3.2.2`` host subcomponent -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  The only current practical difference between ``~yarl.URL.raw_host`` and ``~yarl.URL.host_subcomponent`` is that IPv6 addresses are returned bracketed.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1159 <https://github.com/aio-libs/yarl/issues/1159>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.12.1\r\n======\r\n\r\n*(2024-09-23)*\r\n\r\n\r\nNo significant changes.\r\n\r\n\r\n----\r\n\r\n\r\n1.12.0\r\n======\r\n\r\n*(2024-09-23)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``~yarl.URL.path_safe`` to be able to fetch the path without ``%2F`` and ``%25`` decoded -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1150 <https://github.com/aio-libs/yarl/issues/1150>`__.\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Restore decoding ``%2F`` (``/``) in ``URL.path`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  This change restored the behavior before `#1057 <https://github.com/aio-libs/yarl/issues/1057>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1151 <https://github.com/aio-libs/yarl/issues/1151>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of processing paths -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1143 <https://github.com/aio-libs/yarl/issues/1143>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.11.1\r\n======\r\n\r\n*(2024-09-09)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Allowed scheme replacement for relative URLs if the scheme does not require a host -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#280 <https://github.com/aio-libs/yarl/issues/280>`__, `#1138 <https://github.com/aio-libs/yarl/issues/1138>`__.\r\n\r\n- Allowed empty host for URL schemes other than the special schemes listed in the WHATWG URL spec -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1136 <https://github.com/aio-libs/yarl/issues/1136>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Loosened restriction on integers as query string values to allow classes that implement ``__int__`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1139 <https://github.com/aio-libs/yarl/issues/1139>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of normalizing paths -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1137 <https://github.com/aio-libs/yarl/issues/1137>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.11.0\r\n======\r\n\r\n*(2024-09-08)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``URL.extend_query()()`` method, which can be used to extend parameters without replacing same named keys -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  This method was primarily added to replace the inefficient hand rolled method currently used in ``aiohttp``.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1128 <https://github.com/aio-libs/yarl/issues/1128>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of the Cython ``cached_property`` implementation -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1122 <https://github.com/aio-libs/yarl/issues/1122>`__.\r\n\r\n- Simplified computing ports by removing unnecessary code -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1123 <https://github.com/aio-libs/yarl/issues/1123>`__.\r\n\r\n- Improved performance of encoding non IPv6 hosts -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1125 <https://github.com/aio-libs/yarl/issues/1125>`__.\r\n\r\n- Improved performance of ``URL.build()()`` when the path, query string, or fragment is an empty string -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1126 <https://github.com/aio-libs/yarl/issues/1126>`__.\r\n\r\n- Improved performance of the ``URL.update_query()()`` method -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1130 <https://github.com/aio-libs/yarl/issues/1130>`__.\r\n\r\n- Improved performance of processing query string changes when arguments are ``str`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1131 <https://github.com/aio-libs/yarl/issues/1131>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.10.0\r\n======\r\n\r\n*(2024-09-06)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed joining a path when the existing path was empty -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  A regression in ``URL.join()()`` was introduced in `#1082 <https://github.com/aio-libs/yarl/issues/1082>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1118 <https://github.com/aio-libs/yarl/issues/1118>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``URL.without_query_params()()`` method, to drop some parameters from query string -- by `@hongquan <https://github.com/sponsors/hongquan>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#774 <https://github.com/aio-libs/yarl/issues/774>`__, `#898 <https://github.com/aio-libs/yarl/issues/898>`__, `#1010 <https://github.com/aio-libs/yarl/issues/1010>`__.\r\n\r\n- The previously protected types ``_SimpleQuery``, ``_QueryVariable``, and ``_Query`` are now available for use externally as ``SimpleQuery``, ``QueryVariable``, and ``Query`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1050 <https://github.com/aio-libs/yarl/issues/1050>`__, `#1113 <https://github.com/aio-libs/yarl/issues/1113>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Replaced all ``~typing.Optional`` with ``~typing.Union`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1095 <https://github.com/aio-libs/yarl/issues/1095>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Significantly improved performance of parsing the network location -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1112 <https://github.com/aio-libs/yarl/issues/1112>`__.\r\n\r\n- Added internal types to the cache to prevent future refactoring errors -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1117 <https://github.com/aio-libs/yarl/issues/1117>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.11\r\n======\r\n\r\n*(2024-09-04)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed a ``TypeError`` with ``MultiDictProxy`` and Python 3.8 -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1084 <https://github.com/aio-libs/yarl/issues/1084>`__, `#1105 <https://github.com/aio-libs/yarl/issues/1105>`__, `#1107 <https://github.com/aio-libs/yarl/issues/1107>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of encoding hosts -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Previously, the library would unconditionally try to parse a host as an IP Address. The library now avoids trying to parse a host as an IP Address if the string is not in one of the formats described in ``3986#section-3.2.2``.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1104 <https://github.com/aio-libs/yarl/issues/1104>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.10\r\n======\r\n\r\n*(2024-09-04)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- ``URL.join()()`` has been changed to match\r\n  ``3986`` and align with\r\n  ``/ operation()`` and ``URL.joinpath()()``\r\n  when joining URLs with empty segments.\r\n  Previously ``urllib.parse.urljoin`` was used,\r\n  which has known issues with empty segments\r\n  (`python/cpython#84774 <https://github.com/python/cpython/issues/84774>`_).\r\n\r\n  Due to the semantics of ``URL.join()()``, joining an\r\n  URL with scheme requires making it relative, prefixing with ``./``.\r\n\r\n  .. code-block:: pycon\r\n\r\n     >>> URL(\"https://web.archive.org/web/\").join(URL(\"./https://github.com/aio-libs/yarl\"))\r\n     URL('https://web.archive.org/web/https://github.com/aio-libs/yarl')\r\n\r\n\r\n  Empty segments are honored in the base as well as the joined part.\r\n\r\n  .. code-block:: pycon\r\n\r\n     >>> URL(\"https://web.archive.org/web/https://\").join(URL(\"github.com/aio-libs/yarl\"))\r\n     URL('https://web.archive.org/web/https://github.com/aio-libs/yarl')\r\n\r\n\r\n\r\n  -- by `@commonism <https://github.com/sponsors/commonism>`__\r\n\r\n  This change initially appeared in 1.9.5 but was reverted in 1.9.6 to resolve a problem with query string handling.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1039 <https://github.com/aio-libs/yarl/issues/1039>`__, `#1082 <https://github.com/aio-libs/yarl/issues/1082>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``~yarl.URL.absolute`` which is now preferred over ``URL.is_absolute()`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1100 <https://github.com/aio-libs/yarl/issues/1100>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.9\r\n=====\r\n\r\n*(2024-09-04)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Added missing type on ``~yarl.URL.port`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1097 <https://github.com/aio-libs/yarl/issues/1097>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.8\r\n=====\r\n\r\n*(2024-09-03)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Covered the ``~yarl.URL`` object with types -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1084 <https://github.com/aio-libs/yarl/issues/1084>`__.\r\n\r\n- Cache parsing of IP Addresses when encoding hosts -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1086 <https://github.com/aio-libs/yarl/issues/1086>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Covered the ``~yarl.URL`` object with types -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1084 <https://github.com/aio-libs/yarl/issues/1084>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of handling ports -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1081 <https://github.com/aio-libs/yarl/issues/1081>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.7\r\n=====\r\n\r\n*(2024-09-01)*\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Removed support ``3986#section-3.2.3`` port normalization when the scheme is not one of ``http``, ``https``, ``wss``, or ``ws`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Support for port normalization was recently added in `#1033 <https://github.com/aio-libs/yarl/issues/1033>`__ and contained code that would do blocking I/O if the scheme was not one of the four listed above. The code has been removed because this library is intended to be safe for usage with ``asyncio``.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1076 <https://github.com/aio-libs/yarl/issues/1076>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- Improved performance of property caching -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  The ``reify`` implementation from ``aiohttp`` was adapted to replace the internal ``cached_property`` implementation.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1070 <https://github.com/aio-libs/yarl/issues/1070>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.6\r\n=====\r\n\r\n*(2024-08-30)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Reverted ``3986`` compatible ``URL.join()()`` honoring empty segments which was introduced in `#1039 <https://github.com/aio-libs/yarl/issues/1039>`__.\r\n\r\n  This change introduced a regression handling query string parameters with joined URLs. The change was reverted to maintain compatibility with the previous behavior.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1067 <https://github.com/aio-libs/yarl/issues/1067>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.5\r\n=====\r\n\r\n*(2024-08-30)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Joining URLs with empty segments has been changed\r\n  to match ``3986``.\r\n\r\n  Previously empty segments would be removed from path,\r\n  breaking use-cases such as\r\n\r\n  .. code-block:: python\r\n\r\n     URL(\"https://web.archive.org/web/\") / \"https://github.com/\"\r\n\r\n  Now ``/ operation()`` and ``URL.joinpath()()``\r\n  keep empty segments, but do not introduce new empty segments.\r\n  e.g.\r\n\r\n  .. code-block:: python\r\n\r\n     URL(\"https://example.org/\") / \"\"\r\n\r\n  does not introduce an empty segment.\r\n\r\n  -- by `@commonism <https://github.com/sponsors/commonism>`__ and `@youtux <https://github.com/sponsors/youtux>`__\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1026 <https://github.com/aio-libs/yarl/issues/1026>`__.\r\n\r\n- The default protocol ports of well-known URI schemes are now taken into account\r\n  during the normalization of the URL string representation in accordance with\r\n  ``3986#section-3.2.3``.\r\n\r\n  Specified ports are removed from the ``str`` representation of a ``~yarl.URL``\r\n  if the port matches the scheme's default port -- by `@commonism <https://github.com/sponsors/commonism>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1033 <https://github.com/aio-libs/yarl/issues/1033>`__.\r\n\r\n- ``URL.join()()`` has been changed to match\r\n  ``3986`` and align with\r\n  ``/ operation()`` and ``URL.joinpath()()``\r\n  when joining URLs with empty segments.\r\n  Previously ``urllib.parse.urljoin`` was used,\r\n  which has known issues with empty segments\r\n  (`python/cpython#84774 <https://github.com/python/cpython/issues/84774>`_).\r\n\r\n  Due to the semantics of ``URL.join()()``, joining an\r\n  URL with scheme requires making it relative, prefixing with ``./``.\r\n\r\n  .. code-block:: pycon\r\n\r\n     >>> URL(\"https://web.archive.org/web/\").join(URL(\"./https://github.com/aio-libs/yarl\"))\r\n     URL('https://web.archive.org/web/https://github.com/aio-libs/yarl')\r\n\r\n\r\n  Empty segments are honored in the base as well as the joined part.\r\n\r\n  .. code-block:: pycon\r\n\r\n     >>> URL(\"https://web.archive.org/web/https://\").join(URL(\"github.com/aio-libs/yarl\"))\r\n     URL('https://web.archive.org/web/https://github.com/aio-libs/yarl')\r\n\r\n\r\n\r\n  -- by `@commonism <https://github.com/sponsors/commonism>`__\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1039 <https://github.com/aio-libs/yarl/issues/1039>`__.\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Stopped decoding ``%2F`` (``/``) in ``URL.path``, as this could lead to code incorrectly treating it as a path separator\r\n  -- by `@Dreamsorcerer <https://github.com/sponsors/Dreamsorcerer>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1057 <https://github.com/aio-libs/yarl/issues/1057>`__.\r\n\r\n- Dropped support for Python 3.7 -- by `@Dreamsorcerer <https://github.com/sponsors/Dreamsorcerer>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1016 <https://github.com/aio-libs/yarl/issues/1016>`__.\r\n\r\n\r\nImproved documentation\r\n----------------------\r\n\r\n- On the ``Contributing docs`` page,\r\n  a link to the ``Towncrier philosophy`` has been fixed.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#981 <https://github.com/aio-libs/yarl/issues/981>`__.\r\n\r\n- The pre-existing ``/ magic method()``\r\n  has been documented in the API reference -- by `@commonism <https://github.com/sponsors/commonism>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1026 <https://github.com/aio-libs/yarl/issues/1026>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- A flaw in the logic for copying the project directory into a\r\n  temporary folder that led to infinite recursion when ``TMPDIR``\r\n  was set to a project subdirectory path. This was happening in Fedora\r\n  and its downstream due to the use of `pyproject-rpm-macros\r\n  <https://src.fedoraproject.org/rpms/pyproject-rpm-macros>`__. It was\r\n  only reproducible with ``pip wheel`` and was not affecting the\r\n  ``pyproject-build`` users.\r\n\r\n  -- by `@hroncok <https://github.com/sponsors/hroncok>`__ and `@webknjaz <https://github.com/sponsors/webknjaz>`__\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#992 <https://github.com/aio-libs/yarl/issues/992>`__, `#1014 <https://github.com/aio-libs/yarl/issues/1014>`__.\r\n\r\n- Support Python 3.13 and publish non-free-threaded wheels\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1054 <https://github.com/aio-libs/yarl/issues/1054>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- The CI/CD setup has been updated to test ``arm64`` wheels\r\n  under macOS 14, except for Python 3.7 that is unsupported\r\n  in that environment -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1015 <https://github.com/aio-libs/yarl/issues/1015>`__.\r\n\r\n- Removed unused type ignores and casts -- by `@hauntsaninja <https://github.com/sponsors/hauntsaninja>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1031 <https://github.com/aio-libs/yarl/issues/1031>`__.\r\n\r\n\r\nMiscellaneous internal changes\r\n------------------------------\r\n\r\n- ``port``, ``scheme``, and ``raw_host`` are now ``cached_property`` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  ``aiohttp`` accesses these properties quite often, which cause ``urllib`` to build the ``_hostinfo`` property every time. ``port``, ``scheme``, and ``raw_host`` are now cached properties, which will improve performance.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#1044 <https://github.com/aio-libs/yarl/issues/1044>`__, `#1058 <https://github.com/aio-libs/yarl/issues/1058>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.9.4 (2023-12-06)\r\n==================\r\n\r\nBug fixes\r\n---------\r\n\r\n- Started raising ``TypeError`` when a string value is passed into\r\n  ``yarl.URL.build()`` as the ``port`` argument  -- by `@commonism <https://github.com/sponsors/commonism>`__.\r\n\r\n  Previously the empty string as port would create malformed URLs when rendered as string representations. (`#883 <https://github.com/aio-libs/yarl/issues/883>`__)\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- The leading ``--`` has been dropped from the `PEP 517 <https://peps.python.org/pep-517>`__ in-tree build\r\n  backend config setting names. ``--pure-python`` is now just ``pure-python``\r\n  -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  The usage now looks as follows:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -m build \\\r\n          --config-setting=pure-python=true \\\r\n          --config-setting=with-cython-tracing=true\r\n\r\n  (`#963 <https://github.com/aio-libs/yarl/issues/963>`__)\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- A step-by-step ``Release Guide`` guide has\r\n  been added, describing how to release *yarl* -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  This is primarily targeting maintainers. (`#960 <https://github.com/aio-libs/yarl/issues/960>`__)\r\n- Coverage collection has been implemented for the Cython modules\r\n  -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  It will also be reported to Codecov from any non-release CI jobs.\r\n\r\n  To measure coverage in a development environment, *yarl* can be\r\n  installed in editable mode:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -Im pip install -e .\r\n\r\n  Editable install produces C-files required for the Cython coverage\r\n  plugin to map the measurements back to the PYX-files.\r\n\r\n  `#961 <https://github.com/aio-libs/yarl/issues/961>`__\r\n\r\n- It is now possible to request line tracing in Cython builds using the\r\n  ``with-cython-tracing`` `PEP 517 <https://peps.python.org/pep-517>`__ config setting\r\n  -- `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  This can be used in CI and development environment to measure coverage\r\n  on Cython modules, but is not normally useful to the end-users or\r\n  downstream packagers.\r\n\r\n  Here's a usage example:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -Im pip install . --config-settings=with-cython-tracing=true\r\n\r\n  For editable installs, this setting is on by default. Otherwise, it's\r\n  off unless requested explicitly.\r\n\r\n  The following produces C-files required for the Cython coverage\r\n  plugin to map the measurements back to the PYX-files:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -Im pip install -e .\r\n\r\n  Alternatively, the ``YARL_CYTHON_TRACING=1`` environment variable\r\n  can be set to do the same as the `PEP 517 <https://peps.python.org/pep-517>`__ config setting.\r\n\r\n  `#962 <https://github.com/aio-libs/yarl/issues/962>`__\r\n\r\n\r\n1.9.3 (2023-11-20)\r\n==================\r\n\r\nBug fixes\r\n---------\r\n\r\n- Stopped dropping trailing slashes in ``yarl.URL.joinpath()`` -- by `@gmacon <https://github.com/sponsors/gmacon>`__. (`#862 <https://github.com/aio-libs/yarl/issues/862>`__, `#866 <https://github.com/aio-libs/yarl/issues/866>`__)\r\n- Started accepting string subclasses in ``yarl.URL.__truediv__()`` operations (``URL / segment``) -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__. (`#871 <https://github.com/aio-libs/yarl/issues/871>`__, `#884 <https://github.com/aio-libs/yarl/issues/884>`__)\r\n- Fixed the human representation of URLs with square brackets in usernames and passwords -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__. (`#876 <https://github.com/aio-libs/yarl/issues/876>`__, `#882 <https://github.com/aio-libs/yarl/issues/882>`__)\r\n- Updated type hints to include ``URL.missing_port()``, ``URL.__bytes__()``\r\n  and the ``encoding`` argument to ``yarl.URL.joinpath()``\r\n  -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__. (`#891 <https://github.com/aio-libs/yarl/issues/891>`__)\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Integrated Cython 3 to enable building *yarl* under Python 3.12 -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__. (`#829 <https://github.com/aio-libs/yarl/issues/829>`__, `#881 <https://github.com/aio-libs/yarl/issues/881>`__)\r\n- Declared modern ``setuptools.build_meta`` as the `PEP 517 <https://peps.python.org/pep-517>`__ build\r\n  backend in ``pyproject.toml`` explicitly -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__. (`#886 <https://github.com/aio-libs/yarl/issues/886>`__)\r\n- Converted most of the packaging setup into a declarative ``setup.cfg``\r\n  config -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__. (`#890 <https://github.com/aio-libs/yarl/issues/890>`__)\r\n- The packaging is replaced from an old-fashioned ``setup.py`` to an\r\n  in-tree `PEP 517 <https://peps.python.org/pep-517>`__ build backend -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  Whenever the end-users or downstream packagers need to build ``yarl`` from\r\n  source (a Git checkout or an sdist), they may pass a ``config_settings``\r\n  flag ``--pure-python``. If this flag is not set, a C-extension will be built\r\n  and included into the distribution.\r\n\r\n  Here is how this can be done with ``pip``:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -m pip install . --config-settings=--pure-python=false\r\n\r\n  This will also work with ``-e | --editable``.\r\n\r\n  The same can be achieved via ``pypa/build``:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -m build --config-setting=--pure-python=false\r\n\r\n  Adding ``-w | --wheel`` can force ``pypa/build`` produce a wheel from source\r\n  directly, as opposed to building an ``sdist`` and then building from it. (`#893 <https://github.com/aio-libs/yarl/issues/893>`__)\r\n\r\n  .. attention::\r\n\r\n     v1.9.3 was the only version using the ``--pure-python`` setting name.\r\n     Later versions dropped the ``--`` prefix, making it just ``pure-python``.\r\n\r\n- Declared Python 3.12 supported officially in the distribution package metadata\r\n  -- by `@edgarrmondragon <https://github.com/sponsors/edgarrmondragon>`__. (`#942 <https://github.com/aio-libs/yarl/issues/942>`__)\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- A regression test for no-host URLs was added per `#821 <https://github.com/aio-libs/yarl/issues/821>`__\r\n  and ``3986`` -- by `@kenballus <https://github.com/sponsors/kenballus>`__. (`#821 <https://github.com/aio-libs/yarl/issues/821>`__, `#822 <https://github.com/aio-libs/yarl/issues/822>`__)\r\n- Started testing *yarl* against Python 3.12 in CI -- by `@mjpieters <https://github.com/sponsors/mjpieters>`__. (`#881 <https://github.com/aio-libs/yarl/issues/881>`__)\r\n- All Python 3.12 jobs are now marked as required to pass in CI\r\n  -- by `@edgarrmondragon <https://github.com/sponsors/edgarrmondragon>`__. (`#942 <https://github.com/aio-libs/yarl/issues/942>`__)\r\n- MyST is now integrated in Sphinx -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  This allows the contributors to author new documents in Markdown\r\n  when they have difficulties with going straight RST. (`#953 <https://github.com/aio-libs/yarl/issues/953>`__)\r\n\r\n\r\n1.9.2 (2023-04-25)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Fix regression with ``yarl.URL.__truediv__()`` and absolute URLs with empty paths causing the raw path to lack the leading ``/``.\r\n  (`#854 <https://github.com/aio-libs/yarl/issues/854>`_)\r\n\r\n\r\n1.9.1 (2023-04-21)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Marked tests that fail on older Python patch releases (< 3.7.10, < 3.8.8 and < 3.9.2) as expected to fail due to missing a security fix for CVE-2021-23336. (`#850 <https://github.com/aio-libs/yarl/issues/850>`_)\r\n\r\n\r\n1.9.0 (2023-04-19)\r\n==================\r\n\r\nThis release was never published to PyPI, due to issues with the build process.\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``URL.joinpath(*elements)``, to create a new URL appending multiple path elements. (`#704 <https://github.com/aio-libs/yarl/issues/704>`_)\r\n- Made ``URL.__truediv__()()`` return ``NotImplemented`` if called with an\r\n  unsupported type â€” by `@michaeljpeters <https://github.com/sponsors/michaeljpeters>`__.\r\n  (`#832 <https://github.com/aio-libs/yarl/issues/832>`_)\r\n\r\n\r\nBugfixes\r\n--------\r\n\r\n- Path normalization for absolute URLs no longer raises a ValueError exception\r\n  when ``..`` segments would otherwise go beyond the URL path root.\r\n  (`#536 <https://github.com/aio-libs/yarl/issues/536>`_)\r\n- Fixed an issue with update_query() not getting rid of the query when argument is None. (`#792 <https://github.com/aio-libs/yarl/issues/792>`_)\r\n- Added some input restrictions on with_port() function to prevent invalid boolean inputs or out of valid port inputs; handled incorrect 0 port representation. (`#793 <https://github.com/aio-libs/yarl/issues/793>`_)\r\n- Made ``yarl.URL.build()`` raise a ``TypeError`` if the ``host`` argument is ``None`` â€” by `@paulpapacz <https://github.com/sponsors/paulpapacz>`__. (`#808 <https://github.com/aio-libs/yarl/issues/808>`_)\r\n- Fixed an issue with ``update_query()`` getting rid of the query when the argument\r\n  is empty but not ``None``. (`#845 <https://github.com/aio-libs/yarl/issues/845>`_)\r\n\r\n\r\nMisc\r\n----\r\n\r\n- `#220 <https://github.com/aio-libs/yarl/issues/220>`_\r\n\r\n\r\n1.8.2 (2022-12-03)\r\n==================\r\n\r\nThis is the first release that started shipping wheels for Python 3.11.\r\n\r\n\r\n1.8.1 (2022-08-01)\r\n==================\r\n\r\nMisc\r\n----\r\n\r\n- `#694 <https://github.com/aio-libs/yarl/issues/694>`_, `#699 <https://github.com/aio-libs/yarl/issues/699>`_, `#700 <https://github.com/aio-libs/yarl/issues/700>`_, `#701 <https://github.com/aio-libs/yarl/issues/701>`_, `#702 <https://github.com/aio-libs/yarl/issues/702>`_, `#703 <https://github.com/aio-libs/yarl/issues/703>`_, `#739 <https://github.com/aio-libs/yarl/issues/739>`_\r\n\r\n\r\n1.8.0 (2022-08-01)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``URL.raw_suffix``, ``URL.suffix``, ``URL.raw_suffixes``, ``URL.suffixes``, ``URL.with_suffix``. (`#613 <https://github.com/aio-libs/yarl/issues/613>`_)\r\n\r\n\r\nImproved Documentation\r\n----------------------\r\n\r\n- Fixed broken internal references to ``yarl.URL.human_repr()``.\r\n  (`#665 <https://github.com/aio-libs/yarl/issues/665>`_)\r\n- Fixed broken external references to ``multidict:index`` docs. (`#665 <https://github.com/aio-libs/yarl/issues/665>`_)\r\n\r\n\r\nDeprecations and Removals\r\n-------------------------\r\n\r\n- Dropped Python 3.6 support. (`#672 <https://github.com/aio-libs/yarl/issues/672>`_)\r\n\r\n\r\nMisc\r\n----\r\n\r\n- `#646 <https://github.com/aio-libs/yarl/issues/646>`_, `#699 <https://github.com/aio-libs/yarl/issues/699>`_, `#701 <https://github.com/aio-libs/yarl/issues/701>`_\r\n\r\n\r\n1.7.2 (2021-11-01)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Changed call in ``with_port()`` to stop reencoding parts of the URL that were already encoded. (`#623 <https://github.com/aio-libs/yarl/issues/623>`_)\r\n\r\n\r\n1.7.1 (2021-10-07)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Fix 1.7.0 build error\r\n\r\n1.7.0 (2021-10-06)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Add ``__bytes__()`` magic method so that ``bytes(url)`` will work and use optimal ASCII encoding.\r\n  (`#582 <https://github.com/aio-libs/yarl/issues/582>`_)\r\n- Started shipping platform-specific arm64 wheels for Apple Silicon. (`#622 <https://github.com/aio-libs/yarl/issues/622>`_)\r\n- Started shipping platform-specific wheels with the ``musl`` tag targeting typical Alpine Linux runtimes. (`#622 <https://github.com/aio-libs/yarl/issues/622>`_)\r\n- Added support for Python 3.10. (`#622 <https://github.com/aio-libs/yarl/issues/622>`_)\r\n\r\n\r\n1.6.3 (2020-11-14)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- No longer loose characters when decoding incorrect percent-sequences (like ``%e2%82%f8``). All non-decodable percent-sequences are now preserved.\r\n  `#517 <https://github.com/aio-libs/yarl/issues/517>`_\r\n- Provide x86 Windows wheels.\r\n  `#535 <https://github.com/aio-libs/yarl/issues/535>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.6.2 (2020-10-12)\r\n==================\r\n\r\n\r\nBugfixes\r\n--------\r\n\r\n- Provide generated ``.c`` files in TarBall distribution.\r\n  `#530  <https://github.com/aio-libs/multidict/issues/530>`_\r\n\r\n1.6.1 (2020-10-12)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Provide wheels for ``aarch64``, ``i686``, ``ppc64le``, ``s390x`` architectures on\r\n  Linux as well as ``x86_64``.\r\n  `#507  <https://github.com/aio-libs/yarl/issues/507>`_\r\n- Provide wheels for Python 3.9.\r\n  `#526 <https://github.com/aio-libs/yarl/issues/526>`_\r\n\r\nBugfixes\r\n--------\r\n\r\n- ``human_repr()`` now always produces valid representation equivalent to the original URL (if the original URL is valid).\r\n  `#511 <https://github.com/aio-libs/yarl/issues/511>`_\r\n- Fixed  requoting a single percent followed by a percent-encoded character in the Cython implementation.\r\n  `#514 <https://github.com/aio-libs/yarl/issues/514>`_\r\n- Fix ValueError when decoding ``%`` which is not followed by two hexadecimal digits.\r\n  `#516 <https://github.com/aio-libs/yarl/issues/516>`_\r\n- Fix decoding ``%`` followed by a space and hexadecimal digit.\r\n  `#520 <https://github.com/aio-libs/yarl/issues/520>`_\r\n- Fix annotation of ``with_query()``/``update_query()`` methods for ``key=[val1, val2]`` case.\r\n  `#528 <https://github.com/aio-libs/yarl/issues/528>`_\r\n\r\nRemoval\r\n-------\r\n\r\n- Drop Python 3.5 support; Python 3.6 is the minimal supported Python version.\r\n\r\n\r\n----\r\n\r\n\r\n1.6.0 (2020-09-23)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Allow for int and float subclasses in query, while still denying bool.\r\n  `#492 <https://github.com/aio-libs/yarl/issues/492>`_\r\n\r\n\r\nBugfixes\r\n--------\r\n\r\n- Do not requote arguments in ``URL.build()``, ``with_xxx()`` and in ``/`` operator.\r\n  `#502 <https://github.com/aio-libs/yarl/issues/502>`_\r\n- Keep IPv6 brackets in ``origin()``.\r\n  `#504 <https://github.com/aio-libs/yarl/issues/504>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.5.1 (2020-08-01)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Fix including relocated internal ``yarl._quoting_c`` C-extension into published PyPI dists.\r\n  `#485 <https://github.com/aio-libs/yarl/issues/485>`_\r\n\r\n\r\nMisc\r\n----\r\n\r\n- `#484 <https://github.com/aio-libs/yarl/issues/484>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.5.0 (2020-07-26)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Convert host to lowercase on URL building.\r\n  `#386 <https://github.com/aio-libs/yarl/issues/386>`_\r\n- Allow using ``mod`` operator (``%``) for updating query string (an alias for ``update_query()`` method).\r\n  `#435 <https://github.com/aio-libs/yarl/issues/435>`_\r\n- Allow use of sequences such as ``list`` and ``tuple`` in the values\r\n  of a mapping such as ``dict`` to represent that a key has many values::\r\n\r\n      url = URL(\"http://example.com\")\r\n      assert url.with_query({\"a\": [1, 2]}) == URL(\"http://example.com/?a=1&a=2\")\r\n\r\n  `#443 <https://github.com/aio-libs/yarl/issues/443>`_\r\n- Support ``URL.build()`` with scheme and path (creates a relative URL).\r\n  `#464 <https://github.com/aio-libs/yarl/issues/464>`_\r\n- Cache slow IDNA encode/decode calls.\r\n  `#476 <https://github.com/aio-libs/yarl/issues/476>`_\r\n- Add ``@final`` / ``Final`` type hints\r\n  `#477 <https://github.com/aio-libs/yarl/issues/477>`_\r\n- Support URL authority/raw_authority properties and authority argument of ``URL.build()`` method.\r\n  `#478 <https://github.com/aio-libs/yarl/issues/478>`_\r\n- Hide the library implementation details, make the exposed public list very clean.\r\n  `#483 <https://github.com/aio-libs/yarl/issues/483>`_\r\n\r\n\r\nBugfixes\r\n--------\r\n\r\n- Fix tests with newer Python (3.7.6, 3.8.1 and 3.9.0+).\r\n  `#409 <https://github.com/aio-libs/yarl/issues/409>`_\r\n- Fix a bug where query component, passed in a form of mapping or sequence, is unquoted in unexpected way.\r\n  `#426 <https://github.com/aio-libs/yarl/issues/426>`_\r\n- Hide ``Query`` and ``QueryVariable`` type aliases in ``__init__.pyi``, now they are prefixed with underscore.\r\n  `#431 <https://github.com/aio-libs/yarl/issues/431>`_\r\n- Keep IPv6 brackets after updating port/user/password.\r\n  `#451 <https://github.com/aio-libs/yarl/issues/451>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.4.2 (2019-12-05)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Workaround for missing ``str.isascii()`` in Python 3.6\r\n  `#389 <https://github.com/aio-libs/yarl/issues/389>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.4.1 (2019-11-29)\r\n==================\r\n\r\n* Fix regression, make the library work on Python 3.5 and 3.6 again.\r\n\r\n1.4.0 (2019-11-29)\r\n==================\r\n\r\n* Distinguish an empty password in URL from a password not provided at all (#262)\r\n\r\n* Fixed annotations for optional parameters of ``URL.build`` (#309)\r\n\r\n* Use None as default value of ``user`` parameter of ``URL.build`` (#309)\r\n\r\n* Enforce building C Accelerated modules when installing from source tarball, use\r\n  ``YARL_NO_EXTENSIONS`` environment variable for falling back to (slower) Pure Python\r\n  implementation (#329)\r\n\r\n* Drop Python 3.5 support\r\n\r\n* Fix quoting of plus in path by pure python version (#339)\r\n\r\n* Don't create a new URL if fragment is unchanged (#292)\r\n\r\n* Included in error message the path that produces starting slash forbidden error (#376)\r\n\r\n* Skip slow IDNA encoding for ASCII-only strings (#387)\r\n\r\n\r\n1.3.0 (2018-12-11)\r\n==================\r\n\r\n* Fix annotations for ``query`` parameter (#207)\r\n\r\n* An incoming query sequence can have int variables (the same as for\r\n  Mapping type) (#208)\r\n\r\n* Add ``URL.explicit_port`` property (#218)\r\n\r\n* Give a friendlier error when port can't be converted to int (#168)\r\n\r\n* ``bool(URL())`` now returns ``False`` (#272)\r\n\r\n1.2.6 (2018-06-14)\r\n==================\r\n\r\n* Drop Python 3.4 trove classifier (#205)\r\n\r\n1.2.5 (2018-05-23)\r\n==================\r\n\r\n* Fix annotations for ``build`` (#199)\r\n\r\n1.2.4 (2018-05-08)\r\n==================\r\n\r\n* Fix annotations for ``cached_property`` (#195)\r\n\r\n1.2.3 (2018-05-03)\r\n==================\r\n\r\n* Accept ``str`` subclasses in ``URL`` constructor (#190)\r\n\r\n1.2.2 (2018-05-01)\r\n==================\r\n\r\n* Fix build\r\n\r\n1.2.1 (2018-04-30)\r\n==================\r\n\r\n* Pin minimal required Python to 3.5.3 (#189)\r\n\r\n1.2.0 (2018-04-30)\r\n==================\r\n\r\n* Forbid inheritance, replace ``__init__`` with ``__new__`` (#171)\r\n\r\n* Support PEP-561 (provide type hinting marker) (#182)\r\n\r\n1.1.1 (2018-02-17)\r\n==================\r\n\r\n* Fix performance regression: don't encode empty ``netloc`` (#170)\r\n\r\n1.1.0 (2018-01-21)\r\n==================\r\n\r\n* Make pure Python quoter consistent with Cython version (#162)\r\n\r\n1.0.0 (2018-01-15)\r\n==================\r\n\r\n* Use fast path if quoted string does not need requoting (#154)\r\n\r\n* Speed up quoting/unquoting by ``_Quoter`` and ``_Unquoter`` classes (#155)\r\n\r\n* Drop ``yarl.quote`` and ``yarl.unquote`` public functions (#155)\r\n\r\n* Add custom string writer, reuse static buffer if available (#157)\r\n  Code is 50-80 times faster than Pure Python version (was 4-5 times faster)\r\n\r\n* Don't recode IP zone (#144)\r\n\r\n* Support ``encoded=True`` in ``yarl.URL.build()`` (#158)\r\n\r\n* Fix updating query with multiple keys (#160)\r\n\r\n0.18.0 (2018-01-10)\r\n===================\r\n\r\n* Fallback to IDNA 2003 if domain name is not IDNA 2008 compatible (#152)\r\n\r\n0.17.0 (2017-12-30)\r\n===================\r\n\r\n* Use IDNA 2008 for domain name processing (#149)\r\n\r\n0.16.0 (2017-12-07)\r\n===================\r\n\r\n* Fix raising ``TypeError`` by ``url.query_string()`` after\r\n  ``url.with_query({})`` (empty mapping) (#141)\r\n\r\n0.15.0 (2017-11-23)\r\n===================\r\n\r\n* Add ``raw_path_qs`` attribute (#137)\r\n\r\n0.14.2 (2017-11-14)\r\n===================\r\n\r\n* Restore ``strict`` parameter as no-op in ``quote`` / ``unquote``\r\n\r\n0.14.1 (2017-11-13)\r\n===================\r\n\r\n* Restore ``strict`` parameter as no-op for sake of compatibility with\r\n  aiohttp 2.2\r\n\r\n0.14.0 (2017-11-11)\r\n===================\r\n\r\n* Drop strict mode (#123)\r\n\r\n* Fix ``\"ValueError: Unallowed PCT %\"`` when there's a ``\"%\"`` in the URL (#124)\r\n\r\n0.13.0 (2017-10-01)\r\n===================\r\n\r\n* Document ``encoded`` parameter (#102)\r\n\r\n* Support relative URLs like ``'?key=value'`` (#100)\r\n\r\n* Unsafe encoding for QS fixed. Encode ``;`` character in value parameter (#104)\r\n\r\n* Process passwords without user names (#95)\r\n\r\n0.12.0 (2017-06-26)\r\n===================\r\n\r\n* Properly support paths without leading slash in ``URL.with_path()`` (#90)\r\n\r\n* Enable type annotation checks\r\n\r\n0.11.0 (2017-06-26)\r\n===================\r\n\r\n* Normalize path (#86)\r\n\r\n* Clear query and fragment parts in ``.with_path()`` (#85)\r\n\r\n0.10.3 (2017-06-13)\r\n===================\r\n\r\n* Prevent double URL arguments unquoting (#83)\r\n\r\n0.10.2 (2017-05-05)\r\n===================\r\n\r\n* Unexpected hash behavior (#75)\r\n\r\n\r\n0.10.1 (2017-05-03)\r\n===================\r\n\r\n* Unexpected compare behavior (#73)\r\n\r\n* Do not quote or unquote + if not a query string. (#74)\r\n\r\n\r\n0.10.0 (2017-03-14)\r\n===================\r\n\r\n* Added ``URL.build`` class method (#58)\r\n\r\n* Added ``path_qs`` attribute (#42)\r\n\r\n\r\n0.9.8 (2017-02-16)\r\n==================\r\n\r\n* Do not quote ``:`` in path\r\n\r\n\r\n0.9.7 (2017-02-16)\r\n==================\r\n\r\n* Load from pickle without _cache (#56)\r\n\r\n* Percent-encoded pluses in path variables become spaces (#59)\r\n\r\n\r\n0.9.6 (2017-02-15)\r\n==================\r\n\r\n* Revert backward incompatible change (BaseURL)\r\n\r\n\r\n0.9.5 (2017-02-14)\r\n==================\r\n\r\n* Fix BaseURL rich comparison support\r\n\r\n\r\n0.9.4 (2017-02-14)\r\n==================\r\n\r\n* Use BaseURL\r\n\r\n\r\n0.9.3 (2017-02-14)\r\n==================\r\n\r\n* Added BaseURL\r\n\r\n\r\n0.9.2 (2017-02-08)\r\n==================\r\n\r\n* Remove debug print\r\n\r\n\r\n0.9.1 (2017-02-07)\r\n==================\r\n\r\n* Do not lose tail chars (#45)\r\n\r\n\r\n0.9.0 (2017-02-07)\r\n==================\r\n\r\n* Allow to quote ``%`` in non strict mode (#21)\r\n\r\n* Incorrect parsing of query parameters with %3B (;) inside (#34)\r\n\r\n* Fix core dumps (#41)\r\n\r\n* ``tmpbuf`` - compiling error (#43)\r\n\r\n* Added ``URL.update_path()`` method\r\n\r\n* Added ``URL.update_query()`` method (#47)\r\n\r\n\r\n0.8.1 (2016-12-03)\r\n==================\r\n\r\n* Fix broken aiohttp: revert back ``quote`` / ``unquote``.\r\n\r\n\r\n0.8.0 (2016-12-03)\r\n==================\r\n\r\n* Support more verbose error messages in ``.with_query()`` (#24)\r\n\r\n* Don't percent-encode ``@`` and ``:`` in path (#32)\r\n\r\n* Don't expose ``yarl.quote`` and ``yarl.unquote``, these functions are\r\n  part of private API\r\n\r\n0.7.1 (2016-11-18)\r\n==================\r\n\r\n* Accept not only ``str`` but all classes inherited from ``str`` also (#25)\r\n\r\n0.7.0 (2016-11-07)\r\n==================\r\n\r\n* Accept ``int`` as value for ``.with_query()``\r\n\r\n0.6.0 (2016-11-07)\r\n==================\r\n\r\n* Explicitly use UTF8 encoding in ``setup.py`` (#20)\r\n* Properly unquote non-UTF8 strings (#19)\r\n\r\n0.5.3 (2016-11-02)\r\n==================\r\n\r\n* Don't use ``typing.NamedTuple`` fields but indexes on URL construction\r\n\r\n0.5.2 (2016-11-02)\r\n==================\r\n\r\n* Inline ``_encode`` class method\r\n\r\n0.5.1 (2016-11-02)\r\n==================\r\n\r\n* Make URL construction faster by removing extra classmethod calls\r\n\r\n0.5.0 (2016-11-02)\r\n==================\r\n\r\n* Add Cython optimization for quoting/unquoting\r\n* Provide binary wheels\r\n\r\n0.4.3 (2016-09-29)\r\n==================\r\n\r\n* Fix typing stubs\r\n\r\n0.4.2 (2016-09-29)\r\n==================\r\n\r\n* Expose ``quote()`` and ``unquote()`` as public API\r\n\r\n0.4.1 (2016-09-28)\r\n==================\r\n\r\n* Support empty values in query (``'/path?arg'``)\r\n\r\n0.4.0 (2016-09-27)\r\n==================\r\n\r\n* Introduce ``relative()`` (#16)\r\n\r\n0.3.2 (2016-09-27)\r\n==================\r\n\r\n* Typo fixes #15\r\n\r\n0.3.1 (2016-09-26)\r\n==================\r\n\r\n* Support sequence of pairs as ``with_query()`` parameter\r\n\r\n0.3.0 (2016-09-26)\r\n==================\r\n\r\n* Introduce ``is_default_port()``\r\n\r\n0.2.1 (2016-09-26)\r\n==================\r\n\r\n* Raise ValueError for URLs like 'http://:8080/'\r\n\r\n0.2.0 (2016-09-18)\r\n==================\r\n\r\n* Avoid doubling slashes when joining paths (#13)\r\n\r\n* Appending path starting from slash is forbidden (#12)\r\n\r\n0.1.4 (2016-09-09)\r\n==================\r\n\r\n* Add ``kwargs`` support for ``with_query()`` (#10)\r\n\r\n0.1.3 (2016-09-07)\r\n==================\r\n\r\n* Document ``with_query()``, ``with_fragment()`` and ``origin()``\r\n\r\n* Allow ``None`` for ``with_query()`` and ``with_fragment()``\r\n\r\n0.1.2 (2016-09-07)\r\n==================\r\n\r\n* Fix links, tune docs theme.\r\n\r\n0.1.1 (2016-09-06)\r\n==================\r\n\r\n* Update README, old version used obsolete API\r\n\r\n0.1.0 (2016-09-06)\r\n==================\r\n\r\n* The library was deeply refactored, bytes are gone away but all\r\n  accepted strings are encoded if needed.\r\n\r\n0.0.1 (2016-08-30)\r\n==================\r\n\r\n* The first release.\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "cython",
          "cext",
          "yarl"
        ],
        "home_page": "https://github.com/aio-libs/yarl",
        "author": "Andrew Svetlov",
        "author_email": "andrew.svetlov@gmail.com",
        "maintainer": "aiohttp team <team@aiohttp.org>",
        "maintainer_email": "team@aiohttp.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE",
          "NOTICE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "idna>=2.0",
          "multidict>=4.0",
          "propcache>=0.2.1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat: Matrix, https://matrix.to/#/#aio-libs:matrix.org",
          "Chat: Matrix Space, https://matrix.to/#/#aio-libs-space:matrix.org",
          "CI: GitHub Workflows, https://github.com/aio-libs/yarl/actions?query=branch:master",
          "Code of Conduct, https://github.com/aio-libs/.github/blob/master/CODE_OF_CONDUCT.md",
          "Coverage: codecov, https://codecov.io/github/aio-libs/yarl",
          "Docs: Changelog, https://yarl.aio-libs.org/en/latest/changes/",
          "Docs: RTD, https://yarl.aio-libs.org",
          "GitHub: issues, https://github.com/aio-libs/yarl/issues",
          "GitHub: repo, https://github.com/aio-libs/yarl"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/9e/dd/d0ee25348ac58245ee9f90b6f3cbb666bf01f69be7e0911f9851bddbda16/fastapi-0.129.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b4946880e48f462692b31c083be0432275cbfb6e2274566b1be91479cc1a84ec",
          "hashes": {
            "sha256": "b4946880e48f462692b31c083be0432275cbfb6e2274566b1be91479cc1a84ec"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "fastapi",
        "version": "0.129.0",
        "summary": "FastAPI framework, high performance, easy to learn, fast to code, ready for production",
        "description": "<p align=\"center\">\n  <a href=\"https://fastapi.tiangolo.com\"><img src=\"https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png\" alt=\"FastAPI\"></a>\n</p>\n<p align=\"center\">\n    <em>FastAPI framework, high performance, easy to learn, fast to code, ready for production</em>\n</p>\n<p align=\"center\">\n<a href=\"https://github.com/fastapi/fastapi/actions?query=workflow%3ATest+event%3Apush+branch%3Amaster\" target=\"_blank\">\n    <img src=\"https://github.com/fastapi/fastapi/actions/workflows/test.yml/badge.svg?event=push&branch=master\" alt=\"Test\">\n</a>\n<a href=\"https://coverage-badge.samuelcolvin.workers.dev/redirect/fastapi/fastapi\" target=\"_blank\">\n    <img src=\"https://coverage-badge.samuelcolvin.workers.dev/fastapi/fastapi.svg\" alt=\"Coverage\">\n</a>\n<a href=\"https://pypi.org/project/fastapi\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/v/fastapi?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n</a>\n<a href=\"https://pypi.org/project/fastapi\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/pyversions/fastapi.svg?color=%2334D058\" alt=\"Supported Python versions\">\n</a>\n</p>\n\n---\n\n**Documentation**: <a href=\"https://fastapi.tiangolo.com\" target=\"_blank\">https://fastapi.tiangolo.com</a>\n\n**Source Code**: <a href=\"https://github.com/fastapi/fastapi\" target=\"_blank\">https://github.com/fastapi/fastapi</a>\n\n---\n\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python based on standard Python type hints.\n\nThe key features are:\n\n* **Fast**: Very high performance, on par with **NodeJS** and **Go** (thanks to Starlette and Pydantic). [One of the fastest Python frameworks available](#performance).\n* **Fast to code**: Increase the speed to develop features by about 200% to 300%. *\n* **Fewer bugs**: Reduce about 40% of human (developer) induced errors. *\n* **Intuitive**: Great editor support. <dfn title=\"also known as auto-complete, autocompletion, IntelliSense\">Completion</dfn> everywhere. Less time debugging.\n* **Easy**: Designed to be easy to use and learn. Less time reading docs.\n* **Short**: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.\n* **Robust**: Get production-ready code. With automatic interactive documentation.\n* **Standards-based**: Based on (and fully compatible with) the open standards for APIs: <a href=\"https://github.com/OAI/OpenAPI-Specification\" class=\"external-link\" target=\"_blank\">OpenAPI</a> (previously known as Swagger) and <a href=\"https://json-schema.org/\" class=\"external-link\" target=\"_blank\">JSON Schema</a>.\n\n<small>* estimation based on tests conducted by an internal development team, building production applications.</small>\n\n## Sponsors\n\n<!-- sponsors -->\n### Keystone Sponsor\n\n<a href=\"https://fastapicloud.com\" target=\"_blank\" title=\"FastAPI Cloud. By the same team behind FastAPI. You code. We Cloud.\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/fastapicloud.png\"></a>\n\n### Gold and Silver Sponsors\n\n<a href=\"https://blockbee.io?ref=fastapi\" target=\"_blank\" title=\"BlockBee Cryptocurrency Payment Gateway\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/blockbee.png\"></a>\n<a href=\"https://github.com/scalar/scalar/?utm_source=fastapi&utm_medium=website&utm_campaign=main-badge\" target=\"_blank\" title=\"Scalar: Beautiful Open-Source API References from Swagger/OpenAPI files\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/scalar.svg\"></a>\n<a href=\"https://www.propelauth.com/?utm_source=fastapi&utm_campaign=1223&utm_medium=mainbadge\" target=\"_blank\" title=\"Auth, user management and more for your B2B product\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/propelauth.png\"></a>\n<a href=\"https://zuplo.link/fastapi-gh\" target=\"_blank\" title=\"Zuplo: Deploy, Secure, Document, and Monetize your FastAPI\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/zuplo.png\"></a>\n<a href=\"https://liblab.com?utm_source=fastapi\" target=\"_blank\" title=\"liblab - Generate SDKs from FastAPI\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/liblab.png\"></a>\n<a href=\"https://docs.render.com/deploy-fastapi?utm_source=deploydoc&utm_medium=referral&utm_campaign=fastapi\" target=\"_blank\" title=\"Deploy & scale any full-stack web app on Render. Focus on building apps, not infra.\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/render.svg\"></a>\n<a href=\"https://www.coderabbit.ai/?utm_source=fastapi&utm_medium=badge&utm_campaign=fastapi\" target=\"_blank\" title=\"Cut Code Review Time & Bugs in Half with CodeRabbit\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/coderabbit.png\"></a>\n<a href=\"https://subtotal.com/?utm_source=fastapi&utm_medium=sponsorship&utm_campaign=open-source\" target=\"_blank\" title=\"The Gold Standard in Retail Account Linking\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/subtotal.svg\"></a>\n<a href=\"https://docs.railway.com/guides/fastapi?utm_medium=integration&utm_source=docs&utm_campaign=fastapi\" target=\"_blank\" title=\"Deploy enterprise applications at startup speed\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/railway.png\"></a>\n<a href=\"https://serpapi.com/?utm_source=fastapi_website\" target=\"_blank\" title=\"SerpApi: Web Search API\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/serpapi.png\"></a>\n<a href=\"https://www.greptile.com/?utm_source=fastapi&utm_medium=sponsorship&utm_campaign=fastapi_sponsor_page\" target=\"_blank\" title=\"Greptile: The AI Code Reviewer\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/greptile.png\"></a>\n<a href=\"https://databento.com/?utm_source=fastapi&utm_medium=sponsor&utm_content=display\" target=\"_blank\" title=\"Pay as you go for market data\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/databento.svg\"></a>\n<a href=\"https://speakeasy.com/editor?utm_source=fastapi+repo&utm_medium=github+sponsorship\" target=\"_blank\" title=\"SDKs for your API | Speakeasy\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/speakeasy.png\"></a>\n<a href=\"https://www.svix.com/\" target=\"_blank\" title=\"Svix - Webhooks as a service\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/svix.svg\"></a>\n<a href=\"https://www.stainlessapi.com/?utm_source=fastapi&utm_medium=referral\" target=\"_blank\" title=\"Stainless | Generate best-in-class SDKs\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/stainless.png\"></a>\n<a href=\"https://www.permit.io/blog/implement-authorization-in-fastapi?utm_source=github&utm_medium=referral&utm_campaign=fastapi\" target=\"_blank\" title=\"Fine-Grained Authorization for FastAPI\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/permit.png\"></a>\n<a href=\"https://www.interviewpal.com/?utm_source=fastapi&utm_medium=open-source&utm_campaign=dev-hiring\" target=\"_blank\" title=\"InterviewPal - AI Interview Coach for Engineers and Devs\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/interviewpal.png\"></a>\n<a href=\"https://dribia.com/en/\" target=\"_blank\" title=\"Dribia - Data Science within your reach\"><img src=\"https://fastapi.tiangolo.com/img/sponsors/dribia.png\"></a>\n\n<!-- /sponsors -->\n\n<a href=\"https://fastapi.tiangolo.com/fastapi-people/#sponsors\" class=\"external-link\" target=\"_blank\">Other sponsors</a>\n\n## Opinions\n\n\"_[...] I'm using **FastAPI** a ton these days. [...] I'm actually planning to use it for all of my team's **ML services at Microsoft**. Some of them are getting integrated into the core **Windows** product and some **Office** products._\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Kabir Khan - <strong>Microsoft</strong> <a href=\"https://github.com/fastapi/fastapi/pull/26\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_We adopted the **FastAPI** library to spawn a **REST** server that can be queried to obtain **predictions**. [for Ludwig]_\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Piero Molino, Yaroslav Dudin, and Sai Sumanth Miryala - <strong>Uber</strong> <a href=\"https://eng.uber.com/ludwig-v0-2/\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_**Netflix** is pleased to announce the open-source release of our **crisis management** orchestration framework: **Dispatch**! [built with **FastAPI**]_\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Kevin Glisson, Marc Vilanova, Forest Monsen - <strong>Netflix</strong> <a href=\"https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_Iâ€™m over the moon excited about **FastAPI**. Itâ€™s so fun!_\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Brian Okken - <strong><a href=\"https://pythonbytes.fm/episodes/show/123/time-to-right-the-py-wrongs?time_in_sec=855\" target=\"_blank\">Python Bytes</a> podcast host</strong> <a href=\"https://x.com/brianokken/status/1112220079972728832\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_Honestly, what you've built looks super solid and polished. In many ways, it's what I wanted **Hug** to be - it's really inspiring to see someone build that._\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Timothy Crosley - <strong><a href=\"https://github.com/hugapi/hug\" target=\"_blank\">Hug</a> creator</strong> <a href=\"https://news.ycombinator.com/item?id=19455465\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_If you're looking to learn one **modern framework** for building REST APIs, check out **FastAPI** [...] It's fast, easy to use and easy to learn [...]_\"\n\n\"_We've switched over to **FastAPI** for our **APIs** [...] I think you'll like it [...]_\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Ines Montani - Matthew Honnibal - <strong><a href=\"https://explosion.ai\" target=\"_blank\">Explosion AI</a> founders - <a href=\"https://spacy.io\" target=\"_blank\">spaCy</a> creators</strong> <a href=\"https://x.com/_inesmontani/status/1144173225322143744\" target=\"_blank\"><small>(ref)</small></a> - <a href=\"https://x.com/honnibal/status/1144031421859655680\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n\"_If anyone is looking to build a production Python API, I would highly recommend **FastAPI**. It is **beautifully designed**, **simple to use** and **highly scalable**, it has become a **key component** in our API first development strategy and is driving many automations and services such as our Virtual TAC Engineer._\"\n\n<div style=\"text-align: right; margin-right: 10%;\">Deon Pillsbury - <strong>Cisco</strong> <a href=\"https://www.linkedin.com/posts/deonpillsbury_cisco-cx-python-activity-6963242628536487936-trAp/\" target=\"_blank\"><small>(ref)</small></a></div>\n\n---\n\n## FastAPI mini documentary\n\nThere's a <a href=\"https://www.youtube.com/watch?v=mpR8ngthqiE\" class=\"external-link\" target=\"_blank\">FastAPI mini documentary</a> released at the end of 2025, you can watch it online:\n\n<a href=\"https://www.youtube.com/watch?v=mpR8ngthqiE\" target=\"_blank\"><img src=\"https://fastapi.tiangolo.com/img/fastapi-documentary.jpg\" alt=\"FastAPI Mini Documentary\"></a>\n\n## **Typer**, the FastAPI of CLIs\n\n<a href=\"https://typer.tiangolo.com\" target=\"_blank\"><img src=\"https://typer.tiangolo.com/img/logo-margin/logo-margin-vector.svg\" style=\"width: 20%;\"></a>\n\nIf you are building a <abbr title=\"Command Line Interface\">CLI</abbr> app to be used in the terminal instead of a web API, check out <a href=\"https://typer.tiangolo.com/\" class=\"external-link\" target=\"_blank\">**Typer**</a>.\n\n**Typer** is FastAPI's little sibling. And it's intended to be the **FastAPI of CLIs**. âŒ¨ï¸ ðŸš€\n\n## Requirements\n\nFastAPI stands on the shoulders of giants:\n\n* <a href=\"https://www.starlette.dev/\" class=\"external-link\" target=\"_blank\">Starlette</a> for the web parts.\n* <a href=\"https://docs.pydantic.dev/\" class=\"external-link\" target=\"_blank\">Pydantic</a> for the data parts.\n\n## Installation\n\nCreate and activate a <a href=\"https://fastapi.tiangolo.com/virtual-environments/\" class=\"external-link\" target=\"_blank\">virtual environment</a> and then install FastAPI:\n\n<div class=\"termy\">\n\n```console\n$ pip install \"fastapi[standard]\"\n\n---> 100%\n```\n\n</div>\n\n**Note**: Make sure you put `\"fastapi[standard]\"` in quotes to ensure it works in all terminals.\n\n## Example\n\n### Create it\n\nCreate a file `main.py` with:\n\n```Python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: str | None = None):\n    return {\"item_id\": item_id, \"q\": q}\n```\n\n<details markdown=\"1\">\n<summary>Or use <code>async def</code>...</summary>\n\nIf your code uses `async` / `await`, use `async def`:\n\n```Python hl_lines=\"7  12\"\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int, q: str | None = None):\n    return {\"item_id\": item_id, \"q\": q}\n```\n\n**Note**:\n\nIf you don't know, check the _\"In a hurry?\"_ section about <a href=\"https://fastapi.tiangolo.com/async/#in-a-hurry\" target=\"_blank\">`async` and `await` in the docs</a>.\n\n</details>\n\n### Run it\n\nRun the server with:\n\n<div class=\"termy\">\n\n```console\n$ fastapi dev main.py\n\n â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI CLI - Development mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n â”‚                                                     â”‚\n â”‚  Serving at: http://127.0.0.1:8000                  â”‚\n â”‚                                                     â”‚\n â”‚  API docs: http://127.0.0.1:8000/docs               â”‚\n â”‚                                                     â”‚\n â”‚  Running in development mode, for production use:   â”‚\n â”‚                                                     â”‚\n â”‚  fastapi run                                        â”‚\n â”‚                                                     â”‚\n â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\nINFO:     Will watch for changes in these directories: ['/home/user/code/awesomeapp']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [2248755] using WatchFiles\nINFO:     Started server process [2248757]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n```\n\n</div>\n\n<details markdown=\"1\">\n<summary>About the command <code>fastapi dev main.py</code>...</summary>\n\nThe command `fastapi dev` reads your `main.py` file, detects the **FastAPI** app in it, and starts a server using <a href=\"https://www.uvicorn.dev\" class=\"external-link\" target=\"_blank\">Uvicorn</a>.\n\nBy default, `fastapi dev` will start with auto-reload enabled for local development.\n\nYou can read more about it in the <a href=\"https://fastapi.tiangolo.com/fastapi-cli/\" target=\"_blank\">FastAPI CLI docs</a>.\n\n</details>\n\n### Check it\n\nOpen your browser at <a href=\"http://127.0.0.1:8000/items/5?q=somequery\" class=\"external-link\" target=\"_blank\">http://127.0.0.1:8000/items/5?q=somequery</a>.\n\nYou will see the JSON response as:\n\n```JSON\n{\"item_id\": 5, \"q\": \"somequery\"}\n```\n\nYou already created an API that:\n\n* Receives HTTP requests in the _paths_ `/` and `/items/{item_id}`.\n* Both _paths_ take `GET` <em>operations</em> (also known as HTTP _methods_).\n* The _path_ `/items/{item_id}` has a _path parameter_ `item_id` that should be an `int`.\n* The _path_ `/items/{item_id}` has an optional `str` _query parameter_ `q`.\n\n### Interactive API docs\n\nNow go to <a href=\"http://127.0.0.1:8000/docs\" class=\"external-link\" target=\"_blank\">http://127.0.0.1:8000/docs</a>.\n\nYou will see the automatic interactive API documentation (provided by <a href=\"https://github.com/swagger-api/swagger-ui\" class=\"external-link\" target=\"_blank\">Swagger UI</a>):\n\n![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)\n\n### Alternative API docs\n\nAnd now, go to <a href=\"http://127.0.0.1:8000/redoc\" class=\"external-link\" target=\"_blank\">http://127.0.0.1:8000/redoc</a>.\n\nYou will see the alternative automatic documentation (provided by <a href=\"https://github.com/Rebilly/ReDoc\" class=\"external-link\" target=\"_blank\">ReDoc</a>):\n\n![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)\n\n## Example upgrade\n\nNow modify the file `main.py` to receive a body from a `PUT` request.\n\nDeclare the body using standard Python types, thanks to Pydantic.\n\n```Python hl_lines=\"2  7-10 23-25\"\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\n\nclass Item(BaseModel):\n    name: str\n    price: float\n    is_offer: bool | None = None\n\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: str | None = None):\n    return {\"item_id\": item_id, \"q\": q}\n\n\n@app.put(\"/items/{item_id}\")\ndef update_item(item_id: int, item: Item):\n    return {\"item_name\": item.name, \"item_id\": item_id}\n```\n\nThe `fastapi dev` server should reload automatically.\n\n### Interactive API docs upgrade\n\nNow go to <a href=\"http://127.0.0.1:8000/docs\" class=\"external-link\" target=\"_blank\">http://127.0.0.1:8000/docs</a>.\n\n* The interactive API documentation will be automatically updated, including the new body:\n\n![Swagger UI](https://fastapi.tiangolo.com/img/index/index-03-swagger-02.png)\n\n* Click on the button \"Try it out\", it allows you to fill the parameters and directly interact with the API:\n\n![Swagger UI interaction](https://fastapi.tiangolo.com/img/index/index-04-swagger-03.png)\n\n* Then click on the \"Execute\" button, the user interface will communicate with your API, send the parameters, get the results and show them on the screen:\n\n![Swagger UI interaction](https://fastapi.tiangolo.com/img/index/index-05-swagger-04.png)\n\n### Alternative API docs upgrade\n\nAnd now, go to <a href=\"http://127.0.0.1:8000/redoc\" class=\"external-link\" target=\"_blank\">http://127.0.0.1:8000/redoc</a>.\n\n* The alternative documentation will also reflect the new query parameter and body:\n\n![ReDoc](https://fastapi.tiangolo.com/img/index/index-06-redoc-02.png)\n\n### Recap\n\nIn summary, you declare **once** the types of parameters, body, etc. as function parameters.\n\nYou do that with standard modern Python types.\n\nYou don't have to learn a new syntax, the methods or classes of a specific library, etc.\n\nJust standard **Python**.\n\nFor example, for an `int`:\n\n```Python\nitem_id: int\n```\n\nor for a more complex `Item` model:\n\n```Python\nitem: Item\n```\n\n...and with that single declaration you get:\n\n* Editor support, including:\n    * Completion.\n    * Type checks.\n* Validation of data:\n    * Automatic and clear errors when the data is invalid.\n    * Validation even for deeply nested JSON objects.\n* <dfn title=\"also known as: serialization, parsing, marshalling\">Conversion</dfn> of input data: coming from the network to Python data and types. Reading from:\n    * JSON.\n    * Path parameters.\n    * Query parameters.\n    * Cookies.\n    * Headers.\n    * Forms.\n    * Files.\n* <dfn title=\"also known as: serialization, parsing, marshalling\">Conversion</dfn> of output data: converting from Python data and types to network data (as JSON):\n    * Convert Python types (`str`, `int`, `float`, `bool`, `list`, etc).\n    * `datetime` objects.\n    * `UUID` objects.\n    * Database models.\n    * ...and many more.\n* Automatic interactive API documentation, including 2 alternative user interfaces:\n    * Swagger UI.\n    * ReDoc.\n\n---\n\nComing back to the previous code example, **FastAPI** will:\n\n* Validate that there is an `item_id` in the path for `GET` and `PUT` requests.\n* Validate that the `item_id` is of type `int` for `GET` and `PUT` requests.\n    * If it is not, the client will see a useful, clear error.\n* Check if there is an optional query parameter named `q` (as in `http://127.0.0.1:8000/items/foo?q=somequery`) for `GET` requests.\n    * As the `q` parameter is declared with `= None`, it is optional.\n    * Without the `None` it would be required (as is the body in the case with `PUT`).\n* For `PUT` requests to `/items/{item_id}`, read the body as JSON:\n    * Check that it has a required attribute `name` that should be a `str`.\n    * Check that it has a required attribute `price` that has to be a `float`.\n    * Check that it has an optional attribute `is_offer`, that should be a `bool`, if present.\n    * All this would also work for deeply nested JSON objects.\n* Convert from and to JSON automatically.\n* Document everything with OpenAPI, that can be used by:\n    * Interactive documentation systems.\n    * Automatic client code generation systems, for many languages.\n* Provide 2 interactive documentation web interfaces directly.\n\n---\n\nWe just scratched the surface, but you already get the idea of how it all works.\n\nTry changing the line with:\n\n```Python\n    return {\"item_name\": item.name, \"item_id\": item_id}\n```\n\n...from:\n\n```Python\n        ... \"item_name\": item.name ...\n```\n\n...to:\n\n```Python\n        ... \"item_price\": item.price ...\n```\n\n...and see how your editor will auto-complete the attributes and know their types:\n\n![editor support](https://fastapi.tiangolo.com/img/vscode-completion.png)\n\nFor a more complete example including more features, see the <a href=\"https://fastapi.tiangolo.com/tutorial/\">Tutorial - User Guide</a>.\n\n**Spoiler alert**: the tutorial - user guide includes:\n\n* Declaration of **parameters** from other different places as: **headers**, **cookies**, **form fields** and **files**.\n* How to set **validation constraints** as `maximum_length` or `regex`.\n* A very powerful and easy to use **<dfn title=\"also known as components, resources, providers, services, injectables\">Dependency Injection</dfn>** system.\n* Security and authentication, including support for **OAuth2** with **JWT tokens** and **HTTP Basic** auth.\n* More advanced (but equally easy) techniques for declaring **deeply nested JSON models** (thanks to Pydantic).\n* **GraphQL** integration with <a href=\"https://strawberry.rocks\" class=\"external-link\" target=\"_blank\">Strawberry</a> and other libraries.\n* Many extra features (thanks to Starlette) as:\n    * **WebSockets**\n    * extremely easy tests based on HTTPX and `pytest`\n    * **CORS**\n    * **Cookie Sessions**\n    * ...and more.\n\n### Deploy your app (optional)\n\nYou can optionally deploy your FastAPI app to <a href=\"https://fastapicloud.com\" class=\"external-link\" target=\"_blank\">FastAPI Cloud</a>, go and join the waiting list if you haven't. ðŸš€\n\nIf you already have a **FastAPI Cloud** account (we invited you from the waiting list ðŸ˜‰), you can deploy your application with one command.\n\nBefore deploying, make sure you are logged in:\n\n<div class=\"termy\">\n\n```console\n$ fastapi login\n\nYou are logged in to FastAPI Cloud ðŸš€\n```\n\n</div>\n\nThen deploy your app:\n\n<div class=\"termy\">\n\n```console\n$ fastapi deploy\n\nDeploying to FastAPI Cloud...\n\nâœ… Deployment successful!\n\nðŸ” Ready the chicken! Your app is ready at https://myapp.fastapicloud.dev\n```\n\n</div>\n\nThat's it! Now you can access your app at that URL. âœ¨\n\n#### About FastAPI Cloud\n\n**<a href=\"https://fastapicloud.com\" class=\"external-link\" target=\"_blank\">FastAPI Cloud</a>** is built by the same author and team behind **FastAPI**.\n\nIt streamlines the process of **building**, **deploying**, and **accessing** an API with minimal effort.\n\nIt brings the same **developer experience** of building apps with FastAPI to **deploying** them to the cloud. ðŸŽ‰\n\nFastAPI Cloud is the primary sponsor and funding provider for the *FastAPI and friends* open source projects. âœ¨\n\n#### Deploy to other cloud providers\n\nFastAPI is open source and based on standards. You can deploy FastAPI apps to any cloud provider you choose.\n\nFollow your cloud provider's guides to deploy FastAPI apps with them. ðŸ¤“\n\n## Performance\n\nIndependent TechEmpower benchmarks show **FastAPI** applications running under Uvicorn as <a href=\"https://www.techempower.com/benchmarks/#section=test&runid=7464e520-0dc2-473d-bd34-dbdfd7e85911&hw=ph&test=query&l=zijzen-7\" class=\"external-link\" target=\"_blank\">one of the fastest Python frameworks available</a>, only below Starlette and Uvicorn themselves (used internally by FastAPI). (*)\n\nTo understand more about it, see the section <a href=\"https://fastapi.tiangolo.com/benchmarks/\" class=\"internal-link\" target=\"_blank\">Benchmarks</a>.\n\n## Dependencies\n\nFastAPI depends on Pydantic and Starlette.\n\n### `standard` Dependencies\n\nWhen you install FastAPI with `pip install \"fastapi[standard]\"` it comes with the `standard` group of optional dependencies:\n\nUsed by Pydantic:\n\n* <a href=\"https://github.com/JoshData/python-email-validator\" target=\"_blank\"><code>email-validator</code></a> - for email validation.\n\nUsed by Starlette:\n\n* <a href=\"https://www.python-httpx.org\" target=\"_blank\"><code>httpx</code></a> - Required if you want to use the `TestClient`.\n* <a href=\"https://jinja.palletsprojects.com\" target=\"_blank\"><code>jinja2</code></a> - Required if you want to use the default template configuration.\n* <a href=\"https://github.com/Kludex/python-multipart\" target=\"_blank\"><code>python-multipart</code></a> - Required if you want to support form <dfn title=\"converting the string that comes from an HTTP request into Python data\">\"parsing\"</dfn>, with `request.form()`.\n\nUsed by FastAPI:\n\n* <a href=\"https://www.uvicorn.dev\" target=\"_blank\"><code>uvicorn</code></a> - for the server that loads and serves your application. This includes `uvicorn[standard]`, which includes some dependencies (e.g. `uvloop`) needed for high performance serving.\n* `fastapi-cli[standard]` - to provide the `fastapi` command.\n    * This includes `fastapi-cloud-cli`, which allows you to deploy your FastAPI application to <a href=\"https://fastapicloud.com\" class=\"external-link\" target=\"_blank\">FastAPI Cloud</a>.\n\n### Without `standard` Dependencies\n\nIf you don't want to include the `standard` optional dependencies, you can install with `pip install fastapi` instead of `pip install \"fastapi[standard]\"`.\n\n### Without `fastapi-cloud-cli`\n\nIf you want to install FastAPI with the standard dependencies but without the `fastapi-cloud-cli`, you can install with `pip install \"fastapi[standard-no-fastapi-cloud-cli]\"`.\n\n### Additional Optional Dependencies\n\nThere are some additional dependencies you might want to install.\n\nAdditional optional Pydantic dependencies:\n\n* <a href=\"https://docs.pydantic.dev/latest/usage/pydantic_settings/\" target=\"_blank\"><code>pydantic-settings</code></a> - for settings management.\n* <a href=\"https://docs.pydantic.dev/latest/usage/types/extra_types/extra_types/\" target=\"_blank\"><code>pydantic-extra-types</code></a> - for extra types to be used with Pydantic.\n\nAdditional optional FastAPI dependencies:\n\n* <a href=\"https://github.com/ijl/orjson\" target=\"_blank\"><code>orjson</code></a> - Required if you want to use `ORJSONResponse`.\n* <a href=\"https://github.com/esnme/ultrajson\" target=\"_blank\"><code>ujson</code></a> - Required if you want to use `UJSONResponse`.\n\n## License\n\nThis project is licensed under the terms of the MIT license.\n",
        "description_content_type": "text/markdown",
        "author_email": "=?utf-8?q?Sebasti=C3=A1n_Ram=C3=ADrez?= <tiangolo@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Application Frameworks",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development",
          "Typing :: Typed",
          "Development Status :: 4 - Beta",
          "Environment :: Web Environment",
          "Framework :: AsyncIO",
          "Framework :: FastAPI",
          "Framework :: Pydantic",
          "Framework :: Pydantic :: 2",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet :: WWW/HTTP :: HTTP Servers",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "starlette<1.0.0,>=0.40.0",
          "pydantic>=2.7.0",
          "typing-extensions>=4.8.0",
          "typing-inspection>=0.4.2",
          "annotated-doc>=0.0.2",
          "fastapi-cli[standard]>=0.0.8; extra == \"standard\"",
          "httpx<1.0.0,>=0.23.0; extra == \"standard\"",
          "jinja2>=3.1.5; extra == \"standard\"",
          "python-multipart>=0.0.18; extra == \"standard\"",
          "email-validator>=2.0.0; extra == \"standard\"",
          "uvicorn[standard]>=0.12.0; extra == \"standard\"",
          "pydantic-settings>=2.0.0; extra == \"standard\"",
          "pydantic-extra-types>=2.0.0; extra == \"standard\"",
          "fastapi-cli[standard-no-fastapi-cloud-cli]>=0.0.8; extra == \"standard-no-fastapi-cloud-cli\"",
          "httpx<1.0.0,>=0.23.0; extra == \"standard-no-fastapi-cloud-cli\"",
          "jinja2>=3.1.5; extra == \"standard-no-fastapi-cloud-cli\"",
          "python-multipart>=0.0.18; extra == \"standard-no-fastapi-cloud-cli\"",
          "email-validator>=2.0.0; extra == \"standard-no-fastapi-cloud-cli\"",
          "uvicorn[standard]>=0.12.0; extra == \"standard-no-fastapi-cloud-cli\"",
          "pydantic-settings>=2.0.0; extra == \"standard-no-fastapi-cloud-cli\"",
          "pydantic-extra-types>=2.0.0; extra == \"standard-no-fastapi-cloud-cli\"",
          "fastapi-cli[standard]>=0.0.8; extra == \"all\"",
          "httpx<1.0.0,>=0.23.0; extra == \"all\"",
          "jinja2>=3.1.5; extra == \"all\"",
          "python-multipart>=0.0.18; extra == \"all\"",
          "itsdangerous>=1.1.0; extra == \"all\"",
          "pyyaml>=5.3.1; extra == \"all\"",
          "ujson>=5.8.0; extra == \"all\"",
          "orjson>=3.9.3; extra == \"all\"",
          "email-validator>=2.0.0; extra == \"all\"",
          "uvicorn[standard]>=0.12.0; extra == \"all\"",
          "pydantic-settings>=2.0.0; extra == \"all\"",
          "pydantic-extra-types>=2.0.0; extra == \"all\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/fastapi/fastapi",
          "Documentation, https://fastapi.tiangolo.com/",
          "Repository, https://github.com/fastapi/fastapi",
          "Issues, https://github.com/fastapi/fastapi/issues",
          "Changelog, https://fastapi.tiangolo.com/release-notes/"
        ],
        "provides_extra": [
          "standard",
          "standard-no-fastapi-cloud-cli",
          "all"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/81/0d/13d1d239a25cbfb19e740db83143e95c772a1fe10202dda4b76792b114dd/starlette-0.52.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=0029d43eb3d273bc4f83a08720b4912ea4b071087a3b48db01b7c839f7954d74",
          "hashes": {
            "sha256": "0029d43eb3d273bc4f83a08720b4912ea4b071087a3b48db01b7c839f7954d74"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "starlette",
        "version": "0.52.1",
        "summary": "The little ASGI library that shines.",
        "description": "<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/Kludex/starlette/main/docs/img/starlette_dark.svg\" width=\"420px\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/Kludex/starlette/main/docs/img/starlette.svg\" width=\"420px\">\n    <img alt=\"starlette-logo\" src=\"https://raw.githubusercontent.com/Kludex/starlette/main/docs/img/starlette_dark.svg\">\n  </picture>\n</p>\n\n<p align=\"center\">\n    <em>âœ¨ The little ASGI framework that shines. âœ¨</em>\n</p>\n\n---\n\n[![Build Status](https://github.com/Kludex/starlette/workflows/Test%20Suite/badge.svg)](https://github.com/Kludex/starlette/actions)\n[![Package version](https://badge.fury.io/py/starlette.svg)](https://pypi.python.org/pypi/starlette)\n[![Supported Python Version](https://img.shields.io/pypi/pyversions/starlette.svg?color=%2334D058)](https://pypi.org/project/starlette)\n[![Discord](https://img.shields.io/discord/1051468649518616576?logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/RxKUF5JuHs)\n\n---\n\n**Documentation**: <a href=\"https://starlette.dev/\" target=\"_blank\">https://starlette.dev</a>\n\n**Source Code**: <a href=\"https://github.com/Kludex/starlette\" target=\"_blank\">https://github.com/Kludex/starlette</a>\n\n---\n\n# Starlette\n\nStarlette is a lightweight [ASGI][asgi] framework/toolkit,\nwhich is ideal for building async web services in Python.\n\nIt is production-ready, and gives you the following:\n\n* A lightweight, low-complexity HTTP web framework.\n* WebSocket support.\n* In-process background tasks.\n* Startup and shutdown events.\n* Test client built on `httpx`.\n* CORS, GZip, Static Files, Streaming responses.\n* Session and Cookie support.\n* 100% test coverage.\n* 100% type annotated codebase.\n* Few hard dependencies.\n* Compatible with `asyncio` and `trio` backends.\n* Great overall performance [against independent benchmarks][techempower].\n\n## Installation\n\n```shell\n$ pip install starlette\n```\n\nYou'll also want to install an ASGI server, such as [uvicorn](https://www.uvicorn.org/), [daphne](https://github.com/django/daphne/), or [hypercorn](https://hypercorn.readthedocs.io/en/latest/).\n\n```shell\n$ pip install uvicorn\n```\n\n## Example\n\n```python title=\"main.py\"\nfrom starlette.applications import Starlette\nfrom starlette.responses import JSONResponse\nfrom starlette.routing import Route\n\n\nasync def homepage(request):\n    return JSONResponse({'hello': 'world'})\n\nroutes = [\n    Route(\"/\", endpoint=homepage)\n]\n\napp = Starlette(debug=True, routes=routes)\n```\n\nThen run the application using Uvicorn:\n\n```shell\n$ uvicorn main:app\n```\n\n## Dependencies\n\nStarlette only requires `anyio`, and the following are optional:\n\n* [`httpx`][httpx] - Required if you want to use the `TestClient`.\n* [`jinja2`][jinja2] - Required if you want to use `Jinja2Templates`.\n* [`python-multipart`][python-multipart] - Required if you want to support form parsing, with `request.form()`.\n* [`itsdangerous`][itsdangerous] - Required for `SessionMiddleware` support.\n* [`pyyaml`][pyyaml] - Required for `SchemaGenerator` support.\n\nYou can install all of these with `pip install starlette[full]`.\n\n## Framework or Toolkit\n\nStarlette is designed to be used either as a complete framework, or as\nan ASGI toolkit. You can use any of its components independently.\n\n```python\nfrom starlette.responses import PlainTextResponse\n\n\nasync def app(scope, receive, send):\n    assert scope['type'] == 'http'\n    response = PlainTextResponse('Hello, world!')\n    await response(scope, receive, send)\n```\n\nRun the `app` application in `example.py`:\n\n```shell\n$ uvicorn example:app\nINFO: Started server process [11509]\nINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n```\n\nRun uvicorn with `--reload` to enable auto-reloading on code changes.\n\n## Modularity\n\nThe modularity that Starlette is designed on promotes building re-usable\ncomponents that can be shared between any ASGI framework. This should enable\nan ecosystem of shared middleware and mountable applications.\n\nThe clean API separation also means it's easier to understand each component\nin isolation.\n\n---\n\n<p align=\"center\"><i>Starlette is <a href=\"https://github.com/Kludex/starlette/blob/main/LICENSE.md\">BSD licensed</a> code.<br/>Designed & crafted with care.</i></br>&mdash; â­ï¸ &mdash;</p>\n\n[asgi]: https://asgi.readthedocs.io/en/latest/\n[httpx]: https://www.python-httpx.org/\n[jinja2]: https://jinja.palletsprojects.com/\n[python-multipart]: https://multipart.fastapiexpert.com/\n[itsdangerous]: https://itsdangerous.palletsprojects.com/\n[sqlalchemy]: https://www.sqlalchemy.org\n[pyyaml]: https://pyyaml.org/wiki/PyYAMLDocumentation\n[techempower]: https://www.techempower.com/benchmarks/#hw=ph&test=fortune&l=zijzen-sf\n",
        "description_content_type": "text/markdown",
        "author_email": "Tom Christie <tom@tomchristie.com>",
        "maintainer_email": "Marcelo Trylesinski <marcelotryle@gmail.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Environment :: Web Environment",
          "Framework :: AnyIO",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "anyio<5,>=3.6.2",
          "typing-extensions>=4.10.0; python_version < '3.13'",
          "httpx<0.29.0,>=0.27.0; extra == 'full'",
          "itsdangerous; extra == 'full'",
          "jinja2; extra == 'full'",
          "python-multipart>=0.0.18; extra == 'full'",
          "pyyaml; extra == 'full'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/Kludex/starlette",
          "Documentation, https://starlette.dev/",
          "Changelog, https://starlette.dev/release-notes/",
          "Funding, https://github.com/sponsors/Kludex",
          "Source, https://github.com/Kludex/starlette"
        ],
        "provides_extra": [
          "full"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3d/d8/2083a1daa7439a66f3a48589a57d576aa117726762618f6bb09fe3798796/uvicorn-0.40.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=c6c8f55bc8bf13eb6fa9ff87ad62308bbbc33d0b67f84293151efe87e0d5f2ee",
          "hashes": {
            "sha256": "c6c8f55bc8bf13eb6fa9ff87ad62308bbbc33d0b67f84293151efe87e0d5f2ee"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "uvicorn",
        "version": "0.40.0",
        "summary": "The lightning-fast ASGI server.",
        "description": "<p align=\"center\">\n  <img width=\"320\" height=\"320\" src=\"https://raw.githubusercontent.com/tomchristie/uvicorn/main/docs/uvicorn.png\" alt='uvicorn'>\n</p>\n\n<p align=\"center\">\n<em>An ASGI web server, for Python.</em>\n</p>\n\n---\n\n[![Build Status](https://github.com/Kludex/uvicorn/workflows/Test%20Suite/badge.svg)](https://github.com/Kludex/uvicorn/actions)\n[![Package version](https://badge.fury.io/py/uvicorn.svg)](https://pypi.python.org/pypi/uvicorn)\n[![Supported Python Version](https://img.shields.io/pypi/pyversions/uvicorn.svg?color=%2334D058)](https://pypi.org/project/uvicorn)\n[![Discord](https://img.shields.io/discord/1051468649518616576?logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/RxKUF5JuHs)\n\n---\n\n**Documentation**: [https://uvicorn.dev](https://uvicorn.dev)\n\n**Source Code**: [https://www.github.com/Kludex/uvicorn](https://www.github.com/Kludex/uvicorn)\n\n---\n\nUvicorn is an ASGI web server implementation for Python.\n\nUntil recently Python has lacked a minimal low-level server/application interface for\nasync frameworks. The [ASGI specification][asgi] fills this gap, and means we're now able to\nstart building a common set of tooling usable across all async frameworks.\n\nUvicorn supports HTTP/1.1 and WebSockets.\n\n## Quickstart\n\nInstall using `pip`:\n\n```shell\n$ pip install uvicorn\n```\n\nThis will install uvicorn with minimal (pure Python) dependencies.\n\n```shell\n$ pip install 'uvicorn[standard]'\n```\n\nThis will install uvicorn with \"Cython-based\" dependencies (where possible) and other \"optional extras\".\n\nIn this context, \"Cython-based\" means the following:\n\n- the event loop `uvloop` will be installed and used if possible.\n- the http protocol will be handled by `httptools` if possible.\n\nMoreover, \"optional extras\" means that:\n\n- the websocket protocol will be handled by `websockets` (should you want to use `wsproto` you'd need to install it manually) if possible.\n- the `--reload` flag in development mode will use `watchfiles`.\n- windows users will have `colorama` installed for the colored logs.\n- `python-dotenv` will be installed should you want to use the `--env-file` option.\n- `PyYAML` will be installed to allow you to provide a `.yaml` file to `--log-config`, if desired.\n\nCreate an application, in `example.py`:\n\n```python\nasync def app(scope, receive, send):\n    assert scope['type'] == 'http'\n\n    await send({\n        'type': 'http.response.start',\n        'status': 200,\n        'headers': [\n            (b'content-type', b'text/plain'),\n        ],\n    })\n    await send({\n        'type': 'http.response.body',\n        'body': b'Hello, world!',\n    })\n```\n\nRun the server:\n\n```shell\n$ uvicorn example:app\n```\n\n---\n\n## Why ASGI?\n\nMost well established Python Web frameworks started out as WSGI-based frameworks.\n\nWSGI applications are a single, synchronous callable that takes a request and returns a response.\nThis doesnâ€™t allow for long-lived connections, like you get with long-poll HTTP or WebSocket connections,\nwhich WSGI doesn't support well.\n\nHaving an async concurrency model also allows for options such as lightweight background tasks,\nand can be less of a limiting factor for endpoints that have long periods being blocked on network\nI/O such as dealing with slow HTTP requests.\n\n---\n\n## Alternative ASGI servers\n\nA strength of the ASGI protocol is that it decouples the server implementation\nfrom the application framework. This allows for an ecosystem of interoperating\nwebservers and application frameworks.\n\n### Daphne\n\nThe first ASGI server implementation, originally developed to power Django Channels, is [the Daphne webserver][daphne].\n\nIt is run widely in production, and supports HTTP/1.1, HTTP/2, and WebSockets.\n\nAny of the example applications given here can equally well be run using `daphne` instead.\n\n```\n$ pip install daphne\n$ daphne app:App\n```\n\n### Hypercorn\n\n[Hypercorn][hypercorn] was initially part of the Quart web framework, before\nbeing separated out into a standalone ASGI server.\n\nHypercorn supports HTTP/1.1, HTTP/2, and WebSockets.\n\nIt also supports [the excellent `trio` async framework][trio], as an alternative to `asyncio`.\n\n```\n$ pip install hypercorn\n$ hypercorn app:App\n```\n\n### Mangum\n\n[Mangum][mangum] is an adapter for using ASGI applications with AWS Lambda & API Gateway.\n\n### Granian\n\n[Granian][granian] is an ASGI compatible Rust HTTP server which supports HTTP/2, TLS and WebSockets.\n\n---\n\n<p align=\"center\"><i>Uvicorn is <a href=\"https://github.com/Kludex/uvicorn/blob/main/LICENSE.md\">BSD licensed</a> code.<br/>Designed & crafted with care.</i><br/>&mdash; ðŸ¦„  &mdash;</p>\n\n[asgi]: https://asgi.readthedocs.io/en/latest/\n[daphne]: https://github.com/django/daphne\n[hypercorn]: https://github.com/pgjones/hypercorn\n[trio]: https://trio.readthedocs.io\n[mangum]: https://github.com/jordaneremieff/mangum\n[granian]: https://github.com/emmett-framework/granian\n",
        "description_content_type": "text/markdown",
        "author_email": "Tom Christie <tom@tomchristie.com>",
        "maintainer_email": "Marcelo Trylesinski <marcelotryle@gmail.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "click>=7.0",
          "h11>=0.8",
          "typing-extensions>=4.0; python_version < '3.11'",
          "colorama>=0.4; (sys_platform == 'win32') and extra == 'standard'",
          "httptools>=0.6.3; extra == 'standard'",
          "python-dotenv>=0.13; extra == 'standard'",
          "pyyaml>=5.1; extra == 'standard'",
          "uvloop>=0.15.1; (sys_platform != 'win32' and (sys_platform != 'cygwin' and platform_python_implementation != 'PyPy')) and extra == 'standard'",
          "watchfiles>=0.13; extra == 'standard'",
          "websockets>=10.4; extra == 'standard'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Changelog, https://uvicorn.dev/release-notes",
          "Funding, https://github.com/sponsors/encode",
          "Homepage, https://uvicorn.dev/",
          "Source, https://github.com/Kludex/uvicorn"
        ],
        "provides_extra": [
          "standard"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/86/58/3433abd77811237bc91a6118f659e13a557c6d97903acb47f56a8c141171/azure_monitor_opentelemetry-1.8.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f7da4de1320486ce69a9e804fc5e5a5431643888afb1b7ded55d1fb80c89c9c0",
          "hashes": {
            "sha256": "f7da4de1320486ce69a9e804fc5e5a5431643888afb1b7ded55d1fb80c89c9c0"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-monitor-opentelemetry",
        "version": "1.8.2",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Monitor Opentelemetry Distro Client Library for Python",
        "description": "# Azure Monitor Opentelemetry Distro client library for Python\n\nThe Azure Monitor Distro of [Opentelemetry Python][ot_sdk_python] is a \"one-stop-shop\" telemetry solution, requiring only one line of code to instrument your application. The distro captures telemetry via [OpenTelemetry instrumentations][azure_monitor_opentelemetry_exporters] and reports telemetry to Azure Monitor via the [Azure Monitor exporters][azure_monitor_opentelemetry_exporters].\n\nPrior to using this SDK, please read and understand [Data Collection Basics](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-overview?tabs=python), especially the section on [telemetry types](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-overview?tabs=python#telemetry-types). OpenTelemetry terminology differs from Application Insights terminology so it is important to understand the way the telemetry types map to each other.\n\nThis distro automatically installs the following libraries:\n\n* [Azure Monitor OpenTelemetry exporters][azure_monitor_opentelemetry_exporters]\n* A subset of OpenTelemetry [instrumentations][ot_instrumentations] that are officially supported as listed below.\n\n## Officially supported instrumentations\n\nOpenTelemetry instrumentations allow automatic collection of requests sent from underlying instrumented libraries. The following is a list of OpenTelemetry instrumentations that come bundled in with the Azure monitor distro. These instrumentations are enabled by default. See the [Usage](#usage) section below for how to opt-out of these instrumentations.\n\n| Instrumentation | Supported library Name | Supported versions |\n| --------------- | ---------------------- | ------------------ |\n| [Azure Core Tracing OpenTelemetry][azure_core_tracing_opentelemetry_plugin] | `azure_sdk` | |\n| [OpenTelemetry Django Instrumentation][ot_instrumentation_django] | [django][pypi_django] | [link][ot_instrumentation_django_version]\n| [OpenTelemetry FastApi Instrumentation][ot_instrumentation_fastapi] | [fastapi][pypi_fastapi] | [link][ot_instrumentation_fastapi_version]\n| [OpenTelemetry Flask Instrumentation][ot_instrumentation_flask] | [flask][pypi_flask] | [link][ot_instrumentation_flask_version]\n| [OpenTelemetry Psycopg2 Instrumentation][ot_instrumentation_psycopg2] | [psycopg2][pypi_psycopg2] | [link][ot_instrumentation_psycopg2_version]\n| [OpenTelemetry Requests Instrumentation][ot_instrumentation_requests] | [requests][pypi_requests] | [link][ot_instrumentation_requests_version]\n| [OpenTelemetry UrlLib Instrumentation][ot_instrumentation_urllib] | [urllib][pypi_urllib] | All\n| [OpenTelemetry UrlLib3 Instrumentation][ot_instrumentation_urllib3] | [urllib3][pypi_urllib3] | [link][ot_instrumentation_urllib3_version]\n\nIf you would like to add support for another OpenTelemetry instrumentation, please submit a feature [request][distro_feature_request]. In the meantime, you can use the OpenTelemetry instrumentation manually via it's own APIs (i.e. `instrument()`) in your code. See [this][samples_manual] for an example.\n\n## Key concepts\n\nThis package bundles a series of OpenTelemetry and Azure Monitor components to enable the collection and sending of telemetry to Azure Monitor. For MANUAL instrumentation, use the `configure_azure_monitor` function. AUTOMATIC instrumentation is not yet supported.\n\nThe [Azure Monitor OpenTelemetry exporters][azure_monitor_opentelemetry_exporters] are the main components in accomplishing this. You will be able to use the exporters and their APIs directly through this package. Please go the exporter documentation to understand how OpenTelemetry and Azure Monitor components work in enabling telemetry collection and exporting.\n\nCurrently, all instrumentations available in OpenTelemetry are in a beta state, meaning they are not stable and may have breaking changes in the future. Efforts are being made in pushing these to a more stable state.\n\n## Getting started\n\n### Prerequisites\n\nTo use this package, you must have:\n\n* Azure subscription - [Create a free account][azure_sub]\n* Azure Monitor - [How to use application insights][application_insights_namespace]\n* Opentelemetry SDK - [Opentelemetry SDK for Python][ot_sdk_python]\n* Python 3.9 or later - [Install Python][python]\n\n### Install the package\n\nInstall the Azure Monitor Opentelemetry Distro with [pip][pip]:\n\n```Bash\npip install azure-monitor-opentelemetry\n```\n\n### Usage\n\nYou can use `configure_azure_monitor` to set up instrumentation for your app to Azure Monitor. `configure_azure_monitor` supports the following optional arguments. All pass-in parameters take priority over any related environment variables.\n\n| Parameter | Description | Environment Variable |\n|-------------------|----------------------------------------------------|----------------------|\n| `connection_string` | The [connection string][connection_string_doc] for your Application Insights resource. The connection string will be automatically populated from the `APPLICATIONINSIGHTS_CONNECTION_STRING` environment variable if not explicitly passed in. | `APPLICATIONINSIGHTS_CONNECTION_STRING` |\n| `enable_live_metrics` | Enable [live metrics][application_insights_live_metrics] feature. Defaults to `False`. | `N/A` |\n| `enable_performance_counters` | Enable [performance counters][application_insights_performance_counters]. Defaults to `True`. | `N/A` |\n| `logging_formatter` | A Python logging [formatter][python_logging_formatter] that will be used to format collected logs. | `PYTHON_APPLICATIONINSIGHTS_LOGGING_FORMAT` - accepts a STRING field used for formatting, not a [formatter][python_logging_formatter] |\n| `logger_name` | The name of the [Python logger][python_logger] under which telemetry is collected. Setting this value is imperative so logs created from the SDK itself are not tracked. | `PYTHON_APPLICATIONINSIGHTS_LOGGER_NAME` |\n| `instrumentation_options` | A nested dictionary that determines which instrumentations to enable or disable. Instrumentations are referred to by their [Library Names](#officially-supported-instrumentations). For example, `{\"azure_sdk\": {\"enabled\": False}, \"flask\": {\"enabled\": False}, \"django\": {\"enabled\": True}}` will disable Azure Core Tracing and the Flask instrumentation but leave Django and the other default instrumentations enabled. The `OTEL_PYTHON_DISABLED_INSTRUMENTATIONS` environment variable explained below can also be used to disable instrumentations. | `N/A` |\n| `resource` | Specifies the OpenTelemetry [Resource][ot_spec_resource] associated with your application. Passed in [Resource Attributes][ot_spec_resource_attributes] take priority over default attributes and those from [Resource Detectors][ot_python_resource_detectors]. | [OTEL_SERVICE_NAME][ot_spec_service_name], [OTEL_RESOURCE_ATTRIBUTES][ot_spec_resource_attributes], [OTEL_EXPERIMENTAL_RESOURCE_DETECTORS][ot_python_resource_detectors] |\n| `span_processors` | A list of [span processors][ot_span_processor] that will perform processing on each of your spans before they are exported. Useful for filtering/modifying telemetry. | `N/A` |\n| `views` | A list of [views][ot_view] that will be used to customize metrics exported by the SDK. | `N/A` |\n| `traces_per_second` | Configures the Rate Limited sampler by specifying the maximum number of traces to sample per second. When set, this automatically enables the rate-limited sampler. Alternatively, you can configure sampling using the `OTEL_TRACES_SAMPLER` and `OTEL_TRACES_SAMPLER_ARG` environment variables as described in the table below. Please note that the sampling configuration via environment variables will have precedence over the sampling exporter/distro options. | `N/A`\n\nYou can configure further with [OpenTelemetry environment variables][ot_env_vars].\n\n| Environment Variable | Description |\n|-------------|----------------------|\n| [OTEL_SERVICE_NAME][ot_spec_service_name], [OTEL_RESOURCE_ATTRIBUTES][ot_spec_resource_attributes] | Specifies the OpenTelemetry [Resource][ot_spec_resource] associated with your application. |\n| `OTEL_LOGS_EXPORTER` | If set to `None`, disables collection and export of logging telemetry. |\n| `OTEL_METRICS_EXPORTER` | If set to `None`, disables collection and export of metric telemetry. |\n| `OTEL_TRACES_EXPORTER` | If set to `None`, disables collection and export of distributed tracing telemetry. |\n| `OTEL_BLRP_SCHEDULE_DELAY` | Specifies the logging export interval in milliseconds. Defaults to 5000. |\n| `OTEL_BSP_SCHEDULE_DELAY` | Specifies the distributed tracing export interval in milliseconds. Defaults to 5000. |\n| `OTEL_TRACES_SAMPLER` | Specifies the sampler to be used for traces. Supports both [application_insights_sampling] and [rate_limited_sampling]. Use `microsoft.fixed.percentage` for the Application Insights sampler or `microsoft.rate_limited` for the Rate Limited sampler. |\n| `OTEL_TRACES_SAMPLER_ARG` | Specifies the sampling parameter for the configured sampler. For the Application Insights sampler, this sets the ratio of distributed tracing telemetry to be [sampled][application_insights_sampling] with accepted values in the range [0,1]. Defaults to 1.0 (no sampling). For the Rate Limited sampler, this sets the maximum traces per second to be [sampled][rate_limited_sampler]. For example, 0.5 means one trace every two seconds, while 5.0 means five traces per second. |\n| `OTEL_PYTHON_DISABLED_INSTRUMENTATIONS` | Specifies which of the supported instrumentations to disable. Disabled instrumentations will not be instrumented as part of `configure_azure_monitor`. However, they can still be manually instrumented with `instrument()` directly. Accepts a comma-separated list of lowercase [Library Names](#officially-supported-instrumentations). For example, set to `\"psycopg2,fastapi\"` to disable the Psycopg2 and FastAPI instrumentations. Defaults to an empty list, enabling all supported instrumentations. |\n| `OTEL_EXPERIMENTAL_RESOURCE_DETECTORS` | An experimental OpenTelemetry environment variable used to specify Resource Detectors to be used to generate Resource Attributes. This is an experimental feature and the name of this variable and its behavior can change in a non-backwards compatible way. Defaults to \"azure_app_service,azure_vm\" to enable the [Azure Resource Detectors][ot_resource_detector_azure] for Azure App Service and Azure VM. To add or remove specific resource detectors, set the environment variable accordingly. See the [OpenTelemetry Python Resource Detector Documentation][ot_python_resource_detectors] for more. |\n\n#### Azure monitor OpenTelemetry Exporter configurations\n\nYou can pass Azure monitor OpenTelemetry exporter configuration parameters directly into `configure_azure_monitor`. See additional [configuration related to exporting here][exporter_configuration_docs].\n\n```python\n...\nconfigure_azure_monitor(\n   connection_string=\"<your-connection-string>\",\n   disable_offline_storage=True,\n)\n...\n```\n\n### Examples\n\nSamples are available [here][samples] to demonstrate how to utilize the above configuration options.\n\n### Monitoring in Azure Functions\n\n#### Trace correlation\n\nTracked incoming requests coming into your Python application hosted in Azure Functions will not be automatically correlated with telemetry being tracked within it. You can manually achieve trace correlation by extract the `TraceContext` directly as shown below:\n\n```python\n\nimport azure.functions as func\n\nfrom azure.monitor.opentelemetry import configure_azure_monitor\nfrom opentelemetry import trace\nfrom opentelemetry.propagate import extract\n\n# Configure Azure monitor collection telemetry pipeline\nconfigure_azure_monitor()\n\ndef main(req: func.HttpRequest, context) -> func.HttpResponse:\n   ...\n   # Store current TraceContext in dictionary format\n   carrier = {\n      \"traceparent\": context.trace_context.Traceparent,\n      \"tracestate\": context.trace_context.Tracestate,\n   }\n   tracer = trace.get_tracer(__name__)\n   # Start a span using the current context\n   with tracer.start_as_current_span(\n      \"http_trigger_span\",\n      context=extract(carrier),\n   ):\n      ...\n\n```\n\n#### Logging issues\n\nThe Azure Functions worker itself sends logging telemetry itself without the use of the azure monitor sdk (the call to `configure_azure_monitor()`). This will cause you to possibly experience duplicate telemetry entries when sending logging telemetry. Our recommendation to customers is to use solely the SDK as it will allow much more rich telemetry and features than using the built in one provided by the Azure Functions worker. You can turn off the Azure Functions telemetry logger by clearing the list of handlers of your logger.\n\n```python\n...\nroot_logger = logging.getLogger()\nfor handler in root_logger.handlers[:]:\n    root_logger.removeHandler(handler)\n...\n```\n\nBe sure to call the above BEFORE any loggers or the call to `configure_azure_monitor()` is setup.\n\nYou may also disable logging through [Azure Functions configuration](https://learn.microsoft.com/azure/azure-functions/configure-monitoring?tabs=v2#configure-log-levels).\n\nv2.x+\n```\n...\n{\n  \"logging\": {\n    ...\n    \"logLevel\": {\n      \"default\": \"None\",\n      ...\n    }\n  }\n}\n...\n```\n\nv1.x\n```\n...\n{\n  \"logger\": {\n    \"categoryFilter\": {\n      \"defaultLevel\": \"None\",\n      ...\n    }\n  }\n}\n...\n```\n\n## Troubleshooting\n\nThe exporter raises exceptions defined in [Azure Core](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#azure-core-library-exceptions).\n\n## Next steps\n\nCheck out the [documentation][azure_monitor_enable_docs] for more.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Additional documentation\n\n* [Azure Portal][azure_portal]\n* [Official Azure monitor docs][azure_monitor_enable_docs]\n* [OpenTelemetry Python Official Docs][ot_python_docs]\n\n<!-- LINKS -->\n[azure_core_tracing_opentelemetry_plugin]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/core/azure-core-tracing-opentelemetry\n[azure_core_tracing_opentelemetry_plugin_sample]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry/samples/tracing/azure_core.py\n[azure_monitor_enable_docs]: https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python\n[azure_monitor_opentelemetry_exporters]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry-exporter#microsoft-opentelemetry-exporter-for-azure-monitor\n[azure_portal]: https://portal.azure.com\n[azure_sub]: https://azure.microsoft.com/free/\n[application_insights_performance_counters]: https://learn.microsoft.com/azure/azure-monitor/app/metrics-overview?tabs=standard#performance-counters\n[application_insights_live_metrics]: https://learn.microsoft.com/azure/azure-monitor/app/live-stream\n[application_insights_namespace]: https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview\n[application_insights_sampling]: https://learn.microsoft.com/azure/azure-monitor/app/sampling\n[rate_limited_sampling]: https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-configuration\n[connection_string_doc]: https://learn.microsoft.com/azure/azure-monitor/app/sdk-connection-string\n[distro_feature_request]: https://github.com/Azure/azure-sdk-for-python/issues/new\n[exporter_configuration_docs]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry-exporter#configuration\n[ot_env_vars]: https://opentelemetry.io/docs/reference/specification/sdk-environment-variables/\n[ot_instrumentations]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation\n[ot_metric_reader]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/sdk.md#metricreader\n[ot_python_docs]: https://opentelemetry.io/docs/instrumentation/python/\n[ot_sdk_python]: https://github.com/open-telemetry/opentelemetry-python\n[ot_sdk_python_metric_reader]: https://opentelemetry-python.readthedocs.io/en/latest/sdk/metrics.export.html#opentelemetry.sdk.metrics.export.MetricReader\n[ot_span_processor]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/sdk.md#span-processor\n[ot_view]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/sdk.md#view\n[ot_sdk_python_view_examples]: https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples/metrics/views\n[ot_instrumentation_django]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-django\n[ot_instrumentation_django_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-django/src/opentelemetry/instrumentation/django/package.py#L16\n[ot_instrumentation_fastapi]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-fastapi\n[ot_instrumentation_fastapi_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-fastapi/src/opentelemetry/instrumentation/fastapi/package.py#L16\n[ot_instrumentation_flask]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-flask\n[ot_instrumentation_flask_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-flask/src/opentelemetry/instrumentation/flask/package.py#L16\n[ot_instrumentation_psycopg2]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-psycopg2\n[ot_instrumentation_psycopg2_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-psycopg2/src/opentelemetry/instrumentation/psycopg2/package.py#L16\n[ot_instrumentation_requests]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-requests\n[ot_instrumentation_requests_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-requests/src/opentelemetry/instrumentation/requests/package.py#L16\n[ot_instrumentation_urllib]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-urllib\n[ot_instrumentation_urllib3]: https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-urllib3\n[ot_instrumentation_urllib3_version]: https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/instrumentation/opentelemetry-instrumentation-urllib3/src/opentelemetry/instrumentation/urllib3/package.py#L16\n[ot_python_resource_detectors]: https://opentelemetry-python.readthedocs.io/en/latest/sdk/environment_variables.html#opentelemetry.sdk.environment_variables.OTEL_EXPERIMENTAL_RESOURCE_DETECTORS\n[ot_resource_detector_azure]: https://pypi.org/project/opentelemetry_resource_detector_azure/\n[ot_spec_resource]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/sdk.md#resource-sdk\n[ot_spec_resource_attributes]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/sdk.md#specifying-resource-information-via-an-environment-variable\n[ot_spec_service_name]: https://github.com/open-telemetry/semantic-conventions/blob/main/docs/resource/README.md#service\n[ot_spec_view]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/sdk.md#view\n[pip]: https://pypi.org/project/pip/\n[pypi_django]: https://pypi.org/project/Django/\n[pypi_fastapi]: https://pypi.org/project/fastapi/\n[pypi_flask]: https://pypi.org/project/Flask/\n[pypi_psycopg2]: https://pypi.org/project/psycopg2/\n[pypi_requests]: https://pypi.org/project/requests/\n[pypi_urllib]: https://docs.python.org/3/library/urllib.html\n[pypi_urllib3]: https://pypi.org/project/urllib3/\n[python]: https://www.python.org/downloads/\n[python_logger]: https://docs.python.org/3/library/logging.html#logger-objects\n[python_logging_formatter]: https://docs.python.org/3/library/logging.html#formatter-objects\n[python_logging_level]: https://docs.python.org/3/library/logging.html#levels\n[samples]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry/samples\n[samples_manual]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry/samples/tracing/manually_instrumented.py\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry",
        "author": "Microsoft Corporation",
        "author_email": "ascl@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE",
          "NOTICE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-core<2.0.0,>=1.28.0",
          "azure-core-tracing-opentelemetry~=1.0.0b11",
          "azure-monitor-opentelemetry-exporter~=1.0.0b43",
          "opentelemetry-sdk~=1.36",
          "opentelemetry-instrumentation-django~=0.57b0",
          "opentelemetry-instrumentation-fastapi~=0.57b0",
          "opentelemetry-instrumentation-flask~=0.57b0",
          "opentelemetry-instrumentation-psycopg2~=0.57b0",
          "opentelemetry-instrumentation-requests~=0.57b0",
          "opentelemetry-instrumentation-urllib~=0.57b0",
          "opentelemetry-instrumentation-urllib3~=0.57b0",
          "opentelemetry-resource-detector-azure<1.0.0,>=0.1.5"
        ],
        "requires_python": ">=3.8"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7d/cc/6e808328ba54662e50babdcab21138eae4250bc0fddf67d55526a615a2ca/opentelemetry_instrumentation_fastapi-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=af94b7a239ad1085fc3a820ecf069f67f579d7faf4c085aaa7bd9b64eafc8eaf",
          "hashes": {
            "sha256": "af94b7a239ad1085fc3a820ecf069f67f579d7faf4c085aaa7bd9b64eafc8eaf"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-fastapi",
        "version": "0.60b1",
        "summary": "OpenTelemetry FastAPI Instrumentation",
        "description": "OpenTelemetry FastAPI Instrumentation\n=======================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-fastapi.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-fastapi/\n\n\nThis library provides automatic and manual instrumentation of FastAPI web frameworks,\ninstrumenting http requests served by applications utilizing the framework.\n\nauto-instrumentation using the opentelemetry-instrumentation package is also supported.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-fastapi\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation-asgi==0.60b1",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "fastapi~=0.92; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-fastapi",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/77/d2/6788e83c5c86a2690101681aeef27eeb2a6bf22df52d3f263a22cee20915/opentelemetry_instrumentation-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=04480db952b48fb1ed0073f822f0ee26012b7be7c3eac1a3793122737c78632d",
          "hashes": {
            "sha256": "04480db952b48fb1ed0073f822f0ee26012b7be7c3eac1a3793122737c78632d"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation",
        "version": "0.60b1",
        "summary": "Instrumentation Tools & Auto Instrumentation for OpenTelemetry Python",
        "description": "OpenTelemetry Instrumentation\n=============================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation/\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation\n\n\nThis package provides commands that help automatically instrument a program:\n\n.. note::\n    You need to install a distro package to get auto instrumentation working. The ``opentelemetry-distro``\n    package contains the default distro and configurator and automatically configures some of the common options for users.\n    For more info about ``opentelemetry-distro`` check `here <https://opentelemetry-python.readthedocs.io/en/latest/examples/distro/README.html>`__\n    ::\n\n        pip install \"opentelemetry-distro[otlp]\"\n\n    When creating a custom distro and/or configurator, be sure to add entry points for each under `opentelemetry_distro` and `opentelemetry_configurator` respectfully.\n    If you have entry points for multiple distros or configurators present in your environment, you should specify the entry point name of the distro and configurator you want to be used via the `OTEL_PYTHON_DISTRO` and `OTEL_PYTHON_CONFIGURATOR` environment variables.\n\n\nopentelemetry-bootstrap\n-----------------------\n\n::\n\n    opentelemetry-bootstrap [-a |--action=][install|requirements]\n\nThis command install default instrumentation packages and detects active Python site-packages\nto figure out which instrumentation packages the user might want to install. By default, it\nprints out a list of the default and detected instrumentation packages that can be added to a\nrequirements.txt file. It also supports installing the packages when run with\n:code:`--action=install` or :code:`-a install` flag. All default and detectable\ninstrumentation packages are defined `here <https://github.com/open-telemetry/opentelemetry-python-contrib/blob/main/opentelemetry-instrumentation/src/opentelemetry/instrumentation/bootstrap_gen.py>`.\n\n\nopentelemetry-instrument\n------------------------\n\n::\n\n    opentelemetry-instrument python program.py\n\nThe instrument command will try to automatically detect packages used by your python program\nand when possible, apply automatic tracing instrumentation on them. This means your program\nwill get automatic distributed tracing without having to make any code changes. This will\nalso configure a global tracer and tracing exporter as well as a meter and meter exporter.\nBy default, the instrument command will use the OTLP exporter but this can be overridden.\n\nThe command supports the following configuration options as CLI arguments and environment\nvariables:\n\n\n* ``--traces_exporter`` or ``OTEL_TRACES_EXPORTER``\n* ``--metrics_exporter`` or ``OTEL_METRICS_EXPORTER``\n* ``--distro`` or ``OTEL_PYTHON_DISTRO``\n* ``--configurator`` or ``OTEL_PYTHON_CONFIGURATOR``\n\nThe exporter options define what exporter destination to use and can be set to one or more\nexporter names (see below). You can pass multiple values to configure multiple exporters\n(e.g., ``zipkin_json,otlp``).\n\n    - Defaults to `otlp`.\n    - Can be set to `none` to disable automatic tracer initialization.\n    - Can be set to 'console` to display JSON results locally.\n\nTrace exporter names:\n\n    - jaeger_proto\n    - jaeger_thrift\n    - opencensus\n    - otlp\n    - otlp_proto_grpc (`deprecated`)\n    - otlp_proto_http (`deprecated`)\n    - zipkin_json\n    - zipkin_proto\n\nMetric exporter names:\n\n    - otlp\n    - otlp_proto_grpc (`deprecated`)\n    - prometheus\n\nNote: The default transport protocol for ``otlp`` is gRPC.\n\n* ``--id-generator`` or ``OTEL_PYTHON_ID_GENERATOR``\n\nUsed to specify which IDs Generator to use for the global Tracer Provider. By default, it\nwill use the random IDs generator.\n\nThe code in ``program.py`` needs to use one of the packages for which there is\nan OpenTelemetry integration. For a list of the available integrations please\ncheck `here <https://opentelemetry-python.readthedocs.io/en/stable/index.html#integrations>`_\n\n* ``OTEL_PYTHON_DISABLED_INSTRUMENTATIONS``\n\nIf set by the user, opentelemetry-instrument will read this environment variable to disable specific instrumentations.\ne.g OTEL_PYTHON_DISABLED_INSTRUMENTATIONS=\"requests,django\"\n\nIf the variables contains ``*`` as member no instrumentation will be enabled.\n\n* ``OTEL_PYTHON_AUTO_INSTRUMENTATION_EXPERIMENTAL_GEVENT_PATCH``\n\nIf set by the user to `patch_all` , opentelemetry instrument will call the gevent monkeypatching method ``patch_all``.\nThis is considered experimental but can be useful to instrument gevent applications.\ne.g OTEL_PYTHON_AUTO_INSTRUMENTATION_EXPERIMENTAL_GEVENT_PATCH=patch_all\n\n\nExamples\n^^^^^^^^\n\n::\n\n    opentelemetry-instrument --traces_exporter console flask run --port=3000\n\nThe above command will pass ``--traces_exporter console`` to the instrument command and ``--port=3000`` to ``flask run``.\n\n::\n\n    opentelemetry-instrument --traces_exporter zipkin_json,otlp celery -A tasks worker --loglevel=info\n\nThe above command will configure global trace provider, attach zipkin and otlp exporters to it and then\nstart celery with the rest of the arguments.\n\n::\n\n    opentelemetry-instrument --id_generator random flask run --port=3000\n\nThe above command will configure the global trace provider to use the Random IDs Generator, and then\npass ``--port=3000`` to ``flask run``.\n\nProgrammatic Auto-instrumentation\n---------------------------------\n\n::\n\n    from opentelemetry.instrumentation import auto_instrumentation\n    auto_instrumentation.initialize()\n\n\nIf you are in an environment where you cannot use opentelemetry-instrument to inject auto-instrumentation you can do so programmatically with\nthe code above. Please note that some instrumentations may require the ``initialize()`` method to be called before the library they\ninstrument is imported.\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.4",
          "opentelemetry-semantic-conventions==0.60b1",
          "packaging>=18.0",
          "wrapt<2.0.0,>=1.0.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/opentelemetry-instrumentation",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/76/76/1fb94367cef64420d2171157a6b9509582873bd09a6afe08a78a8d1f59d9/opentelemetry_instrumentation_asgi-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d48def2dbed10294c99cfcf41ebbd0c414d390a11773a41f472d20000fcddc25",
          "hashes": {
            "sha256": "d48def2dbed10294c99cfcf41ebbd0c414d390a11773a41f472d20000fcddc25"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-asgi",
        "version": "0.60b1",
        "summary": "ASGI instrumentation for OpenTelemetry",
        "description": "OpenTelemetry ASGI Instrumentation\n==================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-asgi.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-asgi/\n\n\nThis library provides a ASGI middleware that can be used on any ASGI framework\n(such as Django, Starlette, FastAPI or Quart) to track requests timing through OpenTelemetry.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-asgi\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "asgiref~=3.0",
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "asgiref~=3.0; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-asgi",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/16/5c/d3f1733665f7cd582ef0842fb1d2ed0bc1fba10875160593342d22bba375/opentelemetry_util_http-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=66381ba28550c91bee14dcba8979ace443444af1ed609226634596b4b0faf199",
          "hashes": {
            "sha256": "66381ba28550c91bee14dcba8979ace443444af1ed609226634596b4b0faf199"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-util-http",
        "version": "0.60b1",
        "summary": "Web util for OpenTelemetry",
        "description": "OpenTelemetry Util HTTP\n=======================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-util-http.svg\n   :target: https://pypi.org/project/opentelemetry-util-http/\n\n\nThis library provides ASGI, WSGI middleware and other HTTP-related\nfunctionality that is common to instrumented web frameworks (such as Django,\nStarlette, FastAPI, etc.) to track requests timing through OpenTelemetry.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-util-http\n\n\nUsage (Quart)\n-------------\n\n.. code-block:: python\n\n    from quart import Quart\n    from opentelemetry.instrumentation.asgi import OpenTelemetryMiddleware\n\n    app = Quart(__name__)\n    app.asgi_app = OpenTelemetryMiddleware(app.asgi_app)\n\n    @app.route(\"/\")\n    async def hello():\n        return \"Hello!\"\n\n    if __name__ == \"__main__\":\n        app.run(debug=True)\n\n\nUsage (Django 3.0)\n------------------\n\nModify the application's ``asgi.py`` file as shown below.\n\n.. code-block:: python\n\n    import os\n    from django.core.asgi import get_asgi_application\n    from opentelemetry.instrumentation.asgi import OpenTelemetryMiddleware\n\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'asgi_example.settings')\n\n    application = get_asgi_application()\n    application = OpenTelemetryMiddleware(application)\n\n\nUsage (Raw ASGI)\n----------------\n\n.. code-block:: python\n\n    from opentelemetry.instrumentation.asgi import OpenTelemetryMiddleware\n\n    app = ...  # An ASGI application.\n    app = OpenTelemetryMiddleware(app)\n\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/util/opentelemetry-util-http",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/5c/0a/a72d10ed65068e115044937873362e6e32fab1b7dce0046aeb224682c989/asgiref-3.11.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=e8667a091e69529631969fd45dc268fa79b99c92c5fcdda727757e52146ec133",
          "hashes": {
            "sha256": "e8667a091e69529631969fd45dc268fa79b99c92c5fcdda727757e52146ec133"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "asgiref",
        "version": "3.11.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "ASGI specs, helper code, and adapters",
        "description": "asgiref\n=======\n\n.. image:: https://github.com/django/asgiref/actions/workflows/tests.yml/badge.svg\n    :target: https://github.com/django/asgiref/actions/workflows/tests.yml\n\n.. image:: https://img.shields.io/pypi/v/asgiref.svg\n    :target: https://pypi.python.org/pypi/asgiref\n\nASGI is a standard for Python asynchronous web apps and servers to communicate\nwith each other, and positioned as an asynchronous successor to WSGI. You can\nread more at https://asgi.readthedocs.io/en/latest/\n\nThis package includes ASGI base libraries, such as:\n\n* Sync-to-async and async-to-sync function wrappers, ``asgiref.sync``\n* Server base classes, ``asgiref.server``\n* A WSGI-to-ASGI adapter, in ``asgiref.wsgi``\n\n\nFunction wrappers\n-----------------\n\nThese allow you to wrap or decorate async or sync functions to call them from\nthe other style (so you can call async functions from a synchronous thread,\nor vice-versa).\n\nIn particular:\n\n* AsyncToSync lets a synchronous subthread stop and wait while the async\n  function is called on the main thread's event loop, and then control is\n  returned to the thread when the async function is finished.\n\n* SyncToAsync lets async code call a synchronous function, which is run in\n  a threadpool and control returned to the async coroutine when the synchronous\n  function completes.\n\nThe idea is to make it easier to call synchronous APIs from async code and\nasynchronous APIs from synchronous code so it's easier to transition code from\none style to the other. In the case of Channels, we wrap the (synchronous)\nDjango view system with SyncToAsync to allow it to run inside the (asynchronous)\nASGI server.\n\nNote that exactly what threads things run in is very specific, and aimed to\nkeep maximum compatibility with old synchronous code. See\n\"Synchronous code & Threads\" below for a full explanation. By default,\n``sync_to_async`` will run all synchronous code in the program in the same\nthread for safety reasons; you can disable this for more performance with\n``@sync_to_async(thread_sensitive=False)``, but make sure that your code does\nnot rely on anything bound to threads (like database connections) when you do.\n\n\nThreadlocal replacement\n-----------------------\n\nThis is a drop-in replacement for ``threading.local`` that works with both\nthreads and asyncio Tasks. Even better, it will proxy values through from a\ntask-local context to a thread-local context when you use ``sync_to_async``\nto run things in a threadpool, and vice-versa for ``async_to_sync``.\n\nIf you instead want true thread- and task-safety, you can set\n``thread_critical`` on the Local object to ensure this instead.\n\n\nServer base classes\n-------------------\n\nIncludes a ``StatelessServer`` class which provides all the hard work of\nwriting a stateless server (as in, does not handle direct incoming sockets\nbut instead consumes external streams or sockets to work out what is happening).\n\nAn example of such a server would be a chatbot server that connects out to\na central chat server and provides a \"connection scope\" per user chatting to\nit. There's only one actual connection, but the server has to separate things\ninto several scopes for easier writing of the code.\n\nYou can see an example of this being used in `frequensgi <https://github.com/andrewgodwin/frequensgi>`_.\n\n\nWSGI-to-ASGI adapter\n--------------------\n\nAllows you to wrap a WSGI application so it appears as a valid ASGI application.\n\nSimply wrap it around your WSGI application like so::\n\n    asgi_application = WsgiToAsgi(wsgi_application)\n\nThe WSGI application will be run in a synchronous threadpool, and the wrapped\nASGI application will be one that accepts ``http`` class messages.\n\nPlease note that not all extended features of WSGI may be supported (such as\nfile handles for incoming POST bodies).\n\n\nDependencies\n------------\n\n``asgiref`` requires Python 3.9 or higher.\n\n\nContributing\n------------\n\nPlease refer to the\n`main Channels contributing docs <https://github.com/django/channels/blob/master/CONTRIBUTING.rst>`_.\n\n\nTesting\n'''''''\n\nTo run tests, make sure you have installed the ``tests`` extra with the package::\n\n    cd asgiref/\n    pip install -e .[tests]\n    pytest\n\n\nBuilding the documentation\n''''''''''''''''''''''''''\n\nThe documentation uses `Sphinx <http://www.sphinx-doc.org>`_::\n\n    cd asgiref/docs/\n    pip install sphinx\n\nTo build the docs, you can use the default tools::\n\n    sphinx-build -b html . _build/html  # or `make html`, if you've got make set up\n    cd _build/html\n    python -m http.server\n\n...or you can use ``sphinx-autobuild`` to run a server and rebuild/reload\nyour documentation changes automatically::\n\n    pip install sphinx-autobuild\n    sphinx-autobuild . _build/html\n\n\nReleasing\n'''''''''\n\nTo release, first add details to CHANGELOG.txt and update the version number in ``asgiref/__init__.py``.\n\nThen, build and push the packages::\n\n    python -m build\n    twine upload dist/*\n    rm -r asgiref.egg-info dist\n\n\nImplementation Details\n----------------------\n\nSynchronous code & threads\n''''''''''''''''''''''''''\n\nThe ``asgiref.sync`` module provides two wrappers that let you go between\nasynchronous and synchronous code at will, while taking care of the rough edges\nfor you.\n\nUnfortunately, the rough edges are numerous, and the code has to work especially\nhard to keep things in the same thread as much as possible. Notably, the\nrestrictions we are working with are:\n\n* All synchronous code called through ``SyncToAsync`` and marked with\n  ``thread_sensitive`` should run in the same thread as each other (and if the\n  outer layer of the program is synchronous, the main thread)\n\n* If a thread already has a running async loop, ``AsyncToSync`` can't run things\n  on that loop if it's blocked on synchronous code that is above you in the\n  call stack.\n\nThe first compromise you get to might be that ``thread_sensitive`` code should\njust run in the same thread and not spawn in a sub-thread, fulfilling the first\nrestriction, but that immediately runs you into the second restriction.\n\nThe only real solution is to essentially have a variant of ThreadPoolExecutor\nthat executes any ``thread_sensitive`` code on the outermost synchronous\nthread - either the main thread, or a single spawned subthread.\n\nThis means you now have two basic states:\n\n* If the outermost layer of your program is synchronous, then all async code\n  run through ``AsyncToSync`` will run in a per-call event loop in arbitrary\n  sub-threads, while all ``thread_sensitive`` code will run in the main thread.\n\n* If the outermost layer of your program is asynchronous, then all async code\n  runs on the main thread's event loop, and all ``thread_sensitive`` synchronous\n  code will run in a single shared sub-thread.\n\nCrucially, this means that in both cases there is a thread which is a shared\nresource that all ``thread_sensitive`` code must run on, and there is a chance\nthat this thread is currently blocked on its own ``AsyncToSync`` call. Thus,\n``AsyncToSync`` needs to act as an executor for thread code while it's blocking.\n\nThe ``CurrentThreadExecutor`` class provides this functionality; rather than\nsimply waiting on a Future, you can call its ``run_until_future`` method and\nit will run submitted code until that Future is done. This means that code\ninside the call can then run code on your thread.\n\n\nMaintenance and Security\n------------------------\n\nTo report security issues, please contact security@djangoproject.com. For GPG\nsignatures and more security process information, see\nhttps://docs.djangoproject.com/en/dev/internals/security/.\n\nTo report bugs or request new features, please open a new GitHub issue.\n\nThis repository is part of the Channels project. For the shepherd and maintenance team, please see the\n`main Channels readme <https://github.com/django/channels/blob/master/README.rst>`_.\n",
        "home_page": "https://github.com/django/asgiref/",
        "author": "Django Software Foundation",
        "author_email": "foundation@djangoproject.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Internet :: WWW/HTTP"
        ],
        "requires_dist": [
          "typing_extensions>=4; python_version < \"3.11\"",
          "pytest; extra == \"tests\"",
          "pytest-asyncio; extra == \"tests\"",
          "mypy>=1.14.0; extra == \"tests\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://asgi.readthedocs.io/",
          "Further Documentation, https://docs.djangoproject.com/en/stable/topics/async/#async-adapter-functions",
          "Changelog, https://github.com/django/asgiref/blob/master/CHANGELOG.txt"
        ],
        "provides_extra": [
          "tests"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/db/88/aaea2ad269ce70b446660371286272c1f6ba66541a7f6f635baf8b0db726/azure_core-1.38.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=69f08ee3d55136071b7100de5b198994fc1c5f89d2b91f2f43156d20fcf200a4",
          "hashes": {
            "sha256": "69f08ee3d55136071b7100de5b198994fc1c5f89d2b91f2f43156d20fcf200a4"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-core",
        "version": "1.38.1",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Core Library for Python",
        "description": "\n# Azure Core shared client library for Python\n\nAzure core provides shared exceptions and modules for Python SDK client libraries.\nThese libraries follow the [Azure SDK Design Guidelines for Python](https://azure.github.io/azure-sdk/python/guidelines/index.html) .\n\nIf you are a client library developer, please reference [client library developer reference](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/CLIENT_LIBRARY_DEVELOPER.md) for more information.\n\n[Source code](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/)\n| [Package (Pypi)][package]\n| [Package (Conda)](https://anaconda.org/microsoft/azure-core/)\n| [API reference documentation](https://learn.microsoft.com/python/api/overview/azure/core-readme)\n\n## Getting started\n\nTypically, you will not need to install azure core;\nit will be installed when you install one of the client libraries using it.\nIn case you want to install it explicitly (to implement your own client library, for example),\nyou can find it [here](https://pypi.org/project/azure-core/).\n\n## Key concepts\n\n### Azure Core Library Exceptions\n\n#### AzureError\n\nAzureError is the base exception for all errors.\n\n```python\nclass AzureError(Exception):\n    def __init__(self, message, *args, **kwargs):\n        self.inner_exception = kwargs.get(\"error\")\n        self.exc_type, self.exc_value, self.exc_traceback = sys.exc_info()\n        self.exc_type = self.exc_type.__name__ if self.exc_type else type(self.inner_exception)\n        self.exc_msg = \"{}, {}: {}\".format(message, self.exc_type, self.exc_value)  # type: ignore\n        self.message = str(message)\n        self.continuation_token = kwargs.get(\"continuation_token\")\n        super(AzureError, self).__init__(self.message, *args)\n```\n\n*message* is any message (str) to be associated with the exception.\n\n*args* are any additional args to be included with exception.\n\n*kwargs* are keyword arguments to include with the exception. Use the keyword *error* to pass in an internal exception and *continuation_token* for a token reference to continue an incomplete operation.\n\n**The following exceptions inherit from AzureError:**\n\n#### ServiceRequestError\n\nAn error occurred while attempt to make a request to the service. No request was sent.\n\n#### ServiceResponseError\n\nThe request was sent, but the client failed to understand the response.\nThe connection may have timed out. These errors can be retried for idempotent or safe operations.\n\n#### HttpResponseError\n\nA request was made, and a non-success status code was received from the service.\n\n```python\nclass HttpResponseError(AzureError):\n    def __init__(self, message=None, response=None, **kwargs):\n        self.reason = None\n        self.response = response\n        if response:\n            self.reason = response.reason\n            self.status_code = response.status_code\n        self.error = self._parse_odata_body(ODataV4Format, response)  # type: Optional[ODataV4Format]\n        if self.error:\n            message = str(self.error)\n        else:\n            message = message or \"Operation returned an invalid status '{}'\".format(\n                self.reason\n            )\n\n        super(HttpResponseError, self).__init__(message=message, **kwargs)\n```\n\n*message* is the HTTP response error message (optional)\n\n*response* is the HTTP response (optional).\n\n*kwargs* are keyword arguments to include with the exception.\n\n**The following exceptions inherit from HttpResponseError:**\n\n#### DecodeError\n\nAn error raised during response de-serialization.\n\n#### IncompleteReadError\n\nAn error raised if peer closes the connection before we have received the complete message body.\n\n#### ResourceExistsError\n\nAn error response with status code 4xx. This will not be raised directly by the Azure core pipeline.\n\n#### ResourceNotFoundError\n\nAn error response, typically triggered by a 412 response (for update) or 404 (for get/post).\n\n#### ResourceModifiedError\n\nAn error response with status code 4xx, typically 412 Conflict. This will not be raised directly by the Azure core pipeline.\n\n#### ResourceNotModifiedError\n\nAn error response with status code 304. This will not be raised directly by the Azure core pipeline.\n\n#### ClientAuthenticationError\n\nAn error response with status code 4xx. This will not be raised directly by the Azure core pipeline.\n\n#### TooManyRedirectsError\n\nAn error raised when the maximum number of redirect attempts is reached. The maximum amount of redirects can be configured in the RedirectPolicy.\n\n```python\nclass TooManyRedirectsError(HttpResponseError):\n    def __init__(self, history, *args, **kwargs):\n        self.history = history\n        message = \"Reached maximum redirect attempts.\"\n        super(TooManyRedirectsError, self).__init__(message, *args, **kwargs)\n```\n\n*history* is used to document the requests/responses that resulted in redirected requests.\n\n*args* are any additional args to be included with exception.\n\n*kwargs* are keyword arguments to include with the exception.\n\n#### StreamConsumedError\n\nAn error thrown if you try to access the stream of `azure.core.rest.HttpResponse` or `azure.core.rest.AsyncHttpResponse` once\nthe response stream has been consumed.\n\n#### StreamClosedError\n\nAn error thrown if you try to access the stream of the `azure.core.rest.HttpResponse` or `azure.core.rest.AsyncHttpResponse` once\nthe response stream has been closed.\n\n#### ResponseNotReadError\n\nAn error thrown if you try to access the `content` of `azure.core.rest.HttpResponse` or `azure.core.rest.AsyncHttpResponse` before\nreading in the response's bytes first.\n\n### Configurations\n\nWhen calling the methods, some properties can be configured by passing in as kwargs arguments.\n\n| Parameters | Description |\n| --- | --- |\n| headers | The HTTP Request headers. |\n| request_id | The request id to be added into header. |\n| user_agent | If specified, this will be added in front of the user agent string. |\n| logging_enable| Use to enable per operation. Defaults to `False`. |\n| logger | If specified, it will be used to log information. |\n| response_encoding | The encoding to use if known for this service (will disable auto-detection). |\n| raw_request_hook | Callback function. Will be invoked on request. |\n| raw_response_hook | Callback function. Will be invoked on response. |\n| network_span_namer | A callable to customize the span name. |\n| tracing_attributes | Attributes to set on all created spans. |\n| permit_redirects | Whether the client allows redirects. Defaults to `True`. |\n| redirect_max | The maximum allowed redirects. Defaults to `30`. |\n| retry_total | Total number of retries to allow. Takes precedence over other counts. Default value is `10`. |\n| retry_connect | How many connection-related errors to retry on. These are errors raised before the request is sent to the remote server, which we assume has not triggered the server to process the request. Default value is `3`. |\n| retry_read | How many times to retry on read errors. These errors are raised after the request was sent to the server, so the request may have side-effects. Default value is `3`. |\n| retry_status | How many times to retry on bad status codes. Default value is `3`. |\n| retry_backoff_factor | A backoff factor to apply between attempts after the second try (most errors are resolved immediately by a second try without a delay). Retry policy will sleep for: `{backoff factor} * (2 ** ({number of total retries} - 1))` seconds. If the backoff_factor is 0.1, then the retry will sleep for [0.0s, 0.2s, 0.4s, ...] between retries. The default value is `0.8`. |\n| retry_backoff_max | The maximum back off time. Default value is `120` seconds (2 minutes). |\n| retry_mode | Fixed or exponential delay between attempts, default is `Exponential`. |\n| timeout | Timeout setting for the operation in seconds, default is `604800`s (7 days). |\n| connection_timeout | A single float in seconds for the connection timeout. Defaults to `300` seconds. |\n| read_timeout | A single float in seconds for the read timeout. Defaults to `300` seconds. |\n| connection_verify | SSL certificate verification. Enabled by default. Set to False to disable, alternatively can be set to the path to a CA_BUNDLE file or directory with certificates of trusted CAs. |\n| connection_cert | Client-side certificates. You can specify a local cert to use as client side certificate, as a single file (containing the private key and the certificate) or as a tuple of both files' paths. |\n| proxies | Dictionary mapping protocol or protocol and hostname to the URL of the proxy. |\n| cookies | Dict or CookieJar object to send with the `Request`. |\n| connection_data_block_size | The block size of data sent over the connection. Defaults to `4096` bytes. |\n\n### Async transport\n\nThe async transport is designed to be opt-in. [AioHttp](https://pypi.org/project/aiohttp/) is one of the supported implementations of async transport. It is not installed by default. You need to install it separately.\n\n### Shared modules\n\n#### MatchConditions\n\nMatchConditions is an enum to describe match conditions.\n\n```python\nclass MatchConditions(Enum):\n    Unconditionally = 1  # Matches any condition\n    IfNotModified = 2  # If the target object is not modified. Usually it maps to etag=<specific etag>\n    IfModified = 3  # Only if the target object is modified. Usually it maps to etag!=<specific etag>\n    IfPresent = 4   # If the target object exists. Usually it maps to etag='*'\n    IfMissing = 5   # If the target object does not exist. Usually it maps to etag!='*'\n```\n\n#### CaseInsensitiveEnumMeta\n\nA metaclass to support case-insensitive enums.\n\n```python\nfrom enum import Enum\n\nfrom azure.core import CaseInsensitiveEnumMeta\n\nclass MyCustomEnum(str, Enum, metaclass=CaseInsensitiveEnumMeta):\n    FOO = 'foo'\n    BAR = 'bar'\n```\n\n#### Null Sentinel Value\n\nA falsy sentinel object which is supposed to be used to specify attributes\nwith no data. This gets serialized to `null` on the wire.\n\n```python\nfrom azure.core.serialization import NULL\n\nassert bool(NULL) is False\n\nfoo = Foo(\n    attr=NULL\n)\n```\n\n## Logging\n\nAzure libraries follow the guidance of Python's standard [logging](https://docs.python.org/3/library/logging.html) module. By following the Python documentation on logging, you should be able to configure logging for Azure libraries effectively.\n\nAzure library loggers use a dot-based separated syntax, where the first section is always `azure`, followed by the package name. For example, the Azure Core library uses logger names that start with `azure.core`.\n\nHere's an example of how to configure logging for Azure libraries:\n\n```python\nimport logging\nimport sys\n\n# Enable detailed console logs across Azure libraries\nazure_logger = logging.getLogger(\"azure\")\nazure_logger.setLevel(logging.DEBUG)\nazure_logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n\n# Exclude detailed logs for network calls associated with getting Entra ID token.\nidentity_logger = logging.getLogger(\"azure.identity\")\nidentity_logger.setLevel(logging.ERROR)\n\n# Make sure regular (redacted) detailed azure.core logs are not shown, as we are about to\n# turn on non-redacted logs by passing 'logging_enable=True' to the client constructor \nlogger = logging.getLogger(\"azure.core.pipeline.policies.http_logging_policy\")\nlogger.setLevel(logging.ERROR)\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require\nyou to agree to a Contributor License Agreement (CLA) declaring that you have\nthe right to, and actually do, grant us the rights to use your contribution.\nFor details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether\nyou need to provide a CLA and decorate the PR appropriately (e.g., label,\ncomment). Simply follow the instructions provided by the bot. You will only\nneed to do this once across all repos using our CLA.\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information, see the\n[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any\nadditional questions or comments.\n\n<!-- LINKS -->\n[package]: https://pypi.org/project/azure-core/\n\n\n# Release History\n\n## 1.38.1 (2026-02-10)\n\n### Bugs Fixed\n\n- Fixed `PipelineClient.format_url` to avoid adding trailing slashes when the URL template contains only query parameters.  #45044\n\n## 1.38.0 (2026-01-12)\n\n### Breaking Changes\n\n- Changed the continuation token format. Continuation tokens generated by previous versions of azure-core are not compatible with this version.\n\n## 1.37.0 (2025-12-11)\n\n### Features Added\n\n- Added `get_backcompat_attr_name` to `azure.core.serialization`. `get_backcompat_attr_name` gets the backcompat name of an attribute using backcompat attribute access.  #44084\n\n### Bugs Fixed\n\n- Fixed leaked requests and aiohttp exceptions for streamed responses #43200\n- Improved granularity of ServiceRequestError and ServiceResponseError exceptions raised in timeout scenarios from the requests and aiohttp transports #43200\n\n## 1.36.0 (2025-10-14)\n\n### Features Added\n\n- Added `TypeHandlerRegistry` to `azure.core.serialization` to allow developers to register custom serializers and deserializers for specific types or conditions.  #43051\n\n### Bugs Fixed\n\n- Fixed repeated import attempts of cchardet and chardet when charset_normalizer is used #43092\n\n### Other Changes\n\n- Removed `six` as a dependency since it was unused. #39962\n- Added caching to the tracing implementation detection function to prevent potential performance issues from repeated import attempts. #43338\n\n## 1.35.1 (2025-09-11)\n\n### Bugs Fixed\n\n- Fixed an issue where the `retry_backoff_max` parameter in `RetryPolicy` and `AsyncRetryPolicy` constructors was being ignored, causing retry operations to use default maximum backoff values instead of the user-specified limits. #42444\n\n### Other Changes\n\n- `BearerTokenCredentialPolicy` and `AsyncBearerTokenCredentialPolicy` will now properly surface credential exceptions when handling claims challenges. Previously, exceptions from credential token requests were suppressed; now they are raised and chained with the original 401 `HttpResponseError` response for better debugging visibility. #42536\n\n## 1.35.0 (2025-07-02)\n\n### Features Added\n\n- Added a `start_time` keyword argument to the `start_span` and `start_as_current_span` methods in the `OpenTelemetryTracer` class. This allows users to specify a custom start time for created spans. #41106\n- Added a `context` keyword argument to the `start_span` and `start_as_current_span` methods in the `OpenTelemetryTracer` class. This allows users to specify a custom parent context for created spans. #41511\n- Added method `as_attribute_dict` to `azure.core.serialization` for backcompat migration purposes. Will return a generated model as a dictionary where the keys are in attribute syntax.\n- Added `is_generated_model` method to `azure.core.serialization`. Returns whether a given input is a model from one of our generated sdks. #41445\n- Added `attribute_list` method to `azure.core.serialization`. Returns all of the attributes of a given model from one of our generated sdks. #41571\n\n### Other Changes\n\n- A timeout error when using the `aiohttp` transport (the default for async SDKs) will now be raised as a `azure.core.exceptions.ServiceResponseTimeoutError`, a subtype of the previously raised `ServiceResponseError`.\n- When using with `aiohttp` 3.10 or later, a connection timeout error will now be raised as a `azure.core.exceptions.ServiceRequestTimeoutError`, which can be retried.\n- The default implementation of `on_challenge` in `BearerTokenCredentialPolicy` and `AsyncBearerTokenCredentialPolicy` will now cache the retrieved token. #41857\n\n## 1.34.0 (2025-05-01)\n\n### Features Added\n\n- Added a `set_span_error_status` method to the `OpenTelemetryTracer` class. This method allows users to set the status of a span to `ERROR` after it has been created. #40703\n\n### Other Changes\n\n- Python 3.8 is no longer supported. Please use Python version 3.9 or later.\n\n## 1.33.0 (2025-04-03)\n\n### Features Added\n\n- Added native OpenTelemetry tracing to Azure Core which enables users to use OpenTelemetry to trace Azure SDK operations without needing to install a plugin. #39563\n    - To enable native OpenTelemetry tracing, users need to:\n        1. Have `opentelemetry-api` installed.\n        2. Ensure that `settings.tracing_implementation` is not set.\n        3. Ensure that `settings.tracing_enabled` is set to `True`.\n    - If `setting.tracing_implementation` is set, the tracing plugin will be used instead of the native tracing.\n    - If `settings.tracing_enabled` is set to `False`, tracing will be disabled.\n    - The `OpenTelemetryTracer` class was added to the `azure.core.tracing.opentelemetry` module. This is a wrapper around the OpenTelemetry tracer that is used to create spans for Azure SDK operations.\n    - Added a `get_tracer` method to the new `azure.core.instrumentation` module. This method returns an instance of the `OpenTelemetryTracer` class if OpenTelemetry is available.\n    - A `TracingOptions` TypedDict class was added to define the options that SDK users can use to configure tracing per-operation. These options include the ability to enable or disable tracing and set additional attributes on spans.\n        - Example usage: `client.method(tracing_options={\"enabled\": True, \"attributes\": {\"foo\": \"bar\"}})`\n    - The `DistributedTracingPolicy` and `distributed_trace`/`distributed_trace_async` decorators now uses the OpenTelemetry tracer if it is available and native tracing is enabled.\n        - SDK clients can define an `_instrumentation_config` class variable to configure the OpenTelemetry tracer used in method span creation. Possible configuration options are `library_name`, `library_version`, `schema_url`, and `attributes`.\n        - `DistributedTracingPolicy` now accepts a `instrumentation_config` keyword argument to configure the OpenTelemetry tracer used in HTTP span creation.\n\n### Breaking Changes\n\n- Removed automatic tracing enablement for the OpenTelemetry plugin if `opentelemetry` was imported. To enable tracing with the plugin, please import `azure.core.settings.settings` and set `settings.tracing_implementation` to `\"opentelemetry\"`. #39563\n- In `DistributedTracingPolicy`, the default span name is now just the HTTP method (e.g., \"GET\", \"POST\") and no longer includes the URL path. This change was made to converge with the OpenTelemetry HTTP semantic conventions. The full URL is still included in the span attributes.\n- Renamed span attributes in `DistributedTracingPolicy`:\n    - \"x-ms-client-request-id\" is now \"az.client_request_id\"\n    - \"x-ms-request-id\" is now \"az.service_request_id\"\n\n### Bugs Fixed\n\n- Fixed an issue where the `traceparent` header was not being set correctly in the `DistributedTracingPolicy`. The `traceparent` header will now set based on the context of the HTTP client span. #40074\n\n### Other Changes\n\n- Added `opentelemetry-api` as an optional dependency for tracing. This can be installed with `pip install azure-core[tracing]`. #39563\n\n## 1.32.0 (2024-10-31)\n\n### Features Added\n\n- Added a default implementation to handle token challenges in `BearerTokenCredentialPolicy` and `AsyncBearerTokenCredentialPolicy`.\n\n### Bugs Fixed\n\n- Fixed an issue where the `tracing_attributes` keyword argument wasn't being handled at the request/method level. #38164\n\n### Other Changes\n\n- Log \"x-vss-e2eid\" and \"x-msedge-ref\" headers in `HttpLoggingPolicy`.\n\n## 1.31.0 (2024-09-12)\n\n### Features Added\n\n- Added azure.core.AzureClouds enum to represent the different Azure clouds.\n- Added two new credential protocol classes, `SupportsTokenInfo` and `AsyncSupportsTokenInfo`, to offer more extensibility in supporting various token acquisition scenarios. #36565\n  - Each new protocol class defines a `get_token_info` method that returns an `AccessTokenInfo` object.\n- Added a new `TokenRequestOptions` class, which is a `TypedDict` with optional parameters, that can be used to define options for token requests through the `get_token_info` method. #36565\n- Added a new `AccessTokenInfo` class, which is returned by `get_token_info` implementations. This class contains the token, its expiration time, and optional additional information like when a token should be refreshed. #36565\n- `BearerTokenCredentialPolicy` and `AsyncBearerTokenCredentialPolicy` now first check if a credential has the `get_token_info` method defined. If so, the `get_token_info` method is used to acquire a token. Otherwise, the `get_token` method is used. #36565\n  - These policies now also check the `refresh_on` attribute when determining if a new token request should be made.\n\n### Other Changes\n\n- The Azure Core OpenTelemetry tracing plugin will now be the preferred tracing plugin over the OpenCensus plugin. If both plugins are installed and `opentelemetry` is imported, then OpenTelemetry will be used to trace Azure SDK operations.  #35050\n\n## 1.30.2 (2024-06-06)\n\n### Features Added\n\n- Tracing: `DistributedTracingPolicy` will now set an attribute, `http.request.resend_count`, on HTTP spans for resent requests to indicate the resend attempt number.  #35069\n\n### Bugs Fixed\n\n- Raise correct exception if transport is used while already closed  #35559\n\n### Other Changes\n\n- HTTP tracing spans will now include an `error.type` attribute if an error status code is returned.  #34619\n- Minimum required Python version is now 3.8\n\n## 1.30.1 (2024-02-29)\n\n### Other Changes\n\n- Accept float for `retry_after` header.  #34203\n\n## 1.30.0 (2024-02-01)\n\n### Features Added\n\n- Support tuple input for file values  to `azure.core.rest.HttpRequest`  #33948\n- Support tuple input to `files` with duplicate field names  `azure.core.rest.HttpRequest`  #34021\n\n## 1.29.7 (2024-01-18)\n\n### Other Changes\n\n- Removed dependency on `anyio`.  #33282\n\n## 1.29.6 (2023-12-14)\n\n### Bugs Fixed\n\n- Adjusted `AsyncBearerTokenCredentialPolicy` to work properly with `trio` concurrency mechanisms.   ([#33307](https://github.com/Azure/azure-sdk-for-python/pull/33307))\n\n### Other Changes\n\n- Added dependency on `anyio` >=3.0,<5.0\n- Bumped minimum dependency on `requests` to 2.21.0.\n\n## 1.29.5 (2023-10-19)\n\n### Bugs Fixed\n\n- Fixed an issue with `multipart/form-data` in the async transport where `data` was not getting encoded into the request body. #32473\n\n### Other Changes\n\n- Use ssl context from aiohttp by default.\n\n## 1.29.4 (2023-09-07)\n\n### Bugs Fixed\n\n- Fixed the issue that some urls trigger an infinite loop. #31346\n- Fixed issue where IndexError was raised if multipart responses did not match the number of requests. #31471\n- Fixed issue unbound variable exception if dict is invalid in CloudEvent.from_dict. #31835\n- Fixed issue asyncBearerTokenCredentialPolicy is not backward compatible with SansIOHTTPPolicy. #31836\n- Fixed issue mypy complains with new version of azure-core. #31564\n\n## 1.29.3 (2023-08-22)\n\n### Bugs Fixed\n\n- Typing fix: `message` cannot be `None` in `AzureError`. #31564\n\n## 1.29.2 (2023-08-14)\n\n### Bugs Fixed\n\n- Added a default implementation for `AsyncTokenCredential.__aexit__()` #31573\n\n### Other Changes\n\n- Bumped `typing-extensions` version to 4.6.0.\n\n## 1.29.1 (2023-08-09)\n\n### Bugs Fixed\n\n- Not pass `enabled_cae` unless it is explicitly enabled.\n\n## 1.29.0 (2023-08-03)\n\n### Features Added\n\n- A keyword argument `enable_cae` was added to the `get_token` method of the `TokenCredential` protocol.  #31012\n- `BearerTokenCredentialPolicy` and `AsyncBearerTokenCredentialPolicy` now accept `enable_cae` keyword arguments in their constructors. This is used in determining if [Continuous Access Evaluation (CAE)](https://learn.microsoft.com/azure/active-directory/conditional-access/concept-continuous-access-evaluation) should be enabled for each `get_token` request.  #31012\n\n## 1.28.0 (2023-07-06)\n\n### Features Added\n\n- Added header name parameter to `RequestIdPolicy`. #30772\n- Added `SensitiveHeaderCleanupPolicy` that cleans up sensitive headers if a redirect happens and the new destination is in another domain. #28349\n\n### Other Changes\n\n- Catch aiohttp errors and translate them into azure-core errors.\n\n## 1.27.1 (2023-06-13)\n\n### Bugs Fixed\n\n- Fix url building for some complex query parameters scenarios  #30707\n\n## 1.27.0 (2023-06-01)\n\n### Features Added\n\n- Added support to use sync credentials in `AsyncBearerTokenCredentialPolicy`. #30381\n- Added \"prefix\" parameter to AzureKeyCredentialPolicy #29901\n\n### Bugs Fixed\n\n- Improve error message when providing the wrong credential type for AzureKeyCredential  #30380\n\n## 1.26.4 (2023-04-06)\n\n### Features Added\n\n- Updated settings to include OpenTelemetry as a tracer provider.  #29095\n\n### Other Changes\n\n- Improved typing\n\n## 1.26.3 (2023-02-02)\n\n### Bugs Fixed\n\n- Fixed deflate decompression for aiohttp   #28483\n\n## 1.26.2 (2023-01-05)\n\n### Bugs Fixed\n\n- Fix 'ClientSession' object has no attribute 'auto_decompress'  (thanks to @mghextreme for the contribution)\n\n### Other Changes\n\n- Add \"x-ms-error-code\" as secure header to log\n- Rename \"DEFAULT_HEADERS_WHITELIST\" to \"DEFAULT_HEADERS_ALLOWLIST\". Added a backward compatible alias.\n\n## 1.26.1 (2022-11-03)\n\n### Other Changes\n\n- Added example of RequestsTransport with custom session.  (thanks to @inirudebwoy for the contribution)   #26768\n- Added Python 3.11 support.\n\n## 1.26.0 (2022-10-06)\n\n### Other Changes\n\n- LRO polling will not wait anymore before doing the first status check  #26376\n- Added extra dependency for [aio]. pip install azure-core[aio] installs aiohttp too.\n\n## 1.25.1 (2022-09-01)\n\n### Bugs Fixed\n\n- Added @runtime_checkable to `TokenCredential` protocol definitions  #25187\n\n## 1.25.0 (2022-08-04)\n\nAzure-core is supported on Python 3.7 or later. For more details, please read our page on [Azure SDK for Python version support policy](https://github.com/Azure/azure-sdk-for-python/wiki/Azure-SDKs-Python-version-support-policy).\n\n### Features Added\n\n- Added `CaseInsensitiveDict` implementation in `azure.core.utils` removing dependency on `requests` and `aiohttp`\n\n## 1.24.2 (2022-06-30)\n\n### Bugs Fixed\n\n- Fixed the bug that azure-core could not be imported under Python 3.11.0b3  #24928\n- `ContentDecodePolicy` can now correctly deserialize more JSON bodies with different mime types #22410\n\n## 1.24.1 (2022-06-01)\n\n### Bugs Fixed\n\n- Declare method level span as INTERNAL by default  #24492\n- Fixed type hints for `azure.core.paging.ItemPaged` #24548\n\n## 1.24.0 (2022-05-06)\n\n### Features Added\n\n- Add `SerializationError` and `DeserializationError` in `azure.core.exceptions` for errors raised during serialization / deserialization  #24312\n\n## 1.23.1 (2022-03-31)\n\n### Bugs Fixed\n\n- Allow stream inputs to the `content` kwarg of `azure.core.rest.HttpRequest` from objects with a `read` method  #23578\n\n## 1.23.0 (2022-03-03)\n\n### Features Added\n\n- Improve intellisense type hinting for service client methods. #22891\n\n- Add a case insensitive dict `case_insensitive_dict` in `azure.core.utils`.  #23206\n\n### Bugs Fixed\n\n- Use \"\\n\" rather than \"/n\" for new line in log.     #23261\n\n### Other Changes\n\n- Log \"WWW-Authenticate\" header in `HttpLoggingPolicy`  #22990\n- Added dependency on `typing-extensions` >= 4.0.1\n\n## 1.22.1 (2022-02-09)\n\n### Bugs Fixed\n\n- Limiting `final-state-via` scope to POST until consuming SDKs has been fixed to use this option properly on PUT.  #22989\n\n## 1.22.0 (2022-02-03)\n_[**This version is deprecated.**]_\n\n### Features Added\n\n- Add support for `final-state-via` LRO option in core.  #22713\n\n### Bugs Fixed\n\n- Add response body to string representation of `HttpResponseError` if we're not able to parse out information #22302\n- Raise `AttributeError` when calling azure.core.pipeline.transport.\\_\\_bases__    #22469\n\n### Other Changes\n\n- Python 2.7 is no longer supported. Please use Python version 3.6 or later.\n\n## 1.21.1 (2021-12-06)\n\n### Other Changes\n\n- Revert change in str method  #22023\n\n## 1.21.0 (2021-12-02)\n\n### Breaking Changes\n\n- Sync stream downloading now raises `azure.core.exceptions.DecodeError` rather than `requests.exceptions.ContentDecodingError`\n\n### Bugs Fixed\n\n- Add response body to string representation of `HttpResponseError` if we're not able to parse out information #21800\n\n## 1.20.1 (2021-11-08)\n\n### Bugs Fixed\n\n- Correctly set response's content to decompressed body when users are using aiohttp transport with decompression headers #21620\n\n## 1.20.0 (2021-11-04)\n\n### Features Added\n\n- GA `send_request` onto the `azure.core.PipelineClient` and `azure.core.AsyncPipelineClient`. This method takes in\nrequests and sends them through our pipelines.\n- GA `azure.core.rest`. `azure.core.rest` is our new public simple HTTP library in `azure.core` that users will use to create requests, and consume responses.\n- GA errors `StreamConsumedError`, `StreamClosedError`, and `ResponseNotReadError` to `azure.core.exceptions`. These errors\nare thrown if you mishandle streamed responses from the `azure.core.rest` module\n- add kwargs to the methods for `iter_raw` and `iter_bytes`  #21529\n- no longer raise JSON errors if users pass in file descriptors of JSON to the `json` kwarg in `HttpRequest`  #21504\n- Added new error type `IncompleteReadError` which is raised if peer closes the connection before we have received the complete message body.\n\n### Breaking Changes\n\n- SansIOHTTPPolicy.on_exception returns None instead of bool.\n\n### Bugs Fixed\n\n- The `Content-Length` header in a http response is strictly checked against the actual number of bytes in the body,\n  rather than silently truncating data in case the underlying tcp connection is closed prematurely.\n  (thanks to @jochen-ott-by for the contribution)   #20412\n- UnboundLocalError when SansIOHTTPPolicy handles an exception    #15222\n- Add default content type header of `text/plain` and content length header for users who pass unicode strings to the `content` kwarg of `HttpRequest` in 2.7  #21550\n\n## 1.19.1 (2021-11-01)\n\n### Bugs Fixed\n\n- respect text encoding specified in argument (thanks to @ryohji for the contribution)  #20796\n- Fix \"coroutine x.read() was never awaited\" warning from `ContentDecodePolicy`  #21318\n- fix type check for `data` input to `azure.core.rest` for python 2.7 users  #21341\n- use `charset_normalizer` if `chardet` is not installed to migrate aiohttp 3.8.0 changes.\n\n### Other Changes\n\n- Refactor AzureJSONEncoder (thanks to @Codejune for the contribution)  #21028\n\n## 1.19.0 (2021-09-30)\n\n### Breaking Changes in the Provisional `azure.core.rest` package\n\n- `azure.core.rest.HttpResponse` and `azure.core.rest.AsyncHttpResponse` are now abstract base classes. They should not be initialized directly, instead\nyour transport responses should inherit from them and implement them.\n- The properties of the `azure.core.rest` responses are now all read-only\n\n- HttpLoggingPolicy integrates logs into one record #19925\n\n## 1.18.0 (2021-09-02)\n\n### Features Added\n\n- `azure.core.serialization.AzureJSONEncoder` (introduced in 1.17.0) serializes `datetime.datetime` objects in ISO 8601 format, conforming to RFC 3339's specification.    #20190\n- We now use `azure.core.serialization.AzureJSONEncoder` to serialize `json` input to `azure.core.rest.HttpRequest`.\n\n### Breaking Changes in the Provisional `azure.core.rest` package\n\n- The `text` property on `azure.core.rest.HttpResponse` and `azure.core.rest.AsyncHttpResponse` has changed to a method, which also takes\nan `encoding` parameter.\n- Removed `iter_text` and `iter_lines` from `azure.core.rest.HttpResponse` and `azure.core.rest.AsyncHttpResponse`\n\n### Bugs Fixed\n\n- The behaviour of the headers returned in `azure.core.rest` responses now aligns across sync and async. Items can now be checked case-insensitively and without raising an error for format.\n\n## 1.17.0 (2021-08-05)\n\n### Features Added\n\n- Cut hard dependency on requests library\n- Added a `from_json` method which now accepts storage QueueMessage, eventhub's EventData or ServiceBusMessage or simply json bytes to return a `CloudEvent`\n\n### Fixed\n\n- Not override \"x-ms-client-request-id\" if it already exists in the header.    #17757\n\n### Breaking Changes in the Provisional `azure.core.rest` package\n\n- `azure.core.rest` will not try to guess the `charset` anymore if it was impossible to extract it from `HttpResponse` analysis. This removes our dependency on `charset`.\n\n## 1.16.0 (2021-07-01)\n\n### Features Added\n\n- Add new ***provisional*** methods `send_request` onto the `azure.core.PipelineClient` and `azure.core.AsyncPipelineClient`. This method takes in\nrequests and sends them through our pipelines.\n- Add new ***provisional*** module `azure.core.rest`. `azure.core.rest` is our new public simple HTTP library in `azure.core` that users will use to create requests, and consume responses.\n- Add new ***provisional*** errors `StreamConsumedError`, `StreamClosedError`, and `ResponseNotReadError` to `azure.core.exceptions`. These errors\nare thrown if you mishandle streamed responses from the provisional `azure.core.rest` module\n\n### Fixed\n\n- Improved error message in the `from_dict` method of `CloudEvent` when a wrong schema is sent.\n\n## 1.15.0 (2021-06-04)\n\n### New Features\n\n- Added `BearerTokenCredentialPolicy.on_challenge` and `.authorize_request` to allow subclasses to optionally handle authentication challenges\n\n### Bug Fixes\n\n- Retry policies don't sleep after operations time out\n- The `from_dict` methhod in the `CloudEvent` can now convert a datetime string to datetime object when microsecond exceeds the python limitation\n\n## 1.14.0 (2021-05-13)\n\n### New Features\n\n- Added `azure.core.credentials.AzureNamedKeyCredential` credential #17548.\n- Added `decompress` parameter for `stream_download` method. If it is set to `False`, will not do decompression upon the stream.    #17920\n\n## 1.13.0 (2021-04-02)\n\nAzure core requires Python 2.7 or Python 3.6+ since this release.\n\n### New Features\n\n- Added `azure.core.utils.parse_connection_string` function to parse connection strings across SDKs, with common validation and support for case insensitive keys.\n- Supported adding custom policies  #16519\n- Added `~azure.core.tracing.Link` that should be used while passing `Links` to  `AbstractSpan`.\n- `AbstractSpan` constructor can now take in additional keyword only args.\n\n### Bug fixes\n\n- Make NetworkTraceLoggingPolicy show the auth token in plain text. #14191\n- Fixed RetryPolicy overriding default connection timeout with an extreme value #17481\n\n## 1.12.0 (2021-03-08)\n\nThis version will be the last version to officially support Python 3.5, future versions will require Python 2.7 or Python 3.6+.\n\n### Features\n\n- Added `azure.core.messaging.CloudEvent` model that follows the cloud event spec.\n- Added `azure.core.serialization.NULL` sentinel value\n- Improve `repr`s for `HttpRequest` and `HttpResponse`s  #16972\n\n### Bug Fixes\n\n- Disable retry in stream downloading. (thanks to @jochen-ott-by @hoffmann for the contribution)  #16723\n\n## 1.11.0 (2021-02-08)\n\n### Features\n\n- Added `CaseInsensitiveEnumMeta` class for case-insensitive enums.  #16316\n- Add `raise_for_status` method onto `HttpResponse`. Calling `response.raise_for_status()` on a response with an error code\nwill raise an `HttpResponseError`. Calling it on a good response will do nothing  #16399\n\n### Bug Fixes\n\n- Update conn.conn_kw rather than overriding it when setting block size. (thanks for @jiasli for the contribution)  #16587\n\n## 1.10.0 (2021-01-11)\n\n### Features\n\n- Added `AzureSasCredential` and its respective policy. #15946\n\n## 1.9.0 (2020-11-09)\n\n### Features\n\n- Add a `continuation_token` attribute to the base `AzureError` exception, and set this value for errors raised\n  during paged or long-running operations.\n\n### Bug Fixes\n\n- Set retry_interval to 1 second instead of 1000 seconds (thanks **vbarbaresi** for contributing)  #14357\n\n\n## 1.8.2 (2020-10-05)\n\n### Bug Fixes\n\n- Fixed bug to allow polling in the case of parameterized endpoints with relative polling urls  #14097\n\n\n## 1.8.1 (2020-09-08)\n\n### Bug fixes\n\n- SAS credential replicated \"/\" fix #13159\n\n## 1.8.0 (2020-08-10)\n\n### Features\n\n- Support params as list for exploding parameters  #12410\n\n\n## 1.7.0 (2020-07-06)\n\n### Bug fixes\n\n- `AzureKeyCredentialPolicy` will now accept (and ignore) passed in kwargs  #11963\n- Better error messages if passed endpoint is incorrect  #12106\n- Do not JSON encore a string if content type is \"text\"  #12137\n\n### Features\n\n- Added `http_logging_policy` property on the `Configuration` object, allowing users to individually\nset the http logging policy of the config  #12218\n\n## 1.6.0 (2020-06-03)\n\n### Bug fixes\n\n- Fixed deadlocks in AsyncBearerTokenCredentialPolicy #11543\n- Fix AttributeException in StreamDownloadGenerator #11462\n\n### Features\n\n- Added support for changesets as part of multipart message support #10485\n- Add AsyncLROPoller in azure.core.polling #10801\n- Add get_continuation_token/from_continuation_token/polling_method methods in pollers (sync and async) #10801\n- HttpResponse and PipelineContext objects are now pickable #10801\n\n## 1.5.0 (2020-05-04)\n\n### Features\n\n- Support \"x-ms-retry-after-ms\" in response header   #10743\n- `link` and `link_from_headers` now accepts attributes   #10765\n\n### Bug fixes\n\n- Not retry if the status code is less than 400 #10778\n- \"x-ms-request-id\" is not considered safe header for logging #10967\n\n## 1.4.0 (2020-04-06)\n\n### Features\n\n- Support a default error type in map_error #9773\n- Added `AzureKeyCredential` and its respective policy. #10509\n- Added `azure.core.polling.base_polling` module with a \"Microsoft One API\" polling implementation #10090\n  Also contains the async version in `azure.core.polling.async_base_polling`\n- Support kwarg `enforce_https` to disable HTTPS check on authentication #9821\n- Support additional kwargs in `HttpRequest.set_multipart_mixed` that will be passed into pipeline context.\n\n## 1.3.0 (2020-03-09)\n\n### Bug fixes\n\n- Appended RequestIdPolicy to the default pipeline  #9841\n- Rewind the body position in async_retry   #10117\n\n### Features\n\n- Add raw_request_hook support in custom_hook_policy   #9958\n- Add timeout support in retry_policy   #10011\n- Add OdataV4 error format auto-parsing in all exceptions ('error' attribute)  #9738\n\n## 1.2.2 (2020-02-10)\n\n### Bug fixes\n\n- Fixed a bug that sends None as request_id #9545\n- Enable mypy for customers #9572\n- Handle TypeError in deep copy #9620\n- Fix text/plain content-type in decoder #9589\n\n## 1.2.1 (2020-01-14)\n\n### Bug fixes\n\n- Fixed a regression in 1.2.0 that was incompatible with azure-keyvault-* 4.0.0\n[#9462](https://github.com/Azure/azure-sdk-for-python/issues/9462)\n\n\n## 1.2.0 (2020-01-14)\n\n### Features\n\n- Add user_agent & sdk_moniker kwargs in UserAgentPolicy init   #9355\n- Support OPTIONS HTTP verb     #9322\n- Add tracing_attributes to tracing decorator   #9297\n- Support auto_request_id in RequestIdPolicy   #9163\n- Support fixed retry   #6419\n- Support \"retry-after-ms\" in response header   #9240\n\n### Bug fixes\n\n- Removed `__enter__` and `__exit__` from async context managers    #9313\n\n## 1.1.1 (2019-12-03)\n\n### Bug fixes\n\n- Bearer token authorization requires HTTPS\n- Rewind the body position in retry #8307\n\n## 1.1.0 (2019-11-25)\n\n### Features\n\n- New RequestIdPolicy   #8437\n- Enable logging policy in default pipeline #8053\n- Normalize transport timeout.   #8000\n  Now we have:\n  * 'connection_timeout' - a single float in seconds for the connection timeout. Default 5min\n  * 'read_timeout' - a single float in seconds for the read timeout. Default 5min\n\n### Bug fixes\n\n- RequestHistory: deepcopy fails if request contains a stream  #7732\n- Retry: retry raises error if response does not have http_response #8629\n- Client kwargs are now passed to DistributedTracingPolicy correctly    #8051\n- NetworkLoggingPolicy now logs correctly all requests in case of retry #8262\n\n## 1.0.0 (2019-10-29)\n\n### Features\n\n- Tracing: DistributedTracingPolicy now accepts kwargs network_span_namer to change network span name  #7773\n- Tracing: Implementation of AbstractSpan can now use the mixin HttpSpanMixin to get HTTP span update automatically  #7773\n- Tracing: AbstractSpan contract \"change_context\" introduced  #7773\n- Introduce new policy HttpLoggingPolicy  #7988\n\n### Bug fixes\n\n- Fix AsyncioRequestsTransport if input stream is an async generator  #7743\n- Fix form-data with aiohttp transport  #7749\n\n### Breaking changes\n\n- Tracing: AbstractSpan.set_current_span is longer supported. Use change_context instead.  #7773\n- azure.core.pipeline.policies.ContentDecodePolicy.deserialize_from_text changed\n\n## 1.0.0b4 (2019-10-07)\n\n### Features\n\n- Tracing: network span context is available with the TRACING_CONTEXT in pipeline response  #7252\n- Tracing: Span contract now has `kind`, `traceparent` and is a context manager  #7252\n- SansIOHTTPPolicy methods can now be coroutines #7497\n- Add multipart/mixed support #7083:\n\n  - HttpRequest now has a \"set_multipart_mixed\" method to set the parts of this request\n  - HttpRequest now has a \"prepare_multipart_body\" method to build final body.\n  - HttpResponse now has a \"parts\" method to return an iterator of parts\n  - AsyncHttpResponse now has a \"parts\" methods to return an async iterator of parts\n  - Note that multipart/mixed is a Python 3.x only feature\n\n### Bug fixes\n\n- Tracing: policy cannot fail the pipeline, even in the worst condition  #7252\n- Tracing: policy pass correctly status message if exception  #7252\n- Tracing: incorrect span if exception raised from decorated function  #7133\n- Fixed urllib3 ConnectTimeoutError being raised by Requests during a socket timeout. Now this exception is caught and wrapped as a `ServiceRequestError`  #7542\n\n### Breaking changes\n\n- Tracing: `azure.core.tracing.context` removed\n- Tracing: `azure.core.tracing.context.tracing_context.with_current_context` renamed to `azure.core.tracing.common.with_current_context`  #7252\n- Tracing: `link` renamed `link_from_headers`  and `link` takes now a string\n- Tracing: opencensus implementation has been moved to the package `azure-core-tracing-opencensus`\n- Some modules and classes that were importables from several different places have been removed:\n\n   - `azure.core.HttpResponseError` is now only `azure.core.exceptions.HttpResponseError`\n   - `azure.core.Configuration` is now only `azure.core.configuration.Configuration`\n   - `azure.core.HttpRequest` is now only `azure.core.pipeline.transport.HttpRequest`\n   - `azure.core.version` module has been removed. Use `azure.core.__version__` to get version number.\n   - `azure.core.pipeline_client` has been removed. Import from `azure.core` instead.\n   - `azure.core.pipeline_client_async` has been removed. Import from `azure.core` instead.\n   - `azure.core.pipeline.base` has been removed. Import from `azure.core.pipeline` instead.\n   - `azure.core.pipeline.base_async` has been removed. Import from `azure.core.pipeline` instead.\n   - `azure.core.pipeline.policies.base` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.base_async` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.authentication` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.authentication_async` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.custom_hook` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.redirect` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.redirect_async` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.retry` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.retry_async` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.distributed_tracing` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.pipeline.policies.universal` has been removed. Import from `azure.core.pipeline.policies` instead.\n   - `azure.core.tracing.abstract_span` has been removed. Import from `azure.core.tracing` instead.\n   - `azure.core.pipeline.transport.base` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.pipeline.transport.base_async` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.pipeline.transport.requests_basic` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.pipeline.transport.requests_asyncio` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.pipeline.transport.requests_trio` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.pipeline.transport.aiohttp` has been removed. Import from `azure.core.pipeline.transport` instead.\n   - `azure.core.polling.poller` has been removed. Import from `azure.core.polling` instead.\n   - `azure.core.polling.async_poller` has been removed. Import from `azure.core.polling` instead.\n\n## 1.0.0b3 (2019-09-09)\n\n### Bug fixes\n\n-  Fix aiohttp auto-headers #6992\n-  Add tracing to policies module init  #6951\n\n## 1.0.0b2 (2019-08-05)\n\n### Breaking changes\n\n- Transport classes don't take `config` parameter anymore (use kwargs instead)  #6372\n- `azure.core.paging` has been completely refactored  #6420\n- HttpResponse.content_type attribute is now a string (was a list)  #6490\n- For `StreamDownloadGenerator` subclasses, `response` is now an `HttpResponse`, and not a transport response like `aiohttp.ClientResponse` or `requests.Response`. The transport response is available in `internal_response` attribute  #6490\n\n### Bug fixes\n\n- aiohttp is not required to import async pipelines classes #6496\n- `AsyncioRequestsTransport.sleep` is now a coroutine as expected #6490\n- `RequestsTransport` is not tight to `ProxyPolicy` implementation details anymore #6372\n- `AiohttpTransport` does not raise on unexpected kwargs  #6355\n\n### Features\n\n- New paging base classes that support `continuation_token` and `by_page()`  #6420\n- Proxy support for `AiohttpTransport`  #6372\n\n## 1.0.0b1 (2019-06-26)\n\n- Preview 1 release\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/core/azure-core",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "requests>=2.21.0",
          "typing-extensions>=4.6.0",
          "aiohttp>=3.0; extra == \"aio\"",
          "opentelemetry-api~=1.26; extra == \"tracing\""
        ],
        "requires_python": ">=3.9",
        "provides_extra": [
          "aio",
          "tracing"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/76/5e/97a471f66935e7f89f521d0e11ae49c7f0871ca38f5c319dccae2155c8d8/azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=38fd42709f1cc4bbc4f2797008b1c30a6a01617e49910c05daa3a0d0c65053ac",
          "hashes": {
            "sha256": "38fd42709f1cc4bbc4f2797008b1c30a6a01617e49910c05daa3a0d0c65053ac"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "azure-core-tracing-opentelemetry",
        "version": "1.0.0b12",
        "summary": "Microsoft Azure Azure Core OpenTelemetry plugin Library for Python",
        "description": "\n\n# Azure Core Tracing OpenTelemetry client library for Python\n\n## Getting started\n\nYou can enable distributed tracing in Azure client libraries by configuring the OpenTelemetry SDK.\nOpenTelemetry is a popular open-source observability framework for generating, capturing, and collecting telemetry data for cloud-native software.\n\nThere are two key concepts related to tracing: span and trace. A span represents a single operation in a trace. A span can represent an HTTP request,\na remote procedure call (RPC), a database query, or even the path that your code takes. A trace is a tree of spans showing the path of work through\na system. You can distinguish a trace on its own by a unique 16-byte sequence called a TraceID. For more information on these concepts and how they\nrelate to OpenTelemetry, see the [OpenTelemetry documentation](https://opentelemetry.io/docs/).\n\n## Tracing with Azure Monitor OpenTelemetry Distro\n\n[Azure Monitor OpenTelemetry Distro](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python) supports tracing for Azure\nSDKs by default. Just install and configure the distro and use Azure clients as usual.\n\n```python\n\n# Enable Azure Monitor OpenTelemetry Distro\n# It confiures Azure SDKs to use OpenTelemetry as well\nfrom azure.monitor.opentelemetry import configure_azure_monitor\nfrom opentelemetry import trace\n\nconfigure_azure_monitor(\n   connection_string=\"<your-connection-string>\"\n)\n\n# Use Azure SDKs as usual, here as an example with Storage SDKs\n# you may also report your own spans for it.\nfrom azure.storage.blob import BlobServiceClient\n\ntracer = trace.get_tracer(__name__)\nwith tracer.start_as_current_span(name=\"MyApplication\"):\n    client = BlobServiceClient.from_connection_string('connectionstring')\n    client.create_container('my_container')  # Call will be traced\n```\n\nThe Azure Monitor OpenTelemetry Distro can be found in the [`azure-monitor-opentelemetry`](https://pypi.org/project/azure-monitor-opentelemetry) package.\n\n## Tracing with generic OpenTelemetry\n\nCheck out your observability provider documentation on how to enable distributed tracing with OpenTelemetry\nor follow [OpenTelemetry Python documentation](https://opentelemetry.io/docs/languages/python/) on generic configuration.\n\nIn addition to common OpenTelemetry configuration, follow this steps to configure Azure SDKs:\n\n1. Install the Azure Core OpenTelemetry Tracing plugin for Python with [pip](https://pypi.org/project/pip/):\n\n   ```bash\n   pip install azure-core-tracing-opentelemetry\n   ```\n\n  Now you can use Azure Core OpenTelemetry Tracing plugin for Python as usual with any SDKs that are compatible\n  with azure-core tracing. This includes (not exhaustive list), `azure-storage-blob`, `azure-keyvault-secrets`, `azure-eventhub`, etc.\n\n2. Specify which tracing implementation Azure SDK should use in one of the following ways:\n   - By setting `AZURE_SDK_TRACING_IMPLEMENTATION` environment variable to `opentelemetry`\n     (just make sure you use a fresh version of `azure-core` and `azure-core-tracing-opentelemetry`)\n\n     ```bash\n     AZURE_SDK_TRACING_IMPLEMENTATION=opentelemetry\n     ```\n\n   - Alternatively, you can set it up in the code:\n\n     ```python\n     from azure.core.settings import settings\n     settings.tracing_implementation = \"opentelemetry\"\n     ```\n\nThis configuration instructs Azure SDK clients to emit spans using global OpenTelemetry instance and\ncorresponding tracer provider.\n\nThere is no need to write any additional code to trace Azure SDK calls or pass trace context explicitly -\nAzure SDKs and OpenTelemetry will do it for you.\n\nHere's a full example:\n\n```python\n\n# Declare OpenTelemetry as enabled tracing plugin for Azure SDKs\nfrom azure.core.settings import settings\n\nsettings.tracing_implementation = \"opentelemetry\"\n\n# In the below example, we use a simple console exporter.\n\n# See https://opentelemetry.io/docs/languages/python/ for more details on OpenTelemetry configuration\n\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter\nfrom opentelemetry.sdk.trace.export import SimpleSpanProcessor\n\n# Simple console exporter\nexporter = ConsoleSpanExporter()\n\ntrace.set_tracer_provider(TracerProvider())\ntrace.get_tracer_provider().add_span_processor(\n    SimpleSpanProcessor(exporter)\n)\n\n# Example with Storage SDKs\n\nfrom azure.storage.blob import BlobServiceClient\n\ntracer = trace.get_tracer(__name__)\nwith tracer.start_as_current_span(name=\"MyApplication\"):\n    client = BlobServiceClient.from_connection_string('connectionstring')\n    client.create_container('my_container')  # Call will be traced\n```\n\n## HTTP instrumentation\n\nWith the Azure Core OpenTelemetry Tracing plugin enabled, HTTP requests made by Azure SDK clients are typically instrumented via the [`DistributedTracingPolicy`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/azure/core/pipeline/policies/_distributed_tracing.py) automatically. Since Azure Core handles HTTP instrumentation for Azure service calls, automatic HTTP instrumentation from other libraries such as `opentelemetry-requests-instrumentation` are suppressed to avoid duplicate spans from being created.\n\n## Troubleshooting\n\nThis client raises exceptions defined in [Azure Core](https://learn.microsoft.com/python/api/azure-core/azure.core.exceptions?view=azure-python).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n\n# Release History\n\n## 1.0.0b12 (2025-03-20)\n\n### Features Added\n\n- If a span exits with an exception, the exception name is now recorded in the `error.type` attribute. ([#34619](https://github.com/Azure/azure-sdk-for-python/pull/34619))\n- Added support for passing a schema version to fetch available attribute mappings and set the schema URL on the tracer's instrumentation scope. ([#40161](https://github.com/Azure/azure-sdk-for-python/pull/40161))\n- Added additional span suppression logic to prevent unnecessary spans from being created. ([#39994](https://github.com/Azure/azure-sdk-for-python/pull/39994))\n    - `SpanKind.INTERNAL` spans are suppressed if their parent span is of type `SpanKind.INTERNAL`, `SpanKind.CLIENT`, or `SpanKind.PRODUCER`.\n- Update `OpenTelemetrySpan.change_context` to also accept spans of type `OpenTelemetrySpan`. ([#39994](https://github.com/Azure/azure-sdk-for-python/pull/39994))\n\n### Bugs Fixed\n\n- Fixed an issue where the original context was not properly restored after exiting an `OpenTelemetrySpan` context in certain scenarios. ([#39994](https://github.com/Azure/azure-sdk-for-python/pull/39994))\n\n## 1.0.0b11 (2023-09-07)\n\n### Bugs Fixed\n\n- Fixed `OpenTelemetrySpan` typing to correctly implement the `AbstractSpan` protocol. ([#31943](https://github.com/Azure/azure-sdk-for-python/pull/31943))\n\n## 1.0.0b10 (2023-07-11)\n\n### Features Added\n\n- Enabled the use of the `context` keyword argument for passing in context headers of a parent span. This will be the parent context used when creating the span. ([#30411](https://github.com/Azure/azure-sdk-for-python/pull/30411))\n\n### Breaking Changes\n\n- Remapped certain attributes to converge with OpenTelemetry semantic conventions ([#29203](https://github.com/Azure/azure-sdk-for-python/pull/29203)):\n    - `x-ms-client-request-id` -> `az.client_request_id`,\n    - `x-ms-request-id` -> `az.service_request_id`,\n    - `http.user_agent` -> `user_agent.original`,\n    - `message_bus.destination` -> `messaging.destination.name`,\n    - `peer.address` -> `net.peer.name`,\n\n### Other Changes\n\n- Python 2.7 is no longer supported. Please use Python version 3.7 or later.\n- Nested internal spans are now suppressed with just the outermost internal span being recorded. Nested client spans will be children of the outermost span. ([#29616](https://github.com/Azure/azure-sdk-for-python/pull/29616))\n- When client spans are created, a flag is set to indicate that automatic HTTP instrumentation should be suppressed. Since azure-core already instruments HTTP calls, this prevents duplicate spans from being produced. ([#29616](https://github.com/Azure/azure-sdk-for-python/pull/29616))\n- Schema URL is now set on the tracer's instrumentation scope. ([#30014](https://github.com/Azure/azure-sdk-for-python/pull/30014))\n- Minimum `opentelemetry-api` dependency bumped to `1.12.0`.\n- Minimum `azure-core` dependency bumped to `1.24.0`.\n\n## 1.0.0b9 (2021-04-06)\n\n- Updated opentelemetry-api to version 1.0.0\n- `Link` and `SpanKind` can now be added while creating the span instance.\n\n## 1.0.0b8 (2021-02-08)\n\n- Pinned opentelemetry-api to version 0.17b0\n\n## 1.0.0b7 (2020-10-05)\n\n- Pinned opentelemetry-api to version 0.13b0\n\n## 1.0.0b6 (2020-07-06)\n\n- Pinned opentelemetry-api to version 0.10b0\n\n## 1.0.0b5 (2020-06-08)\n\n- Pinned opentelemetry-api to version 0.8b0\n- Fixed a bug where `DefaultSpan` sometimes throws an AttributeError.\n\n## 1.0.0b4 (2020-05-04)\n\n- `link` and `link_from_headers` now accepts attributes.\n\n## 1.0.0b3 (2020-04-06)\n\n### Features\n\n- Pinned opentelemetry-api to version 0.6b0\n\n## 1.0.0b2 (2020-03-09)\n\n### Features\n\n- Pinned opentelemetry-api to version 0.4a0\n\n## 1.0.0b1\n\n### Features\n\n- Opentelemetry implementation of azure-core tracing protocol\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/core/azure-core-tracing-opentelemetry",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "opentelemetry-api>=1.12.0",
          "azure-core>=1.24.0"
        ],
        "requires_python": ">=3.8"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3a/05/4007d55d7fa88992bf70cdfdf9e7c4ec0734fd853c4c548da9fd36623892/azure_monitor_opentelemetry_exporter-1.0.0b45-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=10d6363ac971fb4530511df464898fe69c0499e85841febad800572d1e8e8ec6",
          "hashes": {
            "sha256": "10d6363ac971fb4530511df464898fe69c0499e85841febad800572d1e8e8ec6"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-monitor-opentelemetry-exporter",
        "version": "1.0.0b45",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Monitor Opentelemetry Exporter Client Library for Python",
        "description": "# Microsoft OpenTelemetry exporter for Azure Monitor\n\nThe exporter for Azure Monitor allows Python applications to export data from the OpenTelemetry SDK to Azure Monitor. The exporter is intended for users who require advanced configuration or have more complicated telemetry needs that require all of distributed tracing, logging and metrics. If you have simpler configuration requirements, we recommend using the [Azure Monitor OpenTelemetry Distro](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python) instead for a simpler one-line setup.\n\nPrior to using this SDK, please read and understand [Data Collection Basics](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-overview?tabs=python), especially the section on [telemetry types](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-overview?tabs=python#telemetry-types). OpenTelemetry terminology differs from Application Insights terminology so it is important to understand the way the telemetry types map to each other.\n\n[Source code](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry-exporter) | [Package (PyPi)][pypi] | [API reference documentation][api_docs] | [Product documentation][product_docs] | [Samples][exporter_samples] | [Changelog](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/monitor/azure-monitor-opentelemetry-exporter/CHANGELOG.md)\n\n## Getting started\n\n### Install the package\n\nInstall the Microsoft OpenTelemetry exporter for Azure Monitor with [pip][pip]:\n\n```Bash\npip install azure-monitor-opentelemetry-exporter --pre\n```\n\n### Prerequisites\n\nTo use this package, you must have:\n\n* Azure subscription - [Create a free account][azure_sub]\n* Azure Monitor - [How to use application insights][application_insights_namespace]\n* OpenTelemetry SDK - [OpenTelemetry SDK for Python][ot_sdk_python]\n* Python 3.8 or later - [Install Python][python]\n\n### Instantiate the client\n\nInteraction with Azure monitor exporter starts with an instance of the `AzureMonitorTraceExporter` class for distributed tracing, `AzureMonitorLogExporter` for logging and `AzureMonitorMetricExporter` for metrics. You will need a **connection_string** to instantiate the object.\nPlease find the samples linked below for demonstration as to how to construct the exporter using a connection string.\n\n#### Logging (experimental)\n\nNOTE: The logging signal for the `AzureMonitorLogExporter` is currently in an EXPERIMENTAL state. Possible breaking changes may ensue in the future.\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\nexporter = AzureMonitorLogExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n```\n\n#### Metrics\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter\nexporter = AzureMonitorMetricExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n```\n\n#### Tracing\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\nexporter = AzureMonitorTraceExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n```\n\nYou can also instantiate the exporter directly via the constructor. In this case, the connection string will be automatically populated from the `APPLICATIONINSIGHTS_CONNECTION_STRING` environment variable.\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\nexporter = AzureMonitorLogExporter()\n```\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter\nexporter = AzureMonitorMetricExporter()\n```\n\n```python\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\nexporter = AzureMonitorTraceExporter()\n```\n\n## Key concepts\n\nSome of the key concepts for the Azure monitor exporter include:\n\n* [OpenTelemetry][opentelemetry_spec]: OpenTelemetry is a set of libraries used to collect and export telemetry data (metrics, logs, and traces) for analysis in order to understand your software's performance and behavior.\n\n* [Instrumentation][instrumentation_library]: The ability to call the OpenTelemetry API directly by any application is facilitated by instrumentation. A library that enables OpenTelemetry observability for another library is called an instrumentation Library.\n\n* [Log][log_concept]: Log refers to capturing of logging, exception and events.\n\n* [LogRecord][log_record]: Represents a log record emitted from a supported logging library.\n\n* [Logger][logger]: Converts a `LogRecord` into a readable `LogData`, and will be pushed through the SDK to be exported.\n\n* [Logger Provider][logger_provider]: Provides a `Logger` for the given instrumentation library.\n\n* [LogRecordProcessor][log_record_processor]: Interface to hook the log record emitting action.\n\n* [LoggingHandler][logging_handler]: A handler class which writes logging records in OpenTelemetry format from the standard Python `logging` library.\n\n* [AzureMonitorLogExporter][log_reference]: This is the class that is initialized to send logging related telemetry to Azure Monitor.\n\n* [Metric][metric_concept]: `Metric` refers to recording raw measurements with predefined aggregation and sets of attributes for a period in time.\n\n* [Measurement][measurement]: Represents a data point recorded at a point in time.\n\n* [Instrument][instrument]: Instruments are used to report `Measurement`s.\n\n* [Meter][meter]: The `Meter` is responsible for creating `Instruments`.\n\n* [Meter Provider][meter_provider]: Provides a `Meter` for the given instrumentation library.\n\n* [Metric Reader][metric_reader]: An SDK implementation object that provides the common configurable aspects of the OpenTelemetry Metrics SDK such as collection, flushing and shutdown.\n\n* [AzureMonitorMetricExporter][metric_reference]: This is the class that is initialized to send metric related telemetry to Azure Monitor.\n\n* [Trace][trace_concept]: Trace refers to distributed tracing. A distributed trace is a set of events, triggered as a result of a single logical operation, consolidated across various components of an application. In particular, a Trace can be thought of as a directed acyclic graph (DAG) of Spans, where the edges between Spans are defined as parent/child relationship.\n\n* [Span][span]: Represents a single operation within a `Trace`. Can be nested to form a trace tree. Each trace contains a root span, which typically describes the entire operation and, optionally, one ore more sub-spans for its sub-operations.\n\n* [Tracer][tracer]: Responsible for creating `Span`s.\n\n* [Tracer Provider][tracer_provider]: Provides a `Tracer` for use by the given instrumentation library.\n\n* [Span Processor][span_processor]: A span processor allows hooks for SDK's `Span` start and end method invocations. Follow the link for more information.\n\n* [AzureMonitorTraceExporter][trace_reference]: This is the class that is initialized to send tracing related telemetry to Azure Monitor.\n\n* [Sampling][sampler_ref]: Sampling is a mechanism to control the noise and overhead introduced by OpenTelemetry by reducing the number of samples of traces collected and sent to the backend.\n\n* ApplicationInsightsSampler: Application Insights specific sampler used for consistent sampling across Application Insights SDKs and OpenTelemetry-based SDKs sending data to Application Insights. This sampler MUST be used whenever `AzureMonitorTraceExporter` is used.\n\nFor more information about these resources, see [What is Azure Monitor?][product_docs].\n\n## Configuration\n\nAll configuration options can be passed through the constructors of exporters through `kwargs`. Below is a list of configurable options.\n\n* `connection_string`: The connection string used for your Application Insights resource.\n* `disable_offline_storage`: Boolean value to determine whether to disable storing failed telemetry records for retry. Defaults to `False`.\n* `storage_directory`: Storage directory in which to store retry files. Defaults to `<tempfile.gettempdir()>/Microsoft/AzureMonitor/opentelemetry-python-<your-instrumentation-key>`.\n* `credential`: Token credential, such as ManagedIdentityCredential or ClientSecretCredential, used for [Azure Active Directory (AAD) authentication][aad_for_ai_docs]. Defaults to None. See [samples][exporter_samples] for examples. The credential will be automatically created from the `APPLICATIONINSIGHTS_AUTHENTICATION_STRING` environment variable if not explicitly passed in. See [documentation][aad_env_var_docs] for more.\n\n## Examples\n\n### Logging (experimental)\n\nNOTE: The logging signal for the `AzureMonitorLogExporter` is currently in an EXPERIMENTAL state. Possible breaking changes may ensue in the future.\n\nThe following sections provide several code snippets covering some of the most common tasks, including:\n\n* [Exporting a log record](#export-hello-world-log)\n* [Exporting correlated log record](#export-correlated-log)\n* [Exporting log record with custom properties](#export-custom-properties-log)\n* [Exporting an exceptions log record](#export-exceptions-log)\n\nReview the [OpenTelemetry Logging SDK][ot_logging_sdk] to learn how to use OpenTelemetry components to collect logs.\n\nWhen integrating the `AzureMonitorLogExporter`, it's **strongly advised to utilize a named logger** rather\nthan the root logger.\nThis recommendation stems from the exporter's dependency on `azure-core` for constructing and dispatching requests.\nSince `azure-core` itself uses a Python logger, attaching the handler to the root logger would\ninadvertently capture and export these internal log messages as well.\nThis triggers a recursive loop of logging and exporting, leading to an unnecessary proliferation of log data.\nTo avoid this, configure a named logger for your application's logging needs or set up your logging handler to filter out logs originating from the SDK library.\n\n#### Export Hello World Log\n\n```python\n\"\"\"\nAn example to show an application using Opentelemetry logging sdk. Logging calls to the standard Python\nlogging library are tracked and telemetry is exported to application insights with the AzureMonitorLogExporter.\n\"\"\"\nimport os\nimport logging\n\nfrom opentelemetry._logs import set_logger_provider\nfrom opentelemetry.sdk._logs import (\n    LoggerProvider,\n    LoggingHandler,\n)\nfrom opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\n\nlogger_provider = LoggerProvider()\nset_logger_provider(logger_provider)\n\nexporter = AzureMonitorLogExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n\nlogger_provider.add_log_record_processor(BatchLogRecordProcessor(exporter))\n\n# Attach LoggingHandler to namespaced logger\nhandler = LoggingHandler()\nlogger = logging.getLogger(__name__)\nlogger.addHandler(handler)\nlogger.setLevel(logging.NOTSET)\n\nlogger.warning(\"Hello World!\")\n\n# Telemetry records are flushed automatically upon application exit\n# If you would like to flush records manually yourself, you can call force_flush()\nlogger_provider.force_flush()\n```\n\n#### Export Correlated Log\n\n```python\n\"\"\"\nAn example showing how to include context correlation information in logging telemetry.\n\"\"\"\nimport os\nimport logging\n\nfrom opentelemetry import trace\nfrom opentelemetry._logs import set_logger_provider\nfrom opentelemetry.sdk._logs import (\n    LoggerProvider,\n    LoggingHandler,\n)\nfrom opentelemetry.sdk._logs.export import BatchLogRecordProcessor\nfrom opentelemetry.sdk.trace import TracerProvider\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\n\ntrace.set_tracer_provider(TracerProvider())\ntracer = trace.get_tracer(__name__)\nlogger_provider = LoggerProvider()\nset_logger_provider(logger_provider)\n\nexporter = AzureMonitorLogExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n\nlogger_provider.add_log_record_processor(BatchLogRecordProcessor(exporter))\n\n# Attach LoggingHandler to namespaced logger\nhandler = LoggingHandler()\nlogger = logging.getLogger(__name__)\nlogger.addHandler(handler)\nlogger.setLevel(logging.NOTSET)\n\nlogger.info(\"INFO: Outside of span\")\nwith tracer.start_as_current_span(\"foo\"):\n    logger.warning(\"WARNING: Inside of span\")\nlogger.error(\"ERROR: After span\")\n```\n\n#### Export Custom Properties Log\n\n```python\n\"\"\"\nAn example showing how to add custom properties to logging telemetry.\n\"\"\"\nimport os\nimport logging\n\nfrom opentelemetry._logs import set_logger_provider\nfrom opentelemetry.sdk._logs import (\n    LoggerProvider,\n    LoggingHandler,\n)\nfrom opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\n\nlogger_provider = LoggerProvider()\nset_logger_provider(logger_provider)\n\nexporter = AzureMonitorLogExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n\nlogger_provider.add_log_record_processor(BatchLogRecordProcessor(exporter))\n\n# Attach LoggingHandler to namespaced logger\nhandler = LoggingHandler()\nlogger = logging.getLogger(__name__)\nlogger.addHandler(handler)\nlogger.setLevel(logging.NOTSET)\n\n# Custom properties\nlogger.debug(\"DEBUG: Debug with properties\", extra={\"debug\": \"true\"})\n```\n\n#### Export Exceptions Log\n\n```python\n\"\"\"\nAn example showing how to export exception telemetry using the AzureMonitorLogExporter.\n\"\"\"\nimport os\nimport logging\n\nfrom opentelemetry._logs import (\n    get_logger_provider,\n    set_logger_provider,\n)\nfrom opentelemetry.sdk._logs import (\n    LoggerProvider,\n    LoggingHandler,\n)\nfrom opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter\n\nset_logger_provider(LoggerProvider())\nexporter = AzureMonitorLogExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nget_logger_provider().add_log_record_processor(BatchLogRecordProcessor(exporter))\n\n# Attach LoggingHandler to namespaced logger\nhandler = LoggingHandler()\nlogger = logging.getLogger(__name__)\nlogger.addHandler(handler)\nlogger.setLevel(logging.NOTSET)\n\n# The following code will generate two pieces of exception telemetry\n# that are identical in nature\ntry:\n    val = 1 / 0\n    print(val)\nexcept ZeroDivisionError:\n    logger.exception(\"Error: Division by zero\")\n\ntry:\n    val = 1 / 0\n    print(val)\nexcept ZeroDivisionError:\n    logger.error(\"Error: Division by zero\", stack_info=True, exc_info=True)\n```\n\n### Metrics\n\nThe following sections provide several code snippets covering some of the most common tasks, including:\n\n* [Using different metric instruments](#metric-instrument-usage)\n* [Customizing outputted metrics with views](#metric-custom-views)\n* [Recording instruments with attributes](#metric-record-attributes)\n\nReview the [OpenTelemetry Metrics SDK][ot_metrics_sdk] to learn how to use OpenTelemetry components to collect metrics.\n\n#### Metric instrument usage\n\n```python\n\"\"\"\nAn example to show an application using all instruments in the OpenTelemetry SDK. Metrics created\nand recorded using the sdk are tracked and telemetry is exported to application insights with the\nAzureMonitorMetricsExporter.\n\"\"\"\nimport os\nfrom typing import Iterable\n\nfrom opentelemetry import metrics\nfrom opentelemetry.metrics import CallbackOptions, Observation\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter\n\nexporter = AzureMonitorMetricExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nreader = PeriodicExportingMetricReader(exporter, export_interval_millis=5000)\nmetrics.set_meter_provider(MeterProvider(metric_readers=[reader]))\n\n# Create a namespaced meter\nmeter = metrics.get_meter_provider().get_meter(\"sample\")\n\n# Callback functions for observable instruments\ndef observable_counter_func(options: CallbackOptions) -> Iterable[Observation]:\n    yield Observation(1, {})\n\n\ndef observable_up_down_counter_func(\n    options: CallbackOptions,\n) -> Iterable[Observation]:\n    yield Observation(-10, {})\n\n\ndef observable_gauge_func(options: CallbackOptions) -> Iterable[Observation]:\n    yield Observation(9, {})\n\n# Counter\ncounter = meter.create_counter(\"counter\")\ncounter.add(1)\n\n# Async Counter\nobservable_counter = meter.create_observable_counter(\n    \"observable_counter\", [observable_counter_func]\n)\n\n# UpDownCounter\nup_down_counter = meter.create_up_down_counter(\"up_down_counter\")\nup_down_counter.add(1)\nup_down_counter.add(-5)\n\n# Async UpDownCounter\nobservable_up_down_counter = meter.create_observable_up_down_counter(\n    \"observable_up_down_counter\", [observable_up_down_counter_func]\n)\n\n# Histogram\nhistogram = meter.create_histogram(\"histogram\")\nhistogram.record(99.9)\n\n# Async Gauge\ngauge = meter.create_observable_gauge(\"gauge\", [observable_gauge_func])\n\n# Upon application exit, one last collection is made and telemetry records are\n# flushed automatically. # If you would like to flush records manually yourself,\n# you can call force_flush()\nmeter_provider.force_flush()\n```\n\n#### Metric custom views\n\n```python\n\"\"\"\nThis example shows how to customize the metrics that are output by the SDK using Views. Metrics created\nand recorded using the sdk are tracked and telemetry is exported to application insights with the\nAzureMonitorMetricsExporter.\n\"\"\"\nimport os\n\nfrom opentelemetry import metrics\nfrom opentelemetry.sdk.metrics import Counter, MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\nfrom opentelemetry.sdk.metrics.view import View\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter\n\nexporter = AzureMonitorMetricExporter.from_connection_string(\n    os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\n# Create a view matching the counter instrument `my.counter`\n# and configure the new name `my.counter.total` for the result metrics stream\nchange_metric_name_view = View(\n    instrument_type=Counter,\n    instrument_name=\"my.counter\",\n    name=\"my.counter.total\",\n)\n\nreader = PeriodicExportingMetricReader(exporter, export_interval_millis=5000)\nprovider = MeterProvider(\n    metric_readers=[\n        reader,\n    ],\n    views=[\n        change_metric_name_view,\n    ],\n)\nmetrics.set_meter_provider(provider)\n\nmeter = metrics.get_meter_provider().get_meter(\"view-name-change\")\nmy_counter = meter.create_counter(\"my.counter\")\nmy_counter.add(100)\n\n```\n\nMore examples with the metrics `Views` SDK can be found [here](https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples/metrics/views).\n\n#### Metric record attributes\n\n```python\n\"\"\"\nAn example to show an application using different attributes with instruments in the OpenTelemetry SDK.\nMetrics created and recorded using the sdk are tracked and telemetry is exported to application insights\nwith the AzureMonitorMetricsExporter.\n\"\"\"\nimport os\n\nfrom opentelemetry import metrics\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter\n\nexporter = AzureMonitorMetricExporter.from_connection_string(\n    os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nreader = PeriodicExportingMetricReader(exporter, export_interval_millis=5000)\nmetrics.set_meter_provider(MeterProvider(metric_readers=[reader]))\n\nattribute_set1 = {\n    \"key1\": \"val1\"\n}\nattribute_set2 = {\n    \"key2\": \"val2\"\n}\nlarge_attribute_set = {}\nfor i in range(20):\n    key = \"key{}\".format(i)\n    val = \"val{}\".format(i)\n    large_attribute_set[key] = val\n\nmeter = metrics.get_meter_provider().get_meter(\"sample\")\n\n# Counter\ncounter = meter.create_counter(\"attr1_counter\")\ncounter.add(1, attribute_set1)\n\n# Counter2\ncounter2 = meter.create_counter(\"attr2_counter\")\ncounter2.add(10, attribute_set1)\ncounter2.add(30, attribute_set2)\n\n# Counter3\ncounter3 = meter.create_counter(\"large_attr_counter\")\ncounter3.add(100, attribute_set1)\ncounter3.add(200, large_attribute_set)\n\n```\n\n### Tracing\n\nThe following sections provide several code snippets covering some of the most common tasks, including:\n\n* [Exporting a custom span](#export-hello-world-trace)\n* [Using an instrumentation to track a library](#instrumentation-with-requests-library)\n* [Enabling sampling to limit the amount of telemetry sent](#enabling-sampling)\n\nReview the [OpenTelemetry Tracing SDK][ot_tracing_sdk] to learn how to use OpenTelemetry components to collect logs.\n\n#### Export Hello World Trace\n\n```python\n\"\"\"\nAn example to show an application using Opentelemetry tracing api and sdk. Custom dependencies are\ntracked via spans and telemetry is exported to application insights with the AzureMonitorTraceExporter.\n\"\"\"\nimport os\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\n\ntracer_provider = TracerProvider()\ntrace.set_tracer_provider(tracer_provider)\ntracer = trace.get_tracer(__name__)\n# This is the exporter that sends data to Application Insights\nexporter = AzureMonitorTraceExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nspan_processor = BatchSpanProcessor(exporter)\ntrace.get_tracer_provider().add_span_processor(span_processor)\n\nwith tracer.start_as_current_span(\"hello\"):\n    print(\"Hello, World!\")\n\n# Telemetry records are flushed automatically upon application exit\n# If you would like to flush records manually yourself, you can call force_flush()\ntracer_provider.force_flush()\n```\n\n#### Instrumentation with requests library\n\nOpenTelemetry also supports several instrumentations which allows to instrument with third party libraries.\n\nFor a list of instrumentations available in OpenTelemetry, visit the contrib [documentation](https://opentelemetry-python-contrib.readthedocs.io/en/latest/).\n\nThis example shows how to instrument with the [requests](https://pypi.org/project/requests/) library.\n\n* Install the requests instrumentation package using pip install opentelemetry-instrumentation-requests.\n\n```python\n\"\"\"\nAn example to show an application instrumented with the OpenTelemetry requests instrumentation.\nCalls made with the requests library will be automatically tracked and telemetry is exported to \napplication insights with the AzureMonitorTraceExporter.\nSee more info on the requests instrumentation here:\nhttps://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-requests\n\"\"\"\nimport os\nimport requests\nfrom opentelemetry import trace\nfrom opentelemetry.instrumentation.requests import RequestsInstrumentor\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\n\n# This line causes your calls made with the requests library to be tracked.\nRequestsInstrumentor().instrument()\n\ntrace.set_tracer_provider(TracerProvider())\ntracer = trace.get_tracer(__name__)\nexporter = AzureMonitorTraceExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nspan_processor = BatchSpanProcessor(exporter)\ntrace.get_tracer_provider().add_span_processor(span_processor)\n\n# This request will be traced\nresponse = requests.get(url=\"https://azure.microsoft.com/\")\n```\n\n#### Enabling sampling\n\nYou can enable sampling to limit the amount of telemetry records you receive. In order to enable correct sampling in Application Insights, use the `ApplicationInsightsSampler` as shown below.\n\n```python\n\"\"\"\nAn example to show an application using the ApplicationInsightsSampler to enable sampling for your telemetry.\nSpecify a sampling rate for the sampler to limit the amount of telemetry records you receive. Custom dependencies\n are tracked via spans and telemetry is exported to application insights with the AzureMonitorTraceExporter.\n\"\"\"\nimport os\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom azure.monitor.opentelemetry.exporter import (\n    ApplicationInsightsSampler,\n    AzureMonitorTraceExporter,\n)\n\n# Sampler expects a sample rate of between 0 and 1 inclusive\n# A rate of 0.75 means approximately 75% of your telemetry will be sent\nsampler = ApplicationInsightsSampler(0.75)\ntrace.set_tracer_provider(TracerProvider(sampler=sampler))\ntracer = trace.get_tracer(__name__)\nexporter = AzureMonitorTraceExporter(\n    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n)\nspan_processor = BatchSpanProcessor(exporter)\ntrace.get_tracer_provider().add_span_processor(span_processor)\n\nfor i in range(100):\n    # Approximately 25% of these spans should be sampled out\n    with tracer.start_as_current_span(\"hello\"):\n        print(\"Hello, World!\")\n```\n\n## Flush/shutdown behavior\n\nFor all applications set up with OpenTelemetry SDK and Azure Monitor exporters, telemetry is flushed automatically upon application exit. Note that this does not include when application ends abruptly or crashes due to uncaught exception.\n\n## Troubleshooting\n\nThe exporter raises exceptions defined in [Azure Core](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#azure-core-library-exceptions).\n\n## Next steps\n\n### More sample code\n\nPlease find further examples in the [samples][exporter_samples] directory demonstrating common scenarios.\n\n### Additional documentation\n\nFor more extensive documentation on the Azure Monitor service, see the [Azure Monitor documentation][product_docs] on learn.microsoft.com.\n\nFor detailed overview of OpenTelemetry, visit their [overview](https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/overview.md) page.\n\nFor the official OpenTelemetry Python documentation and how to enable other telemetry scenarios, visit the official OpenTelemetry [website](https://opentelemetry.io/docs/instrumentation/python/).\n\nFor more information on the Azure Monitor OpenTelemetry Distro, which is a bundle of useful, pre-assembled components (one of them being this current package) that enable telemetry scenarios with Azure Monitor, visit the [README](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n<!-- LINKS -->\n[aad_env_var_docs]: https://learn.microsoft.com/azure/azure-monitor/app/azure-ad-authentication\n<!-- TODO: Update with documentation link to be python-specific after Python docs have been updated to be like Java: https://learn.microsoft.com/en-us/azure/azure-monitor/app/azure-ad-authentication?tabs=java#environment-variable-configuration-2 -->\n[aad_for_ai_docs]: https://learn.microsoft.com/azure/azure-monitor/app/azure-ad-authentication?tabs=python\n[api_docs]: https://azure.github.io/azure-sdk-for-python/monitor.html#azure-monitor-opentelemetry-exporter\n[exporter_samples]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry-exporter/samples\n[product_docs]: https://learn.microsoft.com/azure/azure-monitor/overview\n[azure_sub]: https://azure.microsoft.com/free/\n[pip]: https://pypi.org/project/pip/\n[pypi]: https://pypi.org/project/azure-monitor-opentelemetry-exporter/\n[python]: https://www.python.org/downloads/\n[ot_sdk_python]: https://github.com/open-telemetry/opentelemetry-python\n[application_insights_namespace]: https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview#how-do-i-use-application-insights\n[opentelemetry_spec]: https://opentelemetry.io/\n[instrumentation_library]: https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/overview.md#instrumentation-libraries\n[log_concept]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/overview.md#log-signal\n[log_record]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html#opentelemetry.sdk._logs.LogRecord\n[logger]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html#opentelemetry.sdk._logs.Logger\n[logger_provider]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html#opentelemetry.sdk._logs.LoggerProvider\n[log_record_processor]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html#opentelemetry.sdk._logs.LogRecordProcessor\n[logging_handler]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html#opentelemetry.sdk._logs.LoggingHandler\n[log_reference]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/monitor/azure-monitor-opentelemetry-exporter/azure/monitor/opentelemetry/exporter/export/logs/_exporter.py\n[ot_logging_sdk]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/_logs.html\n[metric_concept]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/overview.md#metric-signal\n[measurement]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/api.md#measurement\n[instrument]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/api.md#instrument\n[meter]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/api.md#meter\n[meter_provider]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/api.md#meterprovider\n[metric_reader]:https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/sdk.md#metricreader\n[metric_reference]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/monitor/azure-monitor-opentelemetry-exporter/azure/monitor/opentelemetry/exporter/export/metrics/_exporter.py\n[ot_metrics_sdk]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/metrics.html\n[trace_concept]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/overview.md#tracing-signal\n[span]: https://opentelemetry-python.readthedocs.io/en/stable/api/trace.html?highlight=TracerProvider#opentelemetry.trace.Span\n[tracer]: https://opentelemetry-python.readthedocs.io/en/stable/api/trace.html?highlight=TracerProvider#opentelemetry.trace.Tracer\n[tracer_provider]: https://opentelemetry-python.readthedocs.io/en/stable/api/trace.html?highlight=TracerProvider#opentelemetry.trace.TracerProvider\n[span_processor]: https://opentelemetry-python.readthedocs.io/en/stable/_modules/opentelemetry/sdk/trace.html?highlight=SpanProcessor#\n[trace_reference]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/monitor/azure-monitor-opentelemetry-exporter/azure/monitor/opentelemetry/exporter/export/trace/_exporter.py\n[ot_tracing_sdk]: https://opentelemetry-python.readthedocs.io/en/stable/sdk/trace.html\n[sampler_ref]: https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/trace/sdk.md#sampling\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/monitor/azure-monitor-opentelemetry-exporter",
        "author": "Microsoft Corporation",
        "author_email": "ascl@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-core<2.0.0,>=1.28.0",
          "azure-identity~=1.17",
          "msrest>=0.6.10",
          "opentelemetry-api~=1.35",
          "opentelemetry-sdk~=1.35",
          "psutil<8,>=5.9"
        ],
        "requires_python": ">=3.8"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/9b/77/f658c76f9e9a52c784bd836aaca6fd5b9aae176f1f53273e758a2bcda695/azure_identity-1.25.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=1b40060553d01a72ba0d708b9a46d0f61f56312e215d8896d836653ffdc6753d",
          "hashes": {
            "sha256": "1b40060553d01a72ba0d708b9a46d0f61f56312e215d8896d836653ffdc6753d"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-identity",
        "version": "1.25.2",
        "dynamic": [
          "license-file"
        ],
        "summary": "Microsoft Azure Identity Library for Python",
        "description": "# Azure Identity client library for Python\n\nThe Azure Identity library provides [Microsoft Entra ID](https://learn.microsoft.com/entra/fundamentals/whatis) token-based authentication support across the Azure SDK. It provides a set of [`TokenCredential`][token_cred_ref]/[`SupportsTokenInfo`][supports_token_info_ref] implementations, which can be used to construct Azure SDK clients that support Microsoft Entra token authentication.\n\n[Source code](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity)\n| [Package (PyPI)](https://pypi.org/project/azure-identity/)\n| [Package (Conda)](https://anaconda.org/microsoft/azure-identity/)\n| [API reference documentation][ref_docs]\n| [Microsoft Entra ID documentation](https://learn.microsoft.com/entra/identity/)\n\n## Getting started\n\n### Install the package\n\nInstall Azure Identity with pip:\n\n```sh\npip install azure-identity\n```\n\n### Prerequisites\n\n- An [Azure subscription](https://azure.microsoft.com/free/python)\n- Python 3.9 or a recent version of Python 3 (this library doesn't support end-of-life versions)\n\n### Authenticate the client\n\nWhen debugging and executing code locally, it's typical for a developer to use their own account for authenticating calls to Azure services. There are several developer tools that can be used to perform this authentication in your development environment. For more information, see [Authentication during local development](https://learn.microsoft.com/azure/developer/python/sdk/authentication/overview#authentication-during-local-development).\n\n## Key concepts\n\n### Credentials\n\nA credential is a class that contains or can obtain the data needed for a service client to authenticate requests. Service clients across the Azure SDK accept a credential instance when they're constructed, and use that credential to authenticate requests.\n\nThe Azure Identity library focuses on OAuth authentication with Microsoft Entra ID. It offers various credential classes capable of acquiring a Microsoft Entra access token. See the [Credential classes](#credential-classes \"Credential classes\") section for a list of this library's credential classes.\n\n### DefaultAzureCredential\n\n`DefaultAzureCredential` simplifies authentication while developing apps that deploy to Azure by combining credentials used in Azure hosting environments with credentials used in local development. For more information, see [DefaultAzureCredential overview][dac_overview].\n\n#### Continuation policy\n\nAs of version 1.14.0, `DefaultAzureCredential` attempts to authenticate with all developer credentials until one succeeds, regardless of any errors previous developer credentials experienced. For example, a developer credential may attempt to get a token and fail, so `DefaultAzureCredential` will continue to the next credential in the flow. Deployed service credentials stop the flow with a thrown exception if they're able to attempt token retrieval, but don't receive one. Prior to version 1.14.0, developer credentials would similarly stop the authentication flow if token retrieval failed, but this is no longer the case.\n\nThis allows for trying all of the developer credentials on your machine while having predictable deployed behavior.\n\n## Examples\n\nThe following examples are provided:\n\n- [Define a custom authentication flow with ChainedTokenCredential](#define-a-custom-authentication-flow-with-chainedtokencredential \"Define a custom authentication flow with ChainedTokenCredential\")\n- [Async credentials](#async-credentials \"Async credentials\")\n\n### Define a custom authentication flow with `ChainedTokenCredential`\n\nWhile `DefaultAzureCredential` is generally the quickest way to authenticate apps for Azure, you can create a customized chain of credentials to be considered. `ChainedTokenCredential` enables users to combine multiple credential instances to define a customized chain of credentials. For more information, see [ChainedTokenCredential overview][ctc_overview].\n\n### Async credentials\n\nThis library includes a set of async APIs. To use the async credentials in [azure.identity.aio][ref_docs_aio], you must first install an async transport, such as [aiohttp](https://pypi.org/project/aiohttp/). For more information, see [azure-core documentation][azure_core_transport_doc].\n\nAsync credentials should be closed when they're no longer needed. Each async credential is an async context manager and defines an async `close` method. For example:\n\n```python\nfrom azure.identity.aio import DefaultAzureCredential\n\n# call close when the credential is no longer needed\ncredential = DefaultAzureCredential()\n...\nawait credential.close()\n\n# alternatively, use the credential as an async context manager\ncredential = DefaultAzureCredential()\nasync with credential:\n  ...\n```\n\nThis example demonstrates authenticating the asynchronous `SecretClient` from [azure-keyvault-secrets][azure_keyvault_secrets] with an asynchronous credential.\n\n```python\nfrom azure.identity.aio import DefaultAzureCredential\nfrom azure.keyvault.secrets.aio import SecretClient\n\ndefault_credential = DefaultAzureCredential()\nclient = SecretClient(\"https://my-vault.vault.azure.net\", default_credential)\n```\n\n## Managed identity support\n\n[Managed identity authentication](https://learn.microsoft.com/entra/identity/managed-identities-azure-resources/overview) is supported either indirectly via `DefaultAzureCredential` or directly via `ManagedIdentityCredential` for the following Azure services:\n\n- [Azure App Service and Azure Functions](https://learn.microsoft.com/azure/app-service/overview-managed-identity?tabs=python)\n- [Azure Arc](https://learn.microsoft.com/azure/azure-arc/servers/managed-identity-authentication)\n- [Azure Cloud Shell](https://learn.microsoft.com/azure/cloud-shell/msi-authorization)\n- [Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/use-managed-identity)\n- [Azure Service Fabric](https://learn.microsoft.com/azure/service-fabric/concepts-managed-identity)\n- [Azure Virtual Machines](https://learn.microsoft.com/entra/identity/managed-identities-azure-resources/how-to-use-vm-token)\n- [Azure Virtual Machines Scale Sets](https://learn.microsoft.com/entra/identity/managed-identities-azure-resources/qs-configure-powershell-windows-vmss)\n\n## Cloud configuration\n\nCredentials default to authenticating to the Microsoft Entra endpoint for Azure Public Cloud. To access resources in other clouds, such as Azure Government or a private cloud, configure credentials with the `authority` argument. [AzureAuthorityHosts](https://aka.ms/azsdk/python/identity/docs#azure.identity.AzureAuthorityHosts) defines authorities for well-known clouds:\n\n```python\nfrom azure.identity import AzureAuthorityHosts\n\nDefaultAzureCredential(authority=AzureAuthorityHosts.AZURE_GOVERNMENT)\n```\n\nIf the authority for your cloud isn't listed in `AzureAuthorityHosts`, you can explicitly specify its URL:\n\n```python\nDefaultAzureCredential(authority=\"https://login.partner.microsoftonline.cn\")\n```\n\nAs an alternative to specifying the `authority` argument, you can also set the `AZURE_AUTHORITY_HOST` environment variable to the URL of your cloud's authority. This approach is useful when configuring multiple credentials to authenticate to the same cloud:\n\n```sh\nAZURE_AUTHORITY_HOST=https://login.partner.microsoftonline.cn\n```\n\nNot all credentials require this configuration. Credentials that authenticate through a development tool, such as `AzureCliCredential`, use that tool's configuration.\n\n## Credential classes\n\n### Credential chains\n\n| Credential                                   | Usage                                                                                                  | Reference                                       |\n|----------------------------------------------|--------------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| [`DefaultAzureCredential`][default_cred_ref] | Provides a simplified authentication experience to quickly start developing applications run in Azure. | [DefaultAzureCredential overview][dac_overview] |\n| [`ChainedTokenCredential`][chain_cred_ref]   | Allows users to define custom authentication flows composing multiple credentials.                     | [ChainedTokenCredential overview][ctc_overview] |\n\n### Authenticate Azure-hosted applications\n\n| Credential                                           | Usage                                                                                                                   | Reference                                                                                |\n|------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|\n| [`EnvironmentCredential`][environment_cred_ref]      | Authenticates a service principal or user via credential information specified in environment variables.                |                                                                                          |\n| [`ManagedIdentityCredential`][managed_id_cred_ref]   | Authenticates the managed identity of an Azure resource.                                                                | [user-assigned managed identity][uami_doc]<br>[system-assigned managed identity][sami_doc] |\n| [`WorkloadIdentityCredential`][workload_id_cred_ref] | Supports [Microsoft Entra Workload ID](https://learn.microsoft.com/azure/aks/workload-identity-overview) on Kubernetes. |                                                                                          |\n\n### Authenticate service principals\n\n| Credential                                               | Usage                                                                                                                                                                | Reference                                                                                                                  |\n|----------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|\n| [`AzurePipelinesCredential`][az_pipelines_cred_ref]      | Supports [Microsoft Entra Workload ID](https://learn.microsoft.com/azure/devops/pipelines/release/configure-workload-identity?view=azure-devops) on Azure Pipelines. |                                                                                                                            |\n| [`CertificateCredential`][cert_cred_ref]                 | Authenticates a service principal using a certificate.                                                                                                               | [Service principal authentication](https://learn.microsoft.com/entra/identity-platform/app-objects-and-service-principals) |\n| [`ClientAssertionCredential`][client_assertion_cred_ref] | Authenticates a service principal using a signed client assertion.                                                                                                   |                                                                                                                            |\n| [`ClientSecretCredential`][client_secret_cred_ref]       | Authenticates a service principal using a secret.                                                                                                                    | [Service principal authentication](https://learn.microsoft.com/entra/identity-platform/app-objects-and-service-principals) |\n\n### Authenticate users\n\n| Credential                                             | Usage                                                                             | Reference                                                                                                      | Notes                                                                                                                                  |\n|--------------------------------------------------------|-----------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n| [`AuthorizationCodeCredential`][auth_code_cred_ref]    | Authenticates a user with a previously obtained authorization code.               | [OAuth2 authentication code](https://learn.microsoft.com/entra/identity-platform/v2-oauth2-auth-code-flow)     |                                                                                                                                        |\n| [`DeviceCodeCredential`][device_code_cred_ref]         | Interactively authenticates a user on devices with limited UI.                    | [Device code authentication](https://learn.microsoft.com/entra/identity-platform/v2-oauth2-device-code)        |                                                                                                                                        |\n| [`InteractiveBrowserCredential`][interactive_cred_ref] | Interactively authenticates a user with the default system browser.               | [OAuth2 authentication code](https://learn.microsoft.com/entra/identity-platform/v2-oauth2-auth-code-flow)     | `InteractiveBrowserCredential` doesn't support GitHub Codespaces. As a workaround, use [`DeviceCodeCredential`][device_code_cred_ref]. |\n| [`OnBehalfOfCredential`][obo_cred_ref]                 | Propagates the delegated user identity and permissions through the request chain. | [On-behalf-of authentication](https://learn.microsoft.com/entra/identity-platform/v2-oauth2-on-behalf-of-flow) |                                                                                                                                        |\n\n### Authenticate via development tools\n\n| Credential                                         | Usage                                                                    | Reference                                                                                                  |\n|----------------------------------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|\n| [`AzureCliCredential`][cli_cred_ref]               | Authenticates in a development environment with the Azure CLI.           | [Azure CLI authentication](https://learn.microsoft.com/cli/azure/authenticate-azure-cli)                   |\n| [`AzureDeveloperCliCredential`][azd_cli_cred_ref]  | Authenticates in a development environment with the Azure Developer CLI. | [Azure Developer CLI Reference](https://learn.microsoft.com/azure/developer/azure-developer-cli/reference) |\n| [`AzurePowerShellCredential`][powershell_cred_ref] | Authenticates in a development environment with the Azure PowerShell.    | [Azure PowerShell authentication](https://learn.microsoft.com/powershell/azure/authenticate-azureps)       |\n| [`VisualStudioCodeCredential`][vsc_cred_ref]       | Authenticates in a development environment with Visual Studio Code.      |                                                                                                            |\n\n## Environment variables\n\n[DefaultAzureCredential][default_cred_ref] and [EnvironmentCredential][environment_cred_ref] can be configured with environment variables. Each type of authentication requires values for specific\nvariables:\n\n### Service principal with secret\n\n| Variable name         | Value                                          |\n|-----------------------|------------------------------------------------|\n| `AZURE_CLIENT_ID`     | ID of a Microsoft Entra application            |\n| `AZURE_TENANT_ID`     | ID of the application's Microsoft Entra tenant |\n| `AZURE_CLIENT_SECRET` | one of the application's client secrets        |\n\n### Service principal with certificate\n\n| Variable name                         | Value                                                                                                                                                      | Required                                                                                                                                                                   |\n|---------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `AZURE_CLIENT_ID`                     | ID of a Microsoft Entra application                                                                                                                        | X                                                                                                                                                                          |\n| `AZURE_TENANT_ID`                     | ID of the application's Microsoft Entra tenant                                                                                                             | X                                                                                                                                                                          |\n| `AZURE_CLIENT_CERTIFICATE_PATH`       | path to a PEM or PKCS12 certificate file including private key                                                                                             | X                                                                                                                                                                          |\n| `AZURE_CLIENT_CERTIFICATE_PASSWORD`   | password of the certificate file, if any                                                                                                                   |                                                                                                                                                                            |\n| `AZURE_CLIENT_SEND_CERTIFICATE_CHAIN` | If `True`, the credential sends the public certificate chain in the x5c header of each token request's JWT. This is required for Subject Name/Issuer (SNI) authentication. Defaults to False. There's a [known limitation](https://github.com/Azure/azure-sdk-for-python/issues/13349) that async SNI authentication isn't supported. |                                                                                                                                                                            |\n\nConfiguration is attempted in the preceding order. For example, if values for a client secret and certificate are both present, the client secret is used.\n\n## Continuous Access Evaluation\n\nAs of version 1.14.0, accessing resources protected by [Continuous Access Evaluation (CAE)][cae] is possible on a per-request basis. This behavior can be enabled by setting the `enable_cae` keyword argument to `True` in the credential's `get_token` method. CAE isn't supported for developer and managed identity credentials.\n\n## Token caching\n\nToken caching is a feature provided by the Azure Identity library that allows apps to:\n\n- Cache tokens in memory (default) or on disk (opt-in).\n- Improve resilience and performance.\n- Reduce the number of requests made to Microsoft Entra ID to obtain access tokens.\n\nThe Azure Identity library offers both in-memory and persistent disk caching. For more information, see the [token caching documentation](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/TOKEN_CACHING.md).\n\n## Brokered authentication\n\nAn authentication broker is an application that runs on a userâ€™s machine and manages the authentication handshakes and token maintenance for connected accounts. Currently, only the Windows Web Account Manager (WAM) is supported. Authentication via WAM is used by `DefaultAzureCredential` to enable secure sign-in. To enable support, use the [`azure-identity-broker`][azure_identity_broker] package. For details on authenticating using WAM, see the [broker plugin documentation][azure_identity_broker_readme].\n\n## Troubleshooting\n\nSee the [troubleshooting guide][troubleshooting_guide] for details on how to diagnose various failure scenarios.\n\n### Error handling\n\nCredentials raise `CredentialUnavailableError` when they're unable to attempt authentication because they lack required data or state. For example, [EnvironmentCredential][environment_cred_ref] raises this exception when [its configuration](#environment-variables \"its configuration\") is incomplete.\n\nCredentials raise `azure.core.exceptions.ClientAuthenticationError` when they fail to authenticate. `ClientAuthenticationError` has a `message` attribute, which describes why authentication failed. When raised by `DefaultAzureCredential` or `ChainedTokenCredential`, the message collects error messages from each credential in the chain.\n\nFor more information on handling specific Microsoft Entra ID errors, see the Microsoft Entra ID [error code documentation](https://learn.microsoft.com/entra/identity-platform/reference-error-codes).\n\n### Logging\n\nThis library uses the standard [logging](https://docs.python.org/3/library/logging.html) library for logging. Credentials log basic information, including HTTP sessions (URLs, headers, etc.) at INFO level. These log entries don't contain authentication secrets.\n\nDetailed DEBUG-level logging, including request/response bodies and header values, isn't enabled by default. It can be enabled with the `logging_enable` argument. For example:\n\n```python\ncredential = DefaultAzureCredential(logging_enable=True)\n```\n\n> CAUTION: DEBUG-level logs from credentials contain sensitive information.\n> These logs must be protected to avoid compromising account security.\n\n## Next steps\n\n### Client library support\n\nClient and management libraries listed on the [Azure SDK release page](https://azure.github.io/azure-sdk/releases/latest/python.html) that support Microsoft Entra authentication accept credentials from this library. You can learn more about using these libraries in their documentation, which is linked from the release page.\n\n### Known issues\n\nThis library doesn't support [Azure AD B2C][b2c].\n\nFor other open issues, refer to the library's [GitHub repository](https://github.com/Azure/azure-sdk-for-python/issues?q=is%3Aopen+is%3Aissue+label%3AAzure.Identity).\n\n### Provide feedback\n\nIf you encounter bugs or have suggestions, [open an issue](https://github.com/Azure/azure-sdk-for-python/issues).\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You'll only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information, see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n[auth_code_cred_ref]: https://aka.ms/azsdk/python/identity/authorizationcodecredential\n[az_pipelines_cred_ref]: https://aka.ms/azsdk/python/identity/azurepipelinescredential\n[azd_cli_cred_ref]: https://aka.ms/azsdk/python/identity/azuredeveloperclicredential\n[azure_core_transport_doc]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/CLIENT_LIBRARY_DEVELOPER.md#transport\n[azure_identity_broker]: https://pypi.org/project/azure-identity-broker\n[azure_identity_broker_readme]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity-broker\n[azure_keyvault_secrets]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/keyvault/azure-keyvault-secrets\n[b2c]: https://learn.microsoft.com/azure/active-directory-b2c/overview\n[cae]: https://learn.microsoft.com/entra/identity/conditional-access/concept-continuous-access-evaluation\n[cert_cred_ref]: https://aka.ms/azsdk/python/identity/certificatecredential\n[chain_cred_ref]: https://aka.ms/azsdk/python/identity/chainedtokencredential\n[cli_cred_ref]: https://aka.ms/azsdk/python/identity/azclicredential\n[client_assertion_cred_ref]: https://aka.ms/azsdk/python/identity/clientassertioncredential\n[client_secret_cred_ref]: https://aka.ms/azsdk/python/identity/clientsecretcredential\n[ctc_overview]: https://aka.ms/azsdk/python/identity/credential-chains#chainedtokencredential-overview\n[dac_overview]: https://aka.ms/azsdk/python/identity/credential-chains#defaultazurecredential-overview\n[default_cred_ref]: https://aka.ms/azsdk/python/identity/defaultazurecredential\n[device_code_cred_ref]: https://aka.ms/azsdk/python/identity/devicecodecredential\n[environment_cred_ref]: https://aka.ms/azsdk/python/identity/environmentcredential\n[interactive_cred_ref]: https://aka.ms/azsdk/python/identity/interactivebrowsercredential\n[managed_id_cred_ref]: https://aka.ms/azsdk/python/identity/managedidentitycredential\n[obo_cred_ref]: https://aka.ms/azsdk/python/identity/onbehalfofcredential\n[powershell_cred_ref]: https://aka.ms/azsdk/python/identity/powershellcredential\n[ref_docs]: https://aka.ms/azsdk/python/identity/docs\n[ref_docs_aio]: https://aka.ms/azsdk/python/identity/aio/docs\n[token_cred_ref]: https://learn.microsoft.com/python/api/azure-core/azure.core.credentials.tokencredential?view=azure-python\n[sami_doc]: https://learn.microsoft.com/azure/developer/python/sdk/authentication/system-assigned-managed-identity\n[supports_token_info_ref]: https://learn.microsoft.com/python/api/azure-core/azure.core.credentials.supportstokeninfo?view=azure-python\n[troubleshooting_guide]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/TROUBLESHOOTING.md\n[uami_doc]: https://learn.microsoft.com/azure/developer/python/sdk/authentication/user-assigned-managed-identity\n[vsc_cred_ref]: https://aka.ms/azsdk/python/identity/vscodecredential\n[workload_id_cred_ref]: https://aka.ms/azsdk/python/identity/workloadidentitycredential\n\n# Release History\n\n## 1.25.2 (2026-02-10)\n\n### Bugs Fixed\n\n- Fixed an issue with certain credentials not bypassing the token cache when claims are provided in `get_token` or `get_token_info` calls. ([#44552](https://github.com/Azure/azure-sdk-for-python/pull/44552)) ([#44815](https://github.com/Azure/azure-sdk-for-python/pull/44815))\n- Fixed an issue where an unhelpful TypeError was raised during Entra ID token requests that returned empty responses. Now, a ClientAuthenticationError is raised with the full response for better troubleshooting. ([#44258](https://github.com/Azure/azure-sdk-for-python/pull/44258))\n\n### Other Changes\n\n- Bumped minimum dependency on `msal` to `>=1.31.0`.\n- Added debug logging of access token cache hits in several credentials to improve troubleshooting of token cache behavior. ([#44963](https://github.com/Azure/azure-sdk-for-python/pull/44963))\n- Replace instances of `azure.core.pipeline.transport.HttpRequest` with `azure.core.rest.HttpRequest`. ([#44993](https://github.com/Azure/azure-sdk-for-python/pull/44993))\n\n## 1.26.0b1 (2025-11-07)\n\n### Features Added\n\n- Added support for `WorkloadIdentityCredential` identity binding mode in AKS environments. This feature addresses Entra's limitation on the number of federated identity credentials (FICs) per managed identity by utilizing an AKS proxy that handles FIC exchanges on behalf of pods. ([#43287](https://github.com/Azure/azure-sdk-for-python/pull/43287))\n\n## 1.25.1 (2025-10-06)\n\n### Other Changes\n\n- When `AZURE_TOKEN_CREDENTIALS` is set to `ManagedIdentityCredential`, `DefaultAzureCredential` now skips the IMDS endpoint probe request and directly attempts token acquisition with full retry logic, matching the behavior of using `ManagedIdentityCredential` standalone. ([#43080](https://github.com/Azure/azure-sdk-for-python/pull/43080))\n- Improved error messages from `ManagedIdentityCredential` to include the full error response from managed identity endpoints for better troubleshooting. ([#43231](https://github.com/Azure/azure-sdk-for-python/pull/43231))\n\n## 1.25.0 (2025-09-11)\n\n### Features Added\n\n- `AzureDeveloperCliCredential` now supports `claims` in `get_token` and `get_token_info`. ([#42568](https://github.com/Azure/azure-sdk-for-python/pull/42568))\n- Added new keyword argument `require_envvar` to `DefaultAzureCredential` to enforce the presence of the `AZURE_TOKEN_CREDENTIALS` environment variable. ([#42660](https://github.com/Azure/azure-sdk-for-python/pull/42660))\n\n### Bugs Fixed\n\n- Fixed an issue where `AzureDeveloperCliCredential` would time out during token requests when `azd` prompts for user interaction. This issue commonly occurred in environments where the `AZD_DEBUG` environment variable was set, causing the Azure Developer CLI to display additional prompts that interfered with automated token acquisition. ([#42535](https://github.com/Azure/azure-sdk-for-python/pull/42535))\n- Fixed an issue where credentials configured with a default tenant ID of \"organizations\" (such as `InteractiveBrowserCredential` and `DeviceCodeCredential`) would fail authentication when a specific tenant ID was provided in `get_token` or `get_token_info` method calls. ([#42721](https://github.com/Azure/azure-sdk-for-python/pull/42721))\n\n### Other Changes\n\n- Updated `SharedTokenCacheCredential` to raise `CredentialUnavailableError` instead of `ClientAuthenticationError` during token refresh failures when within the context of `DefaultAzureCredential`. ([#42934](https://github.com/Azure/azure-sdk-for-python/pull/42934))\n\n## 1.24.0 (2025-08-07)\n\n### Bugs Fixed\n\n- Fixed an issue where CAE (Continuous Access Evaluation) caches were not properly used by `AuthorizationCodeCredential` and the asynchronous `OnBehalfOfCredential`. ([#42145](https://github.com/Azure/azure-sdk-for-python/pull/42145))\n- Fixed an issue where brokered authentication was not included in the `DefaultAzureCredential` chain when `AZURE_TOKEN_CREDENTIALS` was set to `dev`. ([#42599](https://github.com/Azure/azure-sdk-for-python/pull/42599))\n\n### Other Changes\n\n- `ManagedIdentityCredential` now retries IMDS 410 status responses for at least 70 seconds total duration as required by [Azure IMDS documentation](https://learn.microsoft.com/azure/virtual-machines/instance-metadata-service?tabs=windows#errors-and-debugging).  ([#42330](https://github.com/Azure/azure-sdk-for-python/pull/42330))\n- Improved `DefaultAzureCredential` diagnostics when `WorkloadIdentityCredential` initialization fails. If DAC fails to find a successful credential in the chain, the reason `WorkloadIdentityCredential` failed will be included in the error message. ([#42346](https://github.com/Azure/azure-sdk-for-python/pull/42346))\n- `AzureCliCredential` and `AzurePowerShellCredential` now raise `ClientAuthenticationError` when `claims` are provided to `get_token` or `get_token_info`, as these credentials do not support claims challenges. The error message includes instructions for handling claims authentication scenarios. ([#42568](https://github.com/Azure/azure-sdk-for-python/pull/42568))\n\n## 1.24.0b1 (2025-07-17)\n\n### Features Added\n\n- Expanded the set of acceptable values for environment variable `AZURE_TOKEN_CREDENTIALS` to allow for selection of a specific credential in the `DefaultAzureCredential` chain. At runtime, only the specified credential will be used when acquiring tokens with `DefaultAzureCredential`. For example, setting `AZURE_TOKEN_CREDENTIALS=WorkloadIdentityCredential` will make `DefaultAzureCredential` use only `WorkloadIdentityCredential`.\n  - Valid values are `EnvironmentCredential`, `WorkloadIdentityCredential`, `ManagedIdentityCredential`, `VisualStudioCodeCredential`, `AzureCliCredential`, `AzurePowershellCredential`, `AzureDeveloperCliCredential`, and `InteractiveBrowserCredential`. ([#41709](https://github.com/Azure/azure-sdk-for-python/pull/41709))\n- Re-enabled `VisualStudioCodeCredential` - Previously deprecated `VisualStudioCodeCredential` has been re-implemented to work with the VS Code Azure Resources extension instead of the deprecated Azure Account extension. This requires the `azure-identity-broker` package to be installed for authentication. ([#41822](https://github.com/Azure/azure-sdk-for-python/pull/41822))\n  - `VisualStudioCodeCredential` is now included in the `DefaultAzureCredential` token chain by default.\n- `DefaultAzureCredential` now supports authentication with the currently signed-in Windows account, provided the `azure-identity-broker` package is installed. This auth mechanism is added at the end of the `DefaultAzureCredential` credential chain.  ([#40335](https://github.com/Azure/azure-sdk-for-python/pull/40335))\n\n## 1.23.1 (2025-07-15)\n\n### Bugs Fixed\n\n- Fixed an issue with `AzurePowerShellCredential` not working correctly for users still using older versions of PowerShell (e.g., Windows PowerShell 5.1) where `-AsPlainText` is not supported in the `ConvertFrom-SecureString` cmdlet.  ([#41675](https://github.com/Azure/azure-sdk-for-python/pull/41675))\n- Fixed an issue with `AzureCliCredential` being unable to find the correct `az` executable for certain Python versions on Windows. ([#41806](https://github.com/Azure/azure-sdk-for-python/pull/41806))\n\n## 1.23.0 (2025-05-13)\n\n### Features Added\n\n- Added `AZURE_TOKEN_CREDENTIALS` environment variable to `DefaultAzureCredential` to allow for choosing groups of credentials.\n  - `prod` for `EnvironmentCredential`, `WorkloadIdentityCredential`,  and `ManagedIdentityCredential`.\n  - `dev` for `SharedTokenCacheCredential`, `AzureCliCredential`, `AzurePowershellCredential`, and `AzureDeveloperCliCredential`.\n\n## 1.22.0 (2025-05-06)\n\n### Breaking Changes\n\n- Previously, if a `client_id` or `identity_config` was specified in `ManagedIdentityCredential` for Service Fabric managed identity, which is not supported, the `client_id` (or `resource_id`/`object_id` specified `identity_config`) would be silently ignored. Now, an exception will be raised during a token request if a `client_id` or `identity_config` is specified for Service Fabric managed identity.\n\n### Bugs Fixed\n\n- Fixed an issue with error handling in MSAL-based credentials when the response content is a string rather than a dictionary. ([#40281](https://github.com/Azure/azure-sdk-for-python/pull/40281))\n\n### Other Changes\n\n- Deprecated `VisualStudioCodeCredential` as the VS Code Azure Account extension on which this credential depends on has been deprecated. See the Azure Account extension [deprecation notice](https://github.com/microsoft/vscode-azure-account/issues/964).  ([#40613](https://github.com/Azure/azure-sdk-for-python/pull/40613))\n- Python 3.8 is no longer supported. Please use Python version 3.9 or later.\n\n## 1.21.0 (2025-03-11)\n\n### Other Changes\n\n- Updated the asynchronous `CertificateCredential` to use the PS256 algorithm with PSS padding for certificate authentication in non-ADFS tenants. ([#39761](https://github.com/Azure/azure-sdk-for-python/pull/39761))\n- Deprecated `UsernamePasswordCredential`, as it doesn't support multifactor authentication (MFA). MFA will soon be enforced on all Microsoft Entra tenants. For more details, see [Planning for mandatory MFA](https://aka.ms/mfaforazure). ([#39785](https://github.com/Azure/azure-sdk-for-python/pull/39785))\n\n## 1.20.0 (2025-02-11)\n\n### Features Added\n\n- Added `subscription` parameter to `AzureCliCredential` to specify the subscription to use when authenticating with the Azure CLI. ([#37994](https://github.com/Azure/azure-sdk-for-python/pull/37994))\n\n### Bugs Fixed\n\n- A bug in the error handling for AzureCliCredentials and AzureDeveloperCliCredential which would result in the unexpected error `'NoneType' object has no attribute 'startswith'` has been fixed ([#39176](https://github.com/Azure/azure-sdk-for-python/pull/39176))\n\n### Other Changes\n\n- `AzureCliCredential` and `AzureDeveloperCliCredential` will now call their corresponding executables directly instead of going through the shell. ([#38606](https://github.com/Azure/azure-sdk-for-python/pull/38606))\n- `ManagedIdentityCredential` will now log the configured user-assigned identity if one is set. ([#39621](https://github.com/Azure/azure-sdk-for-python/pull/39621))\n\n## 1.19.0 (2024-10-08)\n\n### Bugs Fixed\n\n- Fixed the request sent in `AzurePipelinesCredential` so it doesn't result in a redirect response when an invalid system access token is provided. ([#37510](https://github.com/Azure/azure-sdk-for-python/pull/37510))\n\n### Other Changes\n\n- Deprecated `AzureAuthorityHosts.AZURE_GERMANY`\n\n## 1.18.0 (2024-09-19)\n\n### Features Added\n\n- All credentials now implement the `SupportsTokenInfo` or `AsyncSupportsTokenInfo` protocol. Each credential now has a `get_token_info` method which returns an `AccessTokenInfo` object. The `get_token_info` method is an alternative method to `get_token` that improves support for more complex authentication scenarios. ([#36882](https://github.com/Azure/azure-sdk-for-python/pull/36882))\n    - Information on when a token should be refreshed is now saved in `AccessTokenInfo` (if available).\n\n### Other Changes\n\n- Added identity config validation to `ManagedIdentityCredential` to avoid non-deterministic states (e.g. both `resource_id` and `object_id` are specified). ([#36950](https://github.com/Azure/azure-sdk-for-python/pull/36950))\n- Additional validation was added for `ManagedIdentityCredential` in Azure Cloud Shell environments. ([#36438](https://github.com/Azure/azure-sdk-for-python/issues/36438))\n- Bumped minimum dependency on `azure-core` to `>=1.31.0`.\n\n## 1.18.0b2 (2024-08-09)\n\n### Features Added\n\n- Added support of `send_certificate_chain` keyword argument when using certs with the synchronous `OnBehalfOfCredential`. ([#36810](https://github.com/Azure/azure-sdk-for-python/pull/36810))\n- `AzurePowerShellCredential` now supports using secure strings when authenticating with PowerShell. ([#36653](https://github.com/Azure/azure-sdk-for-python/pull/36653))\n\n## 1.18.0b1 (2024-07-16)\n\n- Fixed the issue that `SharedTokenCacheCredential` was not picklable.\n\n### Other Changes\n\n- The synchronous `ManagedIdentityCredential` was updated to use MSAL (Microsoft Authentication Library) for handling most of the underlying managed identity implementations.\n\n## 1.17.1 (2024-06-21)\n\n### Bugs Fixed\n\n- Continue to attempt requesting token if the probing request receives non-json response. ([#36184](https://github.com/Azure/azure-sdk-for-python/pull/36184))\n\n## 1.17.0 (2024-06-18)\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.16.0.\n> Only code written against a beta version such as 1.17.0b1 is affected.\n- `AzurePipelinesCredential` now has a required keyword argument `system_access_token`.  ([#35858](https://github.com/Azure/azure-sdk-for-python/pull/35858))\n\n### Bugs Fixed\n\n- Allow credential chains to continue when an IMDS probe request returns a non-JSON response in `ManagedIdentityCredential`. ([#36016](https://github.com/Azure/azure-sdk-for-python/pull/36016))\n\n## 1.17.0b2 (2024-06-11)\n\n### Features Added\n\n- `OnBehalfOfCredential` now supports client assertion callbacks through the `client_assertion_func` keyword argument. This enables authenticating with client assertions such as federated credentials.  ([#35812](https://github.com/Azure/azure-sdk-for-python/pull/35812))\n\n### Bugs Fixed\n\n- Managed identity bug fixes\n\n## 1.16.1 (2024-06-11)\n\n### Bugs Fixed\n\n- Managed identity bug fixes\n\n## 1.17.0b1 (2024-05-13)\n\n### Features Added\n\n- Added environment variable `AZURE_CLIENT_SEND_CERTIFICATE_CHAIN` support for `EnvironmentCredential`.\n- Introduced a new credential, `AzurePipelinesCredential`, for supporting workload identity federation in Azure Pipelines with service connections ([#35397](https://github.com/Azure/azure-sdk-for-python/pull/35397)).\n\n### Bugs Fixed\n\n- Fixed typing errors when certain credentials are used as context managers. ([#35415](https://github.com/Azure/azure-sdk-for-python/pull/35415))\n\n## 1.16.0 (2024-04-09)\n\n### Other Changes\n\n- For IMDS requests in `ManagedIdentityCredential`, the retry backoff factor was reduced from 2 to 0.8 in order to avoid excessive retry delays and improve responsiveness. Users can customize this setting with the `retry_backoff_factor` parameter: `ManagedIdentityCredential(retry_backoff_factor=2)`.  ([#35070](https://github.com/Azure/azure-sdk-for-python/pull/35070))\n\n## 1.16.0b2 (2024-03-05)\n\n### Features Added\n\n- Added pickling support. ([#34134](https://github.com/Azure/azure-sdk-for-python/pull/34134))\n\n### Bugs Fixed\n\n- Fixed an issue in `AzurePowerShellCredential` where if `pwsh` isn't available and the Command Prompt language is not English, it would not fall back to `powershell`. ([#34271](https://github.com/Azure/azure-sdk-for-python/pull/34271))\n\n## 1.16.0b1 (2024-02-06)\n\n### Bugs Fixed\n\n- Fixed the bug that `ClientAssertionCredential` constructor fails if kwargs are provided. ([#33673](https://github.com/Azure/azure-sdk-for-python/issues/33673))\n- `ManagedIdentityCredential` is more lenient with the error message it matches when falling through to the next credential in the chain in the case that Docker Desktop returns a 403 response when attempting to access the IMDS endpoint. ([#33928](https://github.com/Azure/azure-sdk-for-python/pull/33928))\n\n### Other Changes\n\n- `AzureCliCredential` utilizes the new `expires_on` property returned by `az` CLI versions >= 2.54.0 to determine token expiration. ([#33947](https://github.com/Azure/azure-sdk-for-python/issues/33947))\n- Azure-identity is supported on Python 3.8 or later.\n\n## 1.15.0 (2023-10-26)\n\n### Features Added\n\n- Added bearer token provider.  ([#32655](https://github.com/Azure/azure-sdk-for-python/pull/32655))\n\n### Bugs Fixed\n\n- Fixed issue InteractiveBrowserCredential does not hand over to next credential in chain if no browser is supported.([#32276](https://github.com/Azure/azure-sdk-for-python/pull/32276))\n\n## 1.15.0b2 (2023-10-12)\n\n### Features Added\n\n- Added `enable_support_logging` as a keyword argument to credentials using MSAL's `PublicClientApplication`. This allows additional support logging which may contain PII. ([#32135](https://github.com/Azure/azure-sdk-for-python/pull/32135))\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.14.0.\n> Only code written against a beta version such as 1.15.0b1 may be affected.\n- Windows Web Account Manager (WAM) Brokered Authentication is moved into another package.\n\n### Bugs Fixed\n\n- `ManagedIdentityCredential` will now correctly retry when the instance metadata endpoint returns a 410 response.  ([#32200](https://github.com/Azure/azure-sdk-for-python/pull/32200))\n\n## 1.14.1 (2023-10-09)\n\n### Bugs Fixed\n\n- Bug fixes for developer credentials\n\n## 1.15.0b1 (2023-09-12)\n\n### Features Added\n\n- Added Windows Web Account Manager (WAM) Brokered Authentication support.\n- Added `enable_msa_passthrough` suppport for `InteractiveBrowserCredential`. By default `InteractiveBrowserCredential` only lists Microsoft Entra accounts. If you set `enable_msa_passthrough` to `True`, it lists both Microsoft Entra accounts and MSA outlook.com accounts that are logged in to Windows.\n\n### Bugs Fixed\n\n- Ensure `AzurePowershellCredential` calls PowerShell with the `-NoProfile` flag to avoid loading user profiles for more consistent behavior.  ([#31682](https://github.com/Azure/azure-sdk-for-python/pull/31682))\n- Fixed an issue with subprocess-based developer credentials (such as AzureCliCredential) where the process would sometimes hang waiting for user input.  ([#31534](https://github.com/Azure/azure-sdk-for-python/pull/31534))\n- Fixed an issue with `ClientAssertionCredential` not properly checking if CAE should be enabled.  ([#31544](https://github.com/Azure/azure-sdk-for-python/pull/31544))\n- `ManagedIdentityCredential` will fall through to the next credential in the chain in the case that Docker Desktop returns a 403 response when attempting to access the IMDS endpoint.  ([#31824](https://github.com/Azure/azure-sdk-for-python/pull/31824))\n\n### Other Changes\n\n- Update typing of async credentials to match the `AsyncTokenCredential` protocol.\n- If within `DefaultAzureCredential`, `EnvironmentCredential` will now use log level INFO instead of WARNING to inform users of an incomplete environment configuration.  ([#31814](https://github.com/Azure/azure-sdk-for-python/pull/31814))\n- Strengthened `AzureCliCredential` and `AzureDeveloperCliCredential` error checking when determining if a user is logged in or not. Now, if an `AADSTS` error exists in the error, the full error message is propagated instead of a canned error message. ([#30047](https://github.com/Azure/azure-sdk-for-python/pull/30047))\n- `ManagedIdentityCredential` instances using IMDS will now be allowed to continue sending requests to the IMDS endpoint even after previous attempts failed. This is to prevent credential instances from potentially being permanently disabled after a temporary network failure.\n- IMDS endpoint probes in `ManagedIdentityCredential` will now only occur when inside a credential chain such as `DefaultAzureCredential`. This probe request timeout has been increased to 1 second from 0.3 seconds to reduce the likelihood of false negatives.\n\n## 1.14.0 (2023-08-08)\n\n### Features Added\n\n- Continuous Access Evaluation (CAE) is now configurable per-request by setting the `enable_cae` keyword argument to `True` in `get_token`. This applies to user credentials and service principal credentials.  ([#30777](https://github.com/Azure/azure-sdk-for-python/pull/30777))\n\n### Breaking Changes\n\n- CP1 client capabilities for CAE is no longer always-on by default for user credentials. This capability will now be configured as-needed in each `get_token` request by each SDK.  ([#30777](https://github.com/Azure/azure-sdk-for-python/pull/30777))\n  - Suffixes are now appended to persistent cache names to indicate whether CAE or non-CAE tokens are stored in the cache. This is to prevent CAE and non-CAE tokens from being mixed/overwritten in the same cache. This could potentially cause issues if you are trying to share the same cache between applications that are using different versions of the Azure Identity library as each application would be reading from a different cache file.\n  - Since CAE is no longer always enabled for user-credentials, the `AZURE_IDENTITY_DISABLE_CP1` environment variable is no longer supported.\n\n### Bugs Fixed\n\n- Credential types correctly implement `azure-core`'s `TokenCredential` protocol.  ([#25175](https://github.com/Azure/azure-sdk-for-python/issues/25175))\n\n## 1.14.0b2 (2023-07-11)\n\n### Features Added\n\n- Added `workload_identity_tenant_id` support in `DefaultAzureCredential`.\n\n## 1.14.0b1 (2023-06-06)\n\n### Features Added\n\n- Continue attempt next credential when finding an expired token from cached token credential in DefaultAzureCredential. ([#30441](https://github.com/Azure/azure-sdk-for-python/pull/30441))\n\n### Other Changes\n\n- VisualStudioCodeCredential prints an informative error message when used (as it is currently broken) ([#30385](https://github.com/Azure/azure-sdk-for-python/pull/30385))\n- Removed dependency on `six`. ([#30613](https://github.com/Azure/azure-sdk-for-python/pull/30613))\n\n## 1.13.0 (2023-05-11)\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.12.0.\n> Only code written against a beta version such as 1.13.0b4 may be affected.\n- Windows Web Account Manager (WAM) Brokered Authentication is still in preview and not available in this release. It will be available in the next beta release.\n- Additional Continuous Access Evaluation (CAE) support for service principal credentials is still in preview and not available in this release. It will be available in the next beta release.\n- Renamed keyword argument `developer_credential_timeout` to `process_timeout` in `DefaultAzureCredential` to remain consistent with the other credentials that launch a subprocess to acquire tokens.\n\n## 1.13.0b4 (2023-04-11)\n\n### Features Added\n\n- Credentials that are implemented via launching a subprocess to acquire tokens now have configurable timeouts using the `process_timeout` keyword argument. This addresses scenarios where these proceses can take longer than the current default timeout values. The affected credentials are `AzureCliCredential`, `AzureDeveloperCliCredential`, and `AzurePowerShellCredential`. (Note: For `DefaultAzureCredential`, the `developer_credential_timeout` keyword argument allows users to propagate this option to `AzureCliCredential`, `AzureDeveloperCliCredential`, and `AzurePowerShellCredential` in the authentication chain.) ([#28290](https://github.com/Azure/azure-sdk-for-python/pull/28290))\n\n## 1.13.0b3 (2023-03-07)\n\n### Features Added\n\n- Changed parameter from `instance_discovery` to `disable_instance_discovery` to make it more explicit.\n- Service principal credentials now enable support for [Continuous Access Evaluation (CAE)](https://learn.microsoft.com/entra/identity/conditional-access/concept-continuous-access-evaluation-workload). This indicates to Microsoft Entra ID that your application can handle CAE claims challenges.\n\n## 1.13.0b2 (2023-02-07)\n\n### Features Added\n\n- Added `AzureDeveloperCredential` for Azure Developer CLI. ([#27916](https://github.com/Azure/azure-sdk-for-python/pull/27916))\n- Added `WorkloadIdentityCredential` for Workload Identity Federation on Kubernetes ([#28536](https://github.com/Azure/azure-sdk-for-python/pull/28536))\n- Added support to use \"TryAutoDetect\" as the value for `AZURE_REGIONAL_AUTHORITY_NAME` to enable auto detecting the appropriate authority ([#526](https://github.com/AzureAD/microsoft-authentication-library-for-python/issues/526))\n\n## 1.13.0b1 (2023-01-10)\n\n### Features Added\n\n- Added Windows Web Account Manager (WAM) Brokered Authentication support. ([#23687](https://github.com/Azure/azure-sdk-for-python/issues/23687))\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.12.0.\n> Only code written against a beta version such as 1.12.0b1 may be affected.\n- Replaced `validate_authority` with `instance_discovery`. Now instead of setting validate_authority=False to disable authority validation and instance discovery, you need to use instance_discovery=False.\n\n### Bugs Fixed\n\n- Fixed an issue where `AzureCliCredential` would return the wrong error message when the Azure CLI was not installed on non-English consoles. ([#27965](https://github.com/Azure/azure-sdk-for-python/issues/27965))\n\n## 1.12.0 (2022-11-08)\n\n### Bugs Fixed\n\n- `AzureCliCredential` now works even when `az` prints warnings to stderr. ([#26857](https://github.com/Azure/azure-sdk-for-python/issues/26857)) (thanks to @micromaomao for the contribution)\n- Fixed issue where user-supplied `TokenCachePersistenceOptions` weren't propagated when using `SharedTokenCacheCredential` ([#26982](https://github.com/Azure/azure-sdk-for-python/issues/26982))\n\n### Breaking Changes\n\n- Excluded `VisualStudioCodeCredential` from `DefaultAzureCredential` token chain by default as SDK\n  authentication via Visual Studio Code is broken due to\n  issue [#23249](https://github.com/Azure/azure-sdk-for-python/issues/23249). The `VisualStudioCodeCredential` will be\n  re-enabled in the `DefaultAzureCredential` flow once a fix is in place.\n  Issue [#25713](https://github.com/Azure/azure-sdk-for-python/issues/25713) tracks this. In the meantime\n  Visual Studio Code users can authenticate their development environment using the [Azure CLI](https://learn.microsoft.com/cli/azure/).\n\n### Other Changes\n\n- Added Python 3.11 support and stopped supporting Python 3.6.\n\n## 1.12.0b2 (2022-10-11)\n\n1.12.0 release candidate\n\n## 1.12.0b1 (2022-09-22)\n\n### Features Added\n\n- Added ability to specify `tenant_id` for `AzureCliCredential` & `AzurePowerShellCredential` (thanks @tikicoder)    ([#25207](https://github.com/Azure/azure-sdk-for-python/pull/25207))\n- Removed `VisualStudioCodeCredential` from `DefaultAzureCredential` token chain. ([#23249](https://github.com/Azure/azure-sdk-for-python/issues/23249))\n- `EnvironmentCredential` added `AZURE_CLIENT_CERTIFICATE_PASSWORD` support for the cert password    ([#24652](https://github.com/Azure/azure-sdk-for-python/issues/24652))\n- Added `validate_authority` support for msal client  ([#22625](https://github.com/Azure/azure-sdk-for-python/issues/22625))\n\n## 1.11.0 (2022-09-19)\n\n### Features Added\n\n- Added `additionally_allowed_tenants` to the following credential options to force explicit opt-in behavior for multi-tenant authentication:\n  - `AuthorizationCodeCredential`\n  - `AzureCliCredential`\n  - `AzurePowerShellCredential`\n  - `CertificateCredential`\n  - `ClientAssertionCredential`\n  - `ClientSecretCredential`\n  - `DefaultAzureCredential`\n  - `OnBehalfOfCredential`\n  - `UsernamePasswordCredential`\n  - `VisualStudioCodeCredential`\n\n### Breaking Changes\n\n- Credential types supporting multi-tenant authentication will now throw `ClientAuthenticationError` if the requested tenant ID doesn't match the credential's tenant ID, and is not included in `additionally_allowed_tenants`. Applications must now explicitly add additional tenants to the `additionally_allowed_tenants` list, or add '*' to list, to enable acquiring tokens from tenants other than the originally specified tenant ID.\n\nMore information on this change and the consideration behind it can be found [here](https://aka.ms/azsdk/blog/multi-tenant-guidance).\n\n- These beta features in 1.11.0b3 have been removed from this release and will be added back in 1.12.0b1\n  - `tenant_id` for `AzureCliCredential`\n  - removed `VisualStudioCodeCredential` from `DefaultAzureCredential` token chain\n  - `AZURE_CLIENT_CERTIFICATE_PASSWORD` support for `EnvironmentCredential`\n  - `validate_authority` support\n\n## 1.11.0b3 (2022-08-09)\n\nAzure-identity is supported on Python 3.7 or later. For more details, please read our page on [Azure SDK for Python version support policy](https://github.com/Azure/azure-sdk-for-python/wiki/Azure-SDKs-Python-version-support-policy).\n\n### Features Added\n\n- Added ability to specify `tenant_id` for `AzureCliCredential` (thanks @tikicoder)    ([#25207](https://github.com/Azure/azure-sdk-for-python/pull/25207))\n\n### Breaking Changes\n\n- Removed `VisualStudioCodeCredential` from `DefaultAzureCredential` token chain. ([#23249](https://github.com/Azure/azure-sdk-for-python/issues/23249))\n\n## 1.11.0b2 (2022-07-05)\n\n### Features Added\n\n- `EnvironmentCredential` added `AZURE_CLIENT_CERTIFICATE_PASSWORD` support for the cert password    ([#24652](https://github.com/Azure/azure-sdk-for-python/issues/24652))\n\n### Bugs Fixed\n\n- Fixed the issue that failed to parse PEM certificate if it does not start with \"-----\"    ([#24643](https://github.com/Azure/azure-sdk-for-python/issues/24643))\n\n## 1.11.0b1 (2022-05-10)\n\n### Features Added\n\n- Added `validate_authority` support for msal client  ([#22625](https://github.com/Azure/azure-sdk-for-python/issues/22625))\n\n## 1.10.0 (2022-04-28)\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.9.0.\n> Only code written against a beta version such as 1.10.0b1 may be affected.\n- `validate_authority` support is not available in 1.10.0.\n\n### Other Changes\n\n- Supported msal-extensions version 1.0.0    ([#23927](https://github.com/Azure/azure-sdk-for-python/issues/23927))\n\n## 1.10.0b1 (2022-04-07)\n\n### Features Added\n\n- Added `validate_authority` support for msal client  ([#22625](https://github.com/Azure/azure-sdk-for-python/issues/22625))\n\n## 1.9.0 (2022-04-05)\n\n### Features Added\n\n- Added PII logging if logging.DEBUG is enabled.    ([#23203](https://github.com/Azure/azure-sdk-for-python/issues/23203))\n\n### Breaking Changes\n\n> These changes do not impact the API of stable versions such as 1.8.0.\n> Only code written against a beta version such as 1.9.0b1 may be affected.\n- `validate_authority` support is not available in 1.9.0.\n\n### Bugs Fixed\n\n- Added check on `content` from msal response.    ([#23483](https://github.com/Azure/azure-sdk-for-python/issues/23483))\n- Fixed the issue that async OBO credential does not refresh correctly.    ([#21981](https://github.com/Azure/azure-sdk-for-python/issues/21981))\n\n### Other Changes\n\n- Removed `resource_id`, please use `identity_config` instead.\n- Renamed argument name `get_assertion` to `func` for `ClientAssertionCredential`.\n\n## 1.9.0b1 (2022-03-08)\n\n### Features Added\n\n- Added `validate_authority` support for msal client  ([#22625](https://github.com/Azure/azure-sdk-for-python/issues/22625))\n- Added `resource_id` support for user-assigned managed identity  ([#22329](https://github.com/Azure/azure-sdk-for-python/issues/22329))\n- Added `ClientAssertionCredential` support  ([#22328](https://github.com/Azure/azure-sdk-for-python/issues/22328))\n- Updated App service API version to \"2019-08-01\" ([#23034](https://github.com/Azure/azure-sdk-for-python/issues/23034))\n\n## 1.8.0 (2022-03-01)\n\n### Bugs Fixed\n\n- Handle injected \"tenant_id\" and \"claims\" ([#23138](https://github.com/Azure/azure-sdk-for-python/issues/23138))\n\n  \"tenant_id\" argument in get_token() method is only supported by:\n\n  - `AuthorizationCodeCredential`\n  - `AzureCliCredential`\n  - `AzurePowerShellCredential`\n  - `InteractiveBrowserCredential`\n  - `DeviceCodeCredential`\n  - `EnvironmentCredential`\n  - `UsernamePasswordCredential`\n\n   it is ignored by other types of credentials.\n\n### Other Changes\n\n- Python 2.7 is no longer supported. Please use Python version 3.6 or later.\n\n## 1.7.1 (2021-11-09)\n\n### Bugs Fixed\n\n- Fix multi-tenant auth using async AadClient ([#21289](https://github.com/Azure/azure-sdk-for-python/issues/21289))\n\n## 1.7.0 (2021-10-14)\n\n### Breaking Changes\n> These changes do not impact the API of stable versions such as 1.6.0.\n> Only code written against a beta version such as 1.7.0b1 may be affected.\n\n- The `allow_multitenant_authentication` argument has been removed and the default behavior is now as if it were true.\n  The multitenant authentication feature can be totally disabled by setting the environment variable\n  `AZURE_IDENTITY_DISABLE_MULTITENANTAUTH` to `True`.\n- `azure.identity.RegionalAuthority` is removed.\n- `regional_authority` argument is removed for `CertificateCredential` and `ClientSecretCredential`.\n- `AzureApplicationCredential` is removed.\n- `client_credential` in the ctor of `OnBehalfOfCredential` is removed. Please use `client_secret` or `client_certificate` instead.\n- Make `user_assertion` in the ctor of `OnBehalfOfCredential` a keyword only argument.\n\n## 1.7.0b4 (2021-09-09)\n\n### Features Added\n- `CertificateCredential` accepts certificates in PKCS12 format\n  ([#13540](https://github.com/Azure/azure-sdk-for-python/issues/13540))\n- `OnBehalfOfCredential` supports the on-behalf-of authentication flow for\n  accessing resources on behalf of users\n  ([#19308](https://github.com/Azure/azure-sdk-for-python/issues/19308))\n- `DefaultAzureCredential` allows specifying the client ID of interactive browser via keyword argument `interactive_browser_client_id`\n  ([#20487](https://github.com/Azure/azure-sdk-for-python/issues/20487))\n\n### Other Changes\n- Added context manager methods and `close()` to credentials in the\n  `azure.identity` namespace. At the end of a `with` block, or when `close()`\n  is called, these credentials close their underlying transport sessions.\n  ([#18798](https://github.com/Azure/azure-sdk-for-python/issues/18798))\n\n\n## 1.6.1 (2021-08-19)\n\n### Other Changes\n- Persistent cache implementations are now loaded on demand, enabling\n  workarounds when importing transitive dependencies such as pywin32\n  fails\n  ([#19989](https://github.com/Azure/azure-sdk-for-python/issues/19989))\n\n\n## 1.7.0b3 (2021-08-10)\n\n### Breaking Changes\n> These changes do not impact the API of stable versions such as 1.6.0.\n> Only code written against a beta version such as 1.7.0b1 may be affected.\n- Renamed `AZURE_POD_IDENTITY_TOKEN_URL` to `AZURE_POD_IDENTITY_AUTHORITY_HOST`.\n  The value should now be a host, for example \"http://169.254.169.254\" (the\n  default).\n\n### Bugs Fixed\n- Fixed import of `azure.identity.aio.AzureApplicationCredential`\n  ([#19943](https://github.com/Azure/azure-sdk-for-python/issues/19943))\n\n### Other Changes\n- Added `CustomHookPolicy` to credential HTTP pipelines. This allows applications\n  to initialize credentials with `raw_request_hook` and `raw_response_hook`\n  keyword arguments. The value of these arguments should be a callback taking a\n  `PipelineRequest` and `PipelineResponse`, respectively. For example:\n  `ManagedIdentityCredential(raw_request_hook=lambda request: print(request.http_request.url))`\n- Reduced redundant `ChainedTokenCredential` and `DefaultAzureCredential`\n  logging. On Python 3.7+, credentials invoked by these classes now log debug\n  rather than info messages.\n  ([#18972](https://github.com/Azure/azure-sdk-for-python/issues/18972))\n- Persistent cache implementations are now loaded on demand, enabling\n  workarounds when importing transitive dependencies such as pywin32\n  fails\n  ([#19989](https://github.com/Azure/azure-sdk-for-python/issues/19989))\n\n\n## 1.7.0b2 (2021-07-08)\n### Features Added\n- `InteractiveBrowserCredential` keyword argument `login_hint` enables\n  pre-filling the username/email address field on the login page\n  ([#19225](https://github.com/Azure/azure-sdk-for-python/issues/19225))\n- `AzureApplicationCredential`, a default credential chain for applications\n  deployed to Azure\n  ([#19309](https://github.com/Azure/azure-sdk-for-python/issues/19309))\n\n### Bugs Fixed\n- `azure.identity.aio.ManagedIdentityCredential` is an async context manager\n  that closes its underlying transport session at the end of a `with` block\n\n### Other Changes\n- Most credentials can use tenant ID values returned from authentication\n  challenges, enabling them to request tokens from the correct tenant. This\n  behavior is optional and controlled by a new keyword argument,\n  `allow_multitenant_authentication`.\n  ([#19300](https://github.com/Azure/azure-sdk-for-python/issues/19300))\n  - When `allow_multitenant_authentication` is False, which is the default, a\n    credential will raise `ClientAuthenticationError` when its configured tenant\n    doesn't match the tenant specified for a token request. This may be a\n    different exception than was raised by prior versions of the credential. To\n    maintain the prior behavior, set environment variable\n    AZURE_IDENTITY_ENABLE_LEGACY_TENANT_SELECTION to \"True\".\n- `CertificateCredential` and `ClientSecretCredential` support regional STS\n  on Azure VMs by either keyword argument `regional_authority` or environment\n  variable `AZURE_REGIONAL_AUTHORITY_NAME`. See `azure.identity.RegionalAuthority`\n  for possible values.\n  ([#19301](https://github.com/Azure/azure-sdk-for-python/issues/19301))\n- Upgraded minimum `azure-core` version to 1.11.0 and minimum `msal` version to\n  1.12.0\n- After IMDS authentication fails, `ManagedIdentityCredential` raises consistent\n  error messages and uses `raise from` to propagate inner exceptions\n  ([#19423](https://github.com/Azure/azure-sdk-for-python/pull/19423))\n\n## 1.7.0b1 (2021-06-08)\nBeginning with this release, this library requires Python 2.7 or 3.6+.\n\n### Added\n- `VisualStudioCodeCredential` gets its default tenant and authority\n  configuration from VS Code user settings\n  ([#14808](https://github.com/Azure/azure-sdk-for-python/issues/14808))\n\n## 1.6.0 (2021-05-13)\nThis is the last version to support Python 3.5. The next version will require\nPython 2.7 or 3.6+.\n\n### Added\n- `AzurePowerShellCredential` authenticates as the identity logged in to Azure\n  PowerShell. This credential is part of `DefaultAzureCredential` by default\n  but can be disabled by a keyword argument:\n  `DefaultAzureCredential(exclude_powershell_credential=True)`\n  ([#17341](https://github.com/Azure/azure-sdk-for-python/issues/17341))\n\n### Fixed\n- `AzureCliCredential` raises `CredentialUnavailableError` when the CLI times out,\n  and kills timed out subprocesses\n- Reduced retry delay for `ManagedIdentityCredential` on Azure VMs\n\n## 1.6.0b3 (2021-04-06)\n### Breaking Changes\n> These changes do not impact the API of stable versions such as 1.5.0.\n> Only code written against a beta version such as 1.6.0b1 may be affected.\n- Removed property `AuthenticationRequiredError.error_details`\n\n### Fixed\n- Credentials consistently retry token requests after connection failures, or\n  when instructed to by a Retry-After header\n- ManagedIdentityCredential caches tokens correctly\n\n### Added\n- `InteractiveBrowserCredential` functions in more WSL environments\n  ([#17615](https://github.com/Azure/azure-sdk-for-python/issues/17615))\n\n## 1.6.0b2 (2021-03-09)\n### Breaking Changes\n> These changes do not impact the API of stable versions such as 1.5.0.\n> Only code written against a beta version such as 1.6.0b1 may be affected.\n- Renamed `CertificateCredential` keyword argument `certificate_bytes` to\n  `certificate_data`\n- Credentials accepting keyword arguments `allow_unencrypted_cache` and\n  `enable_persistent_cache` to configure persistent caching accept a\n  `cache_persistence_options` argument instead whose value should be an\n  instance of `TokenCachePersistenceOptions`. For example:\n  ```\n  # before (e.g. in 1.6.0b1):\n  DeviceCodeCredential(enable_persistent_cache=True, allow_unencrypted_cache=True)\n\n  # after:\n  cache_options = TokenCachePersistenceOptions(allow_unencrypted_storage=True)\n  DeviceCodeCredential(cache_persistence_options=cache_options)\n  ```\n\n  See the documentation and samples for more details.\n\n### Added\n- New class `TokenCachePersistenceOptions` configures persistent caching\n- The `AuthenticationRequiredError.claims` property provides any additional\n  claims required by a user credential's `authenticate()` method\n\n## 1.6.0b1 (2021-02-09)\n### Changed\n- Raised minimum msal version to 1.7.0\n- Raised minimum six version to 1.12.0\n\n### Added\n- `InteractiveBrowserCredential` uses PKCE internally to protect authorization\n  codes\n- `CertificateCredential` can load a certificate from bytes instead of a file\n  path. To provide a certificate as bytes, use the keyword argument\n  `certificate_bytes` instead of `certificate_path`, for example:\n  `CertificateCredential(tenant_id, client_id, certificate_bytes=cert_bytes)`\n  ([#14055](https://github.com/Azure/azure-sdk-for-python/issues/14055))\n- User credentials support Continuous Access Evaluation (CAE)\n- Application authentication APIs from 1.5.0b2\n\n### Fixed\n- `ManagedIdentityCredential` correctly parses responses from the current\n  (preview) version of Azure ML managed identity\n  ([#15361](https://github.com/Azure/azure-sdk-for-python/issues/15361))\n\n## 1.5.0 (2020-11-11)\n### Breaking Changes\n- Renamed optional `CertificateCredential` keyword argument `send_certificate`\n  (added in 1.5.0b1) to `send_certificate_chain`\n- Removed user authentication APIs added in prior betas. These will be\n  reintroduced in 1.6.0b1. Passing the keyword arguments below\n  generally won't cause a runtime error, but the arguments have no effect.\n  ([#14601](https://github.com/Azure/azure-sdk-for-python/issues/14601))\n  - Removed `authenticate` method from `DeviceCodeCredential`,\n    `InteractiveBrowserCredential`, and `UsernamePasswordCredential`\n  - Removed `allow_unencrypted_cache` and `enable_persistent_cache` keyword\n    arguments from `CertificateCredential`, `ClientSecretCredential`,\n    `DeviceCodeCredential`, `InteractiveBrowserCredential`, and\n    `UsernamePasswordCredential`\n  - Removed `disable_automatic_authentication` keyword argument from\n    `DeviceCodeCredential` and `InteractiveBrowserCredential`\n  - Removed `allow_unencrypted_cache` keyword argument from\n    `SharedTokenCacheCredential`\n  - Removed classes `AuthenticationRecord` and `AuthenticationRequiredError`\n- Removed `identity_config` keyword argument from `ManagedIdentityCredential`\n  (was added in 1.5.0b1)\n\n### Changed\n- `DeviceCodeCredential` parameter `client_id` is now optional. When not\n   provided, the credential will authenticate users to an Azure development\n   application.\n   ([#14354](https://github.com/Azure/azure-sdk-for-python/issues/14354))\n- Credentials raise `ValueError` when constructed with tenant IDs containing\n  invalid characters\n  ([#14821](https://github.com/Azure/azure-sdk-for-python/issues/14821))\n- Raised minimum msal version to 1.6.0\n\n### Added\n- `ManagedIdentityCredential` supports Service Fabric\n  ([#12705](https://github.com/Azure/azure-sdk-for-python/issues/12705))\n  and Azure Arc\n  ([#12702](https://github.com/Azure/azure-sdk-for-python/issues/12702))\n\n### Fixed\n- Prevent `VisualStudioCodeCredential` using invalid authentication data when\n  no user is signed in to Visual Studio Code\n  ([#14438](https://github.com/Azure/azure-sdk-for-python/issues/14438))\n- `ManagedIdentityCredential` uses the API version supported by Azure Functions\n  on Linux consumption hosting plans\n  ([#14670](https://github.com/Azure/azure-sdk-for-python/issues/14670))\n- `InteractiveBrowserCredential.get_token()` raises a clearer error message when\n  it times out waiting for a user to authenticate on Python 2.7\n  ([#14773](https://github.com/Azure/azure-sdk-for-python/pull/14773))\n\n## 1.5.0b2 (2020-10-07)\n### Fixed\n- `AzureCliCredential.get_token` correctly sets token expiration time,\n  preventing clients from using expired tokens\n  ([#14345](https://github.com/Azure/azure-sdk-for-python/issues/14345))\n\n### Changed\n- Adopted msal-extensions 0.3.0\n([#13107](https://github.com/Azure/azure-sdk-for-python/issues/13107))\n\n## 1.4.1 (2020-10-07)\n### Fixed\n- `AzureCliCredential.get_token` correctly sets token expiration time,\n  preventing clients from using expired tokens\n  ([#14345](https://github.com/Azure/azure-sdk-for-python/issues/14345))\n\n## 1.5.0b1 (2020-09-08)\n### Added\n- Application authentication APIs from 1.4.0b7\n- `ManagedIdentityCredential` supports the latest version of App Service\n  ([#11346](https://github.com/Azure/azure-sdk-for-python/issues/11346))\n- `DefaultAzureCredential` allows specifying the client ID of a user-assigned\n  managed identity via keyword argument `managed_identity_client_id`\n  ([#12991](https://github.com/Azure/azure-sdk-for-python/issues/12991))\n- `CertificateCredential` supports Subject Name/Issuer authentication when\n  created with `send_certificate=True`. The async `CertificateCredential`\n  (`azure.identity.aio.CertificateCredential`) will support this in a\n  future version.\n  ([#10816](https://github.com/Azure/azure-sdk-for-python/issues/10816))\n- Credentials in `azure.identity` support ADFS authorities, excepting\n  `VisualStudioCodeCredential`. To configure a credential for this, configure\n  the credential with `authority` and `tenant_id=\"adfs\"` keyword arguments, for\n  example\n  `ClientSecretCredential(authority=\"<your ADFS URI>\", tenant_id=\"adfs\")`.\n  Async credentials (those in `azure.identity.aio`) will support ADFS in a\n  future release.\n  ([#12696](https://github.com/Azure/azure-sdk-for-python/issues/12696))\n- `InteractiveBrowserCredential` keyword argument `redirect_uri` enables\n  authentication with a user-specified application having a custom redirect URI\n  ([#13344](https://github.com/Azure/azure-sdk-for-python/issues/13344))\n\n### Breaking changes\n- Removed `authentication_record` keyword argument from the async\n  `SharedTokenCacheCredential`, i.e. `azure.identity.aio.SharedTokenCacheCredential`\n\n## 1.4.0 (2020-08-10)\n### Added\n- `DefaultAzureCredential` uses the value of environment variable\n`AZURE_CLIENT_ID` to configure a user-assigned managed identity.\n([#10931](https://github.com/Azure/azure-sdk-for-python/issues/10931))\n\n### Breaking Changes\n- Renamed `VSCodeCredential` to `VisualStudioCodeCredential`\n- Removed application authentication APIs added in 1.4.0 beta versions. These\n  will be reintroduced in 1.5.0b1. Passing the keyword arguments below\n  generally won't cause a runtime error, but the arguments have no effect.\n  - Removed `authenticate` method from `DeviceCodeCredential`,\n    `InteractiveBrowserCredential`, and `UsernamePasswordCredential`\n  - Removed `allow_unencrypted_cache` and `enable_persistent_cache` keyword\n    arguments from `CertificateCredential`, `ClientSecretCredential`,\n    `DeviceCodeCredential`, `InteractiveBrowserCredential`, and\n    `UsernamePasswordCredential`\n  - Removed `disable_automatic_authentication` keyword argument from\n    `DeviceCodeCredential` and `InteractiveBrowserCredential`\n  - Removed `allow_unencrypted_cache` keyword argument from\n    `SharedTokenCacheCredential`\n  - Removed classes `AuthenticationRecord` and `AuthenticationRequiredError`\n  - Removed `identity_config` keyword argument from `ManagedIdentityCredential`\n\n## 1.4.0b7 (2020-07-22)\n- `DefaultAzureCredential` has a new optional keyword argument,\n`visual_studio_code_tenant_id`, which sets the tenant the credential should\nauthenticate in when authenticating as the Azure user signed in to Visual\nStudio Code.\n- Renamed `AuthenticationRecord.deserialize` positional parameter `json_string`\nto `data`.\n\n\n## 1.4.0b6 (2020-07-07)\n- `AzureCliCredential` no longer raises an exception due to unexpected output\n  from the CLI when run by PyCharm (thanks @NVolcz)\n  ([#11362](https://github.com/Azure/azure-sdk-for-python/pull/11362))\n- Upgraded minimum `msal` version to 1.3.0\n- The async `AzureCliCredential` correctly invokes `/bin/sh`\n  ([#12048](https://github.com/Azure/azure-sdk-for-python/issues/12048))\n\n## 1.4.0b5 (2020-06-12)\n- Prevent an error on importing `AzureCliCredential` on Windows caused by a bug\n  in old versions of Python 3.6 (this bug was fixed in Python 3.6.5).\n  ([#12014](https://github.com/Azure/azure-sdk-for-python/issues/12014))\n- `SharedTokenCacheCredential.get_token` raises `ValueError` instead of\n  `ClientAuthenticationError` when called with no scopes.\n  ([#11553](https://github.com/Azure/azure-sdk-for-python/issues/11553))\n\n## 1.4.0b4 (2020-06-09)\n- `ManagedIdentityCredential` can configure a user-assigned identity using any\n  identifier supported by the current hosting environment. To specify an\n  identity by its client ID, continue using the `client_id` argument. To\n  specify an identity by any other ID, use the `identity_config` argument,\n  for example: `ManagedIdentityCredential(identity_config={\"object_id\": \"..\"})`\n  ([#10989](https://github.com/Azure/azure-sdk-for-python/issues/10989))\n- `CertificateCredential` and `ClientSecretCredential` can optionally store\n  access tokens they acquire in a persistent cache. To enable this, construct\n  the credential with `enable_persistent_cache=True`. On Linux, the persistent\n  cache requires libsecret and `pygobject`. If these are unavailable or\n  unusable (e.g. in an SSH session), loading the persistent cache will raise an\n  error. You may optionally configure the credential to fall back to an\n  unencrypted cache by constructing it with keyword argument\n  `allow_unencrypted_cache=True`.\n  ([#11347](https://github.com/Azure/azure-sdk-for-python/issues/11347))\n- `AzureCliCredential` raises `CredentialUnavailableError` when no user is\n  logged in to the Azure CLI.\n  ([#11819](https://github.com/Azure/azure-sdk-for-python/issues/11819))\n- `AzureCliCredential` and `VSCodeCredential`, which enable authenticating as\n  the identity signed in to the Azure CLI and Visual Studio Code, respectively,\n  can be imported from `azure.identity` and `azure.identity.aio`.\n- `azure.identity.aio.AuthorizationCodeCredential.get_token()` no longer accepts\n  optional keyword arguments `executor` or `loop`. Prior versions of the method\n  didn't use these correctly, provoking exceptions, and internal changes in this\n  version have made them obsolete.\n- `InteractiveBrowserCredential` raises `CredentialUnavailableError` when it\n  can't start an HTTP server on `localhost`.\n  ([#11665](https://github.com/Azure/azure-sdk-for-python/pull/11665))\n- When constructing `DefaultAzureCredential`, you can now configure a tenant ID\n  for `InteractiveBrowserCredential`. When none is specified, the credential\n  authenticates users in their home tenants. To specify a different tenant, use\n  the keyword argument `interactive_browser_tenant_id`, or set the environment\n  variable `AZURE_TENANT_ID`.\n  ([#11548](https://github.com/Azure/azure-sdk-for-python/issues/11548))\n- `SharedTokenCacheCredential` can be initialized with an `AuthenticationRecord`\n  provided by a user credential.\n  ([#11448](https://github.com/Azure/azure-sdk-for-python/issues/11448))\n- The user authentication API added to `DeviceCodeCredential` and\n  `InteractiveBrowserCredential` in 1.4.0b3 is available on\n  `UsernamePasswordCredential` as well.\n  ([#11449](https://github.com/Azure/azure-sdk-for-python/issues/11449))\n- The optional persistent cache for `DeviceCodeCredential` and\n  `InteractiveBrowserCredential` added in 1.4.0b3 is now available on Linux and\n  macOS as well as Windows.\n  ([#11134](https://github.com/Azure/azure-sdk-for-python/issues/11134))\n  - On Linux, the persistent cache requires libsecret and `pygobject`. If these\n    are unavailable, or libsecret is unusable (e.g. in an SSH session), loading\n    the persistent cache will raise an error. You may optionally configure the\n    credential to fall back to an unencrypted cache by constructing it with\n    keyword argument `allow_unencrypted_cache=True`.\n\n## 1.4.0b3 (2020-05-04)\n- `EnvironmentCredential` correctly initializes `UsernamePasswordCredential`\nwith the value of `AZURE_TENANT_ID`\n([#11127](https://github.com/Azure/azure-sdk-for-python/pull/11127))\n- Values for the constructor keyword argument `authority` and\n`AZURE_AUTHORITY_HOST` may optionally specify an \"https\" scheme. For example,\n\"https://login.microsoftonline.us\" and \"login.microsoftonline.us\" are both valid.\n([#10819](https://github.com/Azure/azure-sdk-for-python/issues/10819))\n- First preview of new API for authenticating users with `DeviceCodeCredential`\n  and `InteractiveBrowserCredential`\n  ([#10612](https://github.com/Azure/azure-sdk-for-python/pull/10612))\n  - new method `authenticate` interactively authenticates a user, returns a\n    serializable `AuthenticationRecord`\n  - new constructor keyword arguments\n    - `authentication_record` enables initializing a credential with an\n      `AuthenticationRecord` from a prior authentication\n    - `disable_automatic_authentication=True` configures the credential to raise\n    `AuthenticationRequiredError` when interactive authentication is necessary\n    to acquire a token rather than immediately begin that authentication\n    - `enable_persistent_cache=True` configures these credentials to use a\n    persistent cache on supported platforms (in this release, Windows only).\n    By default they cache in memory only.\n- Now `DefaultAzureCredential` can authenticate with the identity signed in to\nVisual Studio Code's Azure extension.\n([#10472](https://github.com/Azure/azure-sdk-for-python/issues/10472))\n\n## 1.4.0b2 (2020-04-06)\n- After an instance of `DefaultAzureCredential` successfully authenticates, it\nuses the same authentication method for every subsequent token request. This\nmakes subsequent requests more efficient, and prevents unexpected changes of\nauthentication method.\n([#10349](https://github.com/Azure/azure-sdk-for-python/pull/10349))\n- All `get_token` methods consistently require at least one scope argument,\nraising an error when none is passed. Although `get_token()` may sometimes\nhave succeeded in prior versions, it couldn't do so consistently because its\nbehavior was undefined, and dependened on the credential's type and internal\nstate. ([#10243](https://github.com/Azure/azure-sdk-for-python/issues/10243))\n- `SharedTokenCacheCredential` raises `CredentialUnavailableError` when the\ncache is available but contains ambiguous or insufficient information. This\ncauses `ChainedTokenCredential` to correctly try the next credential in the\nchain. ([#10631](https://github.com/Azure/azure-sdk-for-python/issues/10631))\n- The host of the Active Directory endpoint credentials should use can be set\nin the environment variable `AZURE_AUTHORITY_HOST`. See\n`azure.identity.KnownAuthorities` for a list of common values.\n([#8094](https://github.com/Azure/azure-sdk-for-python/issues/8094))\n\n\n## 1.3.1 (2020-03-30)\n\n- `ManagedIdentityCredential` raises `CredentialUnavailableError` when no\nidentity is configured for an IMDS endpoint. This causes\n`ChainedTokenCredential` to correctly try the next credential in the chain.\n([#10488](https://github.com/Azure/azure-sdk-for-python/issues/10488))\n\n\n## 1.4.0b1 (2020-03-10)\n- `DefaultAzureCredential` can now authenticate using the identity logged in to\nthe Azure CLI, unless explicitly disabled with a keyword argument:\n`DefaultAzureCredential(exclude_cli_credential=True)`\n([#10092](https://github.com/Azure/azure-sdk-for-python/pull/10092))\n\n\n## 1.3.0 (2020-02-11)\n\n- Correctly parse token expiration time on Windows App Service\n([#9393](https://github.com/Azure/azure-sdk-for-python/issues/9393))\n- Credentials raise `CredentialUnavailableError` when they can't attempt to\nauthenticate due to missing data or state\n([#9372](https://github.com/Azure/azure-sdk-for-python/pull/9372))\n- `CertificateCredential` supports password-protected private keys\n([#9434](https://github.com/Azure/azure-sdk-for-python/pull/9434))\n\n\n## 1.2.0 (2020-01-14)\n\n- All credential pipelines include `ProxyPolicy`\n([#8945](https://github.com/Azure/azure-sdk-for-python/pull/8945))\n- Async credentials are async context managers and have an async `close` method\n([#9090](https://github.com/Azure/azure-sdk-for-python/pull/9090))\n\n\n## 1.1.0 (2019-11-27)\n\n- Constructing `DefaultAzureCredential` no longer raises `ImportError` on Python\n3.8 on Windows ([8294](https://github.com/Azure/azure-sdk-for-python/pull/8294))\n- `InteractiveBrowserCredential` raises when unable to open a web browser\n([8465](https://github.com/Azure/azure-sdk-for-python/pull/8465))\n- `InteractiveBrowserCredential` prompts for account selection\n([8470](https://github.com/Azure/azure-sdk-for-python/pull/8470))\n- The credentials composing `DefaultAzureCredential` are configurable by keyword\narguments ([8514](https://github.com/Azure/azure-sdk-for-python/pull/8514))\n- `SharedTokenCacheCredential` accepts an optional `tenant_id` keyword argument\n([8689](https://github.com/Azure/azure-sdk-for-python/pull/8689))\n\n\n## 1.0.1 (2019-11-05)\n\n- `ClientCertificateCredential` uses application and tenant IDs correctly\n([8315](https://github.com/Azure/azure-sdk-for-python/pull/8315))\n- `InteractiveBrowserCredential` properly caches tokens\n([8352](https://github.com/Azure/azure-sdk-for-python/pull/8352))\n- Adopted msal 1.0.0 and msal-extensions 0.1.3\n([8359](https://github.com/Azure/azure-sdk-for-python/pull/8359))\n\n\n## 1.0.0 (2019-10-29)\n### Breaking changes:\n- Async credentials now default to [`aiohttp`](https://pypi.org/project/aiohttp/)\nfor transport but the library does not require it as a dependency because the\nasync API is optional. To use async credentials, please install\n[`aiohttp`](https://pypi.org/project/aiohttp/) or see\n[azure-core documentation](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#transport)\nfor information about customizing the transport.\n- Renamed `ClientSecretCredential` parameter \"`secret`\" to \"`client_secret`\"\n- All credentials with `tenant_id` and `client_id` positional parameters now accept them in that order\n- Changes to `InteractiveBrowserCredential` parameters\n  - positional parameter `client_id` is now an optional keyword argument. If no value is provided,\nthe Azure CLI's client ID will be used.\n  - Optional keyword argument `tenant` renamed `tenant_id`\n- Changes to `DeviceCodeCredential`\n  - optional positional parameter `prompt_callback` is now a keyword argument\n  - `prompt_callback`'s third argument is now a `datetime` representing the\n  expiration time of the device code\n  - optional keyword argument `tenant` renamed `tenant_id`\n- Changes to `ManagedIdentityCredential`\n  - now accepts no positional arguments, and only one keyword argument:\n  `client_id`\n  - transport configuration is now done through keyword arguments as\n  described in\n  [`azure-core` documentation](https://github.com/Azure/azure-sdk-for-python/blob/azure-identity_1.0.0/sdk/core/azure-core/CLIENT_LIBRARY_DEVELOPER.md#transport)\n\n### Fixes and improvements:\n- Authenticating with a single sign-on shared with other Microsoft applications\nonly requires a username when multiple users have signed in\n([#8095](https://github.com/Azure/azure-sdk-for-python/pull/8095))\n- `DefaultAzureCredential` accepts an `authority` keyword argument, enabling\nits use in national clouds\n([#8154](https://github.com/Azure/azure-sdk-for-python/pull/8154))\n\n### Dependency changes\n- Adopted [`msal_extensions`](https://pypi.org/project/msal-extensions/) 0.1.2\n- Constrained [`msal`](https://pypi.org/project/msal/) requirement to >=0.4.1,\n<1.0.0\n\n\n## 1.0.0b4 (2019-10-07)\n### New features:\n- `AuthorizationCodeCredential` authenticates with a previously obtained\nauthorization code. See Microsoft Entra's\n[authorization code documentation](https://learn.microsoft.com/entra/identity-platform/v2-oauth2-auth-code-flow)\nfor more information about this authentication flow.\n- Multi-cloud support: client credentials accept the authority of an Azure Active\nDirectory authentication endpoint as an `authority` keyword argument. Known\nauthorities are defined in `azure.identity.KnownAuthorities`. The default\nauthority is for Azure Public Cloud, `login.microsoftonline.com`\n(`KnownAuthorities.AZURE_PUBLIC_CLOUD`). An application running in Azure\nGovernment would use `KnownAuthorities.AZURE_GOVERNMENT` instead:\n>```\n>from azure.identity import DefaultAzureCredential, KnownAuthorities\n>credential = DefaultAzureCredential(authority=KnownAuthorities.AZURE_GOVERNMENT)\n>```\n\n### Breaking changes:\n- Removed `client_secret` parameter from `InteractiveBrowserCredential`\n\n### Fixes and improvements:\n- `UsernamePasswordCredential` correctly handles environment configuration with\nno tenant information ([#7260](https://github.com/Azure/azure-sdk-for-python/pull/7260))\n- user realm discovery requests are sent through credential pipelines\n([#7260](https://github.com/Azure/azure-sdk-for-python/pull/7260))\n\n\n## 1.0.0b3 (2019-09-10)\n### New features:\n- `SharedTokenCacheCredential` authenticates with tokens stored in a local\ncache shared by Microsoft applications. This enables Azure SDK clients to\nauthenticate silently after you've signed in to Visual Studio 2019, for\nexample. `DefaultAzureCredential` includes `SharedTokenCacheCredential` when\nthe shared cache is available, and environment variable `AZURE_USERNAME`\nis set. See the\n[README](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/README.md#single-sign-on)\nfor more information.\n\n### Dependency changes:\n- New dependency: [`msal-extensions`](https://pypi.org/project/msal-extensions/)\n0.1.1\n\n## 1.0.0b2 (2019-08-05)\n### Breaking changes:\n- Removed `azure.core.Configuration` from the public API in preparation for a\nrevamped configuration API. Static `create_config` methods have been renamed\n`_create_config`, and will be removed in a future release.\n\n### Dependency changes:\n- Adopted [azure-core](https://pypi.org/project/azure-core/) 1.0.0b2\n  - If you later want to revert to a version requiring azure-core 1.0.0b1,\n  of this or another Azure SDK library, you must explicitly install azure-core\n  1.0.0b1 as well. For example:\n  `pip install azure-core==1.0.0b1 azure-identity==1.0.0b1`\n- Adopted [MSAL](https://pypi.org/project/msal/) 0.4.1\n- New dependency for Python 2.7: [mock](https://pypi.org/project/mock/)\n\n### New features:\n- Added credentials for authenticating users:\n - `DeviceCodeCredential`\n - `InteractiveBrowserCredential`\n - `UsernamePasswordCredential`\n  - async versions of these credentials will be added in a future release\n\n## 1.0.0b1 (2019-06-28)\nVersion 1.0.0b1 is the first preview of our efforts to create a user-friendly\nand Pythonic authentication API for Azure SDK client libraries. For more\ninformation about preview releases of other Azure SDK libraries, please visit\nhttps://aka.ms/azure-sdk-preview1-python.\n\nThis release supports service principal and managed identity authentication.\nSee the\n[documentation](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/README.md)\nfor more details. User authentication will be added in an upcoming preview\nrelease.\n\nThis release supports only global Microsoft Entra tenants, i.e. those\nusing the https://login.microsoftonline.com authentication endpoint.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "author_email": "Microsoft Corporation <azpysdkhelp@microsoft.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_dist": [
          "azure-core>=1.31.0",
          "cryptography>=2.5",
          "msal>=1.31.0",
          "msal-extensions>=1.2.0",
          "typing-extensions>=4.0.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "repository, https://github.com/Azure/azure-sdk-for-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/bc/05/6b348ea989f7a9e1e6311fa653e113bd39f4506771323e27a639c2a1ea54/opentelemetry_instrumentation_django-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=3f6b4ba201eee35406dab965b254eed0c64fa1ef42e4a7b0296ad1b30e8e3f81",
          "hashes": {
            "sha256": "3f6b4ba201eee35406dab965b254eed0c64fa1ef42e4a7b0296ad1b30e8e3f81"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-django",
        "version": "0.60b1",
        "summary": "OpenTelemetry Instrumentation for Django",
        "description": "OpenTelemetry Django Tracing\n============================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-django.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-django/\n\nThis library allows tracing requests for Django applications.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-django\n\nReferences\n----------\n\n* `Django <https://www.djangoproject.com/>`_\n* `OpenTelemetry Instrumentation for Django <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/django/django.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation-wsgi==0.60b1",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "opentelemetry-instrumentation-asgi==0.60b1; extra == 'asgi'",
          "django>=1.10; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-django",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "asgi",
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/93/98/c637d9e5cab1355d6765de2304199a1d79a43aa94c33d8eddb475327d81a/opentelemetry_instrumentation_wsgi-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5e7b432778ebf5a39af136227884a6ab2efc3c4e73e2dbb1d05ecf03ea196705",
          "hashes": {
            "sha256": "5e7b432778ebf5a39af136227884a6ab2efc3c4e73e2dbb1d05ecf03ea196705"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-wsgi",
        "version": "0.60b1",
        "summary": "WSGI Middleware for OpenTelemetry",
        "description": "OpenTelemetry WSGI Middleware\n=============================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-wsgi.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-wsgi/\n\n\nThis library provides a WSGI middleware that can be used on any WSGI framework\n(such as Django / Flask) to track requests timing through OpenTelemetry.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-wsgi\n\nReferences\n----------\n\n* `OpenTelemetry WSGI Middleware <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/wsgi/wsgi.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `WSGI <https://www.python.org/dev/peps/pep-3333>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-wsgi",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/58/68/7dd156ea341c73e73afc120f9c877bc827990d5ae8f8265d74d1b14608d6/opentelemetry_instrumentation_flask-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=070cb00f3f1214a4b680c7ab6ae1e5a14a54fd05ef163323500326002dfcfed4",
          "hashes": {
            "sha256": "070cb00f3f1214a4b680c7ab6ae1e5a14a54fd05ef163323500326002dfcfed4"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-flask",
        "version": "0.60b1",
        "summary": "Flask instrumentation for OpenTelemetry",
        "description": "OpenTelemetry Flask Tracing\n===========================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-flask.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-flask/\n\nThis library builds on the OpenTelemetry WSGI middleware to track web requests\nin Flask applications.\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-flask\n\nReferences\n----------\n\n* `OpenTelemetry Flask Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/flask/flask.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation-wsgi==0.60b1",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "packaging>=21.0",
          "flask>=1.0; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-flask",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/af/02/e30d5aae987c99ad4a4b4f98e009bf7c4f010d888da641efb0428814a4a6/opentelemetry_instrumentation_psycopg2-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f3841fe83400ee33c51ba5c38f4034534c3415075a4ebf01b97e49f8e0e5dd3e",
          "hashes": {
            "sha256": "f3841fe83400ee33c51ba5c38f4034534c3415075a4ebf01b97e49f8e0e5dd3e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-psycopg2",
        "version": "0.60b1",
        "summary": "OpenTelemetry psycopg2 instrumentation",
        "description": "OpenTelemetry Psycopg2 Instrumentation\n======================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-psycopg2.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-psycopg2/\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-psycopg2\n\n\nReferences\n----------\n* `OpenTelemetry Psycopg2 Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/psycopg2/psycopg2.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation-dbapi==0.60b1",
          "opentelemetry-instrumentation==0.60b1",
          "psycopg2-binary>=2.7.3.1; extra == 'instruments-any'",
          "psycopg2>=2.7.3.1; extra == 'instruments-any'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-psycopg2",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments",
          "instruments-any"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4e/08/d4c78b6e317d9975d473dd98f7854f5731ff4a1d470c65d2630fa68a1484/opentelemetry_instrumentation_dbapi-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5577189f678de5b9828c930c8fb72e8f1999b304131777b60099e5c4b3948193",
          "hashes": {
            "sha256": "5577189f678de5b9828c930c8fb72e8f1999b304131777b60099e5c4b3948193"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-dbapi",
        "version": "0.60b1",
        "summary": "OpenTelemetry Database API instrumentation",
        "description": "OpenTelemetry Database API instrumentation\n==========================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-dbapi.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-dbapi/\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-instrumentation-dbapi\n\n\nReferences\n----------\n\n* `OpenTelemetry Database API Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/dbapi/dbapi.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "wrapt<2.0.0,>=1.0.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-dbapi",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/f2/7f/969b59a5acccb4c35317421843d63d7853ad7a18078ca3a9b80c248be448/opentelemetry_instrumentation_requests-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=eec9fac3fab84737f663a2e08b12cb095b4bd67643b24587a8ecfa3cf4d0ca4c",
          "hashes": {
            "sha256": "eec9fac3fab84737f663a2e08b12cb095b4bd67643b24587a8ecfa3cf4d0ca4c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-requests",
        "version": "0.60b1",
        "summary": "OpenTelemetry requests instrumentation",
        "description": "OpenTelemetry Requests Instrumentation\n======================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-requests.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-requests/\n\nThis library allows tracing HTTP requests made by the\n`requests <https://requests.readthedocs.io/en/master/>`_ library.\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-instrumentation-requests\n\nConfiguration\n-------------\n\nExclude lists\n*************\nTo exclude certain URLs from being tracked, set the environment variable ``OTEL_PYTHON_REQUESTS_EXCLUDED_URLS``\n(or ``OTEL_PYTHON_EXCLUDED_URLS`` as fallback) with comma delimited regexes representing which URLs to exclude.\n\nFor example,\n\n::\n\n    export OTEL_PYTHON_REQUESTS_EXCLUDED_URLS=\"client/.*/info,healthcheck\"\n\nwill exclude requests such as ``https://site/client/123/info`` and ``https://site/xyz/healthcheck``.\n\nReferences\n----------\n\n* `OpenTelemetry requests Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/requests/requests.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "requests~=2.0; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-requests",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/21/70/b4c7b3bc17081725cf4bfa09286fd87e1d3a0d0589b12b35efba5db8da34/opentelemetry_instrumentation_urllib-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=bf36188d684ca6454b7162492a66749181955011e0cc47a2324cbe66e7f13e81",
          "hashes": {
            "sha256": "bf36188d684ca6454b7162492a66749181955011e0cc47a2324cbe66e7f13e81"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-urllib",
        "version": "0.60b1",
        "summary": "OpenTelemetry urllib instrumentation",
        "description": "OpenTelemetry urllib Instrumentation\n====================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-urllib.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-urllib/\n\nThis library allows tracing HTTP requests made by the\n`urllib <https://docs.python.org/3/library/urllib.html>`_ library.\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-instrumentation-urllib\n\nConfiguration\n-------------\n\nRequest/Response hooks\n**********************\n\nThe urllib instrumentation supports extending tracing behavior with the help of\nrequest and response hooks. These are functions that are called back by the instrumentation\nright after a Span is created for a request and right before the span is finished processing a response respectively.\nThe hooks can be configured as follows:\n\n.. code:: python\n\n    from opentelemetry.instrumentation.urllib import URLLibInstrumentor\n\n    # `request_obj` is an instance of urllib.request.Request\n    def request_hook(span, request_obj):\n        pass\n\n    # `request_obj` is an instance of urllib.request.Request\n    # `response` is an instance of http.client.HTTPResponse\n    def response_hook(span, request_obj, response):\n        pass\n\n    URLLibInstrumentor().instrument(\n        request_hook=request_hook, response_hook=response_hook\n    )\n\nExclude lists\n*************\n\nTo exclude certain URLs from being tracked, set the environment variable ``OTEL_PYTHON_URLLIB_EXCLUDED_URLS``\n(or ``OTEL_PYTHON_EXCLUDED_URLS`` as fallback) with comma delimited regexes representing which URLs to exclude.\n\nFor example,\n\n::\n\n    export OTEL_PYTHON_URLLIB_EXCLUDED_URLS=\"client/.*/info,healthcheck\"\n\nwill exclude requests such as ``https://site/client/123/info`` and ``https://site/xyz/healthcheck``.\n\nReferences\n----------\n\n* `OpenTelemetry urllib Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/urllib/urllib.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-urllib",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e1/07/d3411ae68983a8e7ca7195dc0fc2333a4f83e75f6943a30e69ede4e5fe48/opentelemetry_instrumentation_urllib3-0.60b1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4f17b5d41b25cc1b318260ca32f5321afc65017e4be533b65cd804c52855fdf7",
          "hashes": {
            "sha256": "4f17b5d41b25cc1b318260ca32f5321afc65017e4be533b65cd804c52855fdf7"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-urllib3",
        "version": "0.60b1",
        "summary": "OpenTelemetry urllib3 instrumentation",
        "description": "OpenTelemetry urllib3 Instrumentation\n======================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-instrumentation-urllib3.svg\n   :target: https://pypi.org/project/opentelemetry-instrumentation-urllib3/\n\nThis library allows tracing HTTP requests made by the\n`urllib3 <https://urllib3.readthedocs.io/>`_ library.\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-instrumentation-urllib3\n\nUsage\n-----\n.. code-block:: python\n\n    import urllib3\n    from opentelemetry.instrumentation.urllib3 import URLLib3Instrumentor\n\n    def strip_query_params(url: str) -> str:\n        return url.split(\"?\")[0]\n\n    URLLib3Instrumentor().instrument(\n        # Remove all query params from the URL attribute on the span.\n        url_filter=strip_query_params,\n    )\n\n    http = urllib3.PoolManager()\n    response = http.request(\"GET\", \"https://www.example.org/\")\n\nConfiguration\n-------------\n\nRequest/Response hooks\n**********************\n\nThe urllib3 instrumentation supports extending tracing behavior with the help of\nrequest and response hooks. These are functions that are called back by the instrumentation\nright after a Span is created for a request and right before the span is finished processing a response respectively.\nThe hooks can be configured as follows:\n\n.. code:: python\n\n    from typing import Any\n\n    from urllib3.connectionpool import HTTPConnectionPool\n    from urllib3.response import HTTPResponse\n\n    from opentelemetry.instrumentation.urllib3 import RequestInfo, URLLib3Instrumentor\n    from opentelemetry.trace import Span\n\n    def request_hook(\n        span: Span,\n        pool: HTTPConnectionPool,\n        request_info: RequestInfo,\n    ) -> Any:\n        pass\n\n    def response_hook(\n        span: Span,\n        pool: HTTPConnectionPool,\n        response: HTTPResponse,\n    ) -> Any:\n        pass\n\n    URLLib3Instrumentor().instrument(\n        request_hook=request_hook,\n        response_hook=response_hook,\n    )\n\nExclude lists\n*************\n\nTo exclude certain URLs from being tracked, set the environment variable ``OTEL_PYTHON_URLLIB3_EXCLUDED_URLS``\n(or ``OTEL_PYTHON_EXCLUDED_URLS`` as fallback) with comma delimited regexes representing which URLs to exclude.\n\nFor example,\n\n::\n\n    export OTEL_PYTHON_URLLIB3_EXCLUDED_URLS=\"client/.*/info,healthcheck\"\n\nwill exclude requests such as ``https://site/client/123/info`` and ``https://site/xyz/healthcheck``.\n\nReferences\n----------\n\n* `OpenTelemetry urllib3 Instrumentation <https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/urllib3/urllib3.html>`_\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Python Examples <https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-api~=1.12",
          "opentelemetry-instrumentation==0.60b1",
          "opentelemetry-semantic-conventions==0.60b1",
          "opentelemetry-util-http==0.60b1",
          "wrapt<2.0.0,>=1.0.0",
          "urllib3<3.0.0,>=1.0.0; extra == 'instruments'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-urllib3",
          "Repository, https://github.com/open-telemetry/opentelemetry-python-contrib"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c3/ae/c26d8da88ba2e438e9653a408b0c2ad6f17267801250a8f3cc6405a93a72/opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4dcc5d54ab5c3b11226af39509bc98979a8b9e0f8a24c1b888783755d3bf00eb",
          "hashes": {
            "sha256": "4dcc5d54ab5c3b11226af39509bc98979a8b9e0f8a24c1b888783755d3bf00eb"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "opentelemetry-resource-detector-azure",
        "version": "0.1.5",
        "summary": "Azure Resource Detector for OpenTelemetry",
        "description": "OpenTelemetry Resource detectors for Azure\n==========================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-resource-detector-azure.svg\n   :target: https://pypi.org/project/opentelemetry-resource-detector-azure/\n\nThis library contains OpenTelemetry `Resource Detectors <https://opentelemetry.io/docs/specs/otel/resource/sdk/#detecting-resource-information-from-the-environment>`_ for the following Azure resources:\n * `Azure App Service <https://azure.microsoft.com/en-us/products/app-service>`_\n * `Azure Virtual Machines <https://azure.microsoft.com/en-us/products/virtual-machines>`_\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-resource-detector-azure\n\n---------------------------\n\nUsage example for ``opentelemetry-resource-detector-azure``\n\n.. code-block:: python\n\n    from opentelemetry import trace\n    from opentelemetry.sdk.trace import TracerProvider\n    from opentelemetry.resource.detector.azure.app_service import (\n        AzureAppServiceResourceDetector,\n        AzureVMResourceDetector,\n    )\n    from opentelemetry.resource.detector.azure.vm import (\n        AzureVMResourceDetector,\n    )\n    from opentelemetry.sdk.resources import get_aggregated_resources\n\n\n    trace.set_tracer_provider(\n        TracerProvider(\n            resource=get_aggregated_resources(\n                [\n                    AzureAppServiceResourceDetector(),\n                    AzureVMResourceDetector(),\n                ]\n            ),\n        )\n    )\n\nMappings\n--------\n\nThe Azure App Service Resource Detector sets the following Resource Attributes:\n * ``service.name`` set to the value of the ``WEBSITE_SITE_NAME`` environment variable.\n * ``cloud.platform`` set to ``azure_app_service``.\n * ``cloud.provider`` set to ``azure``.\n * ``cloud.resource_id`` set using the ``WEBSITE_RESOURCE_GROUP``, ``WEBSITE_OWNER_NAME``, and ``WEBSITE_SITE_NAME`` environment variables.\n * ``cloud.region`` set to the value of the ``REGION_NAME`` environment variable.\n * ``deployment.environment`` set to the value of the ``WEBSITE_SLOT_NAME`` environment variable.\n * ``host.id`` set to the value of the ``WEBSITE_HOSTNAME`` environment variable.\n * ``service.instance.id`` set to the value of the ``WEBSITE_INSTANCE_ID`` environment variable.\n * ``azure.app.service.stamp`` set to the value of the ``WEBSITE_HOME_STAMPNAME`` environment variable.\n\n The Azure Functions Resource Detector sets the following Resource Attributes:\n * ``service.name`` set to the value of the ``WEBSITE_SITE_NAME`` environment variable.\n * ``process.id`` set to the process ID collected from the running process.\n * ``cloud.platform`` set to ``azure_functions``.\n * ``cloud.provider`` set to ``azure``.\n * ``cloud.resource_id`` set using the ``WEBSITE_RESOURCE_GROUP``, ``WEBSITE_OWNER_NAME``, and ``WEBSITE_SITE_NAME`` environment variables.\n * ``cloud.region`` set to the value of the ``REGION_NAME`` environment variable.\n * ``faas.instance`` set to the value of the ``WEBSITE_INSTANCE_ID`` environment variable.\n * ``faas.max_memory`` set to the value of the ``WEBSITE_MEMORY_LIMIT_MB`` environment variable.\n\nThe Azure VM Resource Detector sets the following Resource Attributes according to the response from the `Azure Metadata Service <https://learn.microsoft.com/azure/virtual-machines/instance-metadata-service?tabs=windows>`_:\n * ``azure.vm.scaleset.name`` set to the value of the ``vmScaleSetName`` field.\n * ``azure.vm.sku`` set to the value of the ``sku`` field.\n * ``cloud.platform`` set to the value of the ``azure_vm``.\n * ``cloud.provider`` set to the value of the ``azure``.\n * ``cloud.region`` set to the value of the ``location`` field.\n * ``cloud.resource_id`` set to the value of the ``resourceId`` field.\n * ``host.id`` set to the value of the ``vmId`` field.\n * ``host.name`` set to the value of the ``name`` field.\n * ``host.type`` set to the value of the ``vmSize`` field.\n * ``os.type`` set to the value of the ``osType`` field.\n * ``os.version`` set to the value of the ``version`` field.\n * ``service.instance.id`` set to the value of the ``vmId`` field.\n\nFor more information, see the `Semantic Conventions for Cloud Resource Attributes <https://opentelemetry.io/docs/specs/otel/resource/semantic_conventions/cloud/>`_.\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11"
        ],
        "requires_dist": [
          "opentelemetry-sdk~=1.21"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/resource/opentelemetry-resource-detector-azure"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b4/90/e2159492b5426be0c1fef7acba807a03511f97c5f86b3caeda6ad92351a7/psutil-7.2.2-cp37-abi3-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=eb7e81434c8d223ec4a219b5fc1c47d0417b12be7ea866e24fb5ad6e84b3d988",
          "hashes": {
            "sha256": "eb7e81434c8d223ec4a219b5fc1c47d0417b12be7ea866e24fb5ad6e84b3d988"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "psutil",
        "version": "7.2.2",
        "platform": [
          "Platform Independent"
        ],
        "summary": "Cross-platform lib for process and system monitoring.",
        "description": "|  |downloads| |stars| |forks| |contributors| |packages|\r\n|  |version| |license| |stackoverflow| |twitter| |tidelift|\r\n|  |github-actions-wheels| |github-actions-bsd|\r\n\r\n.. |downloads| image:: https://img.shields.io/pypi/dm/psutil.svg\r\n    :target: https://clickpy.clickhouse.com/dashboard/psutil\r\n    :alt: Downloads\r\n\r\n.. |stars| image:: https://img.shields.io/github/stars/giampaolo/psutil.svg\r\n    :target: https://github.com/giampaolo/psutil/stargazers\r\n    :alt: Github stars\r\n\r\n.. |forks| image:: https://img.shields.io/github/forks/giampaolo/psutil.svg\r\n    :target: https://github.com/giampaolo/psutil/network/members\r\n    :alt: Github forks\r\n\r\n.. |contributors| image:: https://img.shields.io/github/contributors/giampaolo/psutil.svg\r\n    :target: https://github.com/giampaolo/psutil/graphs/contributors\r\n    :alt: Contributors\r\n\r\n.. |stackoverflow| image:: https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg\r\n    :target: https://stackoverflow.com/questions/tagged/psutil\r\n    :alt: Stackoverflow\r\n\r\n.. |github-actions-wheels| image:: https://img.shields.io/github/actions/workflow/status/giampaolo/psutil/.github/workflows/build.yml.svg?label=Linux%2C%20macOS%2C%20Windows\r\n    :target: https://github.com/giampaolo/psutil/actions?query=workflow%3Abuild\r\n    :alt: Linux, macOS, Windows\r\n\r\n.. |github-actions-bsd| image:: https://img.shields.io/github/actions/workflow/status/giampaolo/psutil/.github/workflows/bsd.yml.svg?label=FreeBSD,%20NetBSD,%20OpenBSD\r\n    :target: https://github.com/giampaolo/psutil/actions?query=workflow%3Absd-tests\r\n    :alt: FreeBSD, NetBSD, OpenBSD\r\n\r\n.. |version| image:: https://img.shields.io/pypi/v/psutil.svg?label=pypi\r\n    :target: https://pypi.org/project/psutil\r\n    :alt: Latest version\r\n\r\n.. |packages| image:: https://repology.org/badge/tiny-repos/python:psutil.svg\r\n    :target: https://repology.org/metapackage/python:psutil/versions\r\n    :alt: Binary packages\r\n\r\n.. |license| image:: https://img.shields.io/pypi/l/psutil.svg\r\n    :target: https://github.com/giampaolo/psutil/blob/master/LICENSE\r\n    :alt: License\r\n\r\n.. |twitter| image:: https://img.shields.io/twitter/follow/grodola?style=flat\r\n    :target: https://twitter.com/grodola\r\n    :alt: Twitter Follow\r\n\r\n.. |tidelift| image:: https://tidelift.com/badges/github/giampaolo/psutil?style=flat\r\n    :target: https://tidelift.com/subscription/pkg/pypi-psutil?utm_source=pypi-psutil&utm_medium=referral&utm_campaign=readme\r\n    :alt: Tidelift\r\n\r\n-----\r\n\r\nQuick links\r\n===========\r\n\r\n- `Home page <https://github.com/giampaolo/psutil>`_\r\n- `Install <https://github.com/giampaolo/psutil/blob/master/INSTALL.rst>`_\r\n- `Documentation <http://psutil.readthedocs.io>`_\r\n- `Download <https://pypi.org/project/psutil/#files>`_\r\n- `Forum <http://groups.google.com/group/psutil/topics>`_\r\n- `StackOverflow <https://stackoverflow.com/questions/tagged/psutil>`_\r\n- `Blog <https://gmpy.dev/tags/psutil>`_\r\n- `What's new <https://github.com/giampaolo/psutil/blob/master/HISTORY.rst>`_\r\n\r\n\r\nSummary\r\n=======\r\n\r\npsutil (process and system utilities) is a cross-platform library for\r\nretrieving information on **running processes** and **system utilization**\r\n(CPU, memory, disks, network, sensors) in Python.\r\nIt is useful mainly for **system monitoring**, **profiling and limiting process\r\nresources** and **management of running processes**.\r\nIt implements many functionalities offered by classic UNIX command line tools\r\nsuch as *ps, top, iotop, lsof, netstat, ifconfig, free* and others.\r\npsutil currently supports the following platforms:\r\n\r\n- **Linux**\r\n- **Windows**\r\n- **macOS**\r\n- **FreeBSD, OpenBSD**, **NetBSD**\r\n- **Sun Solaris**\r\n- **AIX**\r\n\r\nSupported Python versions are cPython 3.6+ and `PyPy <https://pypy.org/>`__.\r\nLatest psutil version supporting Python 2.7 is\r\n`psutil 6.1.1 <https://pypi.org/project/psutil/6.1.1/>`__.\r\n\r\nExample usages\r\n==============\r\n\r\nThis represents pretty much the whole psutil API.\r\n\r\nCPU\r\n---\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>>\r\n    >>> psutil.cpu_times()\r\n    scputimes(user=3961.46, nice=169.729, system=2150.659, idle=16900.540, iowait=629.59, irq=0.0, softirq=19.42, steal=0.0, guest=0, guest_nice=0.0)\r\n    >>>\r\n    >>> for x in range(3):\r\n    ...     psutil.cpu_percent(interval=1)\r\n    ...\r\n    4.0\r\n    5.9\r\n    3.8\r\n    >>>\r\n    >>> for x in range(3):\r\n    ...     psutil.cpu_percent(interval=1, percpu=True)\r\n    ...\r\n    [4.0, 6.9, 3.7, 9.2]\r\n    [7.0, 8.5, 2.4, 2.1]\r\n    [1.2, 9.0, 9.9, 7.2]\r\n    >>>\r\n    >>> for x in range(3):\r\n    ...     psutil.cpu_times_percent(interval=1, percpu=False)\r\n    ...\r\n    scputimes(user=1.5, nice=0.0, system=0.5, idle=96.5, iowait=1.5, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)\r\n    scputimes(user=1.0, nice=0.0, system=0.0, idle=99.0, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)\r\n    scputimes(user=2.0, nice=0.0, system=0.0, idle=98.0, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)\r\n    >>>\r\n    >>> psutil.cpu_count()\r\n    4\r\n    >>> psutil.cpu_count(logical=False)\r\n    2\r\n    >>>\r\n    >>> psutil.cpu_stats()\r\n    scpustats(ctx_switches=20455687, interrupts=6598984, soft_interrupts=2134212, syscalls=0)\r\n    >>>\r\n    >>> psutil.cpu_freq()\r\n    scpufreq(current=931.42925, min=800.0, max=3500.0)\r\n    >>>\r\n    >>> psutil.getloadavg()  # also on Windows (emulated)\r\n    (3.14, 3.89, 4.67)\r\n\r\nMemory\r\n------\r\n\r\n.. code-block:: python\r\n\r\n    >>> psutil.virtual_memory()\r\n    svmem(total=10367352832, available=6472179712, percent=37.6, used=8186245120, free=2181107712, active=4748992512, inactive=2758115328, buffers=790724608, cached=3500347392, shared=787554304)\r\n    >>> psutil.swap_memory()\r\n    sswap(total=2097147904, used=296128512, free=1801019392, percent=14.1, sin=304193536, sout=677842944)\r\n    >>>\r\n\r\nDisks\r\n-----\r\n\r\n.. code-block:: python\r\n\r\n    >>> psutil.disk_partitions()\r\n    [sdiskpart(device='/dev/sda1', mountpoint='/', fstype='ext4', opts='rw,nosuid'),\r\n     sdiskpart(device='/dev/sda2', mountpoint='/home', fstype='ext', opts='rw')]\r\n    >>>\r\n    >>> psutil.disk_usage('/')\r\n    sdiskusage(total=21378641920, used=4809781248, free=15482871808, percent=22.5)\r\n    >>>\r\n    >>> psutil.disk_io_counters(perdisk=False)\r\n    sdiskio(read_count=719566, write_count=1082197, read_bytes=18626220032, write_bytes=24081764352, read_time=5023392, write_time=63199568, read_merged_count=619166, write_merged_count=812396, busy_time=4523412)\r\n    >>>\r\n\r\nNetwork\r\n-------\r\n\r\n.. code-block:: python\r\n\r\n    >>> psutil.net_io_counters(pernic=True)\r\n    {'eth0': netio(bytes_sent=485291293, bytes_recv=6004858642, packets_sent=3251564, packets_recv=4787798, errin=0, errout=0, dropin=0, dropout=0),\r\n     'lo': netio(bytes_sent=2838627, bytes_recv=2838627, packets_sent=30567, packets_recv=30567, errin=0, errout=0, dropin=0, dropout=0)}\r\n    >>>\r\n    >>> psutil.net_connections(kind='tcp')\r\n    [sconn(fd=115, family=<AddressFamily.AF_INET: 2>, type=<SocketType.SOCK_STREAM: 1>, laddr=addr(ip='10.0.0.1', port=48776), raddr=addr(ip='93.186.135.91', port=80), status='ESTABLISHED', pid=1254),\r\n     sconn(fd=117, family=<AddressFamily.AF_INET: 2>, type=<SocketType.SOCK_STREAM: 1>, laddr=addr(ip='10.0.0.1', port=43761), raddr=addr(ip='72.14.234.100', port=80), status='CLOSING', pid=2987),\r\n     ...]\r\n    >>>\r\n    >>> psutil.net_if_addrs()\r\n    {'lo': [snicaddr(family=<AddressFamily.AF_INET: 2>, address='127.0.0.1', netmask='255.0.0.0', broadcast='127.0.0.1', ptp=None),\r\n            snicaddr(family=<AddressFamily.AF_INET6: 10>, address='::1', netmask='ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff', broadcast=None, ptp=None),\r\n            snicaddr(family=<AddressFamily.AF_LINK: 17>, address='00:00:00:00:00:00', netmask=None, broadcast='00:00:00:00:00:00', ptp=None)],\r\n     'wlan0': [snicaddr(family=<AddressFamily.AF_INET: 2>, address='192.168.1.3', netmask='255.255.255.0', broadcast='192.168.1.255', ptp=None),\r\n               snicaddr(family=<AddressFamily.AF_INET6: 10>, address='fe80::c685:8ff:fe45:641%wlan0', netmask='ffff:ffff:ffff:ffff::', broadcast=None, ptp=None),\r\n               snicaddr(family=<AddressFamily.AF_LINK: 17>, address='c4:85:08:45:06:41', netmask=None, broadcast='ff:ff:ff:ff:ff:ff', ptp=None)]}\r\n    >>>\r\n    >>> psutil.net_if_stats()\r\n    {'lo': snicstats(isup=True, duplex=<NicDuplex.NIC_DUPLEX_UNKNOWN: 0>, speed=0, mtu=65536, flags='up,loopback,running'),\r\n     'wlan0': snicstats(isup=True, duplex=<NicDuplex.NIC_DUPLEX_FULL: 2>, speed=100, mtu=1500, flags='up,broadcast,running,multicast')}\r\n    >>>\r\n\r\nSensors\r\n-------\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>> psutil.sensors_temperatures()\r\n    {'acpitz': [shwtemp(label='', current=47.0, high=103.0, critical=103.0)],\r\n     'asus': [shwtemp(label='', current=47.0, high=None, critical=None)],\r\n     'coretemp': [shwtemp(label='Physical id 0', current=52.0, high=100.0, critical=100.0),\r\n                  shwtemp(label='Core 0', current=45.0, high=100.0, critical=100.0)]}\r\n    >>>\r\n    >>> psutil.sensors_fans()\r\n    {'asus': [sfan(label='cpu_fan', current=3200)]}\r\n    >>>\r\n    >>> psutil.sensors_battery()\r\n    sbattery(percent=93, secsleft=16628, power_plugged=False)\r\n    >>>\r\n\r\nOther system info\r\n-----------------\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>> psutil.users()\r\n    [suser(name='giampaolo', terminal='pts/2', host='localhost', started=1340737536.0, pid=1352),\r\n     suser(name='giampaolo', terminal='pts/3', host='localhost', started=1340737792.0, pid=1788)]\r\n    >>>\r\n    >>> psutil.boot_time()\r\n    1365519115.0\r\n    >>>\r\n\r\nProcess management\r\n------------------\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>> psutil.pids()\r\n    [1, 2, 3, 4, 5, 6, 7, 46, 48, 50, 51, 178, 182, 222, 223, 224, 268, 1215,\r\n     1216, 1220, 1221, 1243, 1244, 1301, 1601, 2237, 2355, 2637, 2774, 3932,\r\n     4176, 4177, 4185, 4187, 4189, 4225, 4243, 4245, 4263, 4282, 4306, 4311,\r\n     4312, 4313, 4314, 4337, 4339, 4357, 4358, 4363, 4383, 4395, 4408, 4433,\r\n     4443, 4445, 4446, 5167, 5234, 5235, 5252, 5318, 5424, 5644, 6987, 7054,\r\n     7055, 7071]\r\n    >>>\r\n    >>> p = psutil.Process(7055)\r\n    >>> p\r\n    psutil.Process(pid=7055, name='python3', status='running', started='09:04:44')\r\n    >>> p.pid\r\n    7055\r\n    >>> p.name()\r\n    'python3'\r\n    >>> p.exe()\r\n    '/usr/bin/python3'\r\n    >>> p.cwd()\r\n    '/home/giampaolo'\r\n    >>> p.cmdline()\r\n    ['/usr/bin/python3', 'main.py']\r\n    >>>\r\n    >>> p.ppid()\r\n    7054\r\n    >>> p.parent()\r\n    psutil.Process(pid=4699, name='bash', status='sleeping', started='09:06:44')\r\n    >>> p.parents()\r\n    [psutil.Process(pid=4699, name='bash', started='09:06:44'),\r\n     psutil.Process(pid=4689, name='gnome-terminal-server', status='sleeping', started='0:06:44'),\r\n     psutil.Process(pid=1, name='systemd', status='sleeping', started='05:56:55')]\r\n    >>> p.children(recursive=True)\r\n    [psutil.Process(pid=29835, name='python3', status='sleeping', started='11:45:38'),\r\n     psutil.Process(pid=29836, name='python3', status='waking', started='11:43:39')]\r\n    >>>\r\n    >>> p.status()\r\n    'running'\r\n    >>> p.create_time()\r\n    1267551141.5019531\r\n    >>> p.terminal()\r\n    '/dev/pts/0'\r\n    >>>\r\n    >>> p.username()\r\n    'giampaolo'\r\n    >>> p.uids()\r\n    puids(real=1000, effective=1000, saved=1000)\r\n    >>> p.gids()\r\n    pgids(real=1000, effective=1000, saved=1000)\r\n    >>>\r\n    >>> p.cpu_times()\r\n    pcputimes(user=1.02, system=0.31, children_user=0.32, children_system=0.1, iowait=0.0)\r\n    >>> p.cpu_percent(interval=1.0)\r\n    12.1\r\n    >>> p.cpu_affinity()\r\n    [0, 1, 2, 3]\r\n    >>> p.cpu_affinity([0, 1])  # set\r\n    >>> p.cpu_num()\r\n    1\r\n    >>>\r\n    >>> p.memory_info()\r\n    pmem(rss=10915840, vms=67608576, shared=3313664, text=2310144, lib=0, data=7262208, dirty=0)\r\n    >>> p.memory_full_info()  # \"real\" USS memory usage (Linux, macOS, Win only)\r\n    pfullmem(rss=10199040, vms=52133888, shared=3887104, text=2867200, lib=0, data=5967872, dirty=0, uss=6545408, pss=6872064, swap=0)\r\n    >>> p.memory_percent()\r\n    0.7823\r\n    >>> p.memory_maps()\r\n    [pmmap_grouped(path='/lib/x8664-linux-gnu/libutil-2.15.so', rss=32768, size=2125824, pss=32768, shared_clean=0, shared_dirty=0, private_clean=20480, private_dirty=12288, referenced=32768, anonymous=12288, swap=0),\r\n     pmmap_grouped(path='/lib/x8664-linux-gnu/libc-2.15.so', rss=3821568, size=3842048, pss=3821568, shared_clean=0, shared_dirty=0, private_clean=0, private_dirty=3821568, referenced=3575808, anonymous=3821568, swap=0),\r\n     pmmap_grouped(path='[heap]',  rss=32768, size=139264, pss=32768, shared_clean=0, shared_dirty=0, private_clean=0, private_dirty=32768, referenced=32768, anonymous=32768, swap=0),\r\n     pmmap_grouped(path='[stack]', rss=2465792, size=2494464, pss=2465792, shared_clean=0, shared_dirty=0, private_clean=0, private_dirty=2465792, referenced=2277376, anonymous=2465792, swap=0),\r\n     ...]\r\n    >>>\r\n    >>> p.io_counters()\r\n    pio(read_count=478001, write_count=59371, read_bytes=700416, write_bytes=69632, read_chars=456232, write_chars=517543)\r\n    >>>\r\n    >>> p.open_files()\r\n    [popenfile(path='/home/giampaolo/monit.py', fd=3, position=0, mode='r', flags=32768),\r\n     popenfile(path='/var/log/monit.log', fd=4, position=235542, mode='a', flags=33793)]\r\n    >>>\r\n    >>> p.net_connections(kind='tcp')\r\n    [pconn(fd=115, family=<AddressFamily.AF_INET: 2>, type=<SocketType.SOCK_STREAM: 1>, laddr=addr(ip='10.0.0.1', port=48776), raddr=addr(ip='93.186.135.91', port=80), status='ESTABLISHED'),\r\n     pconn(fd=117, family=<AddressFamily.AF_INET: 2>, type=<SocketType.SOCK_STREAM: 1>, laddr=addr(ip='10.0.0.1', port=43761), raddr=addr(ip='72.14.234.100', port=80), status='CLOSING')]\r\n    >>>\r\n    >>> p.threads()\r\n    [pthread(id=5234, user_time=22.5, system_time=9.2891),\r\n     pthread(id=5237, user_time=0.0707, system_time=1.1)]\r\n    >>>\r\n    >>> p.num_threads()\r\n    4\r\n    >>> p.num_fds()\r\n    8\r\n    >>> p.num_ctx_switches()\r\n    pctxsw(voluntary=78, involuntary=19)\r\n    >>>\r\n    >>> p.nice()\r\n    0\r\n    >>> p.nice(10)  # set\r\n    >>>\r\n    >>> p.ionice(psutil.IOPRIO_CLASS_IDLE)  # IO priority (Win and Linux only)\r\n    >>> p.ionice()\r\n    pionice(ioclass=<IOPriority.IOPRIO_CLASS_IDLE: 3>, value=0)\r\n    >>>\r\n    >>> p.rlimit(psutil.RLIMIT_NOFILE, (5, 5))  # set resource limits (Linux only)\r\n    >>> p.rlimit(psutil.RLIMIT_NOFILE)\r\n    (5, 5)\r\n    >>>\r\n    >>> p.environ()\r\n    {'LC_PAPER': 'it_IT.UTF-8', 'SHELL': '/bin/bash', 'GREP_OPTIONS': '--color=auto',\r\n    'XDG_CONFIG_DIRS': '/etc/xdg/xdg-ubuntu:/usr/share/upstart/xdg:/etc/xdg',\r\n     ...}\r\n    >>>\r\n    >>> p.as_dict()\r\n    {'status': 'running', 'num_ctx_switches': pctxsw(voluntary=63, involuntary=1), 'pid': 5457, ...}\r\n    >>> p.is_running()\r\n    True\r\n    >>> p.suspend()\r\n    >>> p.resume()\r\n    >>>\r\n    >>> p.terminate()\r\n    >>> p.kill()\r\n    >>> p.wait(timeout=3)\r\n    <Exitcode.EX_OK: 0>\r\n    >>>\r\n    >>> psutil.test()\r\n    USER         PID %CPU %MEM     VSZ     RSS TTY        START    TIME  COMMAND\r\n    root           1  0.0  0.0   24584    2240            Jun17   00:00  init\r\n    root           2  0.0  0.0       0       0            Jun17   00:00  kthreadd\r\n    ...\r\n    giampaolo  31475  0.0  0.0   20760    3024 /dev/pts/0 Jun19   00:00  python2.4\r\n    giampaolo  31721  0.0  2.2  773060  181896            00:04   10:30  chrome\r\n    root       31763  0.0  0.0       0       0            00:05   00:00  kworker/0:1\r\n    >>>\r\n\r\nFurther process APIs\r\n--------------------\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>> for proc in psutil.process_iter(['pid', 'name']):\r\n    ...     print(proc.info)\r\n    ...\r\n    {'pid': 1, 'name': 'systemd'}\r\n    {'pid': 2, 'name': 'kthreadd'}\r\n    {'pid': 3, 'name': 'ksoftirqd/0'}\r\n    ...\r\n    >>>\r\n    >>> psutil.pid_exists(3)\r\n    True\r\n    >>>\r\n    >>> def on_terminate(proc):\r\n    ...     print(\"process {} terminated\".format(proc))\r\n    ...\r\n    >>> # waits for multiple processes to terminate\r\n    >>> gone, alive = psutil.wait_procs(procs_list, timeout=3, callback=on_terminate)\r\n    >>>\r\n\r\nHeap info\r\n---------\r\n\r\n.. code-block:: python\r\n\r\n    >>> import psutil\r\n    >>> psutil.heap_info()\r\n    pheap(heap_used=5177792, mmap_used=819200)\r\n    >>> psutil.heap_trim()\r\n\r\nSee also `psleak <https://github.com/giampaolo/psleak>`__\r\n\r\nWindows services\r\n----------------\r\n\r\n.. code-block:: python\r\n\r\n    >>> list(psutil.win_service_iter())\r\n    [<WindowsService(name='AeLookupSvc', display_name='Application Experience') at 38850096>,\r\n     <WindowsService(name='ALG', display_name='Application Layer Gateway Service') at 38850128>,\r\n     <WindowsService(name='APNMCP', display_name='Ask Update Service') at 38850160>,\r\n     <WindowsService(name='AppIDSvc', display_name='Application Identity') at 38850192>,\r\n     ...]\r\n    >>> s = psutil.win_service_get('alg')\r\n    >>> s.as_dict()\r\n    {'binpath': 'C:\\\\Windows\\\\System32\\\\alg.exe',\r\n     'description': 'Provides support for 3rd party protocol plug-ins for Internet Connection Sharing',\r\n     'display_name': 'Application Layer Gateway Service',\r\n     'name': 'alg',\r\n     'pid': None,\r\n     'start_type': 'manual',\r\n     'status': 'stopped',\r\n     'username': 'NT AUTHORITY\\\\LocalService'}\r\n\r\nProjects using psutil\r\n=====================\r\n\r\nHere's some I find particularly interesting:\r\n\r\n- https://github.com/giampaolo/psleak\r\n- https://github.com/google/grr\r\n- https://github.com/facebook/osquery/\r\n- https://github.com/nicolargo/glances\r\n- https://github.com/aristocratos/bpytop\r\n- https://github.com/Jahaja/psdash\r\n- https://github.com/ajenti/ajenti\r\n- https://github.com/home-assistant/home-assistant/\r\n\r\nPortings\r\n========\r\n\r\n- Go: https://github.com/shirou/gopsutil\r\n- C: https://github.com/hamon-in/cpslib\r\n- Rust: https://github.com/rust-psutil/rust-psutil\r\n- Nim: https://github.com/johnscillieri/psutil-nim\r\n\r\n\r\n\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "ps",
          "top",
          "kill",
          "free",
          "lsof",
          "netstat",
          "nice",
          "tty",
          "ionice",
          "uptime",
          "taskmgr",
          "process",
          "df",
          "iotop",
          "iostat",
          "ifconfig",
          "taskset",
          "who",
          "pidof",
          "pmap",
          "smem",
          "pstree",
          "monitoring",
          "ulimit",
          "prlimit",
          "smem",
          "performance",
          "metrics",
          "agent",
          "observability"
        ],
        "home_page": "https://github.com/giampaolo/psutil",
        "author": "Giampaolo Rodola",
        "author_email": "g.rodola@gmail.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows :: Windows 10",
          "Operating System :: Microsoft :: Windows :: Windows 11",
          "Operating System :: Microsoft :: Windows :: Windows 7",
          "Operating System :: Microsoft :: Windows :: Windows 8",
          "Operating System :: Microsoft :: Windows :: Windows 8.1",
          "Operating System :: Microsoft :: Windows :: Windows Server 2003",
          "Operating System :: Microsoft :: Windows :: Windows Server 2008",
          "Operating System :: Microsoft :: Windows :: Windows Vista",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: Microsoft",
          "Operating System :: OS Independent",
          "Operating System :: POSIX :: AIX",
          "Operating System :: POSIX :: BSD :: FreeBSD",
          "Operating System :: POSIX :: BSD :: NetBSD",
          "Operating System :: POSIX :: BSD :: OpenBSD",
          "Operating System :: POSIX :: BSD",
          "Operating System :: POSIX :: Linux",
          "Operating System :: POSIX :: SunOS/Solaris",
          "Operating System :: POSIX",
          "Programming Language :: C",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Libraries",
          "Topic :: System :: Benchmark",
          "Topic :: System :: Hardware",
          "Topic :: System :: Monitoring",
          "Topic :: System :: Networking :: Monitoring :: Hardware Watchdog",
          "Topic :: System :: Networking :: Monitoring",
          "Topic :: System :: Networking",
          "Topic :: System :: Operating System",
          "Topic :: System :: Systems Administration",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "psleak ; extra == 'dev'",
          "pytest ; extra == 'dev'",
          "pytest-instafail ; extra == 'dev'",
          "pytest-xdist ; extra == 'dev'",
          "setuptools ; extra == 'dev'",
          "abi3audit ; extra == 'dev'",
          "black ; extra == 'dev'",
          "check-manifest ; extra == 'dev'",
          "coverage ; extra == 'dev'",
          "packaging ; extra == 'dev'",
          "pylint ; extra == 'dev'",
          "pyperf ; extra == 'dev'",
          "pypinfo ; extra == 'dev'",
          "pytest-cov ; extra == 'dev'",
          "requests ; extra == 'dev'",
          "rstcheck ; extra == 'dev'",
          "ruff ; extra == 'dev'",
          "sphinx ; extra == 'dev'",
          "sphinx-rtd-theme ; extra == 'dev'",
          "toml-sort ; extra == 'dev'",
          "twine ; extra == 'dev'",
          "validate-pyproject[all] ; extra == 'dev'",
          "virtualenv ; extra == 'dev'",
          "vulture ; extra == 'dev'",
          "wheel ; extra == 'dev'",
          "colorama ; (os_name == \"nt\") and extra == 'dev'",
          "pyreadline3 ; (os_name == \"nt\") and extra == 'dev'",
          "pywin32 ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'dev'",
          "wheel ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'dev'",
          "wmi ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'dev'",
          "psleak ; extra == 'test'",
          "pytest ; extra == 'test'",
          "pytest-instafail ; extra == 'test'",
          "pytest-xdist ; extra == 'test'",
          "setuptools ; extra == 'test'",
          "pywin32 ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'test'",
          "wheel ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'test'",
          "wmi ; (os_name == \"nt\" and implementation_name != \"pypy\") and extra == 'test'"
        ],
        "requires_python": ">=3.6",
        "provides_extra": [
          "dev",
          "test"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/57/54/35a84d0a4d23ea675994104e667ceff49227ce473ba6a59ba2c84f250b74/wrapt-1.17.3-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=1f0b2f40cf341ee8cc1a97d51ff50dddb9fcc73241b9143ec74b30fc4f44f6cb",
          "hashes": {
            "sha256": "1f0b2f40cf341ee8cc1a97d51ff50dddb9fcc73241b9143ec74b30fc4f44f6cb"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "wrapt",
        "version": "1.17.3",
        "dynamic": [
          "license-file"
        ],
        "platform": [
          "any"
        ],
        "summary": "Module for decorators, wrappers and monkey patching.",
        "description": "wrapt\r\n=====\r\n\r\n|PyPI|\r\n\r\nThe aim of the **wrapt** module is to provide a transparent object proxy\r\nfor Python, which can be used as the basis for the construction of function\r\nwrappers and decorator functions.\r\n\r\nThe **wrapt** module focuses very much on correctness. It therefore goes\r\nway beyond existing mechanisms such as ``functools.wraps()`` to ensure that\r\ndecorators preserve introspectability, signatures, type checking abilities\r\netc. The decorators that can be constructed using this module will work in\r\nfar more scenarios than typical decorators and provide more predictable and\r\nconsistent behaviour.\r\n\r\nTo ensure that the overhead is as minimal as possible, a C extension module\r\nis used for performance critical components. An automatic fallback to a\r\npure Python implementation is also provided where a target system does not\r\nhave a compiler to allow the C extension to be compiled.\r\n\r\nDocumentation\r\n-------------\r\n\r\nFor further information on the **wrapt** module see:\r\n\r\n* http://wrapt.readthedocs.org/\r\n\r\nQuick Start\r\n-----------\r\n\r\nTo implement your decorator you need to first define a wrapper function.\r\nThis will be called each time a decorated function is called. The wrapper\r\nfunction needs to take four positional arguments:\r\n\r\n* ``wrapped`` - The wrapped function which in turns needs to be called by your wrapper function.\r\n* ``instance`` - The object to which the wrapped function was bound when it was called.\r\n* ``args`` - The list of positional arguments supplied when the decorated function was called.\r\n* ``kwargs`` - The dictionary of keyword arguments supplied when the decorated function was called.\r\n\r\nThe wrapper function would do whatever it needs to, but would usually in\r\nturn call the wrapped function that is passed in via the ``wrapped``\r\nargument.\r\n\r\nThe decorator ``@wrapt.decorator`` then needs to be applied to the wrapper\r\nfunction to convert it into a decorator which can in turn be applied to\r\nother functions.\r\n\r\n.. code-block:: python\r\n\r\n    import wrapt\r\n    \r\n    @wrapt.decorator\r\n    def pass_through(wrapped, instance, args, kwargs):\r\n        return wrapped(*args, **kwargs)\r\n\r\n    @pass_through\r\n    def function():\r\n        pass\r\n\r\nIf you wish to implement a decorator which accepts arguments, then wrap the\r\ndefinition of the decorator in a function closure. Any arguments supplied\r\nto the outer function when the decorator is applied, will be available to\r\nthe inner wrapper when the wrapped function is called.\r\n\r\n.. code-block:: python\r\n\r\n    import wrapt\r\n\r\n    def with_arguments(myarg1, myarg2):\r\n        @wrapt.decorator\r\n        def wrapper(wrapped, instance, args, kwargs):\r\n            return wrapped(*args, **kwargs)\r\n        return wrapper\r\n\r\n    @with_arguments(1, 2)\r\n    def function():\r\n        pass\r\n\r\nWhen applied to a normal function or static method, the wrapper function\r\nwhen called will be passed ``None`` as the ``instance`` argument.\r\n\r\nWhen applied to an instance method, the wrapper function when called will\r\nbe passed the instance of the class the method is being called on as the\r\n``instance`` argument. This will be the case even when the instance method\r\nwas called explicitly via the class and the instance passed as the first\r\nargument. That is, the instance will never be passed as part of ``args``.\r\n\r\nWhen applied to a class method, the wrapper function when called will be\r\npassed the class type as the ``instance`` argument.\r\n\r\nWhen applied to a class, the wrapper function when called will be passed\r\n``None`` as the ``instance`` argument. The ``wrapped`` argument in this\r\ncase will be the class.\r\n\r\nThe above rules can be summarised with the following example.\r\n\r\n.. code-block:: python\r\n\r\n    import inspect\r\n    \r\n    @wrapt.decorator\r\n    def universal(wrapped, instance, args, kwargs):\r\n        if instance is None:\r\n            if inspect.isclass(wrapped):\r\n                # Decorator was applied to a class.\r\n                return wrapped(*args, **kwargs)\r\n            else:\r\n                # Decorator was applied to a function or staticmethod.\r\n                return wrapped(*args, **kwargs)\r\n        else:\r\n            if inspect.isclass(instance):\r\n                # Decorator was applied to a classmethod.\r\n                return wrapped(*args, **kwargs)\r\n            else:\r\n                # Decorator was applied to an instancemethod.\r\n                return wrapped(*args, **kwargs)\r\n\r\nUsing these checks it is therefore possible to create a universal decorator\r\nthat can be applied in all situations. It is no longer necessary to create\r\ndifferent variants of decorators for normal functions and instance methods,\r\nor use additional wrappers to convert a function decorator into one that\r\nwill work for instance methods.\r\n\r\nIn all cases, the wrapped function passed to the wrapper function is called\r\nin the same way, with ``args`` and ``kwargs`` being passed. The\r\n``instance`` argument doesn't need to be used in calling the wrapped\r\nfunction.\r\n\r\nRepository\r\n----------\r\n\r\nFull source code for the **wrapt** module, including documentation files\r\nand unit tests, can be obtained from github.\r\n\r\n* https://github.com/GrahamDumpleton/wrapt\r\n\r\n.. |PyPI| image:: https://img.shields.io/pypi/v/wrapt.svg?logo=python&cacheSeconds=3600\r\n   :target: https://pypi.python.org/pypi/wrapt\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "wrapper",
          "proxy",
          "decorator"
        ],
        "home_page": "https://github.com/GrahamDumpleton/wrapt",
        "author": "Graham Dumpleton",
        "author_email": "Graham.Dumpleton@gmail.com",
        "license": "BSD",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Bug Tracker, https://github.com/GrahamDumpleton/wrapt/issues/",
          "Changelog, https://wrapt.readthedocs.io/en/latest/changes.html",
          "Documentation, https://wrapt.readthedocs.io/"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/09/44/cbb68c55505a604de61caa44375be7371368e71aa8386b1576be5b789e11/azure_monitor_events_extension-0.1.0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5d92abb5e6a32ab23b12c726def9f9607c6fa1d84900d493b906ff9ec489af4a",
          "hashes": {
            "sha256": "5d92abb5e6a32ab23b12c726def9f9607c6fa1d84900d493b906ff9ec489af4a"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.1",
        "name": "azure-monitor-events-extension",
        "version": "0.1.0",
        "summary": "Microsoft Azure Monitor Events Extension for Python",
        "description": "# Azure Monitor Events Extension\r\n\r\nThe Azure Monitor Events Extension allows users to send custom events to Application Insights in conjunction with the [Azure Monitor OpenTelemetry Distro](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python).\r\nThis distro automatically installs the following libraries:\r\n\r\n### Additional documentation\r\n\r\n* [Azure Portal][https://portal.azure.com]\r\n* [Official Azure monitor docs][https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable?tabs=python]\r\n* [OpenTelemetry Python Official Docs][https://opentelemetry.io/docs/instrumentation/python/]\r\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/microsoft/ApplicationInsights-Python/tree/main/azure-monitor-events-extension",
        "author": "Microsoft Corporation",
        "author_email": "ascl@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "opentelemetry-api ~=1.20",
          "opentelemetry-sdk ~=1.20"
        ],
        "requires_python": ">=3.7"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/14/1b/a298b06749107c305e1fe0f814c6c74aea7b2f1e10989cb30f544a1b3253/python_dotenv-1.2.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b81ee9561e9ca4004139c6cbba3a238c32b03e4894671e181b671e8cb8425d61",
          "hashes": {
            "sha256": "b81ee9561e9ca4004139c6cbba3a238c32b03e4894671e181b671e8cb8425d61"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "python-dotenv",
        "version": "1.2.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "Read key-value pairs from a .env file and set them as environment variables",
        "description": "# python-dotenv\n\n[![Build Status][build_status_badge]][build_status_link]\n[![PyPI version][pypi_badge]][pypi_link]\n\npython-dotenv reads key-value pairs from a `.env` file and can set them as environment\nvariables. It helps in the development of applications following the\n[12-factor](https://12factor.net/) principles.\n\n- [Getting Started](#getting-started)\n- [Other Use Cases](#other-use-cases)\n  * [Load configuration without altering the environment](#load-configuration-without-altering-the-environment)\n  * [Parse configuration as a stream](#parse-configuration-as-a-stream)\n  * [Load .env files in IPython](#load-env-files-in-ipython)\n- [Command-line Interface](#command-line-interface)\n- [File format](#file-format)\n  * [Multiline values](#multiline-values)\n  * [Variable expansion](#variable-expansion)\n- [Related Projects](#related-projects)\n- [Acknowledgements](#acknowledgements)\n\n## Getting Started\n\n```shell\npip install python-dotenv\n```\n\nIf your application takes its configuration from environment variables, like a 12-factor\napplication, launching it in development is not very practical because you have to set\nthose environment variables yourself.\n\nTo help you with that, you can add python-dotenv to your application to make it load the\nconfiguration from a `.env` file when it is present (e.g. in development) while remaining\nconfigurable via the environment:\n\n```python\nfrom dotenv import load_dotenv\n\nload_dotenv()  # reads variables from a .env file and sets them in os.environ\n\n# Code of your application, which uses environment variables (e.g. from `os.environ` or\n# `os.getenv`) as if they came from the actual environment.\n```\n\nBy default, `load_dotenv()` will:\n\n- Look for a `.env` file in the same directory as the Python script (or higher up the directory tree).\n- Read each key-value pair and add it to `os.environ`.\n- **Not override** an environment variable that is already set, unless you explicitly pass `override=True`.\n\nTo configure the development environment, add a `.env` in the root directory of your\nproject:\n\n```\n.\nâ”œâ”€â”€ .env\nâ””â”€â”€ foo.py\n```\n\nThe syntax of `.env` files supported by python-dotenv is similar to that of Bash:\n\n```bash\n# Development settings\nDOMAIN=example.org\nADMIN_EMAIL=admin@${DOMAIN}\nROOT_URL=${DOMAIN}/app\n```\n\nIf you use variables in values, ensure they are surrounded with `{` and `}`, like\n`${DOMAIN}`, as bare variables such as `$DOMAIN` are not expanded.\n\nYou will probably want to add `.env` to your `.gitignore`, especially if it contains\nsecrets like a password.\n\nSee the section \"File format\" below for more information about what you can write in a\n`.env` file.\n\n## Other Use Cases\n\n### Load configuration without altering the environment\n\nThe function `dotenv_values` works more or less the same way as `load_dotenv`, except it\ndoesn't touch the environment, it just returns a `dict` with the values parsed from the\n`.env` file.\n\n```python\nfrom dotenv import dotenv_values\n\nconfig = dotenv_values(\".env\")  # config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n```\n\nThis notably enables advanced configuration management:\n\n```python\nimport os\nfrom dotenv import dotenv_values\n\nconfig = {\n    **dotenv_values(\".env.shared\"),  # load shared development variables\n    **dotenv_values(\".env.secret\"),  # load sensitive variables\n    **os.environ,  # override loaded values with environment variables\n}\n```\n\n### Parse configuration as a stream\n\n`load_dotenv` and `dotenv_values` accept [streams][python_streams] via their `stream`\nargument.  It is thus possible to load the variables from sources other than the\nfilesystem (e.g. the network).\n\n```python\nfrom io import StringIO\n\nfrom dotenv import load_dotenv\n\nconfig = StringIO(\"USER=foo\\nEMAIL=foo@example.org\")\nload_dotenv(stream=config)\n```\n\n### Load .env files in IPython\n\nYou can use dotenv in IPython.  By default, it will use `find_dotenv` to search for a\n`.env` file:\n\n```python\n%load_ext dotenv\n%dotenv\n```\n\nYou can also specify a path:\n\n```python\n%dotenv relative/or/absolute/path/to/.env\n```\n\nOptional flags:\n\n- `-o` to override existing variables.\n- `-v` for increased verbosity.\n\n### Disable load_dotenv\n\nSet `PYTHON_DOTENV_DISABLED=1` to disable `load_dotenv()` from loading .env files or streams. Useful when you can't modify third-party package calls or in production.\n\n## Command-line Interface\n\nA CLI interface `dotenv` is also included, which helps you manipulate the `.env` file\nwithout manually opening it.\n\n```shell\n$ pip install \"python-dotenv[cli]\"\n$ dotenv set USER foo\n$ dotenv set EMAIL foo@example.org\n$ dotenv list\nUSER=foo\nEMAIL=foo@example.org\n$ dotenv list --format=json\n{\n  \"USER\": \"foo\",\n  \"EMAIL\": \"foo@example.org\"\n}\n$ dotenv run -- python foo.py\n```\n\nRun `dotenv --help` for more information about the options and subcommands.\n\n## File format\n\nThe format is not formally specified and still improves over time.  That being said,\n`.env` files should mostly look like Bash files.\n\nKeys can be unquoted or single-quoted. Values can be unquoted, single- or double-quoted.\nSpaces before and after keys, equal signs, and values are ignored. Values can be followed\nby a comment.  Lines can start with the `export` directive, which does not affect their\ninterpretation.\n\nAllowed escape sequences:\n\n- in single-quoted values: `\\\\`, `\\'`\n- in double-quoted values: `\\\\`, `\\'`, `\\\"`, `\\a`, `\\b`, `\\f`, `\\n`, `\\r`, `\\t`, `\\v`\n\n### Multiline values\n\nIt is possible for single- or double-quoted values to span multiple lines.  The following\nexamples are equivalent:\n\n```bash\nFOO=\"first line\nsecond line\"\n```\n\n```bash\nFOO=\"first line\\nsecond line\"\n```\n\n### Variable without a value\n\nA variable can have no value:\n\n```bash\nFOO\n```\n\nIt results in `dotenv_values` associating that variable name with the value `None` (e.g.\n`{\"FOO\": None}`. `load_dotenv`, on the other hand, simply ignores such variables.\n\nThis shouldn't be confused with `FOO=`, in which case the variable is associated with the\nempty string.\n\n### Variable expansion\n\npython-dotenv can interpolate variables using POSIX variable expansion.\n\nWith `load_dotenv(override=True)` or `dotenv_values()`, the value of a variable is the\nfirst of the values defined in the following list:\n\n- Value of that variable in the `.env` file.\n- Value of that variable in the environment.\n- Default value, if provided.\n- Empty string.\n\nWith `load_dotenv(override=False)`, the value of a variable is the first of the values\ndefined in the following list:\n\n- Value of that variable in the environment.\n- Value of that variable in the `.env` file.\n- Default value, if provided.\n- Empty string.\n\n## Related Projects\n\n-   [Honcho](https://github.com/nickstenning/honcho) - For managing\n    Procfile-based applications.\n-   [django-dotenv](https://github.com/jpadilla/django-dotenv)\n-   [django-environ](https://github.com/joke2k/django-environ)\n-   [django-environ-2](https://github.com/sergeyklay/django-environ-2)\n-   [django-configuration](https://github.com/jezdez/django-configurations)\n-   [dump-env](https://github.com/sobolevn/dump-env)\n-   [environs](https://github.com/sloria/environs)\n-   [dynaconf](https://github.com/rochacbruno/dynaconf)\n-   [parse_it](https://github.com/naorlivne/parse_it)\n-   [python-decouple](https://github.com/HBNetwork/python-decouple)\n\n## Acknowledgements\n\nThis project is currently maintained by [Saurabh Kumar](https://saurabh-kumar.com) and\n[Bertrand Bonnefoy-Claudet](https://github.com/bbc2) and would not have been possible\nwithout the support of these [awesome\npeople](https://github.com/theskumar/python-dotenv/graphs/contributors).\n\n[build_status_badge]: https://github.com/theskumar/python-dotenv/actions/workflows/test.yml/badge.svg\n[build_status_link]: https://github.com/theskumar/python-dotenv/actions/workflows/test.yml\n[pypi_badge]: https://badge.fury.io/py/python-dotenv.svg\n[pypi_link]: https://badge.fury.io/py/python-dotenv\n[python_streams]: https://docs.python.org/3/library/io.html\n\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/), and this\nproject adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [1.2.1] - 2025-10-26\n\n- Move more config to `pyproject.toml`, removed `setup.cfg`\n- Add support for reading `.env` from FIFOs (Unix) by [@sidharth-sudhir] in [#586]\n\n## [1.2.0] - 2025-10-26\n\n- Upgrade build system to use PEP 517 & PEP 518 to use `build` and `pyproject.toml` by [@EpicWink] in [#583]\n- Add support for Python 3.14 by [@23f3001135] in [#579](https://github.com/theskumar/python-dotenv/pull/563)\n- Add support for disabling of `load_dotenv()` using `PYTHON_DOTENV_DISABLED` env var. by [@matthewfranglen] in [#569]\n\n## [1.1.1] - 2025-06-24\n\n### Fixed\n\n* CLI: Ensure `find_dotenv` work reliably on python 3.13 by [@theskumar] in [#563](https://github.com/theskumar/python-dotenv/pull/563)\n* CLI: revert the use of execvpe on Windows by [@wrongontheinternet] in [#566](https://github.com/theskumar/python-dotenv/pull/566)\n\n\n## [1.1.0] - 2025-03-25\n\n**Feature**\n\n- Add support for python 3.13\n- Enhance `dotenv run`, switch to `execvpe` for better resource management and signal handling ([#523]) by [@eekstunt]\n\n**Fixed**\n\n- `find_dotenv` and `load_dotenv` now correctly looks up at the current directory when running in debugger or pdb ([#553] by [@randomseed42])\n\n**Misc**\n\n- Drop support for Python 3.8\n\n## [1.0.1] - 2024-01-23\n\n**Fixed**\n\n* Gracefully handle code which has been imported from a zipfile ([#456] by [@samwyma])\n* Allow modules using `load_dotenv` to be reloaded when launched in a separate thread ([#497] by [@freddyaboulton])\n* Fix file not closed after deletion, handle error in the rewrite function ([#469] by [@Qwerty-133])\n\n**Misc**\n* Use pathlib.Path in tests ([#466] by [@eumiro])\n* Fix year in release date in changelog.md ([#454] by [@jankislinger])\n* Use https in README links ([#474] by [@Nicals])\n\n## [1.0.0] - 2023-02-24\n\n**Fixed**\n\n* Drop support for python 3.7, add python 3.12-dev (#449 by [@theskumar])\n* Handle situations where the cwd does not exist. (#446 by [@jctanner])\n\n## [0.21.1] - 2023-01-21\n\n**Added**\n\n* Use Python 3.11 non-beta in CI (#438 by [@bbc2])\n* Modernize variables code (#434 by [@Nougat-Waffle])\n* Modernize main.py and parser.py code (#435 by [@Nougat-Waffle])\n* Improve conciseness of cli.py and __init__.py (#439 by [@Nougat-Waffle])\n* Improve error message for `get` and `list` commands when env file can't be opened (#441 by [@bbc2])\n* Updated License to align with BSD OSI template (#433 by [@lsmith77])\n\n\n**Fixed**\n\n* Fix Out-of-scope error when \"dest\" variable is undefined (#413 by [@theGOTOguy])\n* Fix IPython test warning about deprecated `magic` (#440 by [@bbc2])\n* Fix type hint for dotenv_path var, add StrPath alias (#432 by [@eaf])\n\n## [0.21.0] - 2022-09-03\n\n**Added**\n\n* CLI: add support for invocations via 'python -m'. (#395 by [@theskumar])\n* `load_dotenv` function now returns `False`. (#388 by [@larsks])\n* CLI: add --format= option to list command. (#407 by [@sammck])\n\n**Fixed**\n\n* Drop Python 3.5 and 3.6 and upgrade GA (#393 by [@eggplants])\n* Use `open` instead of `io.open`. (#389 by [@rabinadk1])\n* Improve documentation for variables without a value (#390 by [@bbc2])\n* Add `parse_it` to Related Projects (#410 by [@naorlivne])\n* Update README.md (#415 by [@harveer07])\n* Improve documentation with direct use of MkDocs (#398 by [@bbc2])\n\n## [0.20.0] - 2022-03-24\n\n**Added**\n\n- Add `encoding` (`Optional[str]`) parameter to `get_key`, `set_key` and `unset_key`.\n  (#379 by [@bbc2])\n\n**Fixed**\n\n- Use dict to specify the `entry_points` parameter of `setuptools.setup` (#376 by\n  [@mgorny]).\n- Don't build universal wheels (#387 by [@bbc2]).\n\n## [0.19.2] - 2021-11-11\n\n**Fixed**\n\n- In `set_key`, add missing newline character before new entry if necessary. (#361 by\n  [@bbc2])\n\n## [0.19.1] - 2021-08-09\n\n**Added**\n\n- Add support for Python 3.10. (#359 by [@theskumar])\n\n## [0.19.0] - 2021-07-24\n\n**Changed**\n\n- Require Python 3.5 or a later version.  Python 2 and 3.4 are no longer supported. (#341\n  by [@bbc2]).\n\n**Added**\n\n- The `dotenv_path` argument of `set_key` and `unset_key` now has a type of `Union[str,\n  os.PathLike]` instead of just `os.PathLike` (#347 by [@bbc2]).\n- The `stream` argument of `load_dotenv` and `dotenv_values` can now be a text stream\n  (`IO[str]`), which includes values like `io.StringIO(\"foo\")` and `open(\"file.env\",\n  \"r\")` (#348 by [@bbc2]).\n\n## [0.18.0] - 2021-06-20\n\n**Changed**\n\n- Raise `ValueError` if `quote_mode` isn't one of `always`, `auto` or `never` in\n  `set_key` (#330 by [@bbc2]).\n- When writing a value to a .env file with `set_key` or `dotenv set <key> <value>` (#330\n  by [@bbc2]):\n  - Use single quotes instead of double quotes.\n  - Don't strip surrounding quotes.\n  - In `auto` mode, don't add quotes if the value is only made of alphanumeric characters\n    (as determined by `string.isalnum`).\n\n## [0.17.1] - 2021-04-29\n\n**Fixed**\n\n- Fixed tests for build environments relying on `PYTHONPATH` (#318 by [@befeleme]).\n\n## [0.17.0] - 2021-04-02\n\n**Changed**\n\n- Make `dotenv get <key>` only show the value, not `key=value` (#313 by [@bbc2]).\n\n**Added**\n\n- Add `--override`/`--no-override` option to `dotenv run` (#312 by [@zueve] and [@bbc2]).\n\n## [0.16.0] - 2021-03-27\n\n**Changed**\n\n- The default value of the `encoding` parameter for `load_dotenv` and `dotenv_values` is\n  now `\"utf-8\"` instead of `None` (#306 by [@bbc2]).\n- Fix resolution order in variable expansion with `override=False` (#287 by [@bbc2]).\n\n## [0.15.0] - 2020-10-28\n\n**Added**\n\n- Add `--export` option to `set` to make it prepend the binding with `export` (#270 by\n  [@jadutter]).\n\n**Changed**\n\n- Make `set` command create the `.env` file in the current directory if no `.env` file was\n  found (#270 by [@jadutter]).\n\n**Fixed**\n\n- Fix potentially empty expanded value for duplicate key (#260 by [@bbc2]).\n- Fix import error on Python 3.5.0 and 3.5.1 (#267 by [@gongqingkui]).\n- Fix parsing of unquoted values containing several adjacent space or tab characters\n  (#277 by [@bbc2], review by [@x-yuri]).\n\n## [0.14.0] - 2020-07-03\n\n**Changed**\n\n- Privilege definition in file over the environment in variable expansion (#256 by\n  [@elbehery95]).\n\n**Fixed**\n\n- Improve error message for when file isn't found (#245 by [@snobu]).\n- Use HTTPS URL in package meta data (#251 by [@ekohl]).\n\n## [0.13.0] - 2020-04-16\n\n**Added**\n\n- Add support for a Bash-like default value in variable expansion (#248 by [@bbc2]).\n\n## [0.12.0] - 2020-02-28\n\n**Changed**\n\n- Use current working directory to find `.env` when bundled by PyInstaller (#213 by\n  [@gergelyk]).\n\n**Fixed**\n\n- Fix escaping of quoted values written by `set_key` (#236 by [@bbc2]).\n- Fix `dotenv run` crashing on environment variables without values (#237 by [@yannham]).\n- Remove warning when last line is empty (#238 by [@bbc2]).\n\n## [0.11.0] - 2020-02-07\n\n**Added**\n\n- Add `interpolate` argument to `load_dotenv` and `dotenv_values` to disable interpolation\n  (#232 by [@ulyssessouza]).\n\n**Changed**\n\n- Use logging instead of warnings (#231 by [@bbc2]).\n\n**Fixed**\n\n- Fix installation in non-UTF-8 environments (#225 by [@altendky]).\n- Fix PyPI classifiers (#228 by [@bbc2]).\n\n## [0.10.5] - 2020-01-19\n\n**Fixed**\n\n- Fix handling of malformed lines and lines without a value (#222 by [@bbc2]):\n  - Don't print warning when key has no value.\n  - Reject more malformed lines (e.g. \"A: B\", \"a='b',c\").\n- Fix handling of lines with just a comment (#224 by [@bbc2]).\n\n## [0.10.4] - 2020-01-17\n\n**Added**\n\n- Make typing optional (#179 by [@techalchemy]).\n- Print a warning on malformed line (#211 by [@bbc2]).\n- Support keys without a value (#220 by [@ulyssessouza]).\n\n## 0.10.3\n\n- Improve interactive mode detection ([@andrewsmith])([#183]).\n- Refactor parser to fix parsing inconsistencies ([@bbc2])([#170]).\n  - Interpret escapes as control characters only in double-quoted strings.\n  - Interpret `#` as start of comment only if preceded by whitespace.\n\n## 0.10.2\n\n- Add type hints and expose them to users ([@qnighy])([#172])\n- `load_dotenv` and `dotenv_values` now accept an `encoding` parameter, defaults to `None`\n  ([@theskumar])([@earlbread])([#161])\n- Fix `str`/`unicode` inconsistency in Python 2: values are always `str` now. ([@bbc2])([#121])\n- Fix Unicode error in Python 2, introduced in 0.10.0. ([@bbc2])([#176])\n\n## 0.10.1\n- Fix parsing of variable without a value ([@asyncee])([@bbc2])([#158])\n\n## 0.10.0\n\n- Add support for UTF-8 in unquoted values ([@bbc2])([#148])\n- Add support for trailing comments ([@bbc2])([#148])\n- Add backslashes support in values ([@bbc2])([#148])\n- Add support for newlines in values ([@bbc2])([#148])\n- Force environment variables to str with Python2 on Windows ([@greyli])\n- Drop Python 3.3 support ([@greyli])\n- Fix stderr/-out/-in redirection ([@venthur])\n\n\n## 0.9.0\n\n- Add `--version` parameter to cli ([@venthur])\n- Enable loading from current directory ([@cjauvin])\n- Add 'dotenv run' command for calling arbitrary shell script with .env ([@venthur])\n\n## 0.8.1\n\n-   Add tests for docs ([@Flimm])\n-   Make 'cli' support optional. Use `pip install python-dotenv[cli]`. ([@theskumar])\n\n## 0.8.0\n\n-   `set_key` and `unset_key` only modified the affected file instead of\n    parsing and re-writing file, this causes comments and other file\n    entact as it is.\n-   Add support for `export` prefix in the line.\n-   Internal refractoring ([@theskumar])\n-   Allow `load_dotenv` and `dotenv_values` to work with `StringIO())` ([@alanjds])([@theskumar])([#78])\n\n## 0.7.1\n\n-   Remove hard dependency on iPython ([@theskumar])\n\n## 0.7.0\n\n-   Add support to override system environment variable via .env.\n    ([@milonimrod](https://github.com/milonimrod))\n    ([\\#63](https://github.com/theskumar/python-dotenv/issues/63))\n-   Disable \".env not found\" warning by default\n    ([@maxkoryukov](https://github.com/maxkoryukov))\n    ([\\#57](https://github.com/theskumar/python-dotenv/issues/57))\n\n## 0.6.5\n\n-   Add support for special characters `\\`.\n    ([@pjona](https://github.com/pjona))\n    ([\\#60](https://github.com/theskumar/python-dotenv/issues/60))\n\n## 0.6.4\n\n-   Fix issue with single quotes ([@Flimm])\n    ([\\#52](https://github.com/theskumar/python-dotenv/issues/52))\n\n## 0.6.3\n\n-   Handle unicode exception in setup.py\n    ([\\#46](https://github.com/theskumar/python-dotenv/issues/46))\n\n## 0.6.2\n\n-   Fix dotenv list command ([@ticosax](https://github.com/ticosax))\n-   Add iPython Support\n    ([@tillahoffmann](https://github.com/tillahoffmann))\n\n## 0.6.0\n\n-   Drop support for Python 2.6\n-   Handle escaped characters and newlines in quoted values. (Thanks\n    [@iameugenejo](https://github.com/iameugenejo))\n-   Remove any spaces around unquoted key/value. (Thanks\n    [@paulochf](https://github.com/paulochf))\n-   Added POSIX variable expansion. (Thanks\n    [@hugochinchilla](https://github.com/hugochinchilla))\n\n## 0.5.1\n\n-   Fix `find_dotenv` - it now start search from the file where this\n    function is called from.\n\n## 0.5.0\n\n-   Add `find_dotenv` method that will try to find a `.env` file.\n    (Thanks [@isms](https://github.com/isms))\n\n## 0.4.0\n\n-   cli: Added `-q/--quote` option to control the behaviour of quotes\n    around values in `.env`. (Thanks\n    [@hugochinchilla](https://github.com/hugochinchilla)).\n-   Improved test coverage.\n\n<!-- PR LINKS -->\n[#78]: https://github.com/theskumar/python-dotenv/issues/78\n[#121]: https://github.com/theskumar/python-dotenv/issues/121\n[#148]: https://github.com/theskumar/python-dotenv/issues/148\n[#158]: https://github.com/theskumar/python-dotenv/issues/158\n[#170]: https://github.com/theskumar/python-dotenv/issues/170\n[#172]: https://github.com/theskumar/python-dotenv/issues/172\n[#176]: https://github.com/theskumar/python-dotenv/issues/176\n[#183]: https://github.com/theskumar/python-dotenv/issues/183\n[#359]: https://github.com/theskumar/python-dotenv/issues/359\n[#469]: https://github.com/theskumar/python-dotenv/issues/469\n[#456]: https://github.com/theskumar/python-dotenv/issues/456\n[#466]: https://github.com/theskumar/python-dotenv/issues/466\n[#454]: https://github.com/theskumar/python-dotenv/issues/454\n[#474]: https://github.com/theskumar/python-dotenv/issues/474\n[#523]: https://github.com/theskumar/python-dotenv/issues/523\n[#553]: https://github.com/theskumar/python-dotenv/issues/553\n[#569]: https://github.com/theskumar/python-dotenv/issues/569\n[#583]: https://github.com/theskumar/python-dotenv/issues/583\n[#586]: https://github.com/theskumar/python-dotenv/issues/586\n\n<!-- contributors -->\n[@23f3001135]: https://github.com/23f3001135\n[@EpicWink]: https://github.com/EpicWink\n[@Flimm]: https://github.com/Flimm\n[@Nicals]: https://github.com/Nicals\n[@Nougat-Waffle]: https://github.com/Nougat-Waffle\n[@Qwerty-133]: https://github.com/Qwerty-133\n[@alanjds]: https://github.com/alanjds\n[@altendky]: https://github.com/altendky\n[@andrewsmith]: https://github.com/andrewsmith\n[@asyncee]: https://github.com/asyncee\n[@bbc2]: https://github.com/bbc2\n[@befeleme]: https://github.com/befeleme\n[@cjauvin]: https://github.com/cjauvin\n[@eaf]: https://github.com/eaf\n[@earlbread]: https://github.com/earlbread\n[@eekstunt]: https://github.com/eekstunt\n[@eggplants]: https://github.com/@eggplants\n[@ekohl]: https://github.com/ekohl\n[@elbehery95]: https://github.com/elbehery95\n[@eumiro]: https://github.com/eumiro\n[@freddyaboulton]: https://github.com/freddyaboulton\n[@gergelyk]: https://github.com/gergelyk\n[@gongqingkui]: https://github.com/gongqingkui\n[@greyli]: https://github.com/greyli\n[@harveer07]: https://github.com/@harveer07\n[@jadutter]: https://github.com/jadutter\n[@jankislinger]: https://github.com/jankislinger\n[@jctanner]: https://github.com/jctanner\n[@larsks]: https://github.com/@larsks\n[@lsmith77]: https://github.com/lsmith77\n[@matthewfranglen]: https://github.com/matthewfranglen\n[@mgorny]: https://github.com/mgorny\n[@naorlivne]: https://github.com/@naorlivne\n[@qnighy]: https://github.com/qnighy\n[@rabinadk1]: https://github.com/@rabinadk1\n[@randomseed42]: https://github.com/zueve\n[@sammck]: https://github.com/@sammck\n[@samwyma]: https://github.com/samwyma\n[@sidharth-sudhir]: https://github.com/sidharth-sudhir\n[@snobu]: https://github.com/snobu\n[@techalchemy]: https://github.com/techalchemy\n[@theGOTOguy]: https://github.com/theGOTOguy\n[@theskumar]: https://github.com/theskumar\n[@ulyssessouza]: https://github.com/ulyssessouza\n[@venthur]: https://github.com/venthur\n[@wrongontheinternet]: https://github.com/wrongontheinternet\n[@x-yuri]: https://github.com/x-yuri\n[@yannham]: https://github.com/yannham\n[@zueve]: https://github.com/zueve\n\n[Unreleased]: https://github.com/theskumar/python-dotenv/compare/v1.2.0...HEAD\n[1.2.0]: https://github.com/theskumar/python-dotenv/compare/v1.1.1...v1.2.0\n[1.1.1]: https://github.com/theskumar/python-dotenv/compare/v1.1.0...v1.1.1\n[1.1.0]: https://github.com/theskumar/python-dotenv/compare/v1.0.1...v1.1.0\n[1.0.1]: https://github.com/theskumar/python-dotenv/compare/v1.0.0...v1.0.1\n[1.0.0]: https://github.com/theskumar/python-dotenv/compare/v0.21.0...v1.0.0\n[0.21.1]: https://github.com/theskumar/python-dotenv/compare/v0.21.0...v0.21.1\n[0.21.0]: https://github.com/theskumar/python-dotenv/compare/v0.20.0...v0.21.0\n[0.20.0]: https://github.com/theskumar/python-dotenv/compare/v0.19.2...v0.20.0\n[0.19.2]: https://github.com/theskumar/python-dotenv/compare/v0.19.1...v0.19.2\n[0.19.1]: https://github.com/theskumar/python-dotenv/compare/v0.19.0...v0.19.1\n[0.19.0]: https://github.com/theskumar/python-dotenv/compare/v0.18.0...v0.19.0\n[0.18.0]: https://github.com/theskumar/python-dotenv/compare/v0.17.1...v0.18.0\n[0.17.1]: https://github.com/theskumar/python-dotenv/compare/v0.17.0...v0.17.1\n[0.17.0]: https://github.com/theskumar/python-dotenv/compare/v0.16.0...v0.17.0\n[0.16.0]: https://github.com/theskumar/python-dotenv/compare/v0.15.0...v0.16.0\n[0.15.0]: https://github.com/theskumar/python-dotenv/compare/v0.14.0...v0.15.0\n[0.14.0]: https://github.com/theskumar/python-dotenv/compare/v0.13.0...v0.14.0\n[0.13.0]: https://github.com/theskumar/python-dotenv/compare/v0.12.0...v0.13.0\n[0.12.0]: https://github.com/theskumar/python-dotenv/compare/v0.11.0...v0.12.0\n[0.11.0]: https://github.com/theskumar/python-dotenv/compare/v0.10.5...v0.11.0\n[0.10.5]: https://github.com/theskumar/python-dotenv/compare/v0.10.4...v0.10.5\n[0.10.4]: https://github.com/theskumar/python-dotenv/compare/v0.10.3...v0.10.4\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "environment variables",
          "deployments",
          "settings",
          "env",
          "dotenv",
          "configurations",
          "python"
        ],
        "author_email": "Saurabh Kumar <me+github@saurabh-kumar.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "Operating System :: OS Independent",
          "Topic :: System :: Systems Administration",
          "Topic :: Utilities",
          "Environment :: Web Environment"
        ],
        "requires_dist": [
          "click>=5.0; extra == \"cli\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source, https://github.com/theskumar/python-dotenv"
        ],
        "provides_extra": [
          "cli"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/1b/d0/397f9626e711ff749a95d96b7af99b9c566a9bb5129b8e4c10fc4d100304/python_multipart-0.0.22-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=2b2cd894c83d21bf49d702499531c7bafd057d730c201782048f7945d82de155",
          "hashes": {
            "sha256": "2b2cd894c83d21bf49d702499531c7bafd057d730c201782048f7945d82de155"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "python-multipart",
        "version": "0.0.22",
        "summary": "A streaming multipart parser for Python",
        "description": "# [Python-Multipart](https://kludex.github.io/python-multipart/)\n\n[![Package version](https://badge.fury.io/py/python-multipart.svg)](https://pypi.python.org/pypi/python-multipart)\n[![Supported Python Version](https://img.shields.io/pypi/pyversions/python-multipart.svg?color=%2334D058)](https://pypi.org/project/python-multipart)\n\n---\n\n`python-multipart` is an Apache2-licensed streaming multipart parser for Python.\nTest coverage is currently 100%.\n\n## Why?\n\nBecause streaming uploads are awesome for large files.\n",
        "description_content_type": "text/markdown",
        "author_email": "Andrew Dunham <andrew@du.nham.ca>, Marcelo Trylesinski <marcelotryle@gmail.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/Kludex/python-multipart",
          "Documentation, https://kludex.github.io/python-multipart/",
          "Changelog, https://github.com/Kludex/python-multipart/blob/master/CHANGELOG.md",
          "Source, https://github.com/Kludex/python-multipart"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/81/a3/cc9b66575bd6597b98b886a2067eea2693408d2d5f39dad9ab7fc264f5f3/opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=fa1c136a05c7e9b4c09f739469cbdb927ea20b34088ab1d959a849b5cc589c18",
          "hashes": {
            "sha256": "fa1c136a05c7e9b4c09f739469cbdb927ea20b34088ab1d959a849b5cc589c18"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-exporter-otlp-proto-grpc",
        "version": "1.39.1",
        "summary": "OpenTelemetry Collector Protobuf over gRPC Exporter",
        "description": "OpenTelemetry Collector Protobuf over gRPC Exporter\n===================================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-exporter-otlp-proto-grpc.svg\n   :target: https://pypi.org/project/opentelemetry-exporter-otlp-proto-grpc/\n\nThis library allows to export data to the OpenTelemetry Collector using the OpenTelemetry Protocol using Protobuf over gRPC.\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-exporter-otlp-proto-grpc\n\n\nReferences\n----------\n\n* `OpenTelemetry Collector Exporter <https://opentelemetry-python.readthedocs.io/en/latest/exporter/otlp/otlp.html>`_\n* `OpenTelemetry Collector <https://github.com/open-telemetry/opentelemetry-collector/>`_\n* `OpenTelemetry <https://opentelemetry.io/>`_\n* `OpenTelemetry Protocol Specification <https://github.com/open-telemetry/oteps/blob/main/text/0035-opentelemetry-protocol.md>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Framework :: OpenTelemetry :: Exporters",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "googleapis-common-protos~=1.57",
          "grpcio<2.0.0,>=1.63.2; python_version < '3.13'",
          "grpcio<2.0.0,>=1.66.2; python_version >= '3.13'",
          "opentelemetry-api~=1.15",
          "opentelemetry-exporter-otlp-proto-common==1.39.1",
          "opentelemetry-proto==1.39.1",
          "opentelemetry-sdk~=1.39.1",
          "typing-extensions>=4.6.0",
          "opentelemetry-exporter-credential-provider-gcp>=0.59b0; extra == 'gcp-auth'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/exporter/opentelemetry-exporter-otlp-proto-grpc",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ],
        "provides_extra": [
          "gcp-auth"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/8c/02/ffc3e143d89a27ac21fd557365b98bd0653b98de8a101151d5805b5d4c33/opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=08f8a5862d64cc3435105686d0216c1365dc5701f86844a8cd56597d0c764fde",
          "hashes": {
            "sha256": "08f8a5862d64cc3435105686d0216c1365dc5701f86844a8cd56597d0c764fde"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-exporter-otlp-proto-common",
        "version": "1.39.1",
        "summary": "OpenTelemetry Protobuf encoding",
        "description": "OpenTelemetry Protobuf Encoding\n===============================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-exporter-otlp-proto-common.svg\n   :target: https://pypi.org/project/opentelemetry-exporter-otlp-proto-common/\n\nThis library is provided as a convenience to encode to Protobuf. Currently used by:\n\n* opentelemetry-exporter-otlp-proto-grpc\n* opentelemetry-exporter-otlp-proto-http\n\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-exporter-otlp-proto-common\n\n\nReferences\n----------\n\n* `OpenTelemetry <https://opentelemetry.io/>`_\n* `OpenTelemetry Protocol Specification <https://github.com/open-telemetry/oteps/blob/main/text/0035-opentelemetry-protocol.md>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Framework :: OpenTelemetry :: Exporters",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "opentelemetry-proto==1.39.1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/exporter/opentelemetry-exporter-otlp-proto-common",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/51/95/b40c96a7b5203005a0b03d8ce8cd212ff23f1793d5ba289c87a097571b18/opentelemetry_proto-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=22cdc78efd3b3765d09e68bfbd010d4fc254c9818afd0b6b423387d9dee46007",
          "hashes": {
            "sha256": "22cdc78efd3b3765d09e68bfbd010d4fc254c9818afd0b6b423387d9dee46007"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-proto",
        "version": "1.39.1",
        "summary": "OpenTelemetry Python Proto",
        "description": "OpenTelemetry Python Proto\n==========================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-proto.svg\n   :target: https://pypi.org/project/opentelemetry-proto/\n\nThis library contains the generated code for OpenTelemetry protobuf data model. The code in the current\npackage was generated using the v1.7.0 release_ of opentelemetry-proto.\n\n.. _release: https://github.com/open-telemetry/opentelemetry-proto/releases/tag/v1.7.0\n\nInstallation\n------------\n\n::\n\n    pip install opentelemetry-proto\n\nCode Generation\n---------------\n\nThese files were generated automatically from code in opentelemetry-proto_.\nTo regenerate the code, run ``../scripts/proto_codegen.sh``.\n\nTo build against a new release or specific commit of opentelemetry-proto_,\nupdate the ``PROTO_REPO_BRANCH_OR_COMMIT`` variable in\n``../scripts/proto_codegen.sh``. Then run the script and commit the changes\nas well as any fixes needed in the OTLP exporter.\n\n.. _opentelemetry-proto: https://github.com/open-telemetry/opentelemetry-proto\n\n\nReferences\n----------\n\n* `OpenTelemetry Project <https://opentelemetry.io/>`_\n* `OpenTelemetry Proto <https://github.com/open-telemetry/opentelemetry-proto>`_\n* `proto_codegen.sh script <https://github.com/open-telemetry/opentelemetry-python/blob/main/scripts/proto_codegen.sh>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "protobuf<7.0,>=5.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/opentelemetry-proto",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c4/ab/09169d5a4612a5f92490806649ac8d41e3ec9129c636754575b3553f4ea4/googleapis_common_protos-1.72.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4299c5a82d5ae1a9702ada957347726b167f9f8d1fc352477702a1e851ff4038",
          "hashes": {
            "sha256": "4299c5a82d5ae1a9702ada957347726b167f9f8d1fc352477702a1e851ff4038"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "googleapis-common-protos",
        "version": "1.72.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Common protobufs used in Google APIs",
        "description": "Python Client for Google APIs Common Protos\n===========================================\n\n|stable| |pypi| |versions|\n\n`Google APIs Common Protos`_: \n\n- `Client Library Documentation`_\n- `Product Documentation`_\n\n.. |stable| image:: https://img.shields.io/badge/support-stable-gold.svg\n   :target: https://github.com/googleapis/google-cloud-python/blob/main/README.rst#stability-levels\n.. |pypi| image:: https://img.shields.io/pypi/v/googleapis-common-protos.svg\n   :target: https://pypi.org/project/googleapis-common-protos/\n.. |versions| image:: https://img.shields.io/pypi/pyversions/googleapis-common-protos.svg\n   :target: https://pypi.org/project/googleapis-common-protos/\n.. _Google APIs Common Protos: https://github.com/googleapis/googleapis/tree/master/google\n.. _Client Library Documentation: https://github.com/googleapis/google-cloud-python/tree/main/packages/googleapis-common-protos/summary_overview\n.. _Product Documentation:  https://github.com/googleapis/googleapis/tree/master/google\n\nQuick Start\n-----------\n\nIn order to use this library, you first need to go through the following steps:\n\n1. `Select or create a Cloud Platform project.`_\n2. `Enable billing for your project.`_\n3. `Enable the Google APIs Common Protos.`_\n4. `Set up Authentication.`_\n\n.. _Select or create a Cloud Platform project.: https://console.cloud.google.com/project\n.. _Enable billing for your project.: https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project\n.. _Enable the Google APIs Common Protos.:  https://github.com/googleapis/googleapis/tree/master/google\n.. _Set up Authentication.: https://googleapis.dev/python/google-api-core/latest/auth.html\n\nInstallation\n~~~~~~~~~~~~\n\nInstall this library in a virtual environment using `venv`_. `venv`_ is a tool that\ncreates isolated Python environments. These isolated environments can have separate\nversions of Python packages, which allows you to isolate one project's dependencies\nfrom the dependencies of other projects.\n\nWith `venv`_, it's possible to install this library without needing system\ninstall permissions, and without clashing with the installed system\ndependencies.\n\n.. _`venv`: https://docs.python.org/3/library/venv.html\n\n\nCode samples and snippets\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCode samples and snippets live in the `samples/`_ folder.\n\n.. _samples/: https://github.com/googleapis/google-cloud-python/tree/main/packages/googleapis-common-protos/samples\n\n\nSupported Python Versions\n^^^^^^^^^^^^^^^^^^^^^^^^^\nOur client libraries are compatible with all current `active`_ and `maintenance`_ versions of\nPython.\n\nPython >= 3.7, including 3.14\n\n.. _active: https://devguide.python.org/devcycle/#in-development-main-branch\n.. _maintenance: https://devguide.python.org/devcycle/#maintenance-branches\n\nUnsupported Python Versions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPython <= 3.6\n\nIf you are using an `end-of-life`_\nversion of Python, we recommend that you update as soon as possible to an actively supported version.\n\n.. _end-of-life: https://devguide.python.org/devcycle/#end-of-life-branches\n\nMac/Linux\n^^^^^^^^^\n\n.. code-block:: console\n\n    python3 -m venv <your-env>\n    source <your-env>/bin/activate\n    pip install googleapis-common-protos\n\n\nWindows\n^^^^^^^\n\n.. code-block:: console\n\n    py -m venv <your-env>\n    .\\<your-env>\\Scripts\\activate\n    pip install googleapis-common-protos\n\nNext Steps\n~~~~~~~~~~\n\n-  Read the `Client Library Documentation`_ for Google APIs Common Protos\n   to see other available methods on the client.\n-  Read the `Google APIs Common Protos Product documentation`_ to learn\n   more about the product and see How-to Guides.\n-  View this `README`_ to see the full list of Cloud\n   APIs that we cover.\n\n.. _Google APIs Common Protos Product documentation:  https://github.com/googleapis/googleapis/tree/master/google\n.. _README: https://github.com/googleapis/google-cloud-python/blob/main/README.rst\n\nLogging\n-------\n\nThis library uses the standard Python :code:`logging` functionality to log some RPC events that could be of interest for debugging and monitoring purposes.\nNote the following:\n\n#. Logs may contain sensitive information. Take care to **restrict access to the logs** if they are saved, whether it be on local storage or on Google Cloud Logging.\n#. Google may refine the occurrence, level, and content of various log messages in this library without flagging such changes as breaking. **Do not depend on immutability of the logging events**.\n#. By default, the logging events from this library are not handled. You must **explicitly configure log handling** using one of the mechanisms below.\n\nSimple, environment-based configuration\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo enable logging for this library without any changes in your code, set the :code:`GOOGLE_SDK_PYTHON_LOGGING_SCOPE` environment variable to a valid Google\nlogging scope. This configures handling of logging events (at level :code:`logging.DEBUG` or higher) from this library in a default manner, emitting the logged\nmessages in a structured format. It does not currently allow customizing the logging levels captured nor the handlers, formatters, etc. used for any logging\nevent.\n\nA logging scope is a period-separated namespace that begins with :code:`google`, identifying the Python module or package to log.\n\n- Valid logging scopes: :code:`google`, :code:`google.cloud.asset.v1`, :code:`google.api`, :code:`google.auth`, etc.\n- Invalid logging scopes: :code:`foo`, :code:`123`, etc.\n\n**NOTE**: If the logging scope is invalid, the library does not set up any logging handlers.\n\nEnvironment-Based Examples\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Enabling the default handler for all Google-based loggers\n\n.. code-block:: console\n\n    export GOOGLE_SDK_PYTHON_LOGGING_SCOPE=google\n\n- Enabling the default handler for a specific Google module (for a client library called :code:`library_v1`):\n\n.. code-block:: console\n\n    export GOOGLE_SDK_PYTHON_LOGGING_SCOPE=google.cloud.library_v1\n\n\nAdvanced, code-based configuration\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can also configure a valid logging scope using Python's standard `logging` mechanism.\n\nCode-Based Examples\n^^^^^^^^^^^^^^^^^^^\n\n- Configuring a handler for all Google-based loggers\n\n.. code-block:: python\n\n    import logging\n    \n    from google.cloud import library_v1\n    \n    base_logger = logging.getLogger(\"google\")\n    base_logger.addHandler(logging.StreamHandler())\n    base_logger.setLevel(logging.DEBUG)\n\n- Configuring a handler for a specific Google module (for a client library called :code:`library_v1`):\n\n.. code-block:: python\n\n    import logging\n    \n    from google.cloud import library_v1\n    \n    base_logger = logging.getLogger(\"google.cloud.library_v1\")\n    base_logger.addHandler(logging.StreamHandler())\n    base_logger.setLevel(logging.DEBUG)\n\nLogging details\n~~~~~~~~~~~~~~~\n\n#. Regardless of which of the mechanisms above you use to configure logging for this library, by default logging events are not propagated up to the root\n   logger from the `google`-level logger. If you need the events to be propagated to the root logger, you must explicitly set\n   :code:`logging.getLogger(\"google\").propagate = True` in your code.\n#. You can mix the different logging configurations above for different Google modules. For example, you may want use a code-based logging configuration for\n   one library, but decide you need to also set up environment-based logging configuration for another library.\n\n   #. If you attempt to use both code-based and environment-based configuration for the same module, the environment-based configuration will be ineffectual\n      if the code -based configuration gets applied first.\n\n#. The Google-specific logging configurations (default handlers for environment-based configuration; not propagating logging events to the root logger) get\n   executed the first time *any* client library is instantiated in your application, and only if the affected loggers have not been previously configured.\n   (This is the reason for 2.i. above.)\n",
        "description_content_type": "text/x-rst",
        "author_email": "Google LLC <googleapis-packages@google.com>",
        "license": "Apache 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Operating System :: OS Independent",
          "Topic :: Internet"
        ],
        "requires_dist": [
          "protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2",
          "grpcio<2.0.0,>=1.44.0; extra == \"grpc\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Repository, https://github.com/googleapis/google-cloud-python/tree/main/packages/googleapis-common-protos"
        ],
        "provides_extra": [
          "grpc"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4d/27/d86b89e36de8a951501fb06a0f38df19853210f341d0b28f83f4aa0ffa08/grpcio-1.78.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=f2d4e43ee362adfc05994ed479334d5a451ab7bc3f3fee1b796b8ca66895acb4",
          "hashes": {
            "sha256": "f2d4e43ee362adfc05994ed479334d5a451ab7bc3f3fee1b796b8ca66895acb4"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "grpcio",
        "version": "1.78.0",
        "dynamic": [
          "classifier",
          "license-file",
          "provides-extra",
          "requires-dist",
          "requires-python"
        ],
        "summary": "HTTP/2-based RPC framework",
        "description": "gRPC Python\r\n===========\r\n\r\nPackage for gRPC Python.\r\n\r\n\r\nInstallation\r\n------------\r\n\r\ngRPC Python is available for Linux, macOS, and Windows.\r\n\r\nInstalling From PyPI\r\n~~~~~~~~~~~~~~~~~~~~\r\n\r\nIf you are installing locally...\r\n\r\n::\r\n\r\n  $ pip install grpcio\r\n\r\nElse system wide (on Ubuntu)...\r\n\r\n::\r\n\r\n  $ sudo pip install grpcio\r\n\r\nIf you're on Windows make sure that you installed the :code:`pip.exe` component\r\nwhen you installed Python (if not go back and install it!) then invoke:\r\n\r\n::\r\n\r\n  $ pip.exe install grpcio\r\n\r\nWindows users may need to invoke :code:`pip.exe` from a command line ran as\r\nadministrator.\r\n\r\nn.b. On Windows and on Mac OS X one *must* have a recent release of :code:`pip`\r\nto retrieve the proper wheel from PyPI. Be sure to upgrade to the latest\r\nversion!\r\n\r\nInstalling From Source\r\n~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nBuilding from source requires that you have the Python headers (usually a\r\npackage named :code:`python-dev`).\r\n\r\n::\r\n\r\n  $ export REPO_ROOT=grpc  # REPO_ROOT can be any directory of your choice\r\n  $ git clone -b RELEASE_TAG_HERE https://github.com/grpc/grpc $REPO_ROOT\r\n  $ cd $REPO_ROOT\r\n  $ git submodule update --init\r\n\r\n  # To include systemd socket-activation feature in the build,\r\n  # first install the `libsystemd-dev` package, then :\r\n  $ export GRPC_PYTHON_BUILD_WITH_SYSTEMD=1\r\n\r\n  # For the next two commands do `sudo pip install` if you get permission-denied errors\r\n  $ pip install -r requirements.txt\r\n  $ GRPC_PYTHON_BUILD_WITH_CYTHON=1 pip install .\r\n\r\nYou cannot currently install Python from source on Windows. Things might work\r\nout for you in MSYS2 (follow the Linux instructions), but it isn't officially\r\nsupported at the moment.\r\n\r\nTroubleshooting\r\n~~~~~~~~~~~~~~~\r\n\r\nHelp, I ...\r\n\r\n* **... see the following error on some platforms**\r\n\r\n  ::\r\n\r\n    /tmp/pip-build-U8pSsr/cython/Cython/Plex/Scanners.c:4:20: fatal error: Python.h: No such file or directory\r\n    #include \"Python.h\"\r\n                    ^\r\n    compilation terminated.\r\n\r\n  You can fix it by installing `python-dev` package. i.e\r\n\r\n  ::\r\n\r\n    sudo apt-get install python-dev\r\n\r\n\r\nVersioning\r\n~~~~~~~~~~\r\n\r\ngRPC Python is developed in a monorepo shared with implementations of gRPC in\r\nother programming languages. While the minor versions are released in\r\nlock-step with other languages in the repo (e.g. 1.63.0 is guaranteed to exist\r\nfor all languages), patch versions may be specific to only a single\r\nlanguage. For example, if 1.63.1 is a C++-specific patch, 1.63.1 may not be\r\nuploaded to PyPi. As a result, it is __not__ a good assumption that the latest\r\npatch for a given minor version on Github is also the latest patch for that\r\nsame minor version on PyPi.\r\n\r\n",
        "description_content_type": "text/x-rst",
        "author_email": "The gRPC Authors <grpc-io@googlegroups.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_dist": [
          "typing-extensions~=4.12",
          "grpcio-tools>=1.78.0; extra == \"protobuf\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://grpc.io",
          "Source Code, https://github.com/grpc/grpc",
          "Bug Tracker, https://github.com/grpc/grpc/issues",
          "Documentation, https://grpc.github.io/grpc/python"
        ],
        "provides_extra": [
          "protobuf"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/55/75/bb9bc917d10e9ee13dee8607eb9ab963b7cf8be607c46e7862c748aa2af7/protobuf-6.33.5-cp310-abi3-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=3093804752167bcab3998bec9f1048baae6e29505adaf1afd14a37bddede533c",
          "hashes": {
            "sha256": "3093804752167bcab3998bec9f1048baae6e29505adaf1afd14a37bddede533c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "protobuf",
        "version": "6.33.5",
        "description": "UNKNOWN\n",
        "home_page": "https://developers.google.com/protocol-buffers/",
        "author": "protobuf@googlegroups.com",
        "author_email": "protobuf@googlegroups.com",
        "license": "3-Clause BSD License",
        "classifier": [
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_python": ">=3.9"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/da/3f/af4f73cd29b9fdf27dac9f0a76c5e037308f7f37ba3af24b2fdadd76cb30/opentelemetry_instrumentation_openai-0.52.3-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=7cd786fc2d6663c0a02bc0b9fdc54e54492107f50436a0bef3a610ecaf55afbc",
          "hashes": {
            "sha256": "7cd786fc2d6663c0a02bc0b9fdc54e54492107f50436a0bef3a610ecaf55afbc"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-instrumentation-openai",
        "version": "0.52.3",
        "summary": "OpenTelemetry OpenAI instrumentation",
        "description": "# OpenTelemetry OpenAI Instrumentation\n\n<a href=\"https://pypi.org/project/opentelemetry-instrumentation-openai/\">\n    <img src=\"https://badge.fury.io/py/opentelemetry-instrumentation-openai.svg\">\n</a>\n\nThis library allows tracing OpenAI prompts and completions sent with the official [OpenAI library](https://github.com/openai/openai-python).\n\n## Installation\n\n```bash\npip install opentelemetry-instrumentation-openai\n```\n\n## Example usage\n\n```python\nfrom opentelemetry.instrumentation.openai import OpenAIInstrumentor\n\nOpenAIInstrumentor().instrument()\n```\n\n## Privacy\n\n**By default, this instrumentation logs prompts, completions, and embeddings to span attributes**. This gives you a clear visibility into how your LLM application is working, and can make it easy to debug and evaluate the quality of the outputs.\n\nHowever, you may want to disable this logging for privacy reasons, as they may contain highly sensitive data from your users. You may also simply want to reduce the size of your traces.\n\nTo disable logging, set the `TRACELOOP_TRACE_CONTENT` environment variable to `false`.\n\n```bash\nTRACELOOP_TRACE_CONTENT=false\n```\n",
        "description_content_type": "text/markdown",
        "author_email": "Gal Kleinman <gal@traceloop.com>, Nir Gazit <nir@traceloop.com>, Tomer Friedman <tomer@traceloop.com>",
        "license_expression": "Apache-2.0",
        "requires_dist": [
          "opentelemetry-api<2,>=1.38.0",
          "opentelemetry-instrumentation>=0.59b0",
          "opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.13",
          "opentelemetry-semantic-conventions>=0.59b0",
          "openai; extra == 'instruments'"
        ],
        "requires_python": "<4,>=3.10",
        "project_url": [
          "Repository, https://github.com/traceloop/openllmetry/tree/main/packages/opentelemetry-instrumentation-openai"
        ],
        "provides_extra": [
          "instruments"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/35/b5/cf25da2218910f0d6cdf7f876a06bed118c4969eacaf60a887cbaef44f44/opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=883a30a6bb5deaec0d646912b5f9f6dcbb9f6f72557b73d0f2560bf25d13e2d5",
          "hashes": {
            "sha256": "883a30a6bb5deaec0d646912b5f9f6dcbb9f6f72557b73d0f2560bf25d13e2d5"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "opentelemetry-semantic-conventions-ai",
        "version": "0.4.13",
        "summary": "OpenTelemetry Semantic Conventions Extension for Large Language Models",
        "description": "# OpenTelemetry Semantic Conventions extensions for gen-AI applications\n\n<a href=\"https://pypi.org/project/opentelemetry-semantic-conventions-ai/\">\n    <img src=\"https://badge.fury.io/py/opentelemetry-semantic-conventions-ai.svg\">\n</a>\n\nThis is an extension of the standard [OpenTelemetry Semantic Conventions](https://github.com/open-telemetry/semantic-conventions) for gen AI applications. It defines additional attributes for spans that are useful for debugging and monitoring prompts, completions, token usage, etc.\n\n",
        "description_content_type": "text/markdown",
        "author": "Gal Kleinman",
        "author_email": "gal@traceloop.com",
        "license": "Apache-2.0",
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_python": ">=3.9,<4"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/95/f1/b27d3e2e003cd9a3592c43d099d2ed8d0a947c15281bf8463a256db0b46c/opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=d9f5207183dd752a412c4cd564ca8875ececba13be6e9c6c370ffb752fd59985",
          "hashes": {
            "sha256": "d9f5207183dd752a412c4cd564ca8875ececba13be6e9c6c370ffb752fd59985"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "opentelemetry-exporter-otlp-proto-http",
        "version": "1.39.1",
        "summary": "OpenTelemetry Collector Protobuf over HTTP Exporter",
        "description": "OpenTelemetry Collector Protobuf over HTTP Exporter\n===================================================\n\n|pypi|\n\n.. |pypi| image:: https://badge.fury.io/py/opentelemetry-exporter-otlp-proto-http.svg\n   :target: https://pypi.org/project/opentelemetry-exporter-otlp-proto-http/\n\nThis library allows to export data to the OpenTelemetry Collector using the OpenTelemetry Protocol using Protobuf over HTTP.\n\nInstallation\n------------\n\n::\n\n     pip install opentelemetry-exporter-otlp-proto-http\n\n\nReferences\n----------\n\n* `OpenTelemetry Collector Exporter <https://opentelemetry-python.readthedocs.io/en/latest/exporter/otlp/otlp.html>`_\n* `OpenTelemetry Collector <https://github.com/open-telemetry/opentelemetry-collector/>`_\n* `OpenTelemetry <https://opentelemetry.io/>`_\n* `OpenTelemetry Protocol Specification <https://github.com/open-telemetry/oteps/blob/main/text/0035-opentelemetry-protocol.md>`_\n",
        "description_content_type": "text/x-rst",
        "author_email": "OpenTelemetry Authors <cncf-opentelemetry-contributors@lists.cncf.io>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: OpenTelemetry",
          "Framework :: OpenTelemetry :: Exporters",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "googleapis-common-protos~=1.52",
          "opentelemetry-api~=1.15",
          "opentelemetry-exporter-otlp-proto-common==1.39.1",
          "opentelemetry-proto==1.39.1",
          "opentelemetry-sdk~=1.39.1",
          "requests~=2.7",
          "typing-extensions>=4.5.0",
          "opentelemetry-exporter-credential-provider-gcp>=0.59b0; extra == 'gcp-auth'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/open-telemetry/opentelemetry-python/tree/main/exporter/opentelemetry-exporter-otlp-proto-http",
          "Repository, https://github.com/open-telemetry/opentelemetry-python"
        ],
        "provides_extra": [
          "gcp-auth"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e5/26/ed4498374f9088818278ac225f2bea688b4ec979d81bf83a5355c8c366af/azure_search_documents-11.7.0b2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f82117b321344a84474269ed26df194c24cca619adc024d981b1b86aee3c6f05",
          "hashes": {
            "sha256": "f82117b321344a84474269ed26df194c24cca619adc024d981b1b86aee3c6f05"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-search-documents",
        "version": "11.7.0b2",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Cognitive Search Client Library for Python",
        "description": "# Azure AI Search client library for Python\n\n[Azure AI Search](https://learn.microsoft.com/azure/search/) (formerly known as \"Azure Cognitive Search\") is an AI-powered information retrieval platform that helps developers build rich search experiences and generative AI apps that combine large language models with enterprise data.\n\nAzure AI Search is well suited for the following application scenarios:\n\n* Consolidate varied content types into a single searchable index.\n  To populate an index, you can push JSON documents that contain your content,\n  or if your data is already in Azure, create an indexer to pull in data\n  automatically.\n* Attach skillsets to an indexer to create searchable content from images\n  and unstructured documents. A skillset leverages APIs from Azure AI Services\n  for built-in OCR, entity recognition, key phrase extraction, language\n  detection, text translation, and sentiment analysis. You can also add\n  custom skills to integrate external processing of your content during\n  data ingestion.\n* In a search client application, implement query logic and user experiences\n  similar to commercial web search engines and chat-style apps.\n\nUse the Azure.Search.Documents client library to:\n\n* Submit queries using vector, keyword, and hybrid query forms.\n* Implement filtered queries for metadata, geospatial search, faceted navigation, \n  or to narrow results based on filter criteria.\n* Create and manage search indexes.\n* Upload and update documents in the search index.\n* Create and manage indexers that pull data from Azure into an index.\n* Create and manage skillsets that add AI enrichment to data ingestion.\n* Create and manage analyzers for advanced text analysis or multi-lingual content.\n* Optimize results through semantic ranking and scoring profiles to factor in business logic or freshness.\n\n[Source code](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents)\n| [Package (PyPI)](https://pypi.org/project/azure-search-documents/)\n| [Package (Conda)](https://anaconda.org/microsoft/azure-search-documents/)\n| [API reference documentation](https://azuresdkdocs.z19.web.core.windows.net/python/azure-search-documents/latest/index.html)\n| [Product documentation](https://learn.microsoft.com/azure/search/search-what-is-azure-search)\n| [Samples](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/samples)\n\n## Getting started\n\n### Install the package\n\nInstall the Azure AI Search client library for Python with [pip](https://pypi.org/project/pip/):\n\n```bash\npip install azure-search-documents\n```\n\n### Prerequisites\n\n* Python 3.8 or later is required to use this package.\n* You need an [Azure subscription][azure_sub] and an\n[Azure AI Search service][search_resource] to use this package.\n\nTo create a new search service, you can use the [Azure portal][create_search_service_docs], [Azure PowerShell][create_search_service_ps], or the [Azure CLI][create_search_service_cli].\n\n```Powershell\naz search service create --name <mysearch> --resource-group <mysearch-rg> --sku free --location westus\n```\n\nSee [choosing a pricing tier](https://learn.microsoft.com/azure/search/search-sku-tier)\n for more information about available options.\n\n### Authenticate the client\n\nTo interact with the search service, you'll need to create an instance of the appropriate client class: `SearchClient` for searching indexed documents, `SearchIndexClient` for managing indexes, or `SearchIndexerClient` for crawling data sources and loading search documents into an index. To instantiate a client object, you'll need an **endpoint** and **Azure roles** or an **API key**. You can refer to the documentation for more information on [supported authenticating approaches](https://learn.microsoft.com/azure/search/search-security-overview#authentication) with the search service.\n\n#### Get an API Key\n\nAn API key can be an easier approach to start with because it doesn't require pre-existing role assignments.\n\nYou can get the **endpoint** and an **API key** from the Search service in the [Azure portal](https://portal.azure.com/). Please refer the [documentation](https://learn.microsoft.com/azure/search/search-security-api-keys) for instructions on how to get an API key.\n\nAlternatively, you can use the following [Azure CLI](https://learn.microsoft.com/cli/azure/) command to retrieve the API key from the Search service:\n\n```Powershell\naz search admin-key show --service-name <mysearch> --resource-group <mysearch-rg>\n```\n\nThere are two types of keys used to access your search service: **admin**\n*(read-write)* and **query** *(read-only)* keys.  Restricting access and\noperations in client apps is essential to safeguarding the search assets on your\nservice.  Always use a query key rather than an admin key for any query\noriginating from a client app.\n\n*Note: The example Azure CLI snippet above retrieves an admin key so it's easier\nto get started exploring APIs, but it should be managed carefully.*\n\n#### Create a SearchClient\n\nTo instantiate the `SearchClient`, you'll need the **endpoint**, **API key** and **index name**:\n\n<!-- SNIPPET:sample_authentication.create_search_client_with_key -->\n\n```python\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\n\nservice_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\nindex_name = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\nkey = os.environ[\"AZURE_SEARCH_API_KEY\"]\n\nsearch_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n```\n\n<!-- END SNIPPET -->\n\n#### Create a client using Microsoft Entra ID authentication\n\nYou can also create a `SearchClient`, `SearchIndexClient`, or `SearchIndexerClient` using Microsoft Entra ID authentication. Your user or service principal must be assigned the \"Search Index Data Reader\" role.\nUsing the [DefaultAzureCredential](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/README.md#defaultazurecredential) you can authenticate a service using Managed Identity or a service principal, authenticate as a developer working on an application, and more all without changing code. Please refer the [documentation](https://learn.microsoft.com/azure/search/search-security-rbac?tabs=config-svc-portal%2Croles-portal%2Ctest-portal%2Ccustom-role-portal%2Cdisable-keys-portal) for instructions on how to connect to Azure AI Search using Azure role-based access control (Azure RBAC).\n\nBefore you can use the `DefaultAzureCredential`, or any credential type from [Azure.Identity](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/README.md), you'll first need to [install the Azure.Identity package](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/README.md#install-the-package).\n\nTo use `DefaultAzureCredential` with a client ID and secret, you'll need to set the `AZURE_TENANT_ID`, `AZURE_CLIENT_ID`, and `AZURE_CLIENT_SECRET` environment variables; alternatively, you can pass those values\nto the `ClientSecretCredential` also in Azure.Identity.\n\nMake sure you use the right namespace for `DefaultAzureCredential` at the top of your source file:\n\n```python\nfrom azure.identity import DefaultAzureCredential\nfrom azure.search.documents import SearchClient\n\nservice_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\nindex_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\ncredential = DefaultAzureCredential()\n\nsearch_client = SearchClient(service_endpoint, index_name, credential)\n```\n\n## Key concepts\n\nAn Azure AI Search service contains one or more indexes that provide\npersistent storage of searchable data in the form of JSON documents.  _(If\nyou're brand new to search, you can make a very rough analogy between\nindexes and database tables.)_  The Azure.Search.Documents client library\nexposes operations on these resources through three main client types.\n\n* `SearchClient` helps with:\n  * [Searching](https://learn.microsoft.com/azure/search/search-lucene-query-architecture)\n    your indexed documents using [vector queries](https://learn.microsoft.com/azure/search/vector-search-how-to-query),\n    [keyword queries](https://learn.microsoft.com/azure/search/search-query-create)\n    and [hybrid queries](https://learn.microsoft.com/azure/search/hybrid-search-how-to-query)\n  * [Vector query filters](https://learn.microsoft.com/azure/search/vector-search-filters) and [Text query filters](https://learn.microsoft.com/azure/search/search-filters)\n  * [Semantic ranking](https://learn.microsoft.com/azure/search/semantic-how-to-query-request) and [scoring profiles](https://learn.microsoft.com/azure/search/index-add-scoring-profiles) for boosting relevance\n  * [Autocompleting](https://learn.microsoft.com/rest/api/searchservice/autocomplete)\n    partially typed search terms based on documents in the index\n  * [Suggesting](https://learn.microsoft.com/rest/api/searchservice/suggestions)\n    the most likely matching text in documents as a user types\n  * [Adding, Updating or Deleting Documents](https://learn.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents)\n    documents from an index\n\n* `SearchIndexClient` allows you to:\n  * [Create, delete, update, or configure a search index](https://learn.microsoft.com/rest/api/searchservice/index-operations)\n  * [Declare custom synonym maps to expand or rewrite queries](https://learn.microsoft.com/rest/api/searchservice/synonym-map-operations)\n<!--   * Most of the `SearchServiceClient` functionality is not yet available in our current preview -->\n\n* `SearchIndexerClient` allows you to:\n  * [Start indexers to automatically crawl data sources](https://learn.microsoft.com/rest/api/searchservice/indexer-operations)\n  * [Define AI powered Skillsets to transform and enrich your data](https://learn.microsoft.com/rest/api/searchservice/skillset-operations)\n\nAzure AI Search provides two powerful features: **semantic ranking** and **vector search**.\n\n**Semantic ranking** enhances the quality of search results for text-based queries. By enabling semantic ranking on your search service, you can improve the relevance of search results in two ways:\n\n* It applies secondary ranking to the initial result set, promoting the most semantically relevant results to the top.\n* It extracts and returns captions and answers in the response, which can be displayed on a search page to enhance the user's search experience.\n\nTo learn more about semantic ranking, you can refer to the [documentation](https://learn.microsoft.com/azure/search/vector-search-overview).\n\n**Vector search** is an information retrieval technique that uses numeric representations of searchable documents and query strings. By searching for numeric representations of content that are most similar to the numeric query, vector search can find relevant matches, even if the exact terms of the query are not present in the index. Moreover, vector search can be applied to various types of content, including images and videos and translated text, not just same-language text.\n\nTo learn how to index vector fields and perform vector search, you can refer to the [sample](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/samples/sample_vector_search.py). This sample provides detailed guidance on indexing vector fields and demonstrates how to perform vector search.\n\nAdditionally, for more comprehensive information about vector search, including its concepts and usage, you can refer to the [documentation](https://learn.microsoft.com/azure/search/vector-search-overview). The documentation provides in-depth explanations and guidance on leveraging the power of vector search in Azure AI Search.\n\n_The `Azure.Search.Documents` client library (v1) provides APIs for data plane operations. The\nprevious `Microsoft.Azure.Search` client library (v10) is now retired. It has many similar looking APIs, so please be careful to avoid confusion when exploring online resources. A good rule of thumb is to check for the namespace\n`Azure.Search.Documents;` when you're looking for API reference.\n\n## Examples\n\nThe following examples all use a simple [Hotel data set](https://github.com/Azure-Samples/azure-search-sample-data/blob/master/README.md)\nthat you can [import into your own index from the Azure portal.](https://learn.microsoft.com/azure/search/search-get-started-portal#step-1---start-the-import-data-wizard-and-create-a-data-source)\nThese are just a few of the basics - please [check out our Samples](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/samples) for\nmuch more.\n\n* [Querying](#querying)\n* [Creating an index](#creating-an-index)\n* [Adding documents to your index](#adding-documents-to-your-index)\n* [Retrieving a specific document from your index](#retrieving-a-specific-document-from-your-index)\n* [Async APIs](#async-apis)\n\n### Querying\n\nLet's start by importing our namespaces.\n\n```python\nimport os\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\n```\n\nWe'll then create a `SearchClient` to access our hotels search index.\n\n```python\nindex_name = \"hotels\"\n# Get the service endpoint and API key from the environment\nendpoint = os.environ[\"SEARCH_ENDPOINT\"]\nkey = os.environ[\"SEARCH_API_KEY\"]\n\n# Create a client\ncredential = AzureKeyCredential(key)\nclient = SearchClient(endpoint=endpoint,\n                      index_name=index_name,\n                      credential=credential)\n```\n\nLet's search for a \"luxury\" hotel.\n\n```python\nresults = client.search(search_text=\"luxury\")\n\nfor result in results:\n    print(\"{}: {})\".format(result[\"hotelId\"], result[\"hotelName\"]))\n```\n\n### Creating an index\n\nYou can use the `SearchIndexClient` to create a search index. Fields can be\ndefined using convenient `SimpleField`, `SearchableField`, or `ComplexField`\nmodels. Indexes can also define suggesters, lexical analyzers, and more.\n\n<!-- SNIPPET:sample_index_crud_operations.create_index -->\n\n```python\nclient = SearchIndexClient(service_endpoint, AzureKeyCredential(key))\nname = \"hotels\"\nfields = [\n    SimpleField(name=\"hotelId\", type=SearchFieldDataType.String, key=True),\n    SimpleField(name=\"hotelName\", type=SearchFieldDataType.String, searchable=True),\n    SimpleField(name=\"baseRate\", type=SearchFieldDataType.Double),\n    SearchableField(name=\"description\", type=SearchFieldDataType.String, collection=True),\n    ComplexField(\n        name=\"address\",\n        fields=[\n            SimpleField(name=\"streetAddress\", type=SearchFieldDataType.String),\n            SimpleField(name=\"city\", type=SearchFieldDataType.String),\n        ],\n        collection=True,\n    ),\n]\ncors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\nscoring_profiles: List[ScoringProfile] = []\nindex = SearchIndex(name=name, fields=fields, scoring_profiles=scoring_profiles, cors_options=cors_options)\n\nresult = client.create_index(index)\n```\n\n<!-- END SNIPPET -->\n\n### Adding documents to your index\n\nYou can `Upload`, `Merge`, `MergeOrUpload`, and `Delete` multiple documents from\nan index in a single batched request.  There are\n[a few special rules for merging](https://learn.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents#document-actions)\nto be aware of.\n\n<!-- SNIPPET:sample_crud_operations.upload_document -->\n\n```python\nDOCUMENT = {\n    \"hotelId\": \"1000\",\n    \"hotelName\": \"Azure Inn\",\n}\n\nresult = search_client.upload_documents(documents=[DOCUMENT])\n\nprint(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n```\n\n<!-- END SNIPPET -->\n\n### Authenticate in a National Cloud\n\nTo authenticate in a [National Cloud](https://learn.microsoft.com/azure/active-directory/develop/authentication-national-cloud), you will need to make the following additions to your client configuration:\n\n* Set the `AuthorityHost` in the credential options or via the `AZURE_AUTHORITY_HOST` environment variable\n* Set the `audience` in `SearchClient`, `SearchIndexClient`, or `SearchIndexerClient`\n\n```python\n# Create a SearchClient that will authenticate through AAD in the China national cloud.\nimport os\nfrom azure.identity import DefaultAzureCredential, AzureAuthorityHosts\nfrom azure.search.documents import SearchClient\n\nindex_name = \"hotels\"\nendpoint = os.environ[\"SEARCH_ENDPOINT\"]\nkey = os.environ[\"SEARCH_API_KEY\"]\ncredential = DefaultAzureCredential(authority=AzureAuthorityHosts.AZURE_CHINA)\n\nsearch_client = SearchClient(endpoint, index_name, credential=credential, audience=\"https://search.azure.cn\")\n```\n\n### Retrieving a specific document from your index\n\nIn addition to querying for documents using keywords and optional filters,\nyou can retrieve a specific document from your index if you already know the\nkey. You could get the key from a query, for example, and want to show more\ninformation about it or navigate your customer to that document.\n\n<!-- SNIPPET:sample_get_document.get_document -->\n\n```python\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\n\nsearch_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n\nresult = search_client.get_document(key=\"23\")\n\nprint(\"Details for hotel '23' are:\")\nprint(\"        Name: {}\".format(result[\"hotelName\"]))\n```\n\n<!-- END SNIPPET -->\n\n### Async APIs\n\nThis library includes a complete async API. To use it, you must\nfirst install an async transport, such as [aiohttp](https://pypi.org/project/aiohttp/).\nSee\n[azure-core documentation](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#transport)\nfor more information.\n\n<!-- SNIPPET:sample_simple_query_async.simple_query_async -->\n\n```python\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents.aio import SearchClient\n\nsearch_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n\nasync with search_client:\n    results = await search_client.search(search_text=\"spa\")\n\n    print(\"Hotels containing 'spa' in the name (or other fields):\")\n    async for result in results:\n        print(\"    Name: {} (rating {})\".format(result[\"hotelName\"], result[\"rating\"]))\n```\n\n<!-- END SNIPPET -->\n\n## Troubleshooting\n\n### General\n\nThe Azure AI Search client will raise exceptions defined in [Azure Core][azure_core].\n\n### Logging\n\nThis library uses the standard [logging][python_logging] library for logging.\nBasic information about HTTP sessions (URLs, headers, etc.) is logged at INFO\nlevel.\n\nDetailed DEBUG level logging, including request/response bodies and unredacted\nheaders, can be enabled on a client with the `logging_enable` keyword argument:\n```python\nimport sys\nimport logging\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\n\n# Create a logger for the 'azure' SDK\nlogger = logging.getLogger('azure')\nlogger.setLevel(logging.DEBUG)\n\n# Configure a console output\nhandler = logging.StreamHandler(stream=sys.stdout)\nlogger.addHandler(handler)\n\n# This client will log detailed information about its HTTP sessions, at DEBUG level\nclient = SearchClient(\"<service endpoint>\", \"<index_name>\", AzureKeyCredential(\"<api key>\"), logging_enable=True)\n\n```\n\nSimilarly, `logging_enable` can enable detailed logging for a single operation,\neven when it isn't enabled for the client:\n```python\nresult =  client.search(search_text=\"spa\", logging_enable=True)\n```\n\n## Next steps\n\n* Go further with Azure.Search.Documents and our [https://github.com/Azure/azure-sdk-for-python/blob/master/sdk/search/azure-search-documents/samples](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/samples)\n* Read more about the [Azure AI Search service](https://learn.microsoft.com/azure/search/search-what-is-azure-search)\n\n## Contributing\n\nSee our [Search CONTRIBUTING.md][search_contrib] for details on building,\ntesting, and contributing to this library.\n\nThis project welcomes contributions and suggestions.  Most contributions require\nyou to agree to a Contributor License Agreement (CLA) declaring that you have\nthe right to, and actually do, grant us the rights to use your contribution. For\ndetails, visit [cla.microsoft.com][cla].\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][code_of_conduct].\nFor more information, see the [Code of Conduct FAQ][coc_faq]\nor contact [opencode@microsoft.com][coc_contact] with any\nadditional questions or comments.\n\n\n\n## Related projects\n\n* [Microsoft Azure SDK for Python](https://github.com/Azure/azure-sdk-for-python)\n\n<!-- LINKS -->\n\n\n\n[azure_cli]: https://learn.microsoft.com/cli/azure\n[azure_core]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md\n[azure_sub]: https://azure.microsoft.com/free/\n[search_resource]: https://learn.microsoft.com/azure/search/search-create-service-portal\n[azure_portal]: https://portal.azure.com\n\n[create_search_service_docs]: https://learn.microsoft.com/azure/search/search-create-service-portal\n[create_search_service_ps]: https://learn.microsoft.com/azure/search/search-manage-powershell#create-or-delete-a-service\n[create_search_service_cli]: https://learn.microsoft.com/cli/azure/search/service?view=azure-cli-latest#az-search-service-create\n[search_contrib]: https://github.com/Azure/azure-sdk-for-python/blob/main/CONTRIBUTING.md\n[python_logging]: https://docs.python.org/3.5/library/logging.html\n\n[cla]: https://cla.microsoft.com\n[code_of_conduct]: https://opensource.microsoft.com/codeofconduct/\n[coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/\n[coc_contact]: mailto:opencode@microsoft.com\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents",
        "author": "Microsoft Corporation",
        "author_email": "ascl@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-core>=1.28.0",
          "azure-common>=1.1",
          "isodate>=0.6.0",
          "typing-extensions>=4.6.0"
        ],
        "requires_python": ">=3.8"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/13/fd/477ed56cf10514b539c2de594f6179b7ecd1790728f85f23d26221d93c43/azure_ai_evaluation-1.11.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b357964dbb0f22de0d9281a75e21493b1ad807469572bc9630d47c6f91196f26",
          "hashes": {
            "sha256": "b357964dbb0f22de0d9281a75e21493b1ad807469572bc9630d47c6f91196f26"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-ai-evaluation",
        "version": "1.11.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Evaluation Library for Python",
        "description": "# Azure AI Evaluation client library for Python\n\nUse Azure AI Evaluation SDK to assess the performance of your generative AI applications. Generative AI application generations are quantitatively measured with mathematical based metrics, AI-assisted quality and safety metrics. Metrics are defined as `evaluators`. Built-in or custom evaluators can provide comprehensive insights into the application's capabilities and limitations.\n\nUse Azure AI Evaluation SDK to:\n- Evaluate existing data from generative AI applications\n- Evaluate generative AI applications\n- Evaluate by generating mathematical, AI-assisted quality and safety metrics\n\nAzure AI SDK provides following to evaluate Generative AI Applications:\n- [Evaluators][evaluators] - Generate scores individually or when used together with `evaluate` API.\n- [Evaluate API][evaluate_api] - Python API to evaluate dataset or application using built-in or custom evaluators.\n\n[Source code][source_code]\n| [Package (PyPI)][evaluation_pypi]\n| [API reference documentation][evaluation_ref_docs]\n| [Product documentation][product_documentation]\n| [Samples][evaluation_samples]\n\n\n## Getting started\n\n### Prerequisites\n\n- Python 3.9 or later is required to use this package.\n- [Optional] You must have [Azure AI Foundry Project][ai_project] or [Azure Open AI][azure_openai] to use AI-assisted evaluators\n\n### Install the package\n\nInstall the Azure AI Evaluation SDK for Python with [pip][pip_link]:\n\n```bash\npip install azure-ai-evaluation\n```\n\n## Key concepts\n\n### Evaluators\n\nEvaluators are custom or prebuilt classes or functions that are designed to measure the quality of the outputs from language models or generative AI applications.\n\n#### Built-in evaluators\n\nBuilt-in evaluators are out of box evaluators provided by Microsoft:\n| Category  | Evaluator class                                                                                                                    |\n|-----------|------------------------------------------------------------------------------------------------------------------------------------|\n| [Performance and quality][performance_and_quality_evaluators] (AI-assisted)  | `GroundednessEvaluator`, `RelevanceEvaluator`, `CoherenceEvaluator`, `FluencyEvaluator`, `SimilarityEvaluator`, `RetrievalEvaluator` |\n| [Performance and quality][performance_and_quality_evaluators] (NLP)  | `F1ScoreEvaluator`, `RougeScoreEvaluator`, `GleuScoreEvaluator`, `BleuScoreEvaluator`, `MeteorScoreEvaluator`|\n| [Risk and safety][risk_and_safety_evaluators] (AI-assisted)    | `ViolenceEvaluator`, `SexualEvaluator`, `SelfHarmEvaluator`, `HateUnfairnessEvaluator`, `IndirectAttackEvaluator`, `ProtectedMaterialEvaluator`                                             |\n| [Composite][composite_evaluators] | `QAEvaluator`, `ContentSafetyEvaluator`                                             |\n\nFor more in-depth information on each evaluator definition and how it's calculated, see [Evaluation and monitoring metrics for generative AI][evaluation_metrics].\n\n```python\nimport os\n\nfrom azure.ai.evaluation import evaluate, RelevanceEvaluator, ViolenceEvaluator, BleuScoreEvaluator\n\n# NLP bleu score evaluator\nbleu_score_evaluator = BleuScoreEvaluator()\nresult = bleu_score(\n    response=\"Tokyo is the capital of Japan.\",\n    ground_truth=\"The capital of Japan is Tokyo.\"\n)\n\n# AI assisted quality evaluator\nmodel_config = {\n    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n}\n\nrelevance_evaluator = RelevanceEvaluator(model_config)\nresult = relevance_evaluator(\n    query=\"What is the capital of Japan?\",\n    response=\"The capital of Japan is Tokyo.\"\n)\n\n# There are two ways to provide Azure AI Project.\n# Option #1 : Using Azure AI Project Details \nazure_ai_project = {\n    \"subscription_id\": \"<subscription_id>\",\n    \"resource_group_name\": \"<resource_group_name>\",\n    \"project_name\": \"<project_name>\",\n}\n\nviolence_evaluator = ViolenceEvaluator(azure_ai_project)\nresult = violence_evaluator(\n    query=\"What is the capital of France?\",\n    response=\"Paris.\"\n)\n\n# Option # 2 : Using Azure AI Project Url \nazure_ai_project = \"https://{resource_name}.services.ai.azure.com/api/projects/{project_name}\"\n\nviolence_evaluator = ViolenceEvaluator(azure_ai_project)\nresult = violence_evaluator(\n    query=\"What is the capital of France?\",\n    response=\"Paris.\"\n)\n```\n\n#### Custom evaluators\n\nBuilt-in evaluators are great out of the box to start evaluating your application's generations. However you can build your own code-based or prompt-based evaluator to cater to your specific evaluation needs.\n\n```python\n\n# Custom evaluator as a function to calculate response length\ndef response_length(response, **kwargs):\n    return len(response)\n\n# Custom class based evaluator to check for blocked words\nclass BlocklistEvaluator:\n    def __init__(self, blocklist):\n        self._blocklist = blocklist\n\n    def __call__(self, *, response: str, **kwargs):\n        score = any([word in answer for word in self._blocklist])\n        return {\"score\": score}\n\nblocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad, worst, terrible\"])\n\nresult = response_length(\"The capital of Japan is Tokyo.\")\nresult = blocklist_evaluator(answer=\"The capital of Japan is Tokyo.\")\n\n```\n\n### Evaluate API\nThe package provides an `evaluate` API which can be used to run multiple evaluators together to evaluate generative AI application response.\n\n#### Evaluate existing dataset\n\n```python\nfrom azure.ai.evaluation import evaluate\n\nresult = evaluate(\n    data=\"data.jsonl\", # provide your data here\n    evaluators={\n        \"blocklist\": blocklist_evaluator,\n        \"relevance\": relevance_evaluator\n    },\n    # column mapping\n    evaluator_config={\n        \"relevance\": {\n            \"column_mapping\": {\n                \"query\": \"${data.queries}\"\n                \"ground_truth\": \"${data.ground_truth}\"\n                \"response\": \"${outputs.response}\"\n            } \n        }\n    }\n    # Optionally provide your AI Foundry project information to track your evaluation results in your Azure AI Foundry project\n    azure_ai_project = azure_ai_project,\n    # Optionally provide an output path to dump a json of metric summary, row level data and metric and AI Foundry URL\n    output_path=\"./evaluation_results.json\"\n)\n```\nFor more details refer to [Evaluate on test dataset using evaluate()][evaluate_dataset]\n\n#### Evaluate generative AI application\n```python\nfrom askwiki import askwiki\n\nresult = evaluate(\n    data=\"data.jsonl\",\n    target=askwiki,\n    evaluators={\n        \"relevance\": relevance_eval\n    },\n    evaluator_config={\n        \"default\": {\n            \"column_mapping\": {\n                \"query\": \"${data.queries}\"\n                \"context\": \"${outputs.context}\"\n                \"response\": \"${outputs.response}\"\n            } \n        }\n    }\n)\n```\nAbove code snippet refers to askwiki application in this [sample][evaluate_app].\n\nFor more details refer to [Evaluate on a target][evaluate_target]\n\n### Simulator\n\n\nSimulators allow users to generate synthentic data using their application. Simulator expects the user to have a callback method that invokes their AI application. The intergration between your AI application and the simulator happens at the callback method. Here's how a sample callback would look like:\n\n\n```python\nasync def callback(\n    messages: Dict[str, List[Dict]],\n    stream: bool = False,\n    session_state: Any = None,\n    context: Optional[Dict[str, Any]] = None,\n) -> dict:\n    messages_list = messages[\"messages\"]\n    # Get the last message from the user\n    latest_message = messages_list[-1]\n    query = latest_message[\"content\"]\n    # Call your endpoint or AI application here\n    # response should be a string\n    response = call_to_your_application(query, messages_list, context)\n    formatted_response = {\n        \"content\": response,\n        \"role\": \"assistant\",\n        \"context\": \"\",\n    }\n    messages[\"messages\"].append(formatted_response)\n    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}\n```\n\nThe simulator initialization and invocation looks like this:\n```python\nfrom azure.ai.evaluation.simulator import Simulator\nmodel_config = {\n    \"azure_endpoint\": os.environ.get(\"AZURE_ENDPOINT\"),\n    \"azure_deployment\": os.environ.get(\"AZURE_DEPLOYMENT_NAME\"),\n    \"api_version\": os.environ.get(\"AZURE_API_VERSION\"),\n}\ncustom_simulator = Simulator(model_config=model_config)\noutputs = asyncio.run(custom_simulator(\n    target=callback,\n    conversation_turns=[\n        [\n            \"What should I know about the public gardens in the US?\",\n        ],\n        [\n            \"How do I simulate data against LLMs\",\n        ],\n    ],\n    max_conversation_turns=2,\n))\nwith open(\"simulator_output.jsonl\", \"w\") as f:\n    for output in outputs:\n        f.write(output.to_eval_qr_json_lines())\n```\n\n#### Adversarial Simulator\n\n```python\nfrom azure.ai.evaluation.simulator import AdversarialSimulator, AdversarialScenario\nfrom azure.identity import DefaultAzureCredential\n\n# There are two ways to provide Azure AI Project.\n# Option #1 : Using Azure AI Project \nazure_ai_project = {\n    \"subscription_id\": <subscription_id>,\n    \"resource_group_name\": <resource_group_name>,\n    \"project_name\": <project_name>\n}\n\n# Option #2 : Using Azure AI Project Url \nazure_ai_project = \"https://{resource_name}.services.ai.azure.com/api/projects/{project_name}\"\n\nscenario = AdversarialScenario.ADVERSARIAL_QA\nsimulator = AdversarialSimulator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n\noutputs = asyncio.run(\n    simulator(\n        scenario=scenario,\n        max_conversation_turns=1,\n        max_simulation_results=3,\n        target=callback\n    )\n)\n\nprint(outputs.to_eval_qr_json_lines())\n```\n\nFor more details about the simulator, visit the following links:\n- [Adversarial Simulation docs][adversarial_simulation_docs]\n- [Adversarial scenarios][adversarial_simulation_scenarios]\n- [Simulating jailbreak attacks][adversarial_jailbreak]\n\n## Examples\n\nIn following section you will find examples of:\n- [Evaluate an application][evaluate_app]\n- [Evaluate different models][evaluate_models]\n- [Custom Evaluators][custom_evaluators]\n- [Adversarial Simulation][adversarial_simulation]\n- [Simulate with conversation starter][simulate_with_conversation_starter]\n\nMore examples can be found [here][evaluate_samples].\n\n## Troubleshooting\n\n### General\n\nPlease refer to [troubleshooting][evaluation_tsg] for common issues.\n\n### Logging\n\nThis library uses the standard\n[logging][python_logging] library for logging.\nBasic information about HTTP sessions (URLs, headers, etc.) is logged at INFO\nlevel.\n\nDetailed DEBUG level logging, including request/response bodies and unredacted\nheaders, can be enabled on a client with the `logging_enable` argument.\n\nSee full SDK logging documentation with examples [here][sdk_logging_docs].\n\n## Next steps\n\n- View our [samples][evaluation_samples].\n- View our [documentation][product_documentation]\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit [cla.microsoft.com][cla].\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][code_of_conduct]. For more information see the [Code of Conduct FAQ][coc_faq] or contact [opencode@microsoft.com][coc_contact] with any additional questions or comments.\n\n<!-- LINKS -->\n\n[source_code]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/evaluation/azure-ai-evaluation\n[evaluation_pypi]: https://pypi.org/project/azure-ai-evaluation/\n[evaluation_ref_docs]: https://learn.microsoft.com/python/api/azure-ai-evaluation/azure.ai.evaluation?view=azure-python-preview\n[evaluation_samples]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios\n[product_documentation]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk\n[python_logging]: https://docs.python.org/3/library/logging.html\n[sdk_logging_docs]: https://docs.microsoft.com/azure/developer/python/azure-sdk-logging\n[azure_core_readme]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md\n[pip_link]: https://pypi.org/project/pip/\n[azure_core_ref_docs]: https://aka.ms/azsdk-python-core-policies\n[azure_core]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md\n[azure_identity]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity\n[cla]: https://cla.microsoft.com\n[code_of_conduct]: https://opensource.microsoft.com/codeofconduct/\n[coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/\n[coc_contact]: mailto:opencode@microsoft.com\n[evaluate_target]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#evaluate-on-a-target\n[evaluate_dataset]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#evaluate-on-test-dataset-using-evaluate\n[evaluators]: https://learn.microsoft.com/python/api/azure-ai-evaluation/azure.ai.evaluation?view=azure-python-preview\n[evaluate_api]: https://learn.microsoft.com/python/api/azure-ai-evaluation/azure.ai.evaluation?view=azure-python-preview#azure-ai-evaluation-evaluate\n[evaluate_app]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/Supported_Evaluation_Targets/Evaluate_App_Endpoint\n[evaluation_tsg]: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/evaluation/azure-ai-evaluation/TROUBLESHOOTING.md\n[ai_studio]: https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio\n[ai_project]: https://learn.microsoft.com/azure/ai-studio/how-to/create-projects?tabs=ai-studio\n[azure_openai]: https://learn.microsoft.com/azure/ai-services/openai/\n[evaluate_models]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/Supported_Evaluation_Targets/Evaluate_Base_Model_Endpoint\n[custom_evaluators]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/Supported_Evaluation_Metrics/Custom_Evaluators\n[evaluate_samples]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate\n[evaluation_metrics]: https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in\n[performance_and_quality_evaluators]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#performance-and-quality-evaluators\n[risk_and_safety_evaluators]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#risk-and-safety-evaluators\n[composite_evaluators]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#composite-evaluators\n[adversarial_simulation_docs]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/simulator-interaction-data#generate-adversarial-simulations-for-safety-evaluation\n[adversarial_simulation_scenarios]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/simulator-interaction-data#supported-adversarial-simulation-scenarios\n[adversarial_simulation]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/Simulators/Simulate_Adversarial_Data\n[simulate_with_conversation_starter]: https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/Simulators/Simulate_Context-Relevant_Data/Simulate_From_Conversation_Starter\n[adversarial_jailbreak]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/simulator-interaction-data#simulating-jailbreak-attacks\n\n\n# Release History\n\n## 1.11.0 (2025-09-02)\n\n### Features Added\n- Added support for user-supplied tags in the `evaluate` function. Tags are key-value pairs that can be used for experiment tracking, A/B testing, filtering, and organizing evaluation runs. The function accepts a `tags` parameter.\n- Added support for user-supplied TokenCredentials with LLM based evaluators.\n- Enhanced `GroundednessEvaluator` to support AI agent evaluation with tool calls. The evaluator now accepts agent response data containing tool calls and can extract context from `file_search` tool results for groundedness assessment. This enables evaluation of AI agents that use tools to retrieve information and generate responses. Note: Agent groundedness evaluation is currently supported only when the `file_search` tool is used.\n- Added `language` parameter to `RedTeam` class for multilingual red team scanning support. The parameter accepts values from `SupportedLanguages` enum including English, Spanish, French, German, Italian, Portuguese, Japanese, Korean, and Simplified Chinese, enabling red team attacks to be generated and conducted in multiple languages.\n- Added support for IndirectAttack and UngroundedAttributes risk categories in `RedTeam` scanning. These new risk categories expand red team capabilities to detect cross-platform indirect attacks and evaluate ungrounded inferences about human attributes including emotional state and protected class information.\n\n### Bugs Fixed\n- Fixed issue where evaluation results were not properly aligned with input data, leading to incorrect metrics being reported.\n\n### Other Changes\n- Deprecating `AdversarialSimulator` in favor of the [AI Red Teaming Agent](https://aka.ms/airedteamingagent-sample). `AdversarialSimulator` will be removed in the next minor release. \n- Moved retry configuration constants (`MAX_RETRY_ATTEMPTS`, `MAX_RETRY_WAIT_SECONDS`, `MIN_RETRY_WAIT_SECONDS`) from `RedTeam` class to new `RetryManager` class for better code organization and configurability.\n\n## 1.10.0 (2025-07-31)\n\n### Breaking Changes\n\n- Added `evaluate_query` parameter to all RAI service evaluators that can be passed as a keyword argument. This parameter controls whether queries are included in evaluation data when evaluating query-response pairs. Previously, queries were always included in evaluations. When set to `True`, both query and response will be evaluated; when set to `False` (default), only the response will be evaluated. This parameter is available across all RAI service evaluators including `ContentSafetyEvaluator`, `ViolenceEvaluator`, `SexualEvaluator`, `SelfHarmEvaluator`, `HateUnfairnessEvaluator`, `ProtectedMaterialEvaluator`, `IndirectAttackEvaluator`, `CodeVulnerabilityEvaluator`, `UngroundedAttributesEvaluator`, `GroundednessProEvaluator`, and `EciEvaluator`.  Existing code that relies on queries being evaluated will need to explicitly set `evaluate_query=True` to maintain the previous behavior.\n\n### Features Added\n\n- Added support for Azure OpenAI Python grader via `AzureOpenAIPythonGrader` class, which serves as a wrapper around Azure Open AI Python grader configurations. This new grader object can be supplied to the main `evaluate` method as if it were a normal callable evaluator.\n- Added `attack_success_thresholds` parameter to `RedTeam` class for configuring custom thresholds that determine attack success. This allows users to set specific threshold values for each risk category, with scores greater than the threshold considered successful attacks (i.e. higher threshold means higher \ntolerance for harmful responses).\n- Enhanced threshold reporting in RedTeam results to include default threshold values when custom thresholds aren't specified, providing better transparency about the evaluation criteria used.\n\n\n### Bugs Fixed\n\n- Fixed red team scan `output_path` issue where individual evaluation results were overwriting each other instead of being preserved as separate files. Individual evaluations now create unique files while the user's `output_path` is reserved for final aggregated results.\n- Significant improvements to TaskAdherence evaluator. New version has less variance, is much faster and consumes fewer tokens.\n- Significant improvements to Relevance evaluator. New version has more concrete rubrics and has less variance, is much faster and consumes fewer tokens.\n\n\n### Other Changes\n\n- The default engine for evaluation was changed from `promptflow` (PFClient) to an in-SDK batch client (RunSubmitterClient)\n  - Note: We've temporarily kept an escape hatch to fall back to the legacy `promptflow` implementation by setting `_use_pf_client=True` when invoking `evaluate()`.\n    This is due to be removed in a future release.\n\n\n## 1.9.0 (2025-07-02)\n\n### Features Added\n\n- Added support for Azure Open AI evaluation via `AzureOpenAIScoreModelGrader` class, which serves as a wrapper around Azure Open AI score model configurations. This new grader object can be supplied to the main `evaluate` method as if it were a normal callable evaluator.\n- Added new experimental risk categories ProtectedMaterial and CodeVulnerability for redteam agent scan.\n\n\n### Bugs Fixed\n\n- Significant improvements to IntentResolution evaluator. New version has less variance, is nearly 2x faster and consumes fewer tokens.\n\n- Fixes and improvements to ToolCallAccuracy evaluator. New version has less variance. and now works on all tool calls that happen in a turn at once. Previously, it worked on each tool call independently without having context on the other tool calls that happen in the same turn, and then aggregated the results to a score in the range [0-1]. The score range is now [1-5].\n- Fixed MeteorScoreEvaluator and other threshold-based evaluators returning incorrect binary results due to integer conversion of decimal scores. Previously, decimal scores like 0.9375 were incorrectly converted to integers (0) before threshold comparison, causing them to fail even when above the threshold. [#41415](https://github.com/Azure/azure-sdk-for-python/issues/41415)\n- Added a new enum `ADVERSARIAL_QA_DOCUMENTS` which moves all the \"file_content\" type prompts away from `ADVERSARIAL_QA` to the new enum\n- `AzureOpenAIScoreModelGrader` evaluator now supports `pass_threshold` parameter to set the minimum score required for a response to be considered passing. This allows users to define custom thresholds for evaluation results, enhancing flexibility in grading AI model responses.\n\n## 1.8.0 (2025-05-29)\n\n### Features Added\n\n- Introduces `AttackStrategy.MultiTurn` and `AttackStrategy.Crescendo` to `RedTeam`. These strategies attack the target of a `RedTeam` scan over the course of multi-turn conversations. \n\n### Bugs Fixed\n- AdversarialSimulator in `ADVERSARIAL_CONVERSATION` mode was broken. It is now fixed.\n\n## 1.7.0 (2025-05-12)\n\n### Bugs Fixed\n- azure-ai-evaluation failed with module not found [#40992](https://github.com/Azure/azure-sdk-for-python/issues/40992)\n\n## 1.6.0 (2025-05-07)\n\n### Features Added\n- New `<evaluator>.binary_aggregate` field added to evaluation result metrics. This field contains the aggregated binary evaluation results for each evaluator, providing a summary of the evaluation outcomes.\n- Added support for Azure Open AI evaluation via 4 new 'grader' classes, which serve as wrappers around Azure Open AI grader configurations. These new grader objects can be supplied to the main `evaluate` method as if they were normal callable evaluators. The new classes are:\n    - AzureOpenAIGrader (general class for experienced users)\n    - AzureOpenAILabelGrader\n    - AzureOpenAIStringCheckGrader\n    - AzureOpenAITextSimilarityGrader\n\n### Breaking Changes\n- In the experimental RedTeam's scan method, the `data_only` param has been replaced with `skip_evals` and if you do not want data to be uploaded, use the `skip_upload` flag.\n\n### Bugs Fixed\n- Fixed error in `evaluate` where data fields could not contain numeric characters. Previously, a data file with schema:\n    ```\n    \"query1\": \"some query\", \"response\": \"some response\"\n    ```\n    throws error when passed into `evaluator_config` as `{\"evaluator_name\": {\"column_mapping\": {\"query\": \"${data.query1}\", \"response\": \"${data.response}\"}},}`.\n    Now, users may import data containing fields with numeric characters. \n\n\n## 1.5.0 (2025-04-04)\n\n### Features Added\n\n- New `RedTeam` agent functionality to assess the safety and resilience of AI systems against adversarial prompt attacks\n\n## 1.4.0 (2025-03-27)\n\n### Features Added\n- Enhanced binary evaluation results with customizable thresholds\n  - Added threshold support for QA and ContentSafety evaluators\n  - Evaluation results now include both the score and threshold values\n  - Configurable threshold parameter allows custom binary classification boundaries\n  - Default thresholds provided for backward compatibility\n  - Quality evaluators use \"higher is better\" scoring (score â‰¥ threshold is positive)\n  - Content safety evaluators use \"lower is better\" scoring (score â‰¤ threshold is positive)\n- New Built-in evaluator called CodeVulnerabilityEvaluator is added. \n  - It provides capabilities to identify the following code vulnerabilities.\n    - path-injection\n    - sql-injection\n    - code-injection\n    - stack-trace-exposure\n    - incomplete-url-substring-sanitization\n    - flask-debug\n    - clear-text-logging-sensitive-data\n    - incomplete-hostname-regexp\n    - server-side-unvalidated-url-redirection\n    - weak-cryptographic-algorithm\n    - full-ssrf\n    - bind-socket-all-network-interfaces\n    - client-side-unvalidated-url-redirection\n    - likely-bugs\n    - reflected-xss\n    - clear-text-storage-sensitive-data\n    - tarslip\n    - hardcoded-credentials\n    - insecure-randomness\n  - It also supports multiple coding languages such as (Python, Java, C++, C#, Go, Javascript, SQL)\n  \n- New Built-in evaluator called UngroundedAttributesEvaluator is added.\n  - It evaluates ungrounded inference of human attributes for a given query, response, and context for a single-turn evaluation only, \n  - where query represents the user query and response represents the AI system response given the provided context. \n \n  - Ungrounded Attributes checks for whether a response is first, ungrounded, and checks if it contains information about protected class \n  - or emotional state of a person.\n  \n  - It identifies the following attributes:\n    \n    - emotional_state\n    - protected_class\n    - groundedness\n- New Built-in evaluators for Agent Evaluation (Preview)\n  - IntentResolutionEvaluator - Evaluates the intent resolution of an agent's response to a user query.\n  - ResponseCompletenessEvaluator - Evaluates the response completeness of an agent's response to a user query.\n  - TaskAdherenceEvaluator - Evaluates the task adherence of an agent's response to a user query.\n  - ToolCallAccuracyEvaluator - Evaluates the accuracy of tool calls made by an agent in response to a user query.\n\n### Bugs Fixed\n- Fixed error in `GroundednessProEvaluator` when handling non-numeric values like \"n/a\" returned from the service.\n- Uploading local evaluation results from `evaluate` with the same run name will no longer result in each online run sharing (and bashing) result files.\n\n## 1.3.0 (2025-02-28)\n\n### Breaking Changes\n- Multimodal specific evaluators `ContentSafetyMultimodalEvaluator`, `ViolenceMultimodalEvaluator`, `SexualMultimodalEvaluator`, `SelfHarmMultimodalEvaluator`, `HateUnfairnessMultimodalEvaluator` and `ProtectedMaterialMultimodalEvaluator` has been removed. Please use `ContentSafetyEvaluator`, `ViolenceEvaluator`, `SexualEvaluator`, `SelfHarmEvaluator`, `HateUnfairnessEvaluator` and `ProtectedMaterialEvaluator` instead.\n- Metric name in ProtectedMaterialEvaluator's output is changed from `protected_material.fictional_characters_label` to `protected_material.fictional_characters_defect_rate`. It's now consistent with other evaluator's metric names (ending with `_defect_rate`).\n\n## 1.2.0 (2025-01-27)\n\n### Features Added\n- CSV files are now supported as data file inputs with `evaluate()` API. The CSV file should have a header row with column names that match the `data` and `target` fields in the `evaluate()` method and the filename should be passed as the `data` parameter. Column name 'Conversation' in CSV file is not fully supported yet.  \n\n### Breaking Changes\n- `ViolenceMultimodalEvaluator`, `SexualMultimodalEvaluator`, `SelfHarmMultimodalEvaluator`, `HateUnfairnessMultimodalEvaluator` and `ProtectedMaterialMultimodalEvaluator` will be removed in next release. \n\n### Bugs Fixed\n- Removed `[remote]` extra. This is no longer needed when tracking results in Azure AI Studio.\n- Fixed `AttributeError: 'NoneType' object has no attribute 'get'` while running simulator with 1000+ results\n- Fixed the non adversarial simulator to run in task-free mode\n- Content safety evaluators (violence, self harm, sexual, hate/unfairness) return the maximum result as the\n  main score when aggregating per-turn evaluations from a conversation into an overall\n  evaluation score. Other conversation-capable evaluators still default to a mean for aggregation.\n- Fixed bug in non adversarial simulator sample where `tasks` undefined\n\n### Other Changes\n- Changed minimum required python version to use this package from 3.8 to 3.9\n- Stop dependency on the local promptflow service. No promptflow service will automatically start when running evaluation.\n- Evaluators internally allow for custom aggregation. However, this causes serialization failures if evaluated while the\n  environment variable `AI_EVALS_BATCH_USE_ASYNC` is set to false.\n\n## 1.1.0 (2024-12-12)\n\n### Features Added\n- Added image support in `ContentSafetyEvaluator`, `ViolenceEvaluator`, `SexualEvaluator`, `SelfHarmEvaluator`, `HateUnfairnessEvaluator` and `ProtectedMaterialEvaluator`. Provide image URLs or base64 encoded images in `conversation` input for image evaluation. See below for an example:\n\n```python\nevaluator = ContentSafetyEvaluator(credential=azure_cred, azure_ai_project=project_scope)\nconversation = {\n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"You are an AI assistant that understands images.\"}\n            ],\n        },\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"Can you describe this image?\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"\n                    },\n                },\n            ],\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"The image shows a man with short brown hair smiling, wearing a dark-colored shirt.\",\n                }\n            ],\n        },\n    ]\n}\nprint(\"Calling Content Safety Evaluator for multi-modal\")\nscore = evaluator(conversation=conversation)\n```\n\n- Please switch to generic evaluators for image evaluations as mentioned above. `ContentSafetyMultimodalEvaluator`, `ContentSafetyMultimodalEvaluatorBase`, `ViolenceMultimodalEvaluator`, `SexualMultimodalEvaluator`, `SelfHarmMultimodalEvaluator`, `HateUnfairnessMultimodalEvaluator` and `ProtectedMaterialMultimodalEvaluator` will be deprecated in the next release.\n\n### Bugs Fixed\n- Removed `[remote]` extra. This is no longer needed when tracking results in Azure AI Foundry portal.\n- Fixed `AttributeError: 'NoneType' object has no attribute 'get'` while running simulator with 1000+ results\n\n## 1.0.1 (2024-11-15)\n\n### Bugs Fixed\n- Removing `azure-ai-inference` as dependency.\n- Fixed `AttributeError: 'NoneType' object has no attribute 'get'` while running simulator with 1000+ results\n\n## 1.0.0 (2024-11-13)\n\n### Breaking Changes\n- The `parallel` parameter has been removed from composite evaluators: `QAEvaluator`, `ContentSafetyChatEvaluator`, and `ContentSafetyMultimodalEvaluator`. To control evaluator parallelism, you can now use the `_parallel` keyword argument, though please note that this private parameter may change in the future.\n- Parameters `query_response_generating_prompty_kwargs` and `user_simulator_prompty_kwargs` have been renamed to `query_response_generating_prompty_options` and `user_simulator_prompty_options` in the Simulator's __call__ method.\n\n### Bugs Fixed\n- Fixed an issue where the `output_path` parameter in the `evaluate` API did not support relative path.\n- Output of adversarial simulators are of type `JsonLineList` and the helper function `to_eval_qr_json_lines` now outputs context from both user and assistant turns along with `category` if it exists in the conversation\n- Fixed an issue where during long-running simulations, API token expires causing \"Forbidden\" error. Instead, users can now set an environment variable `AZURE_TOKEN_REFRESH_INTERVAL` to refresh the token more frequently to prevent expiration and ensure continuous operation of the simulation.\n- Fixed an issue with the `ContentSafetyEvaluator` that caused parallel execution of sub-evaluators to fail. Parallel execution is now enabled by default again, but can still be disabled via the '_parallel' boolean keyword argument during class initialization.\n- Fix `evaluate` function not producing aggregated metrics if ANY values to be aggregated were None, NaN, or\notherwise difficult to process. Such values are ignored fully, so the aggregated metric of `[1, 2, 3, NaN]`\nwould be 2, not 1.5.\n\n### Other Changes\n- Refined error messages for serviced-based evaluators and simulators.\n- Tracing has been disabled due to Cosmos DB initialization issue.\n- Introduced environment variable `AI_EVALS_DISABLE_EXPERIMENTAL_WARNING` to disable the warning message for experimental features.\n- Changed the randomization pattern for `AdversarialSimulator` such that there is an almost equal number of Adversarial harm categories (e.g. Hate + Unfairness, Self-Harm, Violence, Sex) represented in the  `AdversarialSimulator` outputs. Previously, for 200 `max_simulation_results` a user might see 140 results belonging to the 'Hate + Unfairness' category and 40 results belonging to the 'Self-Harm' category. Now, user will see 50 results for each of Hate + Unfairness, Self-Harm, Violence, and Sex.\n- For the `DirectAttackSimulator`, the prompt templates used to generate simulated outputs for each Adversarial harm category will no longer be in a randomized order by default. To override this behavior, pass `randomize_order=True` when you call the `DirectAttackSimulator`, for example:\n```python\nadversarial_simulator = DirectAttackSimulator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\noutputs = asyncio.run(\n    adversarial_simulator(\n        scenario=scenario,\n        target=callback,\n        randomize_order=True\n    )\n)\n```\n\n## 1.0.0b5 (2024-10-28)\n\n### Features Added\n- Added `GroundednessProEvaluator`, which is a service-based evaluator for determining response groundedness.\n- Groundedness detection in Non Adversarial Simulator via query/context pairs\n```python\nimport importlib.resources as pkg_resources\npackage = \"azure.ai.evaluation.simulator._data_sources\"\nresource_name = \"grounding.json\"\ncustom_simulator = Simulator(model_config=model_config)\nconversation_turns = []\nwith pkg_resources.path(package, resource_name) as grounding_file:\n    with open(grounding_file, \"r\") as file:\n        data = json.load(file)\nfor item in data:\n    conversation_turns.append([item])\noutputs = asyncio.run(custom_simulator(\n    target=callback,\n    conversation_turns=conversation_turns,\n    max_conversation_turns=1,\n))\n```\n- Adding evaluator for multimodal use cases\n\n### Breaking Changes\n- Renamed environment variable `PF_EVALS_BATCH_USE_ASYNC` to `AI_EVALS_BATCH_USE_ASYNC`.\n- `RetrievalEvaluator` now requires a `context` input in addition to `query` in single-turn evaluation.\n- `RelevanceEvaluator` no longer takes `context` as an input. It now only takes `query` and `response` in single-turn evaluation.\n- `FluencyEvaluator` no longer takes `query` as an input. It now only takes `response` in single-turn evaluation.\n- AdversarialScenario enum does not include `ADVERSARIAL_INDIRECT_JAILBREAK`, invoking IndirectJailbreak or XPIA should be done with `IndirectAttackSimulator`\n- Outputs of `Simulator` and `AdversarialSimulator` previously had `to_eval_qa_json_lines` and now has `to_eval_qr_json_lines`. Where `to_eval_qa_json_lines` had:\n```json\n{\"question\": <user_message>, \"answer\": <assistant_message>}\n```\n`to_eval_qr_json_lines` now has:\n```json\n{\"query\": <user_message>, \"response\": assistant_message}\n```\n\n### Bugs Fixed\n- Non adversarial simulator works with `gpt-4o` models using the `json_schema` response format\n- Fixed an issue where the `evaluate` API would fail with \"[WinError 32] The process cannot access the file because it is being used by another process\" when venv folder and target function file are in the same directory.\n- Fix evaluate API failure when `trace.destination` is set to `none`\n- Non adversarial simulator now accepts context from the callback\n\n### Other Changes\n- Improved error messages for the `evaluate` API by enhancing the validation of input parameters. This update provides more detailed and actionable error descriptions.\n- `GroundednessEvaluator` now supports `query` as an optional input in single-turn evaluation. If `query` is provided, a different prompt template will be used for the evaluation.\n- To align with our support of a diverse set of models, the following evaluators will now have a new key in their result output without the `gpt_` prefix. To maintain backwards compatibility, the old key with the `gpt_` prefix will still be present in the output; however, it is recommended to use the new key moving forward as the old key will be deprecated in the future.\n  - `CoherenceEvaluator`\n  - `RelevanceEvaluator`\n  - `FluencyEvaluator`\n  - `GroundednessEvaluator`\n  - `SimilarityEvaluator`\n  - `RetrievalEvaluator`\n- The following evaluators will now have a new key in their result output including LLM reasoning behind the score. The new key will follow the pattern \"<metric_name>_reason\". The reasoning is the result of a more detailed prompt template being used to generate the LLM response. Note that this requires the maximum number of tokens used to run these evaluators to be increased.\n\n    | Evaluator | New `max_token` for Generation |\n    | --- | --- |\n    | `CoherenceEvaluator` | 800 |\n    | `RelevanceEvaluator` | 800 |\n    | `FluencyEvaluator` | 800 |\n    | `GroundednessEvaluator` | 800 |\n    | `RetrievalEvaluator` | 1600 |\n- Improved the error message for storage access permission issues to provide clearer guidance for users.\n\n## 1.0.0b4 (2024-10-16)\n\n### Breaking Changes\n\n- Removed `numpy` dependency. All NaN values returned by the SDK have been changed to from `numpy.nan` to `math.nan`.\n- `credential` is now required to be passed in for all content safety evaluators and `ProtectedMaterialsEvaluator`. `DefaultAzureCredential` will no longer be chosen if a credential is not passed.\n- Changed package extra name from \"pf-azure\" to \"remote\".\n\n### Bugs Fixed\n- Adversarial Conversation simulations would fail with `Forbidden`. Added logic to re-fetch token in the exponential retry logic to retrive RAI Service response.\n- Fixed an issue where the Evaluate API did not fail due to missing inputs when the target did not return columns required by the evaluators.\n\n### Other Changes\n- Enhance the error message to provide clearer instruction when required packages for the remote tracking feature are missing.\n- Print the per-evaluator run summary at the end of the Evaluate API call to make troubleshooting row-level failures easier.\n\n## 1.0.0b3 (2024-10-01)\n\n### Features Added\n\n- Added `type` field to `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`\n- The following evaluators now support `conversation` as an alternative input to their usual single-turn inputs:\n  - `ViolenceEvaluator`\n  - `SexualEvaluator`\n  - `SelfHarmEvaluator`\n  - `HateUnfairnessEvaluator`\n  - `ProtectedMaterialEvaluator`\n  - `IndirectAttackEvaluator`\n  - `CoherenceEvaluator`\n  - `RelevanceEvaluator`\n  - `FluencyEvaluator`\n  - `GroundednessEvaluator`\n- Surfaced `RetrievalScoreEvaluator`, formally an internal part of `ChatEvaluator` as a standalone conversation-only evaluator.\n\n### Breaking Changes\n\n- Removed `ContentSafetyChatEvaluator` and `ChatEvaluator`\n- The `evaluator_config` parameter of `evaluate` now maps in evaluator name to a dictionary `EvaluatorConfig`, which is a `TypedDict`. The\n`column_mapping` between `data` or `target` and evaluator field names should now be specified inside this new dictionary:\n\nBefore:\n```python\nevaluate(\n    ...,\n    evaluator_config={\n        \"hate_unfairness\": {\n            \"query\": \"${data.question}\",\n            \"response\": \"${data.answer}\",\n        }\n    },\n    ...\n)\n```\n\nAfter\n```python\nevaluate(\n    ...,\n    evaluator_config={\n        \"hate_unfairness\": {\n            \"column_mapping\": {\n                \"query\": \"${data.question}\",\n                \"response\": \"${data.answer}\",\n             }\n        }\n    },\n    ...\n)\n```\n\n- Simulator now requires a model configuration to call the prompty instead of an Azure AI project scope. This enables the usage of simulator with Entra ID based auth.\nBefore:\n```python\nazure_ai_project = {\n    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n    \"resource_group_name\": os.environ.get(\"RESOURCE_GROUP\"),\n    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n}\nsim = Simulator(azure_ai_project=azure_ai_project, credentails=DefaultAzureCredentials())\n```\nAfter:\n```python\nmodel_config = {\n    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n    \"azure_deployment\": os.environ.get(\"AZURE_DEPLOYMENT\"),\n}\nsim = Simulator(model_config=model_config)\n```\nIf `api_key` is not included in the `model_config`, the prompty runtime in `promptflow-core` will pick up `DefaultAzureCredential`.\n\n### Bugs Fixed\n\n- Fixed issue where Entra ID authentication was not working with `AzureOpenAIModelConfiguration`\n\n## 1.0.0b2 (2024-09-24)\n\n### Breaking Changes\n\n- `data` and `evaluators` are now required keywords in `evaluate`.\n\n## 1.0.0b1 (2024-09-20)\n\n### Breaking Changes\n\n- The `synthetic` namespace has been renamed to `simulator`, and sub-namespaces under this module have been removed\n- The `evaluate` and `evaluators` namespaces have been removed, and everything previously exposed in those modules has been added to the root namespace `azure.ai.evaluation`\n- The parameter name `project_scope` in content safety evaluators have been renamed to `azure_ai_project` for consistency with evaluate API and simulators.\n- Model configurations classes are now of type `TypedDict` and are exposed in the `azure.ai.evaluation` module instead of coming from `promptflow.core`.\n- Updated the parameter names for `question` and `answer` in built-in evaluators to more generic terms: `query` and `response`.\n\n### Features Added\n\n- First preview\n- This package is port of `promptflow-evals`. New features will be added only to this package moving forward.\n- Added a `TypedDict` for `AzureAIProject` that allows for better intellisense and type checking when passing in project information\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python",
        "author": "Microsoft Corporation",
        "author_email": "azuresdkengsysadmins@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "NOTICE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "pyjwt>=2.8.0",
          "azure-identity>=1.16.0",
          "azure-core>=1.30.2",
          "nltk>=3.9.1",
          "azure-storage-blob>=12.10.0",
          "httpx>=0.25.1",
          "pandas<3.0.0,>=2.1.2",
          "openai>=1.78.0",
          "ruamel.yaml<1.0.0,>=0.17.10",
          "msrest>=0.6.21",
          "Jinja2>=3.1.6",
          "aiohttp>=3.0",
          "pyrit==0.8.1; extra == \"redteam\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Bug Reports, https://github.com/Azure/azure-sdk-for-python/issues",
          "Source, https://github.com/Azure/azure-sdk-for-python"
        ],
        "provides_extra": [
          "redteam"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4f/c7/e54682c96a895d0c808453269e0b5928a07a127a15704fedb643e9b0a4c8/pandas-2.3.3-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=f8bfc0e12dc78f777f323f55c58649591b2cd0c43534e8355c51d3fede5f4dee",
          "hashes": {
            "sha256": "f8bfc0e12dc78f777f323f55c58649591b2cd0c43534e8355c51d3fede5f4dee"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "pandas",
        "version": "2.3.3",
        "summary": "Powerful data structures for data analysis, time series, and statistics",
        "description": "<div align=\"center\">\n  <img src=\"https://pandas.pydata.org/static/img/pandas.svg\"><br>\n</div>\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n\n| | |\n| --- | --- |\n| Testing | [![CI - Test](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml) [![Coverage](https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main)](https://codecov.io/gh/pandas-dev/pandas) |\n| Package | [![PyPI Latest Release](https://img.shields.io/pypi/v/pandas.svg)](https://pypi.org/project/pandas/) [![PyPI Downloads](https://img.shields.io/pypi/dm/pandas.svg?label=PyPI%20downloads)](https://pypi.org/project/pandas/) [![Conda Latest Release](https://anaconda.org/conda-forge/pandas/badges/version.svg)](https://anaconda.org/conda-forge/pandas) [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pandas.svg?label=Conda%20downloads)](https://anaconda.org/conda-forge/pandas) |\n| Meta | [![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg)](https://doi.org/10.5281/zenodo.3509134) [![License - BSD 3-Clause](https://img.shields.io/pypi/l/pandas.svg)](https://github.com/pandas-dev/pandas/blob/main/LICENSE) [![Slack](https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack)](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) |\n\n\n## What is it?\n\n**pandas** is a Python package that provides fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way towards this goal.\n\n## Table of Contents\n\n- [Main Features](#main-features)\n- [Where to get it](#where-to-get-it)\n- [Dependencies](#dependencies)\n- [Installation from sources](#installation-from-sources)\n- [License](#license)\n- [Documentation](#documentation)\n- [Background](#background)\n- [Getting Help](#getting-help)\n- [Discussion and Development](#discussion-and-development)\n- [Contributing to pandas](#contributing-to-pandas)\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`, `NA`, or `NaT`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    date shifting and lagging\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\nPackage Index (PyPI)](https://pypi.org/project/pandas) and on [Conda](https://docs.conda.io/en/latest/).\n\n```sh\n# conda\nconda install -c conda-forge pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\nThe list of changes to pandas between each release can be found\n[here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/index.html). For full\ndetails, see the commit logs at https://github.com/pandas-dev/pandas.\n\n## Dependencies\n- [NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays](https://www.numpy.org)\n- [python-dateutil - Provides powerful extensions to the standard datetime module](https://dateutil.readthedocs.io/en/stable/index.html)\n- [pytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations](https://github.com/stub42/pytz)\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need [Cython](https://cython.org/) in addition to the normal\ndependencies above. Cython can be installed from PyPI:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npip install .\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/cli/pip_install/#install-editable):\n\n\n```sh\npython -m pip install -ve . --no-build-isolation --config-settings=editable-verbose=true\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/docs/dev/development/contributing_environment.html).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on [PyData.org](https://pandas.pydata.org/pandas-docs/stable/).\n\n## Background\nWork on ``pandas`` started at [AQR](https://www.aqr.com/) (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussions take place on GitHub in this repo, via the [GitHub issue tracker](https://github.com/pandas-dev/pandas/issues).\n\nFurther, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Slack channel](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) is available for quick development related questions.\n\nThere are also frequent [community meetings](https://pandas.pydata.org/docs/dev/development/community.html#community-meeting) for project maintainers open to the community as well as monthly [new contributor meetings](https://pandas.pydata.org/docs/dev/development/community.html#new-contributor-meeting) to help support new contributors.\n\nAdditional information on the communication channels can be found on the [contributor community](https://pandas.pydata.org/docs/development/community.html) page.\n\n## Contributing to pandas\n\n[![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)**.\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub \"issues\" tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs&sort=updated&state=open) and [good first issue](https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&sort=updated&state=open) where you could start out.\n\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking â€˜this can be improvedâ€™...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Slack](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack).\n\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/.github/blob/master/CODE_OF_CONDUCT.md)\n\n<hr>\n\n[Go to Top](#table-of-contents)\n",
        "description_content_type": "text/markdown",
        "author_email": "The Pandas Development Team <pandas-dev@python.org>",
        "license": "BSD 3-Clause License\n\n Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n All rights reserved.\n\n Copyright (c) 2011-2023, Open source contributors.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Scientific/Engineering"
        ],
        "requires_dist": [
          "numpy>=1.22.4; python_version < \"3.11\"",
          "numpy>=1.23.2; python_version == \"3.11\"",
          "numpy>=1.26.0; python_version >= \"3.12\"",
          "python-dateutil>=2.8.2",
          "pytz>=2020.1",
          "tzdata>=2022.7",
          "hypothesis>=6.46.1; extra == \"test\"",
          "pytest>=7.3.2; extra == \"test\"",
          "pytest-xdist>=2.2.0; extra == \"test\"",
          "pyarrow>=10.0.1; extra == \"pyarrow\"",
          "bottleneck>=1.3.6; extra == \"performance\"",
          "numba>=0.56.4; extra == \"performance\"",
          "numexpr>=2.8.4; extra == \"performance\"",
          "scipy>=1.10.0; extra == \"computation\"",
          "xarray>=2022.12.0; extra == \"computation\"",
          "fsspec>=2022.11.0; extra == \"fss\"",
          "s3fs>=2022.11.0; extra == \"aws\"",
          "gcsfs>=2022.11.0; extra == \"gcp\"",
          "pandas-gbq>=0.19.0; extra == \"gcp\"",
          "odfpy>=1.4.1; extra == \"excel\"",
          "openpyxl>=3.1.0; extra == \"excel\"",
          "python-calamine>=0.1.7; extra == \"excel\"",
          "pyxlsb>=1.0.10; extra == \"excel\"",
          "xlrd>=2.0.1; extra == \"excel\"",
          "xlsxwriter>=3.0.5; extra == \"excel\"",
          "pyarrow>=10.0.1; extra == \"parquet\"",
          "pyarrow>=10.0.1; extra == \"feather\"",
          "tables>=3.8.0; extra == \"hdf5\"",
          "pyreadstat>=1.2.0; extra == \"spss\"",
          "SQLAlchemy>=2.0.0; extra == \"postgresql\"",
          "psycopg2>=2.9.6; extra == \"postgresql\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"postgresql\"",
          "SQLAlchemy>=2.0.0; extra == \"mysql\"",
          "pymysql>=1.0.2; extra == \"mysql\"",
          "SQLAlchemy>=2.0.0; extra == \"sql-other\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"sql-other\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"sql-other\"",
          "beautifulsoup4>=4.11.2; extra == \"html\"",
          "html5lib>=1.1; extra == \"html\"",
          "lxml>=4.9.2; extra == \"html\"",
          "lxml>=4.9.2; extra == \"xml\"",
          "matplotlib>=3.6.3; extra == \"plot\"",
          "jinja2>=3.1.2; extra == \"output-formatting\"",
          "tabulate>=0.9.0; extra == \"output-formatting\"",
          "PyQt5>=5.15.9; extra == \"clipboard\"",
          "qtpy>=2.3.0; extra == \"clipboard\"",
          "zstandard>=0.19.0; extra == \"compression\"",
          "dataframe-api-compat>=0.1.7; extra == \"consortium-standard\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"all\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"all\"",
          "beautifulsoup4>=4.11.2; extra == \"all\"",
          "bottleneck>=1.3.6; extra == \"all\"",
          "dataframe-api-compat>=0.1.7; extra == \"all\"",
          "fastparquet>=2022.12.0; extra == \"all\"",
          "fsspec>=2022.11.0; extra == \"all\"",
          "gcsfs>=2022.11.0; extra == \"all\"",
          "html5lib>=1.1; extra == \"all\"",
          "hypothesis>=6.46.1; extra == \"all\"",
          "jinja2>=3.1.2; extra == \"all\"",
          "lxml>=4.9.2; extra == \"all\"",
          "matplotlib>=3.6.3; extra == \"all\"",
          "numba>=0.56.4; extra == \"all\"",
          "numexpr>=2.8.4; extra == \"all\"",
          "odfpy>=1.4.1; extra == \"all\"",
          "openpyxl>=3.1.0; extra == \"all\"",
          "pandas-gbq>=0.19.0; extra == \"all\"",
          "psycopg2>=2.9.6; extra == \"all\"",
          "pyarrow>=10.0.1; extra == \"all\"",
          "pymysql>=1.0.2; extra == \"all\"",
          "PyQt5>=5.15.9; extra == \"all\"",
          "pyreadstat>=1.2.0; extra == \"all\"",
          "pytest>=7.3.2; extra == \"all\"",
          "pytest-xdist>=2.2.0; extra == \"all\"",
          "python-calamine>=0.1.7; extra == \"all\"",
          "pyxlsb>=1.0.10; extra == \"all\"",
          "qtpy>=2.3.0; extra == \"all\"",
          "scipy>=1.10.0; extra == \"all\"",
          "s3fs>=2022.11.0; extra == \"all\"",
          "SQLAlchemy>=2.0.0; extra == \"all\"",
          "tables>=3.8.0; extra == \"all\"",
          "tabulate>=0.9.0; extra == \"all\"",
          "xarray>=2022.12.0; extra == \"all\"",
          "xlrd>=2.0.1; extra == \"all\"",
          "xlsxwriter>=3.0.5; extra == \"all\"",
          "zstandard>=0.19.0; extra == \"all\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "homepage, https://pandas.pydata.org",
          "documentation, https://pandas.pydata.org/docs/",
          "repository, https://github.com/pandas-dev/pandas"
        ],
        "provides_extra": [
          "test",
          "pyarrow",
          "performance",
          "computation",
          "fss",
          "aws",
          "gcp",
          "excel",
          "parquet",
          "feather",
          "hdf5",
          "spss",
          "postgresql",
          "mysql",
          "sql-other",
          "html",
          "xml",
          "plot",
          "output-formatting",
          "clipboard",
          "compression",
          "consortium-standard",
          "all"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b8/0c/51f6841f1d84f404f92463fc2b1ba0da357ca1e3db6b7fbda26956c3b82a/ruamel_yaml-0.19.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=27592957fedf6e0b62f281e96effd28043345e0e66001f97683aa9a40c667c93",
          "hashes": {
            "sha256": "27592957fedf6e0b62f281e96effd28043345e0e66001f97683aa9a40c667c93"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "ruamel.yaml",
        "version": "0.19.1",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "keywords",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-python",
          "summary"
        ],
        "summary": "ruamel.yaml is a YAML parser/emitter that supports roundtrip preservation of comments, seq/map flow style, and map key order",
        "description": "# ruamel.yaml\n\n`ruamel.yaml` is a YAML 1.2 loader/dumper package for Python.\n\n| | |\n| - | - |\n| version |0.19.0 |\n| updated |2025-01-02 |\n| documentation |https://yaml.dev/doc/ruamel.yaml |\n| repository |https://sourceforge.net/projects/ruamel-yaml |\n| pypi |https://pypi.org/project/ruamel.yaml |\n\n\n## breaking changes, that may make future uploads to PyPI impossible\n\n*If you are interested in future upgrades of `ruamel.yaml`\nplease check the [documentation on installing](https://yaml.dev/doc/ruamel.yaml/install/),\nsince at some point I might not be able to upload a new version to PyPI with updated information.*\n\n`ruamel.yaml` was intentionally named as `yaml` in a namespace `ruamel`. The namespace allows the installation\nname to correspond unchanged to how the package is imported, reduces the number of links I have to create\nin site-packages of a Python install during development, as well as providing a recognisable set of packages\nmy company releases to the public. \n\nHowever, after uploading version 0.18.7, I got an email from PyPI, about having to change the project name\nto `ruamel_yaml` to comply with PEP 625, sometime in the future. The email doesn't say if namespace packages are\nno longer allowed, or how to deal with the very real clash with the pre-existing package `ruamel_yaml`.\n\nI might not be able to adapt `ruamel.yaml`, in\na way that does not negatively affect the 0.5 million daily downloads (and my own usage of the package) in time. \nMy experience with other such service downgrades (Bitbucket, Readthedocs), has not been entirely positive. \n\n-----\n\n\n\nStarting with 0.19.1 `ruamel.yaml` no longer has a dependency on `ruamel.yaml.clibz`\nnor on the old `ruamel.yaml.clib`.\n\nSome deployment issues were reported on 0.19.0, due to the lack of proper pinning of the\n`ruamel.yaml` version used. Most of these issues had to do with\nthe environment not having updated `setuptools` installed and the build\ndependency `setuptools-zig` for `ruamel.yaml.clibz` not being invoked, with\nPython falling back to invoking gcc (which was even less likely to be installed).\n\nThe already indicated simple solution of using:\n\n```\n    python -m pip install --no-deps ruamel.yaml ruamel.yaml.clib\n\n```\nturned out not to work for at least one setup.\n\nAs I am not aware that you can create an install requirement that removes\na dependency, the default (Cython) dependency is removed and you should\nuse `ruamel.yaml[libyaml]` resp. `ruamel.yaml[oldlibyaml]` as your requirements.\n(this is the preferred way over using `ruamel.yaml.clibz` and `ruamel.yaml.clib`\ndirectly).\nIf you are using `ruamel.yaml` in its default (round-trip, `YAML(typ='rt')`) mode,\nthere is currently no advantage of installing either optional extension.\n\n\nThe C sources are functionally unchanged,\nbut they are now always compiled (using `setuptools-zig` and `ziglang`) on your system,\ninstead of being downloaded as pre-compiled wheels (if available).\nFor this to function properly your Python (virtual) environment needs to have\nan up-to-date version of `setuptools` and `wheels` pre-installed.\n\nThe code to load `ruamel.yaml.clib` has priority over `ruamel.yaml.clibz`\nif both are installed.\nThis compatibility will at least be available during the 0.19 `ruamel.yaml` series\n(so pin your usage of `ruamel.yaml` if necessary and report any problems).\n\nThe motivitation for this change is the availability,\nand easy of use, of Zig as the toolchain\n(in the form of `ziglang` on PyPi), so lenghty, non-optimized,\npre-compilation and uploading to PyPI,\nis no longer necessary.\nThe time spent on creating ~60 wheels\nand even more time wasted on dealing with CI providers (Appveyor\nnot being updated to support 3.14, Github CI being slow,\nand charging for the use of your own computer,\netc).\n\nThe split out of `ruamel.yaml.clib` after the 0.15.100 release,\nwas also motivated by the time spent\non generating .whl files even if only Python code was changed.\nThe use of `ziglang` and `setuptools-zig` does make re-integration of the C sources\ninto `ruamel.yaml` feasable, but there are no plans yet to make this happen.\n\nThe test matrix for `ruamel.yaml.clibz`, of course still has many dimensions:\n```\n    Python versions: 3.9 - 3.14\n    OS-es:           Linux, Alpine (musl), macOS, Windows\n    Architectures:   Intel/AMD, Arm (and others), in 64 and some also in 32 bit versions\n    Zig version:     ziglang < 0.16 is taken from PyPI\n```\n\nI try to test as much of the combinations as possible,\ntrying at least all supported Python versions,\nincluding freethreading,\non macOS-arm64,\nLinux arm64 (via docker containers),\nUbuntu Linux-Intel,\nLinux musl intel (docker).\nAnd at least one Python version along each of the indicated positions of the\ndimensions above (e.g. Windows10 64bit was tested with Python 3.14, but I\ncould not test the RISC-V architecture).\nAs with generating .whl files previously\n(which I could not all test myself)\nI partly have to rely on the process of compilation/generation being likely correct,\nand feedback from actual users,\nof exotic (for me) platforms, is of course welcome.\n\nThere is new section,\nin the documentation,\non the security of processing unchecked input.\n\n-------\n\nThe potentially breaking change announced for the 0.18 series, in that `YAML(typ='unsafe')`\nwas going to be deprecated (now pending), has not yet  been implemented, but is still considered.\nIf you only use `unsafe` to dump, please use the new `YAML(typ='full')`, the result of that can be *safely*\nloaded with a default  instance `YAML()`, as that will get you inspectable, tagged, scalars, instead of\nexecuted Python functions/classes. (You should probably add constructors for what you actually need, \nbut I do consider adding a `ruamel.yaml.unsafe` package that will re-add the `typ='unsafe'` option.\n*Please adjust/pin your dependencies accordingly if necessary.*\n\n-------\n\nVersion 0.18.16 was the last one tested to be working with Python 3.8.\nVersion 0.18.9 was the last one tested to be working with Python 3.7.\nVersion 0.17.21 was the last one tested to be working on Python 3.5 and 3.6.\nThe 0.16.13 release was the last that was tested to be working on Python 2.7.\n\n\nThere are two extra plug-in packages\n(`ruamel.yaml.bytes` and `ruamel.yaml.string`)\nfor those not wanting to do the streaming to a\n`io.BytesIO/StringIO` buffer themselves.\n\nIf your package uses `ruamel.yaml` and is not listed on PyPI, drop me an\nemail, preferably with some information on how you use the package (or a\nlink to the repository) and I'll keep you informed when the status of\nthe API is stable enough to make the transition.\n\nFor packaging purposes you can use a download of the [tar balls of tagged source](https://yaml.dev/ruamel-dl-tagged-releases)\n\n\n<a href=\"https://bestpractices.coreinfrastructure.org/projects/1128\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/1128/badge\"></a>\n<a href=\"https://opensource.org/licenses/MIT\"><img src=\"https://sourceforge.net/p/ruamel-yaml/code/ci/default/tree/_doc/_static/license.svg?format=raw\"></a>\n<a href=\"https://pypi.org/project/ruamel.yaml/\"><img src=\"https://sourceforge.net/p/ruamel-yaml/code/ci/default/tree/_doc/_static/pypi.svg?format=raw\"></a>\n<a href=\"https://pypi.org/project/oitnb/\"><img src=\"https://sourceforge.net/p/oitnb/code/ci/default/tree/_doc/_static/oitnb.svg?format=raw\"></a>\n<a href=\"http://mypy-lang.org/\"><img src=\"http://www.mypy-lang.org/static/mypy_badge.svg\"></a>\n<a href=\"https://www.pepy.tech/projects/ruamel.yaml\"><img src=\"https://img.shields.io/pepy/dt/ruamel.yaml.svg\"></a>\n\n0.19.0 (2025-01-02):\n\n- removed dependency on `ruamel.yaml.clibz`\n\n0.19.0 (2025-12-31):\n\n- changed dependency on `ruamel.yaml.clib` to `ruamel.yaml.clibz` which includes support for free-threading (revisited after a bug report by [Ahmed Moustafa](https://sourceforge.net/u/aemous/profile/) and some insistance by [Nathan Goldbaum](https://sourceforge.net/u/ngoldbaum/profile/)\n- added `.max_depth` to `YAML()` instance. If set to a (positive) number this limits the recursion, so loading does throw a `MaxDepthExceededError`. Based on comments by Benjamin Oberdorfer via email. This also triggered the new documenation section on processing unchecked input.\n\n0.18.17 (2025-12-17):\n\n- try to load C functions from `_ruamel_yaml_clibz` first.\n\n0.18.16 (2025-10-22):\n\n- root level block style scalars that started with a directives-end marker or a document-end marker, are now indented 2 spaces.\n- merged fix for accessing end_marks on Tokens provided by [Toknak](https://sourceforge.net/u/taknok/)\n\n0.18.15 (2025-08-19):\n\n- duplicate merge keys are never allowed (not even with .allow_duplicate_keys = True\n- merge keys now keep there position if a key before the merge key gets deleted (previously a key after the merge key would move before it)\n\n0.18.14 (2025-06-09):\n\n- Fix issue with constructing dataclasses that have a default factoryi attribute, but were missing a mapping value for that attribute. Reported by [Victor Prieto](https://sourceforge.net/u/vsprieto/profile/)\n- the tagged release tar files can now also be downloaded from https://yaml.dev/ruamel-dl-tagged-releases/ please adjust if you use https://sourceforge.net/projects/ruamel-dl-tagged-releases/files/ as that repository in sourceforge will no longer be updated from some later date.\n\n0.18.13 (2025-06-06):\n\n- Fix line wrapping on plain scalars not observing width correctly. Issue 529, reported by [Sebastien Vermeille](https://sourceforge.net/u/svermeille/profile/)\n- Fix sha256 and length in RECORD files. Reported by [Evan](https://sourceforge.net/u/bempelise/profile/)\n\n0.18.12 (2025-05-30):\n\n- fix additional issue with extra space in double quoted string. Reported by [Saugat Pachhai](https://sourceforge.net/u/skshetry/profile/)\n- fix duplicate key url, now pointing to yaml.dev. Reported by [Hugo](https://sourceforge.net/u/hugovk/profile/)\n- fix broken RECORD file, which was a problem for uv, not pip. Reported by [konstin](https://sourceforge.net/u/konstin/profile/)\n\n0.18.11 (2025-05-19):\n\n- function `load_yaml_guess_indent` now takes an option `yaml` argument so you can provide an already created/configured `YAML` instance\n- Sequence item indicator with both comment/empty line before indicator **and** comment before sequence item, could not move comment and raise `NotImplementedError`. Reported by [Karsten Tessarzik](https://sourceforge.net/u/kars10/profile/).\n- missing f for f-string (reported by Ï€, via email)\n- fixed issue with extra space in double quoted dump (reported by [Jan MÃ¶ller](https://sourceforge.net/u/redfiredragon/profile/))\n\n0.18.10 (2025-01-06):\n\n- implemented changes to the setup.py for Python 3.14 as suggested by [Miro HronÄok](https://sourceforge.net/u/hroncok/profile/) in merge requests (MR not merged as those files are copied in from `develop` config)\n\n0.18.9 (2025-01-05):\n\n- fix issue with roundtripping 0 in YAML 1.1 reported by [Peter Law](https://sourceforge.net/u/peterjclaw/profile/)\n\n0.18.8 (2025-01-02):\n\n- added warning to README.md that PyPI might block updates due to breaking changes\n\n0.18.7 (2024-12-30):\n\n- fixes for README (reported by [Kees Bakker](https://sourceforge.net/u/keesb/profile/))\n- fixes preserving anchor on scalar integer `0` (issue reported by (Mor Peled)[https://sourceforge.net/u/morp/profile/] and also in a question by [Ravi](https://stackoverflow.com/users/6550398/ravi) on [Stackoverflow](https://stackoverflow.com/a/79306830/1307905))\n- fix for formatting of README suggested by [Michael R. Crusoe](https://sourceforge.net/u/crusoe/profile/)\n\n0.18.6 (2024-02-07):\n\n- fixed an issue with dataclass loading when the fields were collections (bug found as a result of a question by [FibroMyAlgebra](https://stackoverflow.com/users/6855070/fibromyalgebra) on [StackOverflow](https://stackoverflow.com/a/77485786/1307905))\n- fixed an issue loading dataclasses with `InitVar` fields when `from __future__ import annotations` was used to delay evaluation of typing.\n\n0.18.5 (2023-11-03):\n\n- there is some indication that dependent packages have been pinned to use specific (tested) and just install the latest even in Python versions that have end-of-life\n\n0.18.4 (2023-11-01):\n\n- YAML() instance has a `doc_infos` attribute which is a cumulative list of DocInfo instances (one for `load()`, one per document for `load_all()`). DocInfo instances contain version information (requested, directive) and tag directive information\n- fix issue that the YAML instance tags attribute was not reset between documents, resulting in mixing of tag directives of multiple documents. Now only provides tag directive information on latest document after loading. This means tags for dumping must be set **again** after a document is loaded with the same instance. (because of this tags will be removed in a favour of a different mechanism in the future)\n- fix issue with multiple document intermixing YAML 1.2 and YAML 1.1, the VersionedResolver now resets\n- fix issue with disappearing comment when next token was Tag (still can't have both a comment before a tag and after a tag, before node)\n\n0.18.3 (2023-10-29):\n\n- fix issue with spurious newline on first item after comment + nested block sequence\n- additional links in the metadata on PyPI (Reported, with pointers how to fix, by [Sorin](https://sourceforge.net/u/ssbarnea/profile/)).\n\n0.18.2 (2023-10-24):\n\n- calling the deprecated functions now raises an `AttributeError` with the, somewhat more informative, orginal warning message. Instead of calling `sys.exit(1)`\n\n0.18.1 (2023-10-24):\n\n- calling the deprecated functions now always displays the warning message. (reported by [Trend Lloyd](https://sourceforge.net/u/lathiat2/profile/))\n\n0.18.0 (2023-10-23):\n\n- the **functions** `scan`, `parse`, `compose`, `load`, `emit`, `serialize`, `dump` and their variants (`_all`, `safe_`, `round_trip_`, etc) have been deprecated (the same named **methods** on `YAML()` instances are, of course, still there.\n- `YAML(typ='unsafe')` now issues a `PendingDeprecationWarning`. This will become deprecated in the 0.18 series\n(probably before the end of 2023).\nYou can use `YAML(typ='full')` to dump unregistered Python classes/functions. \nFor loading you'll have to register your classes/functions\nif you want the old, unsafe, functionality. You can still load any tag, like `!!python/name:posix.system', **safely** \nwith the (default) round-trip parser.\n- fix for `bytes-like object is required not 'str' while dumping binary streams`. This was reported, analysed and a fix provided by [Vit Zikmund](https://sourceforge.net/u/tlwhitec/profile/)\n\n\n------------------------------------------------------------------------\n\nFor older changes see the file\n[CHANGES](https://sourceforge.net/p/ruamel-yaml/code/ci/default/tree/CHANGES)\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=CommonMark",
        "keywords": [
          "yaml",
          "1.2",
          "parser",
          "round-trip",
          "preserve",
          "quotes",
          "order",
          "config"
        ],
        "author": "Anthon van der Neut",
        "author_email": "a.van.der.neut@ruamel.eu",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Markup",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "ruamel.yaml.clib; platform_python_implementation == \"CPython\" and extra == \"oldlibyaml\"",
          "ruamel.yaml.clibz>=0.3.7; platform_python_implementation == \"CPython\" and extra == \"libyaml\"",
          "ruamel.yaml.jinja2>=0.2; extra == \"jinja2\"",
          "ryd; extra == \"docs\"",
          "mercurial>5.7; extra == \"docs\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Home, https://sourceforge.net/p/ruamel-yaml/",
          "Source, https://sourceforge.net/p/ruamel-yaml/code/ci/default/tree/",
          "Tracker, https://sourceforge.net/p/ruamel-yaml/tickets/",
          "Documentation, https://yaml.dev/doc/ruamel.yaml"
        ],
        "provides_extra": [
          "oldlibyaml",
          "libyaml",
          "jinja2",
          "docs"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/77/f5/21d2de20e8b8b0408f0681956ca2c69f1320a3848ac50e6e7f39c6159675/babel-2.18.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=e2b422b277c2b9a9630c1d7903c2a00d0830c409c59ac8cae9081c92f1aeba35",
          "hashes": {
            "sha256": "e2b422b277c2b9a9630c1d7903c2a00d0830c409c59ac8cae9081c92f1aeba35"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": true,
      "metadata": {
        "metadata_version": "2.4",
        "name": "babel",
        "version": "2.18.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Internationalization utilities",
        "description": "A collection of tools for internationalizing Python applications.\n",
        "home_page": "https://babel.pocoo.org/",
        "author": "Armin Ronacher",
        "author_email": "armin.ronacher@active-4.com",
        "maintainer": "Aarni Koskela",
        "maintainer_email": "akx@iki.fi",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Internationalization",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "pytz>=2015.7; python_version < \"3.9\"",
          "tzdata; sys_platform == \"win32\" and extra == \"dev\"",
          "backports.zoneinfo; python_version < \"3.9\" and extra == \"dev\"",
          "freezegun~=1.0; extra == \"dev\"",
          "jinja2>=3.0; extra == \"dev\"",
          "pytest-cov; extra == \"dev\"",
          "pytest>=6.0; extra == \"dev\"",
          "pytz; extra == \"dev\"",
          "setuptools; extra == \"dev\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Source, https://github.com/python-babel/babel"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f349ba8f4b75cb25c99c5c2d84e997e485204d2902a9597802b0371f09331fb8",
          "hashes": {
            "sha256": "f349ba8f4b75cb25c99c5c2d84e997e485204d2902a9597802b0371f09331fb8"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "aiohappyeyeballs",
        "version": "2.6.1",
        "summary": "Happy Eyeballs for asyncio",
        "description": "# aiohappyeyeballs\n\n<p align=\"center\">\n  <a href=\"https://github.com/aio-libs/aiohappyeyeballs/actions/workflows/ci.yml?query=branch%3Amain\">\n    <img src=\"https://img.shields.io/github/actions/workflow/status/aio-libs/aiohappyeyeballs/ci-cd.yml?branch=main&label=CI&logo=github&style=flat-square\" alt=\"CI Status\" >\n  </a>\n  <a href=\"https://aiohappyeyeballs.readthedocs.io\">\n    <img src=\"https://img.shields.io/readthedocs/aiohappyeyeballs.svg?logo=read-the-docs&logoColor=fff&style=flat-square\" alt=\"Documentation Status\">\n  </a>\n  <a href=\"https://codecov.io/gh/aio-libs/aiohappyeyeballs\">\n    <img src=\"https://img.shields.io/codecov/c/github/aio-libs/aiohappyeyeballs.svg?logo=codecov&logoColor=fff&style=flat-square\" alt=\"Test coverage percentage\">\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://python-poetry.org/\">\n    <img src=\"https://img.shields.io/badge/packaging-poetry-299bd7?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAASCAYAAABrXO8xAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAJJSURBVHgBfZLPa1NBEMe/s7tNXoxW1KJQKaUHkXhQvHgW6UHQQ09CBS/6V3hKc/AP8CqCrUcpmop3Cx48eDB4yEECjVQrlZb80CRN8t6OM/teagVxYZi38+Yz853dJbzoMV3MM8cJUcLMSUKIE8AzQ2PieZzFxEJOHMOgMQQ+dUgSAckNXhapU/NMhDSWLs1B24A8sO1xrN4NECkcAC9ASkiIJc6k5TRiUDPhnyMMdhKc+Zx19l6SgyeW76BEONY9exVQMzKExGKwwPsCzza7KGSSWRWEQhyEaDXp6ZHEr416ygbiKYOd7TEWvvcQIeusHYMJGhTwF9y7sGnSwaWyFAiyoxzqW0PM/RjghPxF2pWReAowTEXnDh0xgcLs8l2YQmOrj3N7ByiqEoH0cARs4u78WgAVkoEDIDoOi3AkcLOHU60RIg5wC4ZuTC7FaHKQm8Hq1fQuSOBvX/sodmNJSB5geaF5CPIkUeecdMxieoRO5jz9bheL6/tXjrwCyX/UYBUcjCaWHljx1xiX6z9xEjkYAzbGVnB8pvLmyXm9ep+W8CmsSHQQY77Zx1zboxAV0w7ybMhQmfqdmmw3nEp1I0Z+FGO6M8LZdoyZnuzzBdjISicKRnpxzI9fPb+0oYXsNdyi+d3h9bm9MWYHFtPeIZfLwzmFDKy1ai3p+PDls1Llz4yyFpferxjnyjJDSEy9CaCx5m2cJPerq6Xm34eTrZt3PqxYO1XOwDYZrFlH1fWnpU38Y9HRze3lj0vOujZcXKuuXm3jP+s3KbZVra7y2EAAAAAASUVORK5CYII=\" alt=\"Poetry\">\n  </a>\n  <a href=\"https://github.com/astral-sh/ruff\">\n    <img src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\" alt=\"Ruff\">\n  </a>\n  <a href=\"https://github.com/pre-commit/pre-commit\">\n    <img src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white&style=flat-square\" alt=\"pre-commit\">\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/aiohappyeyeballs/\">\n    <img src=\"https://img.shields.io/pypi/v/aiohappyeyeballs.svg?logo=python&logoColor=fff&style=flat-square\" alt=\"PyPI Version\">\n  </a>\n  <img src=\"https://img.shields.io/pypi/pyversions/aiohappyeyeballs.svg?style=flat-square&logo=python&amp;logoColor=fff\" alt=\"Supported Python versions\">\n  <img src=\"https://img.shields.io/pypi/l/aiohappyeyeballs.svg?style=flat-square\" alt=\"License\">\n</p>\n\n---\n\n**Documentation**: <a href=\"https://aiohappyeyeballs.readthedocs.io\" target=\"_blank\">https://aiohappyeyeballs.readthedocs.io </a>\n\n**Source Code**: <a href=\"https://github.com/aio-libs/aiohappyeyeballs\" target=\"_blank\">https://github.com/aio-libs/aiohappyeyeballs </a>\n\n---\n\n[Happy Eyeballs](https://en.wikipedia.org/wiki/Happy_Eyeballs)\n([RFC 8305](https://www.rfc-editor.org/rfc/rfc8305.html))\n\n## Use case\n\nThis library exists to allow connecting with\n[Happy Eyeballs](https://en.wikipedia.org/wiki/Happy_Eyeballs)\n([RFC 8305](https://www.rfc-editor.org/rfc/rfc8305.html))\nwhen you\nalready have a list of addrinfo and not a DNS name.\n\nThe stdlib version of `loop.create_connection()`\nwill only work when you pass in an unresolved name which\nis not a good fit when using DNS caching or resolving\nnames via another method such as `zeroconf`.\n\n## Installation\n\nInstall this via pip (or your favourite package manager):\n\n`pip install aiohappyeyeballs`\n\n## License\n\n[aiohappyeyeballs is licensed under the same terms as cpython itself.](https://github.com/python/cpython/blob/main/LICENSE)\n\n## Example usage\n\n```python\n\naddr_infos = await loop.getaddrinfo(\"example.org\", 80)\n\nsocket = await start_connection(addr_infos)\nsocket = await start_connection(addr_infos, local_addr_infos=local_addr_infos, happy_eyeballs_delay=0.2)\n\ntransport, protocol = await loop.create_connection(\n    MyProtocol, sock=socket, ...)\n\n# Remove the first address for each family from addr_info\npop_addr_infos_interleave(addr_info, 1)\n\n# Remove all matching address from addr_info\nremove_addr_infos(addr_info, \"dead::beef::\")\n\n# Convert a local_addr to local_addr_infos\nlocal_addr_infos = addr_to_addr_infos((\"127.0.0.1\",0))\n```\n\n## Credits\n\nThis package contains code from cpython and is licensed under the same terms as cpython itself.\n\nThis package was created with\n[Copier](https://copier.readthedocs.io/) and the\n[browniebroke/pypackage-template](https://github.com/browniebroke/pypackage-template)\nproject template.\n\n",
        "description_content_type": "text/markdown",
        "author": "J. Nick Koston",
        "author_email": "nick@koston.org",
        "license": "PSF-2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Topic :: Software Development :: Libraries",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: Python Software Foundation License"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Bug Tracker, https://github.com/aio-libs/aiohappyeyeballs/issues",
          "Changelog, https://github.com/aio-libs/aiohappyeyeballs/blob/main/CHANGELOG.md",
          "Documentation, https://aiohappyeyeballs.readthedocs.io",
          "Repository, https://github.com/aio-libs/aiohappyeyeballs"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/57/ab/31646a49209568cde3b97eeade0d28bb78b400e6645c56422c101df68932/aiortc-1.14.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4b244d7e482f4e1f67e685b3468269628eca1ec91fa5b329ab517738cfca086e",
          "hashes": {
            "sha256": "4b244d7e482f4e1f67e685b3468269628eca1ec91fa5b329ab517738cfca086e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "aiortc",
        "version": "1.14.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "An implementation of WebRTC and ORTC",
        "description": ".. image:: docs/_static/aiortc.svg\n   :width: 120px\n   :alt: aiortc\n\n.. image:: https://img.shields.io/pypi/l/aiortc.svg\n   :target: https://pypi.python.org/pypi/aiortc\n   :alt: License\n\n.. image:: https://img.shields.io/pypi/v/aiortc.svg\n   :target: https://pypi.python.org/pypi/aiortc\n   :alt: Version\n\n.. image:: https://img.shields.io/pypi/pyversions/aiortc.svg\n   :target: https://pypi.python.org/pypi/aiortc\n   :alt: Python versions\n\n.. image:: https://github.com/aiortc/aiortc/workflows/tests/badge.svg\n   :target: https://github.com/aiortc/aiortc/actions\n   :alt: Tests\n\n.. image:: https://img.shields.io/codecov/c/github/aiortc/aiortc.svg\n   :target: https://codecov.io/gh/aiortc/aiortc\n   :alt: Coverage\n\n.. image:: https://readthedocs.org/projects/aiortc/badge/?version=latest\n   :target: https://aiortc.readthedocs.io/\n   :alt: Documentation\n\nWhat is ``aiortc``?\n-------------------\n\n``aiortc`` is a library for `Web Real-Time Communication (WebRTC)`_ and\n`Object Real-Time Communication (ORTC)`_ in Python. It is built on top of\n``asyncio``, Python's standard asynchronous I/O framework.\n\nThe API closely follows its Javascript counterpart while using pythonic\nconstructs:\n\n- promises are replaced by coroutines\n- events are emitted using ``pyee.EventEmitter``\n\nTo learn more about ``aiortc`` please `read the documentation`_.\n\n.. _Web Real-Time Communication (WebRTC): https://webrtc.org/\n.. _Object Real-Time Communication (ORTC): https://ortc.org/\n.. _read the documentation: https://aiortc.readthedocs.io/en/latest/\n\nWhy should I use ``aiortc``?\n----------------------------\n\nThe main WebRTC and ORTC implementations are either built into web browsers,\nor come in the form of native code. While they are extensively battle tested,\ntheir internals are complex and they do not provide Python bindings.\nFurthermore they are tightly coupled to a media stack, making it hard to plug\nin audio or video processing algorithms.\n\nIn contrast, the ``aiortc`` implementation is fairly simple and readable. As\nsuch it is a good starting point for programmers wishing to understand how\nWebRTC works or tinker with its internals. It is also easy to create innovative\nproducts by leveraging the extensive modules available in the Python ecosystem.\nFor instance you can build a full server handling both signaling and data\nchannels or apply computer vision algorithms to video frames using OpenCV.\n\nFurthermore, a lot of effort has gone into writing an extensive test suite for\nthe ``aiortc`` code to ensure best-in-class code quality.\n\nImplementation status\n---------------------\n\n``aiortc`` allows you to exchange audio, video and data channels and\ninteroperability is regularly tested against both Chrome and Firefox. Here are\nsome of its features:\n\n- SDP generation / parsing\n- Interactive Connectivity Establishment, with half-trickle and mDNS support\n- DTLS key and certificate generation\n- DTLS handshake, encryption / decryption (for SCTP)\n- SRTP keying, encryption and decryption for RTP and RTCP\n- Pure Python SCTP implementation\n- Data Channels\n- Sending and receiving audio (Opus / PCMU / PCMA)\n- Sending and receiving video (VP8 / H.264)\n- Bundling audio / video / data channels\n- RTCP reports, including NACK / PLI to recover from packet loss\n\nInstalling\n----------\n\nThe easiest way to install ``aiortc`` is to run:\n\n.. code:: bash\n\n    pip install aiortc\n\nLicense\n-------\n\n``aiortc`` is released under the `BSD license`_.\n\n.. _BSD license: https://aiortc.readthedocs.io/en/latest/license.html\n",
        "description_content_type": "text/x-rst",
        "author_email": "Jeremy LainÃ© <jeremy.laine@m4x.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_dist": [
          "aioice<1.0.0,>=0.10.1",
          "av<17.0.0,>=14.0.0",
          "cryptography>=44.0.0",
          "google-crc32c>=1.1",
          "pyee>=13.0.0",
          "pylibsrtp>=0.10.0",
          "pyopenssl>=25.0.0",
          "aiohttp>=3.7.0; extra == \"dev\"",
          "coverage[toml]>=7.2.2; extra == \"dev\"",
          "numpy>=1.19.0; extra == \"dev\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://github.com/aiortc/aiortc",
          "changelog, https://aiortc.readthedocs.io/en/stable/changelog.html",
          "documentation, https://aiortc.readthedocs.io/"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c7/e3/0d23b1f930c17d371ce1ec36ee529f22fd19ebc2a07fe3418e3d1d884ce2/aioice-0.10.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=14911c15ab12d096dd14d372ebb4aecbb7420b52c9b76fdfcf54375dec17fcbf",
          "hashes": {
            "sha256": "14911c15ab12d096dd14d372ebb4aecbb7420b52c9b76fdfcf54375dec17fcbf"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "aioice",
        "version": "0.10.2",
        "dynamic": [
          "license-file"
        ],
        "summary": "An implementation of Interactive Connectivity Establishment (RFC 5245)",
        "description": "aioice\n======\n\n|rtd| |pypi-v| |pypi-pyversions| |pypi-l| |pypi-wheel| |tests| |codecov|\n\n.. |rtd| image:: https://readthedocs.org/projects/aioice/badge/?version=latest\n   :target: https://aioice.readthedocs.io/\n\n.. |pypi-v| image:: https://img.shields.io/pypi/v/aioice.svg\n    :target: https://pypi.python.org/pypi/aioice\n\n.. |pypi-pyversions| image:: https://img.shields.io/pypi/pyversions/aioice.svg\n    :target: https://pypi.python.org/pypi/aioice\n\n.. |pypi-l| image:: https://img.shields.io/pypi/l/aioice.svg\n    :target: https://pypi.python.org/pypi/aioice\n\n.. |pypi-wheel| image:: https://img.shields.io/pypi/wheel/aioice.svg\n    :target: https://pypi.python.org/pypi/aioice\n\n.. |tests| image:: https://github.com/aiortc/aioice/workflows/tests/badge.svg\n    :target: https://github.com/aiortc/aioice/actions\n\n.. |codecov| image:: https://img.shields.io/codecov/c/github/aiortc/aioice.svg\n    :target: https://codecov.io/gh/aiortc/aioice\n\nWhat is ``aioice``?\n-------------------\n\n``aioice`` is a library for Interactive Connectivity Establishment (RFC 5245)\nin Python. It is built on top of ``asyncio``, Python's standard asynchronous\nI/O framework.\n\nInteractive Connectivity Establishment (ICE) is useful for applications that\nestablish peer-to-peer UDP data streams, as it facilitates NAT traversal.\nTypical usecases include SIP and WebRTC.\n\nTo learn more about ``aioice`` please `read the documentation`_.\n\n.. _read the documentation: https://aioice.readthedocs.io/en/stable/\n\nExample\n-------\n\n.. code:: python\n\n    import asyncio\n    import aioice\n\n    async def connect_using_ice():\n        connection = aioice.Connection(ice_controlling=True)\n\n        # gather local candidates\n        await connection.gather_candidates()\n\n        # send your information to the remote party using your signaling method\n        send_local_info(\n            connection.local_candidates,\n            connection.local_username,\n            connection.local_password)\n\n        # receive remote information using your signaling method\n        remote_candidates, remote_username, remote_password = get_remote_info()\n\n        # perform ICE handshake\n        for candidate in remote_candidates:\n            await connection.add_remote_candidate(candidate)\n        await connection.add_remote_candidate(None)\n        connection.remote_username = remote_username\n        connection.remote_password = remote_password\n        await connection.connect()\n\n        # send and receive data\n        await connection.sendto(b'1234', 1)\n        data, component = await connection.recvfrom()\n\n        # close connection\n        await connection.close()\n\n    asyncio.run(connect_using_ice())\n\nLicense\n-------\n\n``aioice`` is released under the `BSD license`_.\n\n.. _BSD license: https://aioice.readthedocs.io/en/stable/license.html\n",
        "description_content_type": "text/x-rst",
        "author_email": "Jeremy LainÃ© <jeremy.laine@m4x.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "dnspython>=2.0.0",
          "ifaddr>=0.2.0",
          "coverage[toml]>=7.2.2; extra == \"dev\"",
          "mypy; extra == \"dev\"",
          "pyopenssl; extra == \"dev\"",
          "ruff; extra == \"dev\"",
          "websockets; extra == \"dev\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/aiortc/aioice",
          "Changelog, https://aioice.readthedocs.io/en/stable/changelog.html",
          "Documentation, https://aioice.readthedocs.io/"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/fc/7a/22158fb923b2a9a00dfab0e96ef2e8a1763a94dd89e666a5858412383d46/av-16.1.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=565093ebc93b2f4b76782589564869dadfa83af5b852edebedd8fee746457d06",
          "hashes": {
            "sha256": "565093ebc93b2f4b76782589564869dadfa83af5b852edebedd8fee746457d06"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "av",
        "version": "16.1.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Pythonic bindings for FFmpeg's libraries.",
        "description": "PyAV\r\n====\r\n\r\nPyAV is a Pythonic binding for the [FFmpeg][ffmpeg] libraries. We aim to provide all of the power and control of the underlying library, but manage the gritty details as much as possible.\r\n\r\n---\r\n\r\n[![GitHub Test Status][github-tests-badge]][github-tests] [![Documentation][docs-badge]][docs] [![Python Package Index][pypi-badge]][pypi] [![Conda Forge][conda-badge]][conda]\r\n\r\nPyAV is for direct and precise access to your media via containers, streams, packets, codecs, and frames. It exposes a few transformations of that data, and helps you get your data to/from other packages (e.g. Numpy and Pillow).\r\n\r\nThis power does come with some responsibility as working with media is horrendously complicated and PyAV can't abstract it away or make all the best decisions for you. If the `ffmpeg` command does the job without you bending over backwards, PyAV is likely going to be more of a hindrance than a help.\r\n\r\nBut where you can't work without it, PyAV is a critical tool.\r\n\r\n\r\nInstallation\r\n------------\r\n\r\nBinary wheels are provided on [PyPI][pypi] for Linux, MacOS and Windows linked against the latest stable version of ffmpeg. You can install these wheels by running:\r\n\r\n```bash\r\npip install av\r\n```\r\n\r\nAnother way of installing PyAV is via [conda-forge][conda-forge]:\r\n\r\n```bash\r\nconda install av -c conda-forge\r\n```\r\n\r\nSee the [Conda install][conda-install] docs to get started with (mini)Conda.\r\n\r\n\r\nAlternative installation methods\r\n--------------------------------\r\n\r\nDue to the complexity of the dependencies, PyAV is not always the easiest Python package to install from source. If you want to use your existing ffmpeg (must be the correct major version), the source version of PyAV is on [PyPI][pypi]:\r\n\r\n> [!WARNING]\r\n> You must be in a posix env, and have the correct version of ffmpeg installed on your system.\r\n\r\n```bash\r\npip install av --no-binary av\r\n```\r\n\r\n\r\nInstalling From Source\r\n----------------------\r\n\r\nHere's how to build PyAV from source. You must use [MSYS2](https://www.msys2.org/) when using Windows.\r\n\r\n```bash\r\ngit clone https://github.com/PyAV-Org/PyAV.git\r\ncd PyAV\r\nsource scripts/activate.sh\r\n\r\n# Build ffmpeg from source. You can skip this step\r\n# if ffmpeg is already installed.\r\n./scripts/build-deps\r\n\r\n# Build PyAV\r\nmake\r\n\r\n# Testing\r\nmake test\r\n\r\n# Install globally\r\ndeactivate\r\npip install .\r\n```\r\n\r\n---\r\n\r\nHave fun, [read the docs][docs], [come chat with us][discuss], and good luck!\r\n\r\n\r\n\r\n[conda-badge]: https://img.shields.io/conda/vn/conda-forge/av.svg?colorB=CCB39A\r\n[conda]: https://anaconda.org/conda-forge/av\r\n[docs-badge]: https://img.shields.io/badge/docs-on%20pyav.basswood--io.com-blue.svg\r\n[docs]: https://pyav.basswood-io.com\r\n[pypi-badge]: https://img.shields.io/pypi/v/av.svg?colorB=CCB39A\r\n[pypi]: https://pypi.org/project/av\r\n[discuss]: https://github.com/PyAV-Org/PyAV/discussions\r\n\r\n[github-tests-badge]: https://github.com/PyAV-Org/PyAV/workflows/tests/badge.svg\r\n[github-tests]: https://github.com/PyAV-Org/PyAV/actions?workflow=tests\r\n[github]: https://github.com/PyAV-Org/PyAV\r\n\r\n[ffmpeg]: https://ffmpeg.org/\r\n[conda-forge]: https://conda-forge.github.io/\r\n[conda-install]: https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html\r\n",
        "description_content_type": "text/markdown",
        "author_email": "WyattBlue <wyattblue@auto-editor.com>, Jeremy LainÃ© <jeremy.laine@m4x.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt",
          "AUTHORS.py",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Cython",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Multimedia :: Sound/Audio",
          "Topic :: Multimedia :: Sound/Audio :: Conversion",
          "Topic :: Multimedia :: Video",
          "Topic :: Multimedia :: Video :: Conversion"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Bug Tracker, https://github.com/PyAV-Org/PyAV/issues",
          "Source Code, https://github.com/PyAV-Org/PyAV",
          "homepage, https://pyav.basswood-io.com"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=053243f8b92b990551949e63930a839ff0cf0b0ebbe0597b0f3fb19e1a0fe82e",
          "hashes": {
            "sha256": "053243f8b92b990551949e63930a839ff0cf0b0ebbe0597b0f3fb19e1a0fe82e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "aiosignal",
        "version": "1.4.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "aiosignal: a list of registered asynchronous callbacks",
        "description": "=========\naiosignal\n=========\n\n.. image:: https://github.com/aio-libs/aiosignal/workflows/CI/badge.svg\n   :target: https://github.com/aio-libs/aiosignal/actions?query=workflow%3ACI\n   :alt: GitHub status for master branch\n\n.. image:: https://codecov.io/gh/aio-libs/aiosignal/branch/master/graph/badge.svg?flag=pytest\n   :target: https://codecov.io/gh/aio-libs/aiosignal?flags[0]=pytest\n   :alt: codecov.io status for master branch\n\n.. image:: https://badge.fury.io/py/aiosignal.svg\n   :target: https://pypi.org/project/aiosignal\n   :alt: Latest PyPI package version\n\n.. image:: https://readthedocs.org/projects/aiosignal/badge/?version=latest\n   :target: https://aiosignal.readthedocs.io/\n   :alt: Latest Read The Docs\n\n.. image:: https://img.shields.io/discourse/topics?server=https%3A%2F%2Faio-libs.discourse.group%2F\n   :target: https://aio-libs.discourse.group/\n   :alt: Discourse group for io-libs\n\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n   :target: https://gitter.im/aio-libs/Lobby\n   :alt: Chat on Gitter\n\nIntroduction\n============\n\nA project to manage callbacks in `asyncio` projects.\n\n``Signal`` is a list of registered asynchronous callbacks.\n\nThe signal's life-cycle has two stages: after creation its content\ncould be filled by using standard list operations: ``sig.append()``\netc.\n\nAfter you call ``sig.freeze()`` the signal is *frozen*: adding, removing\nand dropping callbacks is forbidden.\n\nThe only available operation is calling the previously registered\ncallbacks by using ``await sig.send(data)``.\n\nFor concrete usage examples see the `Signals\n<https://docs.aiohttp.org/en/stable/web_advanced.html#aiohttp-web-signals>\nsection of the `Web Server Advanced\n<https://docs.aiohttp.org/en/stable/web_advanced.html>` chapter of the `aiohttp\ndocumentation`_.\n\n\nInstallation\n------------\n\n::\n\n   $ pip install aiosignal\n\n\nDocumentation\n=============\n\nhttps://aiosignal.readthedocs.io/\n\nLicense\n=======\n\n``aiosignal`` is offered under the Apache 2 license.\n\nSource code\n===========\n\nThe project is hosted on GitHub_\n\nPlease file an issue in the `bug tracker\n<https://github.com/aio-libs/aiosignal/issues>`_ if you have found a bug\nor have some suggestions to improve the library.\n\n.. _GitHub: https://github.com/aio-libs/aiosignal\n.. _aiohttp documentation: https://docs.aiohttp.org/\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/aio-libs/aiosignal",
        "maintainer": "aiohttp team <team@aiohttp.org>",
        "maintainer_email": "team@aiohttp.org",
        "license": "Apache 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Development Status :: 5 - Production/Stable",
          "Operating System :: POSIX",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Framework :: AsyncIO"
        ],
        "requires_dist": [
          "frozenlist>=1.1.0",
          "typing-extensions>=4.2; python_version < \"3.13\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat: Gitter, https://gitter.im/aio-libs/Lobby",
          "CI: GitHub Actions, https://github.com/aio-libs/aiosignal/actions",
          "Coverage: codecov, https://codecov.io/github/aio-libs/aiosignal",
          "Docs: RTD, https://docs.aiosignal.org",
          "GitHub: issues, https://github.com/aio-libs/aiosignal/issues",
          "GitHub: repo, https://github.com/aio-libs/aiosignal"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/1e/d3/26bf1008eb3d2daa8ef4cacc7f3bfdc11818d111f7e2d0201bc6e3b49d45/annotated_doc-0.0.4-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=571ac1dc6991c450b25a9c2d84a3705e2ae7a53467b5d111c24fa8baabbed320",
          "hashes": {
            "sha256": "571ac1dc6991c450b25a9c2d84a3705e2ae7a53467b5d111c24fa8baabbed320"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "annotated-doc",
        "version": "0.0.4",
        "summary": "Document parameters, class attributes, return types, and variables inline, with Annotated.",
        "description": "# Annotated Doc\n\nDocument parameters, class attributes, return types, and variables inline, with `Annotated`.\n\n<a href=\"https://github.com/fastapi/annotated-doc/actions?query=workflow%3ATest+event%3Apush+branch%3Amain\" target=\"_blank\">\n    <img src=\"https://github.com/fastapi/annotated-doc/actions/workflows/test.yml/badge.svg?event=push&branch=main\" alt=\"Test\">\n</a>\n<a href=\"https://coverage-badge.samuelcolvin.workers.dev/redirect/fastapi/annotated-doc\" target=\"_blank\">\n    <img src=\"https://coverage-badge.samuelcolvin.workers.dev/fastapi/annotated-doc.svg\" alt=\"Coverage\">\n</a>\n<a href=\"https://pypi.org/project/annotated-doc\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/v/annotated-doc?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n</a>\n<a href=\"https://pypi.org/project/annotated-doc\" target=\"_blank\">\n    <img src=\"https://img.shields.io/pypi/pyversions/annotated-doc.svg?color=%2334D058\" alt=\"Supported Python versions\">\n</a>\n\n## Installation\n\n```bash\npip install annotated-doc\n```\n\nOr with `uv`:\n\n```Python\nuv add annotated-doc\n```\n\n## Usage\n\nImport `Doc` and pass a single literal string with the documentation for the specific parameter, class attribute, return type, or variable.\n\nFor example, to document a parameter `name` in a function `hi` you could do:\n\n```Python\nfrom typing import Annotated\n\nfrom annotated_doc import Doc\n\ndef hi(name: Annotated[str, Doc(\"Who to say hi to\")]) -> None:\n    print(f\"Hi, {name}!\")\n```\n\nYou can also use it to document class attributes:\n\n```Python\nfrom typing import Annotated\n\nfrom annotated_doc import Doc\n\nclass User:\n    name: Annotated[str, Doc(\"The user's name\")]\n    age: Annotated[int, Doc(\"The user's age\")]\n```\n\nThe same way, you could document return types and variables, or anything that could have a type annotation with `Annotated`.\n\n## Who Uses This\n\n`annotated-doc` was made for:\n\n* [FastAPI](https://fastapi.tiangolo.com/)\n* [Typer](https://typer.tiangolo.com/)\n* [SQLModel](https://sqlmodel.tiangolo.com/)\n* [Asyncer](https://asyncer.tiangolo.com/)\n\n`annotated-doc` is supported by [griffe-typingdoc](https://github.com/mkdocstrings/griffe-typingdoc), which powers reference documentation like the one in the [FastAPI Reference](https://fastapi.tiangolo.com/reference/).\n\n## Reasons not to use `annotated-doc`\n\nYou are already comfortable with one of the existing docstring formats, like:\n\n* Sphinx\n* numpydoc\n* Google\n* Keras\n\nYour team is already comfortable using them.\n\nYou prefer having the documentation about parameters all together in a docstring, separated from the code defining them.\n\nYou care about a specific set of users, using one specific editor, and that editor already has support for the specific docstring format you use.\n\n## Reasons to use `annotated-doc`\n\n* No micro-syntax to learn for newcomers, itâ€™s **just Python** syntax.\n* **Editing** would be already fully supported by default by any editor (current or future) supporting Python syntax, including syntax errors, syntax highlighting, etc.\n* **Rendering** would be relatively straightforward to implement by static tools (tools that don't need runtime execution), as the information can be extracted from the AST they normally already create.\n* **Deduplication of information**: the name of a parameter would be defined in a single place, not duplicated inside of a docstring.\n* **Elimination** of the possibility of having **inconsistencies** when removing a parameter or class variable and **forgetting to remove** its documentation.\n* **Minimization** of the probability of adding a new parameter or class variable and **forgetting to add its documentation**.\n* **Elimination** of the possibility of having **inconsistencies** between the **name** of a parameter in the **signature** and the name in the docstring when it is renamed.\n* **Access** to the documentation string for each symbol at **runtime**, including existing (older) Python versions.\n* A more formalized way to document other symbols, like type aliases, that could use Annotated.\n* **Support** for apps using FastAPI, Typer and others.\n* **AI Accessibility**: AI tools will have an easier way understanding each parameter as the distance from documentation to parameter is much closer.\n\n## History\n\nI ([@tiangolo](https://github.com/tiangolo)) originally wanted for this to be part of the Python standard library (in [PEP 727](https://peps.python.org/pep-0727/)), but the proposal was withdrawn as there was a fair amount of negative feedback and opposition.\n\nThe conclusion was that this was better done as an external effort, in a third-party library.\n\nSo, here it is, with a simpler approach, as a third-party library, in a way that can be used by others, starting with FastAPI and friends.\n\n## License\n\nThis project is licensed under the terms of the MIT license.\n",
        "description_content_type": "text/markdown",
        "author_email": "=?utf-8?q?Sebasti=C3=A1n_Ram=C3=ADrez?= <tiangolo@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Application Frameworks",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development",
          "Typing :: Typed",
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/fastapi/annotated-doc",
          "Documentation, https://github.com/fastapi/annotated-doc",
          "Repository, https://github.com/fastapi/annotated-doc",
          "Issues, https://github.com/fastapi/annotated-doc/issues",
          "Changelog, https://github.com/fastapi/annotated-doc/release-notes.md"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53",
          "hashes": {
            "sha256": "1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.3",
        "name": "annotated-types",
        "version": "0.7.0",
        "summary": "Reusable constraint types to use with typing.Annotated",
        "description": "# annotated-types\n\n[![CI](https://github.com/annotated-types/annotated-types/workflows/CI/badge.svg?event=push)](https://github.com/annotated-types/annotated-types/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![pypi](https://img.shields.io/pypi/v/annotated-types.svg)](https://pypi.python.org/pypi/annotated-types)\n[![versions](https://img.shields.io/pypi/pyversions/annotated-types.svg)](https://github.com/annotated-types/annotated-types)\n[![license](https://img.shields.io/github/license/annotated-types/annotated-types.svg)](https://github.com/annotated-types/annotated-types/blob/main/LICENSE)\n\n[PEP-593](https://peps.python.org/pep-0593/) added `typing.Annotated` as a way of\nadding context-specific metadata to existing types, and specifies that\n`Annotated[T, x]` _should_ be treated as `T` by any tool or library without special\nlogic for `x`.\n\nThis package provides metadata objects which can be used to represent common\nconstraints such as upper and lower bounds on scalar values and collection sizes,\na `Predicate` marker for runtime checks, and\ndescriptions of how we intend these metadata to be interpreted. In some cases,\nwe also note alternative representations which do not require this package.\n\n## Install\n\n```bash\npip install annotated-types\n```\n\n## Examples\n\n```python\nfrom typing import Annotated\nfrom annotated_types import Gt, Len, Predicate\n\nclass MyClass:\n    age: Annotated[int, Gt(18)]                         # Valid: 19, 20, ...\n                                                        # Invalid: 17, 18, \"19\", 19.0, ...\n    factors: list[Annotated[int, Predicate(is_prime)]]  # Valid: 2, 3, 5, 7, 11, ...\n                                                        # Invalid: 4, 8, -2, 5.0, \"prime\", ...\n\n    my_list: Annotated[list[int], Len(0, 10)]           # Valid: [], [10, 20, 30, 40, 50]\n                                                        # Invalid: (1, 2), [\"abc\"], [0] * 20\n```\n\n## Documentation\n\n_While `annotated-types` avoids runtime checks for performance, users should not\nconstruct invalid combinations such as `MultipleOf(\"non-numeric\")` or `Annotated[int, Len(3)]`.\nDownstream implementors may choose to raise an error, emit a warning, silently ignore\na metadata item, etc., if the metadata objects described below are used with an\nincompatible type - or for any other reason!_\n\n### Gt, Ge, Lt, Le\n\nExpress inclusive and/or exclusive bounds on orderable values - which may be numbers,\ndates, times, strings, sets, etc. Note that the boundary value need not be of the\nsame type that was annotated, so long as they can be compared: `Annotated[int, Gt(1.5)]`\nis fine, for example, and implies that the value is an integer x such that `x > 1.5`.\n\nWe suggest that implementors may also interpret `functools.partial(operator.le, 1.5)`\nas being equivalent to `Gt(1.5)`, for users who wish to avoid a runtime dependency on\nthe `annotated-types` package.\n\nTo be explicit, these types have the following meanings:\n\n* `Gt(x)` - value must be \"Greater Than\" `x` - equivalent to exclusive minimum\n* `Ge(x)` - value must be \"Greater than or Equal\" to `x` - equivalent to inclusive minimum\n* `Lt(x)` - value must be \"Less Than\" `x` - equivalent to exclusive maximum\n* `Le(x)` - value must be \"Less than or Equal\" to `x` - equivalent to inclusive maximum\n\n### Interval\n\n`Interval(gt, ge, lt, le)` allows you to specify an upper and lower bound with a single\nmetadata object. `None` attributes should be ignored, and non-`None` attributes\ntreated as per the single bounds above.\n\n### MultipleOf\n\n`MultipleOf(multiple_of=x)` might be interpreted in two ways:\n\n1. Python semantics, implying `value % multiple_of == 0`, or\n2. [JSONschema semantics](https://json-schema.org/draft/2020-12/json-schema-validation.html#rfc.section.6.2.1),\n   where `int(value / multiple_of) == value / multiple_of`.\n\nWe encourage users to be aware of these two common interpretations and their\ndistinct behaviours, especially since very large or non-integer numbers make\nit easy to cause silent data corruption due to floating-point imprecision.\n\nWe encourage libraries to carefully document which interpretation they implement.\n\n### MinLen, MaxLen, Len\n\n`Len()` implies that `min_length <= len(value) <= max_length` - lower and upper bounds are inclusive.\n\nAs well as `Len()` which can optionally include upper and lower bounds, we also\nprovide `MinLen(x)` and `MaxLen(y)` which are equivalent to `Len(min_length=x)`\nand `Len(max_length=y)` respectively.\n\n`Len`, `MinLen`, and `MaxLen` may be used with any type which supports `len(value)`.\n\nExamples of usage:\n\n* `Annotated[list, MaxLen(10)]` (or `Annotated[list, Len(max_length=10))`) - list must have a length of 10 or less\n* `Annotated[str, MaxLen(10)]` - string must have a length of 10 or less\n* `Annotated[list, MinLen(3))` (or `Annotated[list, Len(min_length=3))`) - list must have a length of 3 or more\n* `Annotated[list, Len(4, 6)]` - list must have a length of 4, 5, or 6\n* `Annotated[list, Len(8, 8)]` - list must have a length of exactly 8\n\n#### Changed in v0.4.0\n\n* `min_inclusive` has been renamed to `min_length`, no change in meaning\n* `max_exclusive` has been renamed to `max_length`, upper bound is now **inclusive** instead of **exclusive**\n* The recommendation that slices are interpreted as `Len` has been removed due to ambiguity and different semantic\n  meaning of the upper bound in slices vs. `Len`\n\nSee [issue #23](https://github.com/annotated-types/annotated-types/issues/23) for discussion.\n\n### Timezone\n\n`Timezone` can be used with a `datetime` or a `time` to express which timezones\nare allowed. `Annotated[datetime, Timezone(None)]` must be a naive datetime.\n`Timezone[...]` ([literal ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis))\nexpresses that any timezone-aware datetime is allowed. You may also pass a specific\ntimezone string or [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects)\nobject such as `Timezone(timezone.utc)` or `Timezone(\"Africa/Abidjan\")` to express that you only\nallow a specific timezone, though we note that this is often a symptom of fragile design.\n\n#### Changed in v0.x.x\n\n* `Timezone` accepts [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects) objects instead of\n  `timezone`, extending compatibility to [`zoneinfo`](https://docs.python.org/3/library/zoneinfo.html) and third party libraries.\n\n### Unit\n\n`Unit(unit: str)` expresses that the annotated numeric value is the magnitude of\na quantity with the specified unit. For example, `Annotated[float, Unit(\"m/s\")]`\nwould be a float representing a velocity in meters per second.\n\nPlease note that `annotated_types` itself makes no attempt to parse or validate\nthe unit string in any way. That is left entirely to downstream libraries,\nsuch as [`pint`](https://pint.readthedocs.io) or\n[`astropy.units`](https://docs.astropy.org/en/stable/units/).\n\nAn example of how a library might use this metadata:\n\n```python\nfrom annotated_types import Unit\nfrom typing import Annotated, TypeVar, Callable, Any, get_origin, get_args\n\n# given a type annotated with a unit:\nMeters = Annotated[float, Unit(\"m\")]\n\n\n# you can cast the annotation to a specific unit type with any\n# callable that accepts a string and returns the desired type\nT = TypeVar(\"T\")\ndef cast_unit(tp: Any, unit_cls: Callable[[str], T]) -> T | None:\n    if get_origin(tp) is Annotated:\n        for arg in get_args(tp):\n            if isinstance(arg, Unit):\n                return unit_cls(arg.unit)\n    return None\n\n\n# using `pint`\nimport pint\npint_unit = cast_unit(Meters, pint.Unit)\n\n\n# using `astropy.units`\nimport astropy.units as u\nastropy_unit = cast_unit(Meters, u.Unit)\n```\n\n### Predicate\n\n`Predicate(func: Callable)` expresses that `func(value)` is truthy for valid values.\nUsers should prefer the statically inspectable metadata above, but if you need\nthe full power and flexibility of arbitrary runtime predicates... here it is.\n\nFor some common constraints, we provide generic types:\n\n* `IsLower       = Annotated[T, Predicate(str.islower)]`\n* `IsUpper       = Annotated[T, Predicate(str.isupper)]`\n* `IsDigit       = Annotated[T, Predicate(str.isdigit)]`\n* `IsFinite      = Annotated[T, Predicate(math.isfinite)]`\n* `IsNotFinite   = Annotated[T, Predicate(Not(math.isfinite))]`\n* `IsNan         = Annotated[T, Predicate(math.isnan)]`\n* `IsNotNan      = Annotated[T, Predicate(Not(math.isnan))]`\n* `IsInfinite    = Annotated[T, Predicate(math.isinf)]`\n* `IsNotInfinite = Annotated[T, Predicate(Not(math.isinf))]`\n\nso that you can write e.g. `x: IsFinite[float] = 2.0` instead of the longer\n(but exactly equivalent) `x: Annotated[float, Predicate(math.isfinite)] = 2.0`.\n\nSome libraries might have special logic to handle known or understandable predicates,\nfor example by checking for `str.isdigit` and using its presence to both call custom\nlogic to enforce digit-only strings, and customise some generated external schema.\nUsers are therefore encouraged to avoid indirection like `lambda s: s.lower()`, in\nfavor of introspectable methods such as `str.lower` or `re.compile(\"pattern\").search`.\n\nTo enable basic negation of commonly used predicates like `math.isnan` without introducing introspection that makes it impossible for implementers to introspect the predicate we provide a `Not` wrapper that simply negates the predicate in an introspectable manner. Several of the predicates listed above are created in this manner.\n\nWe do not specify what behaviour should be expected for predicates that raise\nan exception.  For example `Annotated[int, Predicate(str.isdigit)]` might silently\nskip invalid constraints, or statically raise an error; or it might try calling it\nand then propagate or discard the resulting\n`TypeError: descriptor 'isdigit' for 'str' objects doesn't apply to a 'int' object`\nexception.  We encourage libraries to document the behaviour they choose.\n\n### Doc\n\n`doc()` can be used to add documentation information in `Annotated`, for function and method parameters, variables, class attributes, return types, and any place where `Annotated` can be used.\n\nIt expects a value that can be statically analyzed, as the main use case is for static analysis, editors, documentation generators, and similar tools.\n\nIt returns a `DocInfo` class with a single attribute `documentation` containing the value passed to `doc()`.\n\nThis is the early adopter's alternative form of the [`typing-doc` proposal](https://github.com/tiangolo/fastapi/blob/typing-doc/typing_doc.md).\n\n### Integrating downstream types with `GroupedMetadata`\n\nImplementers may choose to provide a convenience wrapper that groups multiple pieces of metadata.\nThis can help reduce verbosity and cognitive overhead for users.\nFor example, an implementer like Pydantic might provide a `Field` or `Meta` type that accepts keyword arguments and transforms these into low-level metadata:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Iterator\nfrom annotated_types import GroupedMetadata, Ge\n\n@dataclass\nclass Field(GroupedMetadata):\n    ge: int | None = None\n    description: str | None = None\n\n    def __iter__(self) -> Iterator[object]:\n        # Iterating over a GroupedMetadata object should yield annotated-types\n        # constraint metadata objects which describe it as fully as possible,\n        # and may include other unknown objects too.\n        if self.ge is not None:\n            yield Ge(self.ge)\n        if self.description is not None:\n            yield Description(self.description)\n```\n\nLibraries consuming annotated-types constraints should check for `GroupedMetadata` and unpack it by iterating over the object and treating the results as if they had been \"unpacked\" in the `Annotated` type.  The same logic should be applied to the [PEP 646 `Unpack` type](https://peps.python.org/pep-0646/), so that `Annotated[T, Field(...)]`, `Annotated[T, Unpack[Field(...)]]` and `Annotated[T, *Field(...)]` are all treated consistently.\n\nLibraries consuming annotated-types should also ignore any metadata they do not recongize that came from unpacking a `GroupedMetadata`, just like they ignore unrecognized metadata in `Annotated` itself.\n\nOur own `annotated_types.Interval` class is a `GroupedMetadata` which unpacks itself into `Gt`, `Lt`, etc., so this is not an abstract concern.  Similarly, `annotated_types.Len` is a `GroupedMetadata` which unpacks itself into `MinLen` (optionally) and `MaxLen`.\n\n### Consuming metadata\n\nWe intend to not be prescriptive as to _how_ the metadata and constraints are used, but as an example of how one might parse constraints from types annotations see our [implementation in `test_main.py`](https://github.com/annotated-types/annotated-types/blob/f59cf6d1b5255a0fe359b93896759a180bec30ae/tests/test_main.py#L94-L103).\n\nIt is up to the implementer to determine how this metadata is used.\nYou could use the metadata for runtime type checking, for generating schemas or to generate example data, amongst other use cases.\n\n## Design & History\n\nThis package was designed at the PyCon 2022 sprints by the maintainers of Pydantic\nand Hypothesis, with the goal of making it as easy as possible for end-users to\nprovide more informative annotations for use by runtime libraries.\n\nIt is deliberately minimal, and following PEP-593 allows considerable downstream\ndiscretion in what (if anything!) they choose to support. Nonetheless, we expect\nthat staying simple and covering _only_ the most common use-cases will give users\nand maintainers the best experience we can. If you'd like more constraints for your\ntypes - follow our lead, by defining them and documenting them downstream!\n",
        "description_content_type": "text/markdown",
        "author_email": "Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Samuel Colvin <s@muelcolvin.com>, Zac Hatfield-Dodds <zac@zhd.dev>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Unix",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.0.0; python_version < '3.9'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/annotated-types/annotated-types",
          "Source, https://github.com/annotated-types/annotated-types",
          "Changelog, https://github.com/annotated-types/annotated-types/releases"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=adcf7e2a1fb3b36ac48d97835bb6d8ade15b8dcce26aba8bf1d14847b57a3373",
          "hashes": {
            "sha256": "adcf7e2a1fb3b36ac48d97835bb6d8ade15b8dcce26aba8bf1d14847b57a3373"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "attrs",
        "version": "25.4.0",
        "summary": "Classes Without Boilerplate",
        "description": "<p align=\"center\">\n  <a href=\"https://www.attrs.org/\">\n    <img src=\"https://raw.githubusercontent.com/python-attrs/attrs/main/docs/_static/attrs_logo.svg\" width=\"35%\" alt=\"attrs\" />\n  </a>\n</p>\n\n\n*attrs* is the Python package that will bring back the **joy** of **writing classes** by relieving you from the drudgery of implementing object protocols (aka [dunder methods](https://www.attrs.org/en/latest/glossary.html#term-dunder-methods)).\nTrusted by NASA for [Mars missions since 2020](https://github.com/readme/featured/nasa-ingenuity-helicopter)!\n\nIts main goal is to help you to write **concise** and **correct** software without slowing down your code.\n\n\n## Sponsors\n\n*attrs* would not be possible without our [amazing sponsors](https://github.com/sponsors/hynek).\nEspecially those generously supporting us at the *The Organization* tier and higher:\n\n<!-- sponsor-break-begin -->\n\n<p align=\"center\">\n\n<!-- [[[cog\nimport pathlib, tomllib\n\nfor sponsor in tomllib.loads(pathlib.Path(\"pyproject.toml\").read_text())[\"tool\"][\"sponcon\"][\"sponsors\"]:\n      print(f'<a href=\"{sponsor[\"url\"]}\"><img title=\"{sponsor[\"title\"]}\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/{sponsor[\"img\"]}\" width=\"190\" /></a>')\n]]] -->\n<a href=\"https://www.variomedia.de/\"><img title=\"Variomedia AG\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Variomedia.svg\" width=\"190\" /></a>\n<a href=\"https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek\"><img title=\"Tidelift\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Tidelift.svg\" width=\"190\" /></a>\n<a href=\"https://privacy-solutions.org/\"><img title=\"Privacy Solutions\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Privacy-Solutions.svg\" width=\"190\" /></a>\n<a href=\"https://filepreviews.io/\"><img title=\"FilePreviews\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/FilePreviews.svg\" width=\"190\" /></a>\n<a href=\"https://polar.sh/\"><img title=\"Polar\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Polar.svg\" width=\"190\" /></a>\n<!-- [[[end]]] -->\n\n</p>\n\n<!-- sponsor-break-end -->\n\n<p align=\"center\">\n   <strong>Please consider <a href=\"https://github.com/sponsors/hynek\">joining them</a> to help make <em>attrs</em>â€™s maintenance more sustainable!</strong>\n</p>\n\n<!-- teaser-end -->\n\n## Example\n\n*attrs* gives you a class decorator and a way to declaratively define the attributes on that class:\n\n<!-- code-begin -->\n\n```pycon\n>>> from attrs import asdict, define, make_class, Factory\n\n>>> @define\n... class SomeClass:\n...     a_number: int = 42\n...     list_of_numbers: list[int] = Factory(list)\n...\n...     def hard_math(self, another_number):\n...         return self.a_number + sum(self.list_of_numbers) * another_number\n\n\n>>> sc = SomeClass(1, [1, 2, 3])\n>>> sc\nSomeClass(a_number=1, list_of_numbers=[1, 2, 3])\n\n>>> sc.hard_math(3)\n19\n>>> sc == SomeClass(1, [1, 2, 3])\nTrue\n>>> sc != SomeClass(2, [3, 2, 1])\nTrue\n\n>>> asdict(sc)\n{'a_number': 1, 'list_of_numbers': [1, 2, 3]}\n\n>>> SomeClass()\nSomeClass(a_number=42, list_of_numbers=[])\n\n>>> C = make_class(\"C\", [\"a\", \"b\"])\n>>> C(\"foo\", \"bar\")\nC(a='foo', b='bar')\n```\n\nAfter *declaring* your attributes, *attrs* gives you:\n\n- a concise and explicit overview of the class's attributes,\n- a nice human-readable `__repr__`,\n- equality-checking methods,\n- an initializer,\n- and much more,\n\n*without* writing dull boilerplate code again and again and *without* runtime performance penalties.\n\n---\n\nThis example uses *attrs*'s modern APIs that have been introduced in version 20.1.0, and the *attrs* package import name that has been added in version 21.3.0.\nThe classic APIs (`@attr.s`, `attr.ib`, plus their serious-business aliases) and the `attr` package import name will remain **indefinitely**.\n\nCheck out [*On The Core API Names*](https://www.attrs.org/en/latest/names.html) for an in-depth explanation!\n\n\n### Hate Type Annotations!?\n\nNo problem!\nTypes are entirely **optional** with *attrs*.\nSimply assign `attrs.field()` to the attributes instead of annotating them with types:\n\n```python\nfrom attrs import define, field\n\n@define\nclass SomeClass:\n    a_number = field(default=42)\n    list_of_numbers = field(factory=list)\n```\n\n\n## Data Classes\n\nOn the tin, *attrs* might remind you of `dataclasses` (and indeed, `dataclasses` [are a descendant](https://hynek.me/articles/import-attrs/) of *attrs*).\nIn practice it does a lot more and is more flexible.\nFor instance, it allows you to define [special handling of NumPy arrays for equality checks](https://www.attrs.org/en/stable/comparison.html#customization), allows more ways to [plug into the initialization process](https://www.attrs.org/en/stable/init.html#hooking-yourself-into-initialization), has a replacement for `__init_subclass__`, and allows for stepping through the generated methods using a debugger.\n\nFor more details, please refer to our [comparison page](https://www.attrs.org/en/stable/why.html#data-classes), but generally speaking, we are more likely to commit crimes against nature to make things work that one would expect to work, but that are quite complicated in practice.\n\n\n## Project Information\n\n- [**Changelog**](https://www.attrs.org/en/stable/changelog.html)\n- [**Documentation**](https://www.attrs.org/)\n- [**PyPI**](https://pypi.org/project/attrs/)\n- [**Source Code**](https://github.com/python-attrs/attrs)\n- [**Contributing**](https://github.com/python-attrs/attrs/blob/main/.github/CONTRIBUTING.md)\n- [**Third-party Extensions**](https://github.com/python-attrs/attrs/wiki/Extensions-to-attrs)\n- **Get Help**: use the `python-attrs` tag on [Stack Overflow](https://stackoverflow.com/questions/tagged/python-attrs)\n\n\n### *attrs* for Enterprise\n\nAvailable as part of the [Tidelift Subscription](https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek).\n\nThe maintainers of *attrs* and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source packages you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact packages you use.\n\n## Release Information\n\n### Backwards-incompatible Changes\n\n- Class-level `kw_only=True` behavior is now consistent with `dataclasses`.\n\n  Previously, a class that sets `kw_only=True` makes all attributes keyword-only, including those from base classes.\n  If an attribute sets `kw_only=False`, that setting is ignored, and it is still made keyword-only.\n\n  Now, only the attributes defined in that class that doesn't explicitly set `kw_only=False` are made keyword-only.\n\n  This shouldn't be a problem for most users, unless you have a pattern like this:\n\n  ```python\n  @attrs.define(kw_only=True)\n  class Base:\n      a: int\n      b: int = attrs.field(default=1, kw_only=False)\n\n  @attrs.define\n  class Subclass(Base):\n      c: int\n  ```\n\n  Here, we have a `kw_only=True` *attrs* class (`Base`) with an attribute that sets `kw_only=False` and has a default (`Base.b`), and then create a subclass (`Subclass`) with required arguments (`Subclass.c`).\n  Previously this would work, since it would make `Base.b` keyword-only, but now this fails since `Base.b` is positional, and we have a required positional argument (`Subclass.c`) following another argument with defaults.\n  [#1457](https://github.com/python-attrs/attrs/issues/1457)\n\n\n### Changes\n\n- Values passed to the `__init__()` method of `attrs` classes are now correctly passed to `__attrs_pre_init__()` instead of their default values (in cases where *kw_only* was not specified).\n  [#1427](https://github.com/python-attrs/attrs/issues/1427)\n- Added support for Python 3.14 and [PEP 749](https://peps.python.org/pep-0749/).\n  [#1446](https://github.com/python-attrs/attrs/issues/1446),\n  [#1451](https://github.com/python-attrs/attrs/issues/1451)\n- `attrs.validators.deep_mapping()` now allows to leave out either *key_validator* xor *value_validator*.\n  [#1448](https://github.com/python-attrs/attrs/issues/1448)\n- `attrs.validators.deep_iterator()` and `attrs.validators.deep_mapping()` now accept lists and tuples for all validators and wrap them into a `attrs.validators.and_()`.\n  [#1449](https://github.com/python-attrs/attrs/issues/1449)\n- Added a new **experimental** way to inspect classes:\n\n  `attrs.inspect(cls)` returns the _effective_ class-wide parameters that were used by *attrs* to construct the class.\n\n  The returned class is the same data structure that *attrs* uses internally to decide how to construct the final class.\n  [#1454](https://github.com/python-attrs/attrs/issues/1454)\n- Fixed annotations for `attrs.field(converter=...)`.\n  Previously, a `tuple` of converters was only accepted if it had exactly one element.\n  [#1461](https://github.com/python-attrs/attrs/issues/1461)\n- The performance of `attrs.asdict()` has been improved by 45â€“260%.\n  [#1463](https://github.com/python-attrs/attrs/issues/1463)\n- The performance of `attrs.astuple()` has been improved by 49â€“270%.\n  [#1469](https://github.com/python-attrs/attrs/issues/1469)\n- The type annotation for `attrs.validators.or_()` now allows for different types of validators.\n\n  This was only an issue on Pyright.\n  [#1474](https://github.com/python-attrs/attrs/issues/1474)\n\n\n\n---\n\n[Full changelog â†’](https://www.attrs.org/en/stable/changelog.html)\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "attribute",
          "boilerplate",
          "class"
        ],
        "author_email": "Hynek Schlawack <hs@ox.cx>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://www.attrs.org/",
          "Changelog, https://www.attrs.org/en/stable/changelog.html",
          "GitHub, https://github.com/python-attrs/attrs",
          "Funding, https://github.com/sponsors/hynek",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-attrs?utm_source=pypi-attrs&utm_medium=pypi"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/96/d0/930c522f5fa9da163de057e57f8b44539424e13f46618c52624ebc712293/azure_ai_agents-1.2.0b6-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=ce23ad8fb9791118905be1ec8eae5c907cca2e536a455f1d3b830062c72cf2a7",
          "hashes": {
            "sha256": "ce23ad8fb9791118905be1ec8eae5c907cca2e536a455f1d3b830062c72cf2a7"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-ai-agents",
        "version": "1.2.0b6",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Corporation Azure AI Agents Client Library for Python",
        "description": "<!-- PIPY LONG DESCRIPTION BEGIN -->\n# Azure AI Agents client library for Python\n\nUse the AI Agents client library to:\n\n* **Develop Agents using the Azure AI Agents Service**, leveraging an extensive ecosystem of models, tools, and capabilities from OpenAI, Microsoft, and other LLM providers. The Azure AI Agents Service enables the building of Agents for a wide range of generative AI use cases.\n* **Note:** While this package can be used independently, we recommend using the Azure AI Projects client library (azure-ai-projects) for an enhanced experience. \nThe Projects library provides simplified access to advanced functionality, such as creating and managing agents, enumerating AI models, working with datasets and \nmanaging search indexes, evaluating generative AI performance, and enabling OpenTelemetry tracing.\n\n[Product documentation](https://aka.ms/azsdk/azure-ai-agents/product-doc)\n| [Samples][samples]\n| [API reference documentation](https://aka.ms/azsdk/azure-ai-agents/python/reference)\n| [Package (PyPI)](https://aka.ms/azsdk/azure-ai-agents/python/package)\n| [SDK source code](https://aka.ms/azsdk/azure-ai-agents/python/code)\n| [AI Starter Template](https://aka.ms/azsdk/azure-ai-agents/python/ai-starter-template)\n\n## Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention the package name \"azure-ai-agents\" in the title or content.\n\n## Table of contents\n\n- [Getting started](#getting-started)\n  - [Prerequisite](#prerequisite)\n  - [Install the package](#install-the-package)\n- [Key concepts](#key-concepts)\n  - [Create and authenticate the client](#create-and-authenticate-the-client)\n- [Examples](#examples)\n  - [Create an Agent](#create-agent) with:\n    - [File Search](#create-agent-with-file-search)\n    - [Enterprise File Search](#create-agent-with-enterprise-file-search)\n    - [Code interpreter](#create-agent-with-code-interpreter)\n    - [Bing grounding](#create-agent-with-bing-grounding)\n    - [Azure AI Search](#create-agent-with-azure-ai-search)\n    - [Function call](#create-agent-with-function-call)\n    - [Azure Function Call](#create-agent-with-azure-function-call)\n    - [OpenAPI](#create-agent-with-openapi)\n    - [Browser Automation](#create-agent-with-browser-automation)\n    - [Fabric data](#create-an-agent-with-fabric)\n    - [Connected agents](#create-an-agent-using-another-agents)\n    - [Deep Research](#create-agent-with-deep-research)\n    - [MCP](#create-agent-with-mcp)\n  - [Create thread](#create-thread) with\n    - [Tool resource](#create-thread-with-tool-resource)\n  - [Create message](#create-message) with:\n    - [File search attachment](#create-message-with-file-search-attachment)\n    - [Code interpreter attachment](#create-message-with-code-interpreter-attachment)\n    - [Create Message with Image Inputs](#create-message-with-image-inputs)\n  - [Execute Run, Run_and_Process, or Stream](#execute-run-run_and_process-or-stream)\n  - [Retrieve message](#retrieve-message)\n  - [Retrieve file](#retrieve-file)\n  - [Tear down by deleting resource](#teardown)\n  - [Tracing](#tracing)\n    - [Installation](#installation)\n    - [How to enable tracing](#how-to-enable-tracing)\n    - [Enabling content recording](#enabling-content-recording)\n    - [How to trace your own functions](#how-to-trace-your-own-functions)\n    - [Adding custom attributes to spans](#adding-custom-attributes-to-spans)\n- [Troubleshooting](#troubleshooting)\n  - [Logging](#logging)\n  - [Reporting issues](#reporting-issues)\n- [Next steps](#next-steps)\n- [Contributing](#contributing)\n<!-- PIPY LONG DESCRIPTION END -->\n## Getting started\n\n### Prerequisite\n\n- Python 3.9 or later.\n- An [Azure subscription][azure_sub].\n- A [project in Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/create-projects).\n- The project endpoint string. It can be found in your Azure AI Foundry project overview page, under \"Project details\". Below we will assume the environment variable `PROJECT_ENDPOINT_STRING` was defined to hold this value.\n- Entra ID is needed to authenticate the client. Your application needs an object that implements the [TokenCredential](https://learn.microsoft.com/python/api/azure-core/azure.core.credentials.tokencredential) interface. Code samples here use [DefaultAzureCredential](https://learn.microsoft.com/python/api/azure-identity/azure.identity.defaultazurecredential). To get that working, you will need:\n  * An appropriate role assignment. see [Role-based access control in Azure AI Foundry portal](https://learn.microsoft.com/azure/ai-foundry/concepts/rbac-ai-foundry). Role assigned can be done via the \"Access Control (IAM)\" tab of your Azure AI Project resource in the Azure portal.\n  * [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed.\n  * You are logged into your Azure account by running `az login`.\n  * Note that if you have multiple Azure subscriptions, the subscription that contains your Azure AI Project resource must be your default subscription. Run `az account list --output table` to list all your subscription and see which one is the default. Run `az account set --subscription \"Your Subscription ID or Name\"` to change your default subscription.\n\n### Install the package\n\n```bash\npip install azure-ai-agents\n```\n\n## Key concepts\n\n### Create and authenticate the client\n\nTo use this SDK, start by creating an `AIProjectClient`. For more information on `azure-ai-projects`, refer to its [README](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/README.md).\n\nHere is an example of creating a synchronous `AIProjectClient`:\n\n```python\nimport os\nfrom azure.ai.projects import AIProjectClient\nfrom azure.identity import DefaultAzureCredential\n\nproject_client = AIProjectClient(\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n    credential=DefaultAzureCredential(),\n)\n```\n\nTo construct an asynchronous client, install the `aiohttp` package:\n\n```bash\npip install aiohttp\n```\n\nThen use the code below with `AIProjectClient` and `DefaultAzureCredential` in `aio` packages:\n\n```python\nimport asyncio\nimport os\nfrom azure.ai.projects.aio import AIProjectClient\nfrom azure.identity.aio import DefaultAzureCredential\n\nasync def main() -> None:\n    project_client = AIProjectClient(\n       endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n       credential=DefaultAzureCredential(),\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nOnce you have an `AIProjectClient`, you can obtain an `AgentsClient` like this:\n\n**Synchronous Client:**\n```python\nwith project_client:\n    agents_client = project_client.agents\n```\n\n**Asynchronous Client:**\n```python\nasync with project_client:\n    agents_client = project_client.agents\n```\n\nAlternatively, you can instantiate an AgentsClient directly as a standalone approach without using `azure-ai-projects`. However, this is not recommended, as it has limitations and lacks the integrated capabilities provided by using an `AIProjectClient`.   Here is is the example:\n\n**Synchronous Client:**\n```python\nimport os\nfrom azure.ai.agents import AgentsClient\nfrom azure.identity import DefaultAzureCredential\n\nagents_client = AgentsClient(\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n    credential=DefaultAzureCredential()\n)\n\nwith agents_client:\n    # your code to consume the client\n    pass\n\n```\n\n**Asynchronous Client:**\n```python\nimport asyncio\nimport os\nfrom azure.ai.agents.aio import AgentsClient\nfrom azure.identity.aio import DefaultAzureCredential\n\nasync def main() -> None:\n    agents_client = AgentsClient(\n        endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n        credential=DefaultAzureCredential()\n    )\n    async with agents_client:\n        # your code to consume the client\n        pass\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## Examples\n\n### Create Agent\n\nBefore creating an Agent, you need to set up Azure resources to deploy your model. [Create a New Agent Quickstart](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=programming-language-python-azure) details selecting and deploying your Agent Setup.\n\nHere is an example of how to create an Agent:\n<!-- SNIPPET:sample_agents_basics.create_agent -->\n\n```python\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n)\n```\n\n<!-- END SNIPPET -->\n\nTo allow Agents to access your resources or custom functions, you need tools. You can pass tools to `create_agent` by either `toolset` or combination of `tools` and `tool_resources`.\n\nHere is an example of `toolset`:\n<!-- SNIPPET:sample_agents_run_with_toolset.create_agent_toolset -->\n\n```python\nfunctions = FunctionTool(user_functions)\ncode_interpreter = CodeInterpreterTool()\n\ntoolset = ToolSet()\ntoolset.add(functions)\ntoolset.add(code_interpreter)\n\n# To enable tool calls executed automatically\nagents_client.enable_auto_function_calls(toolset)\n\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are a helpful agent\",\n    toolset=toolset,\n)\n```\n\n<!-- END SNIPPET -->\n\nAlso notices that if you use asynchronous client, you use `AsyncToolSet` instead.  Additional information related to `AsyncFunctionTool` be discussed in the later sections.\n\nHere is an example to use `tools` and `tool_resources`:\n<!-- SNIPPET:sample_agents_vector_store_batch_file_search.create_agent_with_tools_and_tool_resources -->\n\n```python\nfile_search_tool = FileSearchTool(vector_store_ids=[vector_store.id])\n\n# Notices that FileSearchTool as tool and tool_resources must be added or the agent unable to search the file\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n    tools=file_search_tool.definitions,\n    tool_resources=file_search_tool.resources,\n)\n```\n\n<!-- END SNIPPET -->\n\nIn the following sections, we show you sample code in either `toolset` or combination of `tools` and `tool_resources`.\n\n### Create Agent with File Search\n\nTo perform file search by an Agent, we first need to upload a file, create a vector store, and associate the file to the vector store. Here is an example:\n\n<!-- SNIPPET:sample_agents_file_search.upload_file_create_vector_store_and_agent_with_file_search_tool -->\n\n```python\nfile = agents_client.files.upload_and_poll(file_path=asset_file_path, purpose=FilePurpose.AGENTS)\nprint(f\"Uploaded file, file ID: {file.id}\")\n\nvector_store = agents_client.vector_stores.create_and_poll(file_ids=[file.id], name=\"my_vectorstore\")\nprint(f\"Created vector store, vector store ID: {vector_store.id}\")\n\n# Create file search tool with resources followed by creating agent\nfile_search = FileSearchTool(vector_store_ids=[vector_store.id])\n\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"Hello, you are helpful agent and can search information from uploaded files\",\n    tools=file_search.definitions,\n    tool_resources=file_search.resources,\n)\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Enterprise File Search\n\nWe can upload file to Azure as it is shown in the example, or use the existing Azure blob storage. In the code below we demonstrate how this can be achieved. First we upload file to azure and create `VectorStoreDataSource`, which then is used to create vector store. This vector store is then given to the `FileSearchTool` constructor.\n\n<!-- SNIPPET:sample_agents_enterprise_file_search.upload_file_and_create_agent_with_file_search -->\n\n```python\n# If provided, we will upload the local file to Azure and will use it for vector store creation.\n# Otherwise, we'll use a previously created dataset reference\nif \"AZURE_BLOB_URI\" in os.environ:\n    asset_uri = os.environ[\"AZURE_BLOB_URI\"]\nelse:\n    dataset_name = os.environ[\"AZURE_DATASET_NAME\"]\n    dataset_version = os.environ[\"AZURE_DATASET_VERSION\"]\n    dataset = project_client.datasets.get(name=dataset_name, version=dataset_version)\n    asset_uri = dataset.id\n\n# Create a vector store and wait for it to be processed\nds = VectorStoreDataSource(asset_identifier=asset_uri, asset_type=VectorStoreDataSourceAssetType.URI_ASSET)\nvector_store = agents_client.vector_stores.create_and_poll(data_sources=[ds], name=\"sample_vector_store\")\nprint(f\"Created vector store, vector store ID: {vector_store.id}\")\nvector_store_files = {}\nfor fle in agents_client.vector_store_files.list(vector_store.id):\n    uploaded_file = agents_client.files.get(fle.id)\n    vector_store_files[fle.id] = uploaded_file.filename\n\n# Create a file search tool\nfile_search_tool = FileSearchTool(vector_store_ids=[vector_store.id])\n\n# Notices that FileSearchTool as tool and tool_resources must be added or the agent unable to search the file\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n    tools=file_search_tool.definitions,\n    tool_resources=file_search_tool.resources,\n)\n```\n\n<!-- END SNIPPET -->\n\nWe also can attach files to the existing vector store. In the code snippet below, we first create an empty vector store and add file to it.\n\n<!-- SNIPPET:sample_agents_vector_store_batch_enterprise_file_search.attach_files_to_store -->\n\n```python\n# Create a vector store with no file and wait for it to be processed\nvector_store = agents_client.vector_stores.create_and_poll(data_sources=[], name=\"sample_vector_store\")\nprint(f\"Created vector store, vector store ID: {vector_store.id}\")\n\nds = VectorStoreDataSource(asset_identifier=asset_uri, asset_type=VectorStoreDataSourceAssetType.URI_ASSET)\n# Add the file to the vector store or you can supply data sources in the vector store creation\nvector_store_file_batch = agents_client.vector_store_file_batches.create_and_poll(\n    vector_store_id=vector_store.id, data_sources=[ds]\n)\nprint(f\"Created vector store file batch, vector store file batch ID: {vector_store_file_batch.id}\")\n\n# Create a file search tool\nfile_search_tool = FileSearchTool(vector_store_ids=[vector_store.id])\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Code Interpreter\n\nHere is an example to upload a file and use it for code interpreter by an Agent:\n\n<!-- SNIPPET:sample_agents_code_interpreter.upload_file_and_create_agent_with_code_interpreter -->\n\n```python\nfile = agents_client.files.upload_and_poll(file_path=asset_file_path, purpose=FilePurpose.AGENTS)\nprint(f\"Uploaded file, file ID: {file.id}\")\n\ncode_interpreter = CodeInterpreterTool(file_ids=[file.id])\n\n# Create agent with code interpreter tool and tools_resources\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n    tools=code_interpreter.definitions,\n    tool_resources=code_interpreter.resources,\n)\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Bing Grounding\n\nTo enable your Agent to perform search through Bing search API, you use `BingGroundingTool` along with a connection.\n\nHere is an example:\n\n<!-- SNIPPET:sample_agents_bing_grounding.create_agent_with_bing_grounding_tool -->\n\n```python\nconn_id = project_client.connections.get(os.environ[\"BING_CONNECTION_NAME\"]).id\n\n# Initialize agent bing tool and add the connection id\nbing = BingGroundingTool(connection_id=conn_id)\n\n# Create agent with the bing tool and process agent run\nwith project_client:\n    agents_client = project_client.agents\n    agent = agents_client.create_agent(\n        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n        name=\"my-agent\",\n        instructions=\"You are a helpful agent\",\n        tools=bing.definitions,\n    )\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Deep Research\n\nTo enable your Agent to do detailed research of a topic, use the `DeepResearchTool` along with a connection to a Bing Grounding resource.\nThis scenarios requires you to specify two model deployments. One is the generic chat model that does arbitration, and is\nspecified as usual when you call the `create_agent` method. The other is the Deep Research model, which is specified\nwhen you define the `DeepResearchTool`.\n\nHere is an example:\n\n<!-- SNIPPET:sample_agents_deep_research.create_agent_with_deep_research_tool -->\n\n```python\nbing_connection = project_client.connections.get(name=os.environ[\"BING_RESOURCE_NAME\"])\n\n# Initialize a Deep Research tool with Bing Connection ID and Deep Research model deployment name\ndeep_research_tool = DeepResearchTool(\n    bing_grounding_connection_id=bing_connection.id,\n    deep_research_model=os.environ[\"DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME\"],\n)\n\n# Create Agent with the Deep Research tool and process Agent run\nwith project_client:\n\n    with project_client.agents as agents_client:\n\n        # Create a new agent that has the Deep Research tool attached.\n        # NOTE: To add Deep Research to an existing agent, fetch it with `get_agent(agent_id)` and then,\n        # update the agent with the Deep Research tool.\n        agent = agents_client.create_agent(\n            model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n            name=\"my-agent\",\n            instructions=\"You are a helpful Agent that assists in researching scientific topics.\",\n            tools=deep_research_tool.definitions,\n        )\n```\n\n<!-- END SNIPPET -->\n\n> **Limitation**: The Deep Research tool is currently recommended **only** in non-streaming scenarios.\n> Using it with streaming can work, but it may occasionally time-out and is therefore not yet recommended.\n\n### Create Agent with MCP\n\nTo enable your Agent to connect to a MCP server, use the `McpTool` along with a server URI to a MCP server and a label for that server.\nNote that approval to send data to that server is required by default (but can be set to not required for each run).\n\nHere is an example:\n\n<!-- SNIPPET:sample_agents_mcp.create_agent_with_mcp_tool -->\n\n```python\n# Initialize agent MCP tool\nmcp_tool = McpTool(\n    server_label=mcp_server_label,\n    server_url=mcp_server_url,\n    allowed_tools=[],  # Optional: specify allowed tools\n)\n\n# You can also add or remove allowed tools dynamically\nsearch_api_code = \"search_azure_rest_api_code\"\nmcp_tool.allow_tool(search_api_code)\nprint(f\"Allowed tools: {mcp_tool.allowed_tools}\")\n\n# Create agent with MCP tool and process agent run\nwith project_client:\n    agents_client = project_client.agents\n\n    # Create a new agent.\n    # NOTE: To reuse existing agent, fetch it with get_agent(agent_id)\n    agent = agents_client.create_agent(\n        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n        name=\"my-mcp-agent\",\n        instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n        tools=mcp_tool.definitions,\n    )\n```\n\n<!-- END SNIPPET -->\n\nThe tool approval flow looks like this:\n\n<!-- SNIPPET:sample_agents_mcp.handle_tool_approvals -->\n\n```python\n# Create and process agent run in thread with MCP tools\nmcp_tool.update_headers(\"SuperSecret\", \"123456\")\n# mcp_tool.set_approval_mode(\"never\")  # Uncomment to disable approval requirement\nrun = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id, tool_resources=mcp_tool.resources)\nprint(f\"Created run, ID: {run.id}\")\n\nwhile run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n    time.sleep(1)\n    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n\n    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolApprovalAction):\n        tool_calls = run.required_action.submit_tool_approval.tool_calls\n        if not tool_calls:\n            print(\"No tool calls provided - cancelling run\")\n            agents_client.runs.cancel(thread_id=thread.id, run_id=run.id)\n            break\n\n        tool_approvals = []\n        for tool_call in tool_calls:\n            if isinstance(tool_call, RequiredMcpToolCall):\n                try:\n                    print(f\"Approving tool call: {tool_call}\")\n                    tool_approvals.append(\n                        ToolApproval(\n                            tool_call_id=tool_call.id,\n                            approve=True,\n                            headers=mcp_tool.headers,\n                        )\n                    )\n                except Exception as e:\n                    print(f\"Error approving tool_call {tool_call.id}: {e}\")\n\n        print(f\"tool_approvals: {tool_approvals}\")\n        if tool_approvals:\n            agents_client.runs.submit_tool_outputs(\n                thread_id=thread.id, run_id=run.id, tool_approvals=tool_approvals\n            )\n\n    print(f\"Current run status: {run.status}\")\n```\n\n<!-- END SNIPPET -->\n\nFor scenarios requiring custom approval logic or additional control over MCP tool calls, you can use a `RunHandler` with the `create_and_process` method. This approach allows you to implement custom logic for approving or denying MCP tool calls.\n\nHere's an example that demonstrates manual MCP tool call approval using a `RunHandler`:\n\n<!-- SNIPPET:sample_agents_mcp_in_create_and_process.run_handler -->\n\n```python\nclass MyRunHandler(RunHandler):\n    def submit_mcp_tool_approval(\n        self, *, run: ThreadRun, tool_call: RequiredMcpToolCall, **kwargs: Any\n    ) -> ToolApproval:\n        return ToolApproval(\n            tool_call_id=tool_call.id,\n            approve=True,\n            headers=mcp_tool.headers,\n        )\n```\n\n<!-- END SNIPPET -->\n\nTo use the RunHandler with `create_and_process` for MCP tools:\n\n<!-- SNIPPET:sample_agents_mcp_in_create_and_process.create_and_process -->\n\n```python\nrun = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id, run_handler=MyRunHandler())\n```\n\n<!-- END SNIPPET -->\n\nFor a complete example, see [`sample_agents_mcp_in_create_and_process.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_tools/sample_agents_mcp_in_create_and_process.py).\n\n### Create Agent with Azure AI Search\n\nAzure AI Search is an enterprise search system for high-performance applications. It integrates with Azure OpenAI Service and Azure Machine Learning, offering advanced search technologies like vector search and full-text search. Ideal for knowledge base insights, information discovery, and automation. Creating an Agent with Azure AI Search requires an existing Azure AI Search Index. For more information and setup guides, see [Azure AI Search Tool Guide](https://learn.microsoft.com/azure/ai-services/agents/how-to/tools/azure-ai-search?tabs=azurecli%2Cpython&pivots=overview-azure-ai-search).\n\nHere is an example to integrate Azure AI Search:\n\n<!-- SNIPPET:sample_agents_azure_ai_search.create_agent_with_azure_ai_search_tool -->\n\n```python\nconn_id = project_client.connections.get_default(ConnectionType.AZURE_AI_SEARCH).id\nprint(conn_id)\n\n# Initialize agent AI search tool and add the search index connection id\nai_search = AzureAISearchTool(\n    index_connection_id=conn_id,\n    index_name=\"sample_index\",\n    query_type=AzureAISearchQueryType.SIMPLE,\n    top_k=3,\n    filter=\"\",\n)\n\nagent = project_client.agents.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are a helpful agent\",\n    tools=ai_search.definitions,\n    tool_resources=ai_search.resources,\n)\n```\n\n<!-- END SNIPPET -->\n\nIf the agent has found the relevant information in the index, the reference\nand annotation will be provided in the message response. In the example above, we replace\nthe reference placeholder by the actual reference and url. Please note, that to\nget sensible result, the index needs to have \"embedding\", \"token\", \"category\" and \"title\" fields.\n\n<!-- SNIPPET:sample_agents_azure_ai_search.populate_references_agent_with_azure_ai_search_tool -->\n\n```python\n# Fetch and log all messages\nmessages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\nfor message in messages:\n    if message.role == MessageRole.AGENT and message.url_citation_annotations:\n        placeholder_annotations = {\n            annotation.text: f\" [see {annotation.url_citation.title}] ({annotation.url_citation.url})\"\n            for annotation in message.url_citation_annotations\n        }\n        for message_text in message.text_messages:\n            message_str = message_text.text.value\n            for k, v in placeholder_annotations.items():\n                message_str = message_str.replace(k, v)\n            print(f\"{message.role}: {message_str}\")\n    else:\n        for message_text in message.text_messages:\n            print(f\"{message.role}: {message_text.text.value}\")\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Function Call\n\nYou can enhance your Agents by defining callback functions as function tools. These can be provided to `create_agent` via either the `toolset` parameter or the combination of `tools` and `tool_resources`. Here are the distinctions:\n\nFor more details about requirements and specification of functions, refer to [Function Tool Specifications](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/FunctionTool.md)\n\nHere is an example to use [user functions](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/utils/user_functions.py) in `toolset`:\n<!-- SNIPPET:sample_agents_stream_eventhandler_with_toolset.create_agent_with_function_tool -->\n\n```python\nfunctions = FunctionTool(user_functions)\ntoolset = ToolSet()\ntoolset.add(functions)\nagents_client.enable_auto_function_calls(toolset)\n\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are a helpful agent\",\n    toolset=toolset,\n)\n```\n\n<!-- END SNIPPET -->\n\nFor asynchronous functions, you must import `AgentsClient` from `azure.ai.agents.aio` and use `AsyncFunctionTool`.   Here is an example using [asynchronous user functions](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_async/sample_agents_functions_async.py):\n\n```python\nfrom azure.ai.agents.aio import AgentsClient\n```\n\n<!-- SNIPPET:sample_agents_run_with_toolset_async.create_agent_with_async_function_tool -->\n\n```python\nfunctions = AsyncFunctionTool(user_async_functions)\n\ntoolset = AsyncToolSet()\ntoolset.add(functions)\nagents_client.enable_auto_function_calls(toolset)\n\nagent = await agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are a helpful agent\",\n    toolset=toolset,\n)\n```\n\n<!-- END SNIPPET -->\n\nWhen `enable_auto_function_calls` is called, the SDK will automatically invoke functions during both `create_and_process` and streaming workflows. This simplifies agent logic by handling function execution internally.  Furthermore, although function tools and definitions are preserved in Agent service, their function implements are not.  Therefore, if your code queries earlier created agents through `update_agents` or `get_agents` function, you MUST also provide the function implementations through `enable_auto_function_calls` to complete auto function callings.\n\n- For examples of automatic function calls in action, refer to [`sample_agents_auto_function_call.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_tools/sample_agents_auto_function_call.py) or [`sample_agents_auto_function_call_async.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_async/sample_agents_auto_function_call_async.py).\n- If you prefer to manage function execution manually, refer to [`sample_agents_stream_eventhandler_with_functions.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_streaming/sample_agents_stream_eventhandler_with_functions.py) or\n[`sample_agents_functions.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_tools/sample_agents_functions.py).\n\n### Create Agent With Azure Function Call\n\nThe AI agent leverages Azure Functions triggered asynchronously via Azure Storage Queues. To enable the agent to perform Azure Function calls, you must set up the corresponding `AzureFunctionTool`, specifying input and output queues as well as parameter definitions.\n\nExample Python snippet illustrating how you create an agent utilizing the Azure Function Tool:\n\n```python\nazure_function_tool = AzureFunctionTool(\n    name=\"foo\",\n    description=\"Get answers from the foo bot.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\"type\": \"string\", \"description\": \"The question to ask.\"},\n            \"outputqueueuri\": {\"type\": \"string\", \"description\": \"The full output queue uri.\"},\n        },\n    },\n    input_queue=AzureFunctionStorageQueue(\n        queue_name=\"azure-function-foo-input\",\n        storage_service_endpoint=storage_service_endpoint,\n    ),\n    output_queue=AzureFunctionStorageQueue(\n        queue_name=\"azure-function-tool-output\",\n        storage_service_endpoint=storage_service_endpoint,\n    ),\n)\n\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"azure-function-agent-foo\",\n    instructions=f\"You are a helpful support agent. Use the provided function any time the prompt contains the string 'What would foo say?'. When you invoke the function, ALWAYS specify the output queue uri parameter as '{storage_service_endpoint}/azure-function-tool-output'. Always responds with \\\"Foo says\\\" and then the response from the tool.\",\n    tools=azure_function_tool.definitions,\n)\nprint(f\"Created agent, agent ID: {agent.id}\")\n```\n\n---\n\n**Limitations**\n\nCurrently, the Azure Function integration for the AI Agent has the following limitations:\n\n- Supported trigger for Azure Function is currently limited to **Queue triggers** only.\n  HTTP or other trigger types and streaming responses are not supported at this time.\n\n---\n\n**Create and Deploy Azure Function**\n\nBefore you can use the agent with AzureFunctionTool, you need to create and deploy Azure Function.\n\nBelow is an example Python Azure Function responding to queue-triggered messages and placing responses on the output queue:\n\n```python\nimport azure.functions as func\nimport logging\nimport json\n\napp = func.FunctionApp()\n\n\n@app.function_name(name=\"Foo\")\n@app.queue_trigger(\n    arg_name=\"arguments\",\n    queue_name=\"azure-function-foo-input\",\n    connection=\"AzureWebJobsStorage\")\n@app.queue_output(\n    arg_name=\"outputQueue\",\n    queue_name=\"azure-function-tool-output\",\n    connection=\"AzureWebJobsStorage\")\ndef foo(arguments: func.QueueMessage, outputQueue: func.Out[str]) -> None:\n    \"\"\"\n    The function, answering question.\n\n    :param arguments: The arguments, containing json serialized request.\n    :param outputQueue: The output queue to write messages to.\n    \"\"\"\n    \n    parsed_args = json.loads(arguments.get_body().decode('utf-8'))\n    try:\n        response = {\n            \"Value\": \"Bar\",\n            \"CorrelationId\": parsed_args['CorrelationId']\n        }\n        outputQueue.set(json.dumps(response))\n        logging.info(f'The function returns the following message: {json.dumps(response)}')\n    except Exception as e:\n        logging.error(f\"Error processing message: {e}\")\n        raise\n```\n\n> **Important:** Both input and output payloads must contain the `CorrelationId`, which must match in request and response.\n\n---\n\n**Azure Function Project Creation and Deployment**\n\nTo deploy your function to Azure properly, follow Microsoft's official documentation step by step:\n\n[Azure Functions Python Developer Guide](https://learn.microsoft.com/azure/azure-functions/create-first-function-cli-python?tabs=windows%2Cbash%2Cazure-cli%2Cbrowser)\n**Note:** The Azure Function may be only used in standard agent setup. Please follow the [instruction](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/microsoft/infrastructure-setup/41-standard-agent-setup) to deploy an agent, capable of calling Azure Functions.\n\n**Summary of required steps:**\n\n- Use the Azure CLI or Azure Portal to create an Azure Function App.\n- Create input and output queues in Azure Storage.\n- Deploy your Function code.\n\n---\n\n**Verification and Testing Azure Function**\n\nTo ensure that your Azure Function deployment functions correctly:\n\n1. Place the following style message manually into the input queue (`input`):\n\n{\n  \"CorrelationId\": \"42\"\n}\n\nCheck the output queue (`output`) and validate the structured message response:\n\n{\n  \"Value\": \"Bar\",\n  \"CorrelationId\": \"42\"\n}\n\n---\n\n**Required Role Assignments (IAM Configuration)**\n\nEnsure your Azure AI Project identity has the following storage account permissions:\n- `Storage Account Contributor`\n- `Storage Blob Data Contributor`\n- `Storage File Data Privileged Contributor`\n- `Storage Queue Data Contributor`\n- `Storage Table Data Contributor`\n\n---\n\n**Additional Important Configuration Notes**\n\n- The Azure Function configured above uses the `AzureWebJobsStorage` connection string for queue connectivity. You may alternatively use managed identity-based connections as described in the official Azure Functions Managed Identity documentation.\n- Storage queues you specify (`input` & `output`) should already exist in the storage account before the Function deployment or invocation, created manually via Azure portal or CLI.\n- When using Azure storage account connection strings, make sure the account has enabled storage account key access (`Storage Account > Settings > Configuration`).\n\n---\n\nWith the above steps complete, your Azure Function integration with your AI Agent is ready for use.\n\n\n### Create Agent With Logic Apps\n\nLogic Apps allow HTTP requests to trigger actions. For more information, refer to the guide [Logic App Workflows for Function Calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/assistants-logic-apps).\n\nYour Logic App must be in the same resource group as your Azure AI Project, shown in the Azure Portal. Agents SDK accesses Logic Apps through Workflow URLs, which are fetched and called as requests in functions.\n\nBelow is an example of how to create an Azure Logic App utility tool and register a function with it.\n\n<!-- SNIPPET:sample_agents_logic_apps.register_logic_app -->\n\n```python\n# Extract subscription and resource group from the project scope\nsubscription_id = os.environ[\"SUBSCRIPTION_ID\"]\nresource_group = os.environ[\"resource_group_name\"]\n\n# Logic App details\nlogic_app_name = \"<LOGIC_APP_NAME>\"\ntrigger_name = \"<TRIGGER_NAME>\"\n\n# Create and initialize AzureLogicAppTool utility\nlogic_app_tool = AzureLogicAppTool(subscription_id, resource_group)\nlogic_app_tool.register_logic_app(logic_app_name, trigger_name)\nprint(f\"Registered logic app '{logic_app_name}' with trigger '{trigger_name}'.\")\n\n# Create the specialized \"send_email_via_logic_app\" function for your agent tools\nsend_email_func = create_send_email_function(logic_app_tool, logic_app_name)\n\n# Prepare the function tools for the agent\nfunctions_to_use: Set = {\n    fetch_current_datetime,\n    send_email_func,  # This references the AzureLogicAppTool instance via closure\n}\n```\n\n<!-- END SNIPPET -->\n\nAfter this the functions can be incorporated normally into code using `FunctionTool`.\n\n\n### Create Agent With OpenAPI\n\nOpenAPI specifications describe REST operations against a specific endpoint. Agents SDK can read an OpenAPI spec, create a function from it, and call that function against the REST endpoint without additional client-side execution.\n\nHere is an example creating an OpenAPI tool (using anonymous authentication):\n\n<!-- SNIPPET:sample_agents_openapi.create_agent_with_openapi -->\n\n```python\n\nwith open(weather_asset_file_path, \"r\") as f:\n    openapi_weather = jsonref.loads(f.read())\n\nwith open(countries_asset_file_path, \"r\") as f:\n    openapi_countries = jsonref.loads(f.read())\n\n# Create Auth object for the OpenApiTool (note that connection or managed identity auth setup requires additional setup in Azure)\nauth = OpenApiAnonymousAuthDetails()\n\n# Initialize agent OpenApi tool using the read in OpenAPI spec\nopenapi_tool = OpenApiTool(\n    name=\"get_weather\", spec=openapi_weather, description=\"Retrieve weather information for a location\", auth=auth\n)\nopenapi_tool.add_definition(\n    name=\"get_countries\", spec=openapi_countries, description=\"Retrieve a list of countries\", auth=auth\n)\n\n# Create agent with OpenApi tool and process agent run\nwith project_client:\n    agents_client = project_client.agents\n\n    agent = agents_client.create_agent(\n        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n        name=\"my-agent\",\n        instructions=\"You are a helpful agent\",\n        tools=openapi_tool.definitions,\n    )\n```\n\n<!-- END SNIPPET -->\n\n### Create Agent with Browser Automation\n\nTo enable your Agent to perform automated Browser navigation tasks, you will need the `BrowserAutomationTool`, along with a connection to\na [Microsoft Playwright Workspace](https://azure.microsoft.com/products/playwright-testing) resource.\n\nHere is an example:\n\n<!-- SNIPPET:sample_agents_browser_automation.create_agent_with_browser_automation -->\n\n```python\nconnection_id = project_client.connections.get(os.environ[\"AZURE_PLAYWRIGHT_CONNECTION_NAME\"]).id\n\n# Initialize Browser Automation tool and add the connection id\nbrowser_automation = BrowserAutomationTool(connection_id=connection_id)\n\nwith project_client:\n\n    agents_client = project_client.agents\n\n    # Create a new Agent that has the Browser Automation tool attached.\n    # Note: To add Browser Automation tool to an existing Agent with an `agent_id`, do the following:\n    # agent = agents_client.update_agent(agent_id, tools=browser_automation.definitions)\n    agent = agents_client.create_agent(\n        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n        name=\"my-agent\",\n        instructions=\"\"\"\n            You are an Agent helping with browser automation tasks. \n            You can answer questions, provide information, and assist with various tasks \n            related to web browsing using the Browser Automation tool available to you.\n            \"\"\",\n        tools=browser_automation.definitions,\n    )\n```\n\n<!-- END SNIPPET -->\n\n### Create an Agent with Fabric\n\nTo enable your Agent to answer queries using Fabric data, use `FabricTool` along with a connection to the Fabric resource.\n\nHere is an example:\n\n<!-- SNIPPET:sample_agents_fabric.create_agent_with_fabric_tool -->\n\n```python\nconn_id = project_client.connections.get(os.environ[\"FABRIC_CONNECTION_NAME\"]).id\n\nprint(conn_id)\n\n# Initialize an Agent Fabric tool and add the connection id\nfabric = FabricTool(connection_id=conn_id)\n\n# Create an Agent with the Fabric tool and process an Agent run\nwith project_client:\n    agents_client = project_client.agents\n\n    agent = agents_client.create_agent(\n        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n        name=\"my-agent\",\n        instructions=\"You are a helpful agent\",\n        tools=fabric.definitions,\n    )\n```\n\n<!-- END SNIPPET -->\n\n### Create an Agent using another agents\n\nWe can use `ConnectedAgentTool` to call specialized agents. In the example below we will create two agents, one is returning the Microsoft stock price and another returns weather. Note that the `ConnectedAgentTool` does not support local functions, we will use Azure function to return weather. The code of that function is given below; please see [Azure Function Call](#create-agent-with-azure-function-call) section for the instructions on how to deploy Azure Function.\n\n```python\nimport azure.functions as func\nimport datetime\nimport json\nimport logging\n\napp = func.FunctionApp()\n\n@app.function_name(name=\"GetWeather\")\n@app.queue_trigger(\n    arg_name=\"arguments\",\n    queue_name=\"weather-input\",\n    connection=\"AzureWebJobsStorage\")\n@app.queue_output(\n    arg_name=\"outputQueue\",\n    queue_name=\"weather-output\",\n    connection=\"AzureWebJobsStorage\")\ndef foo(arguments: func.QueueMessage, outputQueue: func.Out[str]) -> None:\n    \"\"\"\n    The function, answering question about weather.\n\n    :param arguments: The arguments, containing json serialized request.\n    :param outputQueue: The output queue to write messages to.\n    \"\"\"\n\n    parsed_args = json.loads(arguments.get_body().decode('utf-8'))\n    location = parsed_args.get(\"Location\")\n    try:\n        response = {\n            \"Value\": \"60 degrees and cloudy\" if location == \"Seattle\" else \"10 degrees and sunny\",\n            \"CorrelationId\": parsed_args['CorrelationId']\n        }\n        outputQueue.set(json.dumps(response))\n        logging.info(f'The function returns the following message: {json.dumps(response)}')\n    except Exception as e:\n        logging.error(f\"Error processing message: {e}\")\n        raise\n```\nWe will define two agents that has descriptions, explaining when they need to be called.\n\n<!-- SNIPPET:sample_agents_multiple_connected_agents.create_two_toy_agents -->\n\n```python\nconnected_agent_name = \"stock_price_bot\"\nweather_agent_name = \"weather_bot\"\n\nstock_price_agent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=connected_agent_name,\n    instructions=(\n        \"Your job is to get the stock price of a company. If asked for the Microsoft stock price, always return $350.\"\n    ),\n)\n\nazure_function_tool = AzureFunctionTool(\n    name=\"GetWeather\",\n    description=\"Get answers from the weather bot.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"Location\": {\"type\": \"string\", \"description\": \"The location to get the weather for.\"},\n        },\n    },\n    input_queue=AzureFunctionStorageQueue(\n        queue_name=\"weather-input\",\n        storage_service_endpoint=storage_service_endpoint,\n    ),\n    output_queue=AzureFunctionStorageQueue(\n        queue_name=\"weather-output\",\n        storage_service_endpoint=storage_service_endpoint,\n    ),\n)\n\nweather_agent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=weather_agent_name,\n    instructions=(\n        \"Your job is to get the weather for a given location. \"\n        \"Use the provided function to get the weather in the given location.\"\n    ),\n    tools=azure_function_tool.definitions,\n)\n\n# Initialize Connected Agent tools with the agent id, name, and description\nconnected_agent = ConnectedAgentTool(\n    id=stock_price_agent.id, name=connected_agent_name, description=\"Gets the stock price of a company\"\n)\nconnected_weather_agent = ConnectedAgentTool(\n    id=weather_agent.id, name=weather_agent_name, description=\"Gets the weather for a given location\"\n)\n```\n\n<!-- END SNIPPET -->\n\nAdd the `ConnectedAgentTool`-s to main agent.\n\n<!-- SNIPPET:sample_agents_multiple_connected_agents.create_agent_with_connected_agent_tool -->\n\n```python\n# Create agent with the Connected Agent tool and process assistant run\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-assistant\",\n    instructions=\"You are a helpful assistant, and use the connected agents to get stock prices and weather.\",\n    tools=[\n        connected_agent.definitions[0],\n        connected_weather_agent.definitions[0],\n    ],\n)\n```\n\n<!-- END SNIPPET -->\n\nCreate thread and run.\n\n<!-- SNIPPET:sample_agents_multiple_connected_agents.run_agent_with_connected_agent_tool -->\n\n```python\n# Create thread for communication\nthread = agents_client.threads.create()\nprint(f\"Created thread, ID: {thread.id}\")\n\n# Create message to thread\nmessage = agents_client.messages.create(\n    thread_id=thread.id,\n    role=MessageRole.USER,\n    content=\"What is the stock price of Microsoft and the weather in Seattle?\",\n)\nprint(f\"Created message, ID: {message.id}\")\n\n# Create and process Agent run in thread with tools\nrun = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\nprint(f\"Run finished with status: {run.status}\")\n```\n\n<!-- END SNIPPET -->\n\nTo understand what calls were made by the main agent to the connected ones, we will list run steps.\n\n<!-- SNIPPET:sample_agents_multiple_connected_agents.list_tool_calls -->\n\n```python\nfor run_step in agents_client.run_steps.list(thread_id=thread.id, run_id=run.id, order=ListSortOrder.ASCENDING):\n    if isinstance(run_step.step_details, RunStepToolCallDetails):\n        for tool_call in run_step.step_details.tool_calls:\n            if isinstance(tool_call, RunStepConnectedAgentToolCall):\n                print(\n                    f\"\\tAgent: {tool_call.connected_agent.name} \" f\"query: {tool_call.connected_agent.arguments} \",\n                    f\"output: {tool_call.connected_agent.output}\",\n                )\n```\n\n<!-- END SNIPPET -->\n\nThe messages contain references, marked by unicode opening and closing brackets, which cannot be printed by python `print` command. To fix this issue we will replace them by ASCII brackets.\n\n<!-- SNIPPET:sample_agents_multiple_connected_agents.list_messages -->\n\n```python\n# Fetch and log all messages\nmessages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\nfor msg in messages:\n    if msg.text_messages:\n        last_text = msg.text_messages[-1]\n        text = last_text.text.value.replace(\"\\u3010\", \"[\").replace(\"\\u3011\", \"]\")\n        print(f\"{msg.role}: {text}\")\n```\n\n<!-- END SNIPPET -->\n\n\n### Create Thread\n\nFor each session or conversation, a thread is required.   Here is an example:\n\n<!-- SNIPPET:sample_agents_basics.create_thread -->\n\n```python\nthread = agents_client.threads.create()\n```\n\n<!-- END SNIPPET -->\n\n### Create Thread with Tool Resource\n\nIn some scenarios, you might need to assign specific resources to individual threads. To achieve this, you provide the `tool_resources` argument to `create_thread`. In the following example, you create a vector store and upload a file, enable an Agent for file search using the `tools` argument, and then associate the file with the thread using the `tool_resources` argument.\n\n<!-- SNIPPET:sample_agents_with_resources_in_thread.create_agent_and_thread_for_file_search -->\n\n```python\nfile = agents_client.files.upload_and_poll(file_path=asset_file_path, purpose=FilePurpose.AGENTS)\nprint(f\"Uploaded file, file ID: {file.id}\")\n\nvector_store = agents_client.vector_stores.create_and_poll(file_ids=[file.id], name=\"my_vectorstore\")\nprint(f\"Created vector store, vector store ID: {vector_store.id}\")\n\n# Create file search tool with resources followed by creating agent\nfile_search = FileSearchTool(vector_store_ids=[vector_store.id])\n\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"Hello, you are helpful agent and can search information from uploaded files\",\n    tools=file_search.definitions,\n)\n\nprint(f\"Created agent, ID: {agent.id}\")\n\n# Create thread with file resources.\n# If the agent has multiple threads, only this thread can search this file.\nthread = agents_client.threads.create(tool_resources=file_search.resources)\n```\n\n<!-- END SNIPPET -->\n\n#### List Threads\n\nTo list all threads attached to a given agent, use the list_threads API:\n\n```python\nthreads = agents_client.threads.list()\n```\n\n### Create Message\n\nTo create a message for agent to process, you pass `user` as `role` and a question as `content`:\n\n<!-- SNIPPET:sample_agents_basics.create_message -->\n\n```python\nmessage = agents_client.messages.create(thread_id=thread.id, role=\"user\", content=\"Hello, tell me a joke\")\n```\n\n<!-- END SNIPPET -->\n\n### Create Message with File Search Attachment\n\nTo attach a file to a message for content searching, you use `MessageAttachment` and `FileSearchTool`:\n\n<!-- SNIPPET:sample_agents_with_file_search_attachment.create_message_with_attachment -->\n\n```python\nattachment = MessageAttachment(file_id=file.id, tools=FileSearchTool().definitions)\nmessage = agents_client.messages.create(\n    thread_id=thread.id, role=\"user\", content=\"What feature does Smart Eyewear offer?\", attachments=[attachment]\n)\n```\n\n<!-- END SNIPPET -->\n\n### Create Message with Code Interpreter Attachment\n\nTo attach a file to a message for data analysis, use `MessageAttachment` and `CodeInterpreterTool` classes. You must pass `CodeInterpreterTool` as `tools` or `toolset` in `create_agent` call or the file attachment cannot be opened for code interpreter.\n\nHere is an example to pass `CodeInterpreterTool` as tool:\n\n<!-- SNIPPET:sample_agents_with_code_interpreter_file_attachment.create_agent_and_message_with_code_interpreter_file_attachment -->\n\n```python\n# Notice that CodeInterpreter must be enabled in the agent creation,\n# otherwise the agent will not be able to see the file attachment for code interpretation\nagent = agents_client.create_agent(\n    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n    name=\"my-agent\",\n    instructions=\"You are helpful agent\",\n    tools=CodeInterpreterTool().definitions,\n)\nprint(f\"Created agent, agent ID: {agent.id}\")\n\nthread = agents_client.threads.create()\nprint(f\"Created thread, thread ID: {thread.id}\")\n\n# Create an attachment\nattachment = MessageAttachment(file_id=file.id, tools=CodeInterpreterTool().definitions)\n\n# Create a message\nmessage = agents_client.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Could you please create bar chart in TRANSPORTATION sector for the operating profit from the uploaded csv file and provide file to me?\",\n    attachments=[attachment],\n)\n```\n\n<!-- END SNIPPET -->\n\nAzure blob storage can be used as a message attachment. In this case, use `VectorStoreDataSource` as a data source:\n\n<!-- SNIPPET:sample_agents_code_interpreter_attachment_enterprise_search.upload_file_and_create_message_with_code_interpreter -->\n\n```python\n# We will upload the local file to Azure and will use it for vector store creation.\nasset_uri = os.environ[\"AZURE_BLOB_URI\"]\nds = VectorStoreDataSource(asset_identifier=asset_uri, asset_type=VectorStoreDataSourceAssetType.URI_ASSET)\n\n# Create a message with the attachment\nattachment = MessageAttachment(data_source=ds, tools=code_interpreter.definitions)\nmessage = agents_client.messages.create(\n    thread_id=thread.id, role=\"user\", content=\"What does the attachment say?\", attachments=[attachment]\n)\n```\n\n<!-- END SNIPPET -->\n\n### Create Message with Image Inputs\n\nYou can send messages to Azure agents with image inputs in following ways:\n\n- **Using an image stored as a uploaded file**\n- **Using a public image accessible via URL**\n- **Using a base64 encoded image string**\n\nThe following examples demonstrate each method:\n\n#### Create message using uploaded image file\n\n```python\n# Upload the local image file\nimage_file = agents_client.files.upload_and_poll(file_path=\"image_file.png\", purpose=\"assistants\")\n\n# Construct content using uploaded image\nfile_param = MessageImageFileParam(file_id=image_file.id, detail=\"high\")\ncontent_blocks = [\n    MessageInputTextBlock(text=\"Hello, what is in the image?\"),\n    MessageInputImageFileBlock(image_file=file_param),\n]\n\n# Create the message\nmessage = agents_client.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=content_blocks\n)\n```\n\n#### Create message with an image URL input\n\n```python\n# Specify the public image URL\nimage_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n\n# Create content directly referencing image URL\nurl_param = MessageImageUrlParam(url=image_url, detail=\"high\")\ncontent_blocks = [\n    MessageInputTextBlock(text=\"Hello, what is in the image?\"),\n    MessageInputImageUrlBlock(image_url=url_param),\n]\n\n# Create the message\nmessage = agents_client.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=content_blocks\n)\n```\n\n#### Create message with base64-encoded image input\n\n```python\nimport base64\n\ndef image_file_to_base64(path: str) -> str:\n    with open(path, \"rb\") as f:\n        return base64.b64encode(f.read()).decode(\"utf-8\")\n\n# Convert your image file to base64 format\nimage_base64 = image_file_to_base64(\"image_file.png\")\n\n# Prepare the data URL\nimg_data_url = f\"data:image/png;base64,{image_base64}\"\n\n# Use base64 encoded string as image URL parameter\nurl_param = MessageImageUrlParam(url=img_data_url, detail=\"high\")\ncontent_blocks = [\n    MessageInputTextBlock(text=\"Hello, what is in the image?\"),\n    MessageInputImageUrlBlock(image_url=url_param),\n]\n\n# Create the message\nmessage = agents_client.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=content_blocks\n)\n```\n\n### Execute Run, Run_and_Process, or Stream\n\nTo process your message, you can use `runs.create`, `runs.create_and_process`, or `runs.stream`.\n\n`runs.create` requests the Agent to process the message without polling for the result. If you are using `function tools`, your code is responsible for polling for the result and acknowledging the status of `Run`. When the status is `requires_action`, your code is responsible for calling the function tools. For a code sample, visit [`sample_agents_functions.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_tools/sample_agents_functions.py).\n\nHere is an example of `runs.create` and poll until the run is completed:\n\n<!-- SNIPPET:sample_agents_basics.create_run -->\n\n```python\nrun = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n\n# Poll the run as long as run status is queued or in progress\nwhile run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n    # Wait for a second\n    time.sleep(1)\n    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n```\n\n<!-- END SNIPPET -->\n\nTo have the SDK poll on your behalf and call `function tools`, supply your function implementations through `enable_auto_function_calls` along with `runs.create_and_process` method .\n\nHere is an example:\n\n```python\nfunctions = FunctionTool(user_functions)\n\ntoolset = ToolSet()\ntoolset.add(functions)\n\n# To enable tool calls executed automatically\nagents_client.enable_auto_function_calls(toolset)\n```\n\n<!-- SNIPPET:sample_agents_run_with_toolset.create_and_process_run -->\n\n```python\nrun = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n```\n\n<!-- END SNIPPET -->\n\nFor scenarios requiring manual approval or custom control over function execution (such as security-sensitive operations), you can use a `RunHandler` with the `create_and_process` method. This approach allows you to implement custom logic to decide whether, when, and how functions should be executed.\n\nHere's an example that demonstrates manual function calls using a `RunHandler`:\n\n<!-- SNIPPET:sample_agents_functions_in_create_and_process.run_handler -->\n\n```python\nclass MyRunHandler(RunHandler):\n    def submit_function_call_output(\n        self,\n        *,\n        run: ThreadRun,\n        tool_call: RequiredFunctionToolCall,\n        tool_call_details: RequiredFunctionToolCallDetails,\n        **kwargs: Any,\n    ) -> Any:\n        function_name = tool_call_details.name\n        if function_name == send_email.__name__:\n            # Parse arguments from tool call\n            args_dict = json.loads(tool_call_details.arguments) if tool_call_details.arguments else {}\n            # Call the function directly with the arguments\n            return send_email(**args_dict)\n```\n\n<!-- END SNIPPET -->\n\nTo use the RunHandler with `create_and_process`:\n\n<!-- SNIPPET:sample_agents_functions_in_create_and_process.create_and_process -->\n\n```python\nrun = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id, run_handler=MyRunHandler())\n```\n\n<!-- END SNIPPET -->\n\nFor a complete example, see [`sample_agents_functions_in_create_and_process.py`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_tools/sample_agents_functions_in_create_and_process.py).\n\nWith streaming, polling need not be considered. If `function tools` were added to the agents, you should decide to have the function tools called manually or automatically.  Please visit [`manual function call sample`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_streaming/sample_agents_stream_eventhandler_with_functions.py) or [`automatic function call sample`](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_streaming/sample_agents_stream_iteration_with_toolset.py).    \n\nHere is a basic example of streaming:\n\n<!-- SNIPPET:sample_agents_basics_stream_iteration.iterate_stream -->\n\n```python\nwith agents_client.runs.stream(thread_id=thread.id, agent_id=agent.id) as stream:\n\n    for event_type, event_data, _ in stream:\n\n        if isinstance(event_data, MessageDeltaChunk):\n            print(f\"Text delta received: {event_data.text}\")\n\n        elif isinstance(event_data, ThreadMessage):\n            print(f\"ThreadMessage created. ID: {event_data.id}, Status: {event_data.status}\")\n\n        elif isinstance(event_data, ThreadRun):\n            print(f\"ThreadRun status: {event_data.status}\")\n\n        elif isinstance(event_data, RunStep):\n            print(f\"RunStep type: {event_data.type}, Status: {event_data.status}\")\n\n        elif event_type == AgentStreamEvent.ERROR:\n            print(f\"An error occurred. Data: {event_data}\")\n\n        elif event_type == AgentStreamEvent.DONE:\n            print(\"Stream completed.\")\n            break\n\n        else:\n            print(f\"Unhandled Event Type: {event_type}, Data: {event_data}\")\n```\n\n<!-- END SNIPPET -->\n\nIn the code above, because an `event_handler` object is not passed to the `stream` function, the SDK will instantiate `AgentEventHandler` or `AsyncAgentEventHandler` as the default event handler and produce an iterable object with `event_type` and `event_data`.  `AgentEventHandler` and `AsyncAgentEventHandler` are overridable.  Here is an example:\n\n<!-- SNIPPET:sample_agents_basics_stream_eventhandler.stream_event_handler -->\n\n```python\n# With AgentEventHandler[str], the return type for each event functions is optional string.\nclass MyEventHandler(AgentEventHandler[str]):\n\n    def on_message_delta(self, delta: \"MessageDeltaChunk\") -> Optional[str]:\n        return f\"Text delta received: {delta.text}\"\n\n    def on_thread_message(self, message: \"ThreadMessage\") -> Optional[str]:\n        return f\"ThreadMessage created. ID: {message.id}, Status: {message.status}\"\n\n    def on_thread_run(self, run: \"ThreadRun\") -> Optional[str]:\n        return f\"ThreadRun status: {run.status}\"\n\n    def on_run_step(self, step: \"RunStep\") -> Optional[str]:\n        return f\"RunStep type: {step.type}, Status: {step.status}\"\n\n    def on_error(self, data: str) -> Optional[str]:\n        return f\"An error occurred. Data: {data}\"\n\n    def on_done(self) -> Optional[str]:\n        return \"Stream completed.\"\n\n    def on_unhandled_event(self, event_type: str, event_data: Any) -> Optional[str]:\n        return f\"Unhandled Event Type: {event_type}, Data: {event_data}\"\n```\n\n<!-- END SNIPPET -->\n\n\n<!-- SNIPPET:sample_agents_basics_stream_eventhandler.create_stream -->\n\n```python\nwith agents_client.runs.stream(thread_id=thread.id, agent_id=agent.id, event_handler=MyEventHandler()) as stream:\n    for event_type, event_data, func_return in stream:\n        print(f\"Received data.\")\n        print(f\"Streaming receive Event Type: {event_type}\")\n        print(f\"Event Data: {str(event_data)[:100]}...\")\n        print(f\"Event Function return: {func_return}\\n\")\n```\n\n<!-- END SNIPPET -->\n\nAs you can see, this SDK parses the events and produces various event types similar to OpenAI agents. In your use case, you might not be interested in handling all these types and may decide to parse the events on your own. To achieve this, please refer to [override base event handler](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_streaming/sample_agents_stream_with_base_override_eventhandler.py).\n\n```\nNote: Multiple streaming processes may be chained behind the scenes.\n\nWhen the SDK receives a `ThreadRun` event with the status `requires_action`, the next event will be `Done`, followed by termination. The SDK will submit the tool calls using the same event handler. The event handler will then chain the main stream with the tool stream.\n\nConsequently, when you iterate over the streaming using a for loop similar to the example above, the for loop will receive events from the main stream followed by events from the tool stream.\n```\n\n\n### Retrieve Message\n\nTo retrieve messages from agents, use the following example:\n\n<!-- SNIPPET:sample_agents_basics.list_messages -->\n\n```python\nmessages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\nfor msg in messages:\n    if msg.text_messages:\n        last_text = msg.text_messages[-1]\n        print(f\"{msg.role}: {last_text.text.value}\")\n```\n\n<!-- END SNIPPET -->\n\nIn addition, `messages` and `messages.data[]` offer helper properties such as `text_messages`, `image_contents`, `file_citation_annotations`, and `file_path_annotations` to quickly retrieve content from one message or all messages.\n\n### Retrieve File\n\nFiles uploaded by Agents cannot be retrieved back. If your use case need to access the file content uploaded by the Agents, you are advised to keep an additional copy accessible by your application. However, files generated by Agents are retrievable by `save_file` or `get_file_content`.\n\nHere is an example retrieving file ids from messages and save to the local drive:\n\n<!-- SNIPPET:sample_agents_code_interpreter.get_messages_and_save_files -->\n\n```python\nmessages = agents_client.messages.list(thread_id=thread.id)\nprint(f\"Messages: {messages}\")\n\nfor msg in messages:\n    # Save every image file in the message\n    for img in msg.image_contents:\n        file_id = img.image_file.file_id\n        file_name = f\"{file_id}_image_file.png\"\n        agents_client.files.save(file_id=file_id, file_name=file_name)\n        print(f\"Saved image file to: {Path.cwd() / file_name}\")\n\n    # Print details of every file-path annotation\n    for ann in msg.file_path_annotations:\n        print(\"File Paths:\")\n        print(f\"  Type: {ann.type}\")\n        print(f\"  Text: {ann.text}\")\n        print(f\"  File ID: {ann.file_path.file_id}\")\n        print(f\"  Start Index: {ann.start_index}\")\n        print(f\"  End Index: {ann.end_index}\")\n```\n\n<!-- END SNIPPET -->\n\nHere is an example to use `get_file_content`:\n\n```python\nfrom pathlib import Path\n\nasync def save_file_content(client, file_id: str, file_name: str, target_dir: Optional[Union[str, Path]] = None):\n    # Determine the target directory\n    path = Path(target_dir).expanduser().resolve() if target_dir else Path.cwd()\n    path.mkdir(parents=True, exist_ok=True)\n\n    # Retrieve the file content\n    file_content_stream = await client.files.get_content(file_id)\n    if not file_content_stream:\n        raise RuntimeError(f\"No content retrievable for file ID '{file_id}'.\")\n\n    # Collect all chunks asynchronously\n    chunks = []\n    async for chunk in file_content_stream:\n        if isinstance(chunk, (bytes, bytearray)):\n            chunks.append(chunk)\n        else:\n            raise TypeError(f\"Expected bytes or bytearray, got {type(chunk).__name__}\")\n\n    target_file_path = path / file_name\n\n    # Write the collected content to the file synchronously\n    with open(target_file_path, \"wb\") as file:\n        for chunk in chunks:\n            file.write(chunk)\n```\n\n### Teardown\n\nTo remove resources after completing tasks, use the following functions:\n\n<!-- SNIPPET:sample_agents_file_search.teardown -->\n\n```python\n# Delete the file when done\nagents_client.vector_stores.delete(vector_store.id)\nprint(\"Deleted vector store\")\n\nagents_client.files.delete(file_id=file.id)\nprint(\"Deleted file\")\n\n# Delete the agent when done\nagents_client.delete_agent(agent.id)\nprint(\"Deleted agent\")\n```\n\n<!-- END SNIPPET -->\n\n## Tracing\n\nYou can add an Application Insights Azure resource to your Azure AI Foundry project. See the Tracing tab in your AI Foundry project. If one was enabled, you can get the Application Insights connection string, configure your Agents, and observe the full execution path through Azure Monitor. Typically, you might want to start tracing before you create an Agent.\n\n### Installation\n\nMake sure to install OpenTelemetry and the Azure SDK tracing plugin via\n\n```bash\npip install azure-ai-agents azure-identity opentelemetry-sdk azure-core-tracing-opentelemetry\n```\n\nYou will also need an exporter to send telemetry to your observability backend. You can print traces to the console or use a local viewer such as [Aspire Dashboard](https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash).\n\nTo connect to Aspire Dashboard or another OpenTelemetry compatible backend, install OTLP exporter:\n\n```bash\npip install opentelemetry-exporter-otlp\n```\n\n### How to enable tracing\n\nHere is a code sample that shows how to enable Azure Monitor tracing:\n\n<!-- SNIPPET:sample_agents_basics_with_azure_monitor_tracing.enable_tracing -->\n\n```python\nfrom opentelemetry import trace\nfrom azure.monitor.opentelemetry import configure_azure_monitor\n\n# Enable Azure Monitor tracing\napplication_insights_connection_string = os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\nconfigure_azure_monitor(connection_string=application_insights_connection_string)\n\nscenario = os.path.basename(__file__)\ntracer = trace.get_tracer(__name__)\n\nwith tracer.start_as_current_span(scenario):\n    with project_client:\n        agents_client = project_client.agents\n```\n\n<!-- END SNIPPET -->\n\nIn addition, you might find helpful to see the tracing logs in console. You can achieve by the following code:\n\n```python\nfrom azure.ai.agents.telemetry import enable_telemetry\n\nenable_telemetry(destination=sys.stdout)\n```\n\n### Enabling content recording\n\nContent recording controls whether message contents and tool call related details, such as parameters and return values, are captured with the traces. This data may include sensitive user information.\n\nTo enable content recording set the `OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT` environment variable to `true`. This environment variable is defined\nby [OpenTelemetry](https://opentelemetry.io/), and all new applications are encouraged to use it when content recording is required. For legacy reasons, content recordings will also be enabled if `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED` environment variable is set to `true`.\n\nIf neither environment variable is set, content recording defaults to `false`. If either variable is set to `false`, content recording will be disabled, regardless of the other's value.\n\n**Important:** The environment variables only control content recording for built-in agent traces. When you use the `@trace_function` decorator on your own functions, all parameters and return values are always traced.\n\n### How to trace your own functions\n\nThe decorator `trace_function` is provided for tracing your own function calls using OpenTelemetry. By default the function name is used as the name for the span. Alternatively you can provide the name for the span as a parameter to the decorator.\n\nThis decorator handles various data types for function parameters and return values, and records them as attributes in the trace span. The supported data types include:\n* Basic data types: str, int, float, bool\n* Collections: list, dict, tuple, set\n    * Special handling for collections:\n      - If a collection (list, dict, tuple, set) contains nested collections, the entire collection is converted to a string before being recorded as an attribute.\n      - Sets and dictionaries are always converted to strings to ensure compatibility with span attributes.\n\nObject types are omitted, and the corresponding parameter is not traced.\n\nThe parameters are recorded in attributes `code.function.parameter.<parameter_name>` and the return value is recorder in attribute `code.function.return.value`\n\n### Adding custom attributes to spans\n\nDefine your own span processor which adds your custom attributes:\n\n<!-- SNIPPET:sample_agents_basics_with_console_tracing_custom_attributes.custom_attribute_span_processor -->\n\n```python\nclass CustomAttributeSpanProcessor(SpanProcessor):\n    def __init__(self):\n        pass\n\n    def on_start(self, span: Span, parent_context=None):\n        # Add this attribute to all spans\n        span.set_attribute(\"trace_sample.sessionid\", \"123\")\n\n        # Add another attribute only to create_message spans\n        if span.name == \"create_message\":\n            span.set_attribute(\"trace_sample.message.context\", \"abc\")\n\n    def on_end(self, span: ReadableSpan):\n        # Clean-up logic can be added here if necessary\n        pass\n```\n\n<!-- END SNIPPET -->\n\nAdd the span processor to trace provider:\n\n<!-- SNIPPET:sample_agents_basics_with_console_tracing_custom_attributes.add_custom_span_processor_to_tracer_provider -->\n\n```python\nprovider = cast(TracerProvider, trace.get_tracer_provider())\nprovider.add_span_processor(CustomAttributeSpanProcessor())\n```\n\n<!-- END SNIPPET -->\n\n\n## Troubleshooting\n\n### Logging\n\nThe client uses the standard [Python logging library](https://docs.python.org/3/library/logging.html). The SDK logs HTTP request and response details, which may be useful in troubleshooting. To log to stdout, add the following:\n\n```python\nimport sys\nimport logging\n\n# Acquire the logger for this client library. Use 'azure' to affect both\n# 'azure.core` and `azure.ai.inference' libraries.\nlogger = logging.getLogger(\"azure\")\n\n# Set the desired logging level. logging.INFO or logging.DEBUG are good options.\nlogger.setLevel(logging.DEBUG)\n\n# Direct logging output to stdout:\nhandler = logging.StreamHandler(stream=sys.stdout)\n# Or direct logging output to a file:\n# handler = logging.FileHandler(filename=\"sample.log\")\nlogger.addHandler(handler)\n\n# Optional: change the default logging format. Here we add a timestamp.\n#formatter = logging.Formatter(\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\")\n#handler.setFormatter(formatter)\n```\n\nBy default logs redact the values of URL query strings, the values of some HTTP request and response headers (including `Authorization` which holds the key or token), and the request and response payloads. To create logs without redaction, add `logging_enable = True` to the client constructor:\n\n```python\nagents_client = AgentsClient(\n    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n    credential=DefaultAzureCredential(),\n    logging_enable = True\n)\n```\n\nNote that the log level must be set to `logging.DEBUG` (see above code). Logs will be redacted with any other log level.\n\nBe sure to protect non redacted logs to avoid compromising security.\n\nFor more information, see [Configure logging in the Azure libraries for Python](https://aka.ms/azsdk/python/logging)\n\n### Reporting issues\n\nTo report an issue with the client library, or request additional features, please open a GitHub issue [here](https://github.com/Azure/azure-sdk-for-python/issues). Mention the package name \"azure-ai-agents\" in the title or content.\n\n\n## Next steps\n\nHave a look at the [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-agents/samples) folder, containing fully runnable Python code for synchronous and asynchronous clients.\n\nExplore the [AI Starter Template](https://aka.ms/azsdk/azure-ai-agents/python/ai-starter-template). This template creates an Azure AI Foundry hub, project and connected resources including Azure OpenAI Service, AI Search and more. It also deploys a simple chat application to Azure Container Apps.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require\nyou to agree to a Contributor License Agreement (CLA) declaring that you have\nthe right to, and actually do, grant us the rights to use your contribution.\nFor details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether\nyou need to provide a CLA and decorate the PR appropriately (e.g., label,\ncomment). Simply follow the instructions provided by the bot. You will only\nneed to do this once across all repos using our CLA.\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct][code_of_conduct]. For more information,\nsee the Code of Conduct FAQ or contact opencode@microsoft.com with any\nadditional questions or comments.\n\n<!-- LINKS -->\n[samples]: https://aka.ms/azsdk/azure-ai-projects/python/samples/\n[code_of_conduct]: https://opensource.microsoft.com/codeofconduct/\n[entra_id]: https://learn.microsoft.com/azure/ai-services/authentication?tabs=powershell#authenticate-with-microsoft-entra-id\n[azure_identity_credentials]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#credentials\n[azure_identity_pip]: https://pypi.org/project/azure-identity/\n[default_azure_credential]: https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#defaultazurecredential\n[pip]: https://pypi.org/project/pip/\n[azure_sub]: https://azure.microsoft.com/free/\n[evaluators]: https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk\n[azure_ai_evaluation]: https://learn.microsoft.com/python/api/overview/azure/ai-evaluation-readme\n[evaluator_library]: https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-generative-ai-app#view-and-manage-the-evaluators-in-the-evaluator-library\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "isodate>=0.6.1",
          "azure-core>=1.30.0",
          "typing-extensions>=4.6.0"
        ],
        "requires_python": ">=3.9"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/62/55/7f118b9c1b23ec15ca05d15a578d8207aa1706bc6f7c87218efffbbf875d/azure_common-1.1.28-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5c12d3dcf4ec20599ca6b0d3e09e86e146353d443e7fcc050c9a19c1f9df20ad",
          "hashes": {
            "sha256": "5c12d3dcf4ec20599ca6b0d3e09e86e146353d443e7fcc050c9a19c1f9df20ad"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "azure-common",
        "version": "1.1.28",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Microsoft Azure Client Library for Python (Common)",
        "description": "# Microsoft Azure SDK for Python\n\nThis is the Microsoft Azure common code.\n\nThis package provides shared code by the Azure packages.\n\nIf you are looking to install the Azure client libraries, refer to the main Github repository:\nhttps://github.com/Azure/azure-sdk-for-python\n\n\n![Impressions](https://azure-sdk-impressions.azurewebsites.net/api/impressions/azure-sdk-for-python%2Fazure-common%2FREADME.png)\n\n\n# Release History\n\n## 1.1.28 (2022-02-03)\n\n- Raise a NotImplementedError if trying to use CLI credentials were CLI version is higher than 2.21.0  #20657 #21313\n- Deprecate all methods that needs access to CLI code using azure-cli-core, since this package is no longer importable as public API\n\n## 1.1.27 (2021-03-23)\n\n- Deprecate JSON and auth file client factory  #15075\n- Add 2020-09-01-hybrid profile definition  #14642\n\n## 1.1.26 (2020-11-10)\n\n- get_client_from_cli_profile now supports azure-applicationinsights 0.1.0 package\n\n## 1.1.25 (2020-03-09)\n\n- get_client_from_cli_profile no longer requires \"azure-core\" if not necessary\n\n## 1.1.24 (2019-12-18)\n\n- get_client_from_cli_profile now supports KV 4.x, Storage 12.x, AppConfig and all packages based on azure-core\n\n## 1.1.23 (2019-06-24)\n\n- Add Monitor into Profile v2019_03_01_hybrid (requires azure-mgmt-monitor >= 0.7.0)\n\n## 1.1.22 (2019-06-06)\n\n- Fix KeyVaultClient support for get_client_from_auth_file\n\n## 1.1.21 (2019-05-21)\n\n- Fix compute support in profile v2019_03_01_hybrid\n\n## 1.1.20 (2019-04-30)\n\n- Add support for profile v2019_03_01_hybrid\n- Fix profile v2018_03_01_hybrid for DNS definition\n\n## 1.1.19 (2019-04-18)\n\n- Azure Stack support for get_client_from_auth_file and get_client_from_json_dict\n\n## 1.1.18 (2019-01-29)\n\n- Remove deprecated extra dependencies\n\n## 1.1.17 (2019-01-15)\n\n- Fix KeyVaultClient creation with get_client_from_cli_profile\n\nThanks to patrikn for the contribution\n\n## 1.1.16 (2018-09-26)\n\n- azure-nspkg is not installed anymore on Python 3 (PEP420-based namespace package)\n\n## 1.1.15 (2018-09-13)\n\n**Features**\n\n- Adding profile v2018-03-01-hybrid definition\n\n## 1.1.14 (2018-07-23)\n\n**Features**\n\n- Adding KeyVault to profile v2017_03_09_profile\n\n## 1.1.13 (2018-07-03)\n\n**Features**\n\n- get_azure_cli_credentials has a new parameter \"with_tenant\" to get default CLI tenant ID\n\n**Bugfixes**\n\n- get_client_from_cli_profile now supports the \"azure-graphrbac\" package #2867\n- get_client_from_auth_file now supports the \"azure-graphrbac\" package #2867\n\n## 1.1.12 (2018-05-29)\n\n**Features**\n\n- Add Authorization profile definition\n\n## 1.1.11 (2018-05-08)\n\n**Features**\n\n- Add support for \"resource\" in \"get_azure_cli_credentials\"\n\n## 1.1.10 (2018-04-30)\n\n**Bugfixes**\n\n- Fix MultiApiClientMixin.__init__ to be a real mixin\n\n## 1.1.9 (2018-04-03)\n\n**Features**\n\n- Add \"azure.profiles\" namespace #2247\n\n**Bugfixes**\n\n- get_client_from_cli_profile now supports Datalake #2318\n\n## 1.1.8 (2017-07-28)\n\n**Bugfix**\n\n- Fix get_client_from_auth_file and get_client_from_json_dict on Python 2.7\n\nThank you to @jayden-at-arista for the contribution.\n\n## 1.1.7 (2017-07-19)\n\n- Adds azure.common.client_factory.get_client_from_auth_file\n- Adds azure.common.client_factory.get_client_from_json_dict\n\n## 1.1.6 (2017-05-16)\n\n- Adds azure.common.client_factory.get_client_from_cli_profile\n\n## 1.1.5 (2017-04-11)\n\n- \"extra_requires\" autorest is deprecated and should not be used anymore\n- This wheel package is now built with the azure wheel extension\n\n## 1.1.4 (2016-05-25)\n\n- Support for msrest/msrestazure 0.4.x series\n- Drop support for msrest/msrestazure 0.3.x series\n\n## 1.1.3 (2016-04-26)\n\n- Support for msrest/msrestazure 0.3.x series\n- Drop support for msrest/msrestazure 0.2.x series\n\n## 1.1.2 (2016-03-28)\n\n- Support for msrest/msrestazure 0.2.x series\n- Drop support for msrest/msrestazure 0.1.x series\n\n## 1.1.1 (2016-03-07)\n\n- Move msrestazure depency as \"extra_requires\"\n\n## 1.1.0 (2016-03-04)\n\n- Support for msrest/msrestazure 0.1.x series\n- Adds alias from msrestazure.azure_active_directory.* to azure.common.credentials\n\n## 1.0.0 (2015-08-31)\n\nInitial release, extracted from azure==0.11.1\n\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/Azure/azure-sdk-for-python",
        "author": "Microsoft Corporation",
        "author_email": "azpysdkhelp@microsoft.com",
        "license": "MIT License",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-nspkg ; python_version<'3.0'"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/d8/3a/6ef2047a072e54e1142718d433d50e9514c999a58f51abfff7902f3a72f8/azure_storage_blob-12.28.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=00fb1db28bf6a7b7ecaa48e3b1d5c83bfadacc5a678b77826081304bd87d6461",
          "hashes": {
            "sha256": "00fb1db28bf6a7b7ecaa48e3b1d5c83bfadacc5a678b77826081304bd87d6461"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "azure-storage-blob",
        "version": "12.28.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Microsoft Azure Blob Storage Client Library for Python",
        "description": "# Azure Storage Blobs client library for Python\nAzure Blob storage is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data, such as text or binary data.\n\nBlob storage is ideal for:\n\n* Serving images or documents directly to a browser\n* Storing files for distributed access\n* Streaming video and audio\n* Storing data for backup and restore, disaster recovery, and archiving\n* Storing data for analysis by an on-premises or Azure-hosted service\n\n[Source code](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/azure/storage/blob)\n| [Package (PyPI)](https://pypi.org/project/azure-storage-blob/)\n| [Package (Conda)](https://anaconda.org/microsoft/azure-storage/)\n| [API reference documentation](https://aka.ms/azsdk-python-storage-blob-ref)\n| [Product documentation](https://learn.microsoft.com/azure/storage/)\n| [Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples)\n\n\n## Getting started\n\n### Prerequisites\n* Python 3.9 or later is required to use this package. For more details, please read our page on [Azure SDK for Python version support policy](https://github.com/Azure/azure-sdk-for-python/wiki/Azure-SDKs-Python-version-support-policy).\n* You must have an [Azure subscription](https://azure.microsoft.com/free/) and an\n[Azure storage account](https://learn.microsoft.com/azure/storage/common/storage-account-overview) to use this package.\n\n### Install the package\nInstall the Azure Storage Blobs client library for Python with [pip](https://pypi.org/project/pip/):\n\n```bash\npip install azure-storage-blob\n```\n\n### Create a storage account\nIf you wish to create a new storage account, you can use the\n[Azure Portal](https://learn.microsoft.com/azure/storage/common/storage-quickstart-create-account?tabs=azure-portal),\n[Azure PowerShell](https://learn.microsoft.com/azure/storage/common/storage-quickstart-create-account?tabs=azure-powershell),\nor [Azure CLI](https://learn.microsoft.com/azure/storage/common/storage-quickstart-create-account?tabs=azure-cli):\n\n```bash\n# Create a new resource group to hold the storage account -\n# if using an existing resource group, skip this step\naz group create --name my-resource-group --location westus2\n\n# Create the storage account\naz storage account create -n my-storage-account-name -g my-resource-group\n```\n\n### Create the client\nThe Azure Storage Blobs client library for Python allows you to interact with three types of resources: the storage\naccount itself, blob storage containers, and blobs. Interaction with these resources starts with an instance of a\n[client](#clients). To create a client object, you will need the storage account's blob service account URL and a\ncredential that allows you to access the storage account:\n\n```python\nfrom azure.storage.blob import BlobServiceClient\n\nservice = BlobServiceClient(account_url=\"https://<my-storage-account-name>.blob.core.windows.net/\", credential=credential)\n```\n\n#### Looking up the account URL\nYou can find the storage account's blob service URL using the\n[Azure Portal](https://learn.microsoft.com/azure/storage/common/storage-account-overview#storage-account-endpoints),\n[Azure PowerShell](https://learn.microsoft.com/powershell/module/az.storage/get-azstorageaccount),\nor [Azure CLI](https://learn.microsoft.com/cli/azure/storage/account?view=azure-cli-latest#az-storage-account-show):\n\n```bash\n# Get the blob service account url for the storage account\naz storage account show -n my-storage-account-name -g my-resource-group --query \"primaryEndpoints.blob\"\n```\n\n#### Types of credentials\nThe `credential` parameter may be provided in a number of different forms, depending on the type of\n[authorization](https://learn.microsoft.com/azure/storage/common/storage-auth) you wish to use:\n1. To use an [Azure Active Directory (AAD) token credential](https://learn.microsoft.com/azure/storage/common/storage-auth-aad),\n   provide an instance of the desired credential type obtained from the\n   [azure-identity](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#credentials) library.\n   For example, [DefaultAzureCredential](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#defaultazurecredential)\n   can be used to authenticate the client.\n\n   This requires some initial setup:\n   * [Install azure-identity](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/identity/azure-identity#install-the-package)\n   * [Register a new AAD application](https://learn.microsoft.com/azure/active-directory/develop/quickstart-register-app) and give permissions to access Azure Storage\n   * [Grant access](https://learn.microsoft.com/azure/storage/common/storage-auth-aad-rbac-portal) to Azure Blob data with RBAC in the Azure Portal\n   * Set the values of the client ID, tenant ID, and client secret of the AAD application as environment variables:\n     AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET\n\n   Use the returned token credential to authenticate the client:\n    ```python\n    from azure.identity import DefaultAzureCredential\n    from azure.storage.blob import BlobServiceClient\n    token_credential = DefaultAzureCredential()\n\n    blob_service_client = BlobServiceClient(\n        account_url=\"https://<my_account_name>.blob.core.windows.net\",\n        credential=token_credential\n    )\n    ```\n\n2. To use a [shared access signature (SAS) token](https://learn.microsoft.com/azure/storage/common/storage-sas-overview),\n   provide the token as a string. If your account URL includes the SAS token, omit the credential parameter.\n   You can generate a SAS token from the Azure Portal under \"Shared access signature\" or use one of the `generate_sas()`\n   functions to create a sas token for the storage account, container, or blob:\n\n    ```python\n    from datetime import datetime, timedelta\n    from azure.storage.blob import BlobServiceClient, generate_account_sas, ResourceTypes, AccountSasPermissions\n\n    sas_token = generate_account_sas(\n        account_name=\"<storage-account-name>\",\n        account_key=\"<account-access-key>\",\n        resource_types=ResourceTypes(service=True),\n        permission=AccountSasPermissions(read=True),\n        expiry=datetime.utcnow() + timedelta(hours=1)\n    )\n\n    blob_service_client = BlobServiceClient(account_url=\"https://<my_account_name>.blob.core.windows.net\", credential=sas_token)\n    ```\n\n3. To use a storage account [shared key](https://learn.microsoft.com/rest/api/storageservices/authenticate-with-shared-key/)\n   (aka account key or access key), provide the key as a string. This can be found in the Azure Portal under the \"Access Keys\"\n   section or by running the following Azure CLI command:\n\n    ```az storage account keys list -g MyResourceGroup -n MyStorageAccount```\n\n    Use the key as the credential parameter to authenticate the client:\n    ```python\n    from azure.storage.blob import BlobServiceClient\n    service = BlobServiceClient(account_url=\"https://<my_account_name>.blob.core.windows.net\", credential=\"<account_access_key>\")\n    ```\n    \n    If you are using **customized url** (which means the url is not in this format `<my_account_name>.blob.core.windows.net`),\n    please instantiate the client using the credential below:\n    ```python\n    from azure.storage.blob import BlobServiceClient\n    service = BlobServiceClient(account_url=\"https://<my_account_name>.blob.core.windows.net\", \n       credential={\"account_name\": \"<your_account_name>\", \"account_key\":\"<account_access_key>\"})\n    ```\n\n4. To use [anonymous public read access](https://learn.microsoft.com/azure/storage/blobs/storage-manage-access-to-resources),\n   simply omit the credential parameter.\n\n#### Creating the client from a connection string\nDepending on your use case and authorization method, you may prefer to initialize a client instance with a storage\nconnection string instead of providing the account URL and credential separately. To do this, pass the storage\nconnection string to the client's `from_connection_string` class method:\n\n```python\nfrom azure.storage.blob import BlobServiceClient\n\nconnection_string = \"DefaultEndpointsProtocol=https;AccountName=xxxx;AccountKey=xxxx;EndpointSuffix=core.windows.net\"\nservice = BlobServiceClient.from_connection_string(conn_str=connection_string)\n```\n\nThe connection string to your storage account can be found in the Azure Portal under the \"Access Keys\" section or by running the following CLI command:\n\n```bash\naz storage account show-connection-string -g MyResourceGroup -n MyStorageAccount\n```\n\n## Key concepts\nThe following components make up the Azure Blob Service:\n* The storage account itself\n* A container within the storage account\n* A blob within a container\n\nThe Azure Storage Blobs client library for Python allows you to interact with each of these components through the\nuse of a dedicated client object.\n\n### Clients\nFour different clients are provided to interact with the various components of the Blob Service:\n1. [BlobServiceClient](https://aka.ms/azsdk-python-storage-blob-blobserviceclient) -\n    this client represents interaction with the Azure storage account itself, and allows you to acquire preconfigured\n    client instances to access the containers and blobs within. It provides operations to retrieve and configure the\n    account properties as well as list, create, and delete containers within the account. To perform operations on a\n    specific container or blob, retrieve a client using the `get_container_client` or `get_blob_client` methods.\n2. [ContainerClient](https://aka.ms/azsdk-python-storage-blob-containerclient) -\n    this client represents interaction with a specific container (which need not exist yet), and allows you to acquire\n    preconfigured client instances to access the blobs within. It provides operations to create, delete, or configure a\n    container and includes operations to list, upload, and delete the blobs within it. To perform operations on a\n    specific blob within the container, retrieve a client using the `get_blob_client` method.\n3. [BlobClient](https://aka.ms/azsdk-python-storage-blob-blobclient) -\n    this client represents interaction with a specific blob (which need not exist yet). It provides operations to\n    upload, download, delete, and create snapshots of a blob, as well as specific operations per blob type.\n4. [BlobLeaseClient](https://aka.ms/azsdk-python-storage-blob-blobleaseclient) -\n    this client represents lease interactions with a `ContainerClient` or `BlobClient`. It provides operations to\n    acquire, renew, release, change, and break a lease on a specified resource.\n\n### Async Clients \nThis library includes a complete async API supported on Python 3.5+. To use it, you must\nfirst install an async transport, such as [aiohttp](https://pypi.org/project/aiohttp/).\nSee\n[azure-core documentation](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/CLIENT_LIBRARY_DEVELOPER.md#transport)\nfor more information.\n\nAsync clients and credentials should be closed when they're no longer needed. These\nobjects are async context managers and define async `close` methods.\n\n### Blob Types\nOnce you've initialized a Client, you can choose from the different types of blobs:\n* [Block blobs](https://learn.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-block-blobs)\n  store text and binary data, up to approximately 4.75 TiB. Block blobs are made up of blocks of data that can be\n  managed individually\n* [Append blobs](https://learn.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-append-blobs)\n  are made up of blocks like block blobs, but are optimized for append operations. Append blobs are ideal for scenarios\n  such as logging data from virtual machines\n* [Page blobs](https://learn.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-page-blobs)\n  store random access files up to 8 TiB in size. Page blobs store virtual hard drive (VHD) files and serve as disks for\n  Azure virtual machines\n\n## Examples\nThe following sections provide several code snippets covering some of the most common Storage Blob tasks, including:\n\n* [Create a container](#create-a-container \"Create a container\")\n* [Uploading a blob](#uploading-a-blob \"Uploading a blob\")\n* [Downloading a blob](#downloading-a-blob \"Downloading a blob\")\n* [Enumerating blobs](#enumerating-blobs \"Enumerating blobs\")\n\nNote that a container must be created before to upload or download a blob.\n\n### Create a container\n\nCreate a container from where you can upload or download blobs.\n```python\nfrom azure.storage.blob import ContainerClient\n\ncontainer_client = ContainerClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\")\n\ncontainer_client.create_container()\n```\n\nUse the async client to create a container\n\n```python\nfrom azure.storage.blob.aio import ContainerClient\n\ncontainer_client = ContainerClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\")\n\nawait container_client.create_container()\n```\n\n### Uploading a blob\nUpload a blob to your container\n\n```python\nfrom azure.storage.blob import BlobClient\n\nblob = BlobClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\", blob_name=\"my_blob\")\n\nwith open(\"./SampleSource.txt\", \"rb\") as data:\n    blob.upload_blob(data)\n```\n\nUse the async client to upload a blob\n\n```python\nfrom azure.storage.blob.aio import BlobClient\n\nblob = BlobClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\", blob_name=\"my_blob\")\n\nwith open(\"./SampleSource.txt\", \"rb\") as data:\n    await blob.upload_blob(data)\n```\n\n### Downloading a blob\nDownload a blob from your container\n\n```python\nfrom azure.storage.blob import BlobClient\n\nblob = BlobClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\", blob_name=\"my_blob\")\n\nwith open(\"./BlockDestination.txt\", \"wb\") as my_blob:\n    blob_data = blob.download_blob()\n    blob_data.readinto(my_blob)\n```\n\nDownload a blob asynchronously\n\n```python\nfrom azure.storage.blob.aio import BlobClient\n\nblob = BlobClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\", blob_name=\"my_blob\")\n\nwith open(\"./BlockDestination.txt\", \"wb\") as my_blob:\n    stream = await blob.download_blob()\n    data = await stream.readall()\n    my_blob.write(data)\n```\n\n### Enumerating blobs\nList the blobs in your container\n\n```python\nfrom azure.storage.blob import ContainerClient\n\ncontainer = ContainerClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\")\n\nblob_list = container.list_blobs()\nfor blob in blob_list:\n    print(blob.name + '\\n')\n```\n\nList the blobs asynchronously\n\n```python\nfrom azure.storage.blob.aio import ContainerClient\n\ncontainer = ContainerClient.from_connection_string(conn_str=\"<connection_string>\", container_name=\"mycontainer\")\n\nblob_list = []\nasync for blob in container.list_blobs():\n    blob_list.append(blob)\nprint(blob_list)\n```\n\n## Optional Configuration\n\nOptional keyword arguments that can be passed in at the client and per-operation level.\n\n### Retry Policy configuration\n\nUse the following keyword arguments when instantiating a client to configure the retry policy:\n\n* __retry_total__ (int): Total number of retries to allow. Takes precedence over other counts.\nPass in `retry_total=0` if you do not want to retry on requests. Defaults to 10.\n* __retry_connect__ (int): How many connection-related errors to retry on. Defaults to 3.\n* __retry_read__ (int): How many times to retry on read errors. Defaults to 3.\n* __retry_status__ (int): How many times to retry on bad status codes. Defaults to 3.\n* __retry_to_secondary__ (bool): Whether the request should be retried to secondary, if able.\nThis should only be enabled of RA-GRS accounts are used and potentially stale data can be handled.\nDefaults to `False`.\n\n### Encryption configuration\n\nUse the following keyword arguments when instantiating a client to configure encryption:\n\n* __require_encryption__ (bool): If set to True, will enforce that objects are encrypted and decrypt them.\n* __encryption_version__ (str): Specifies the version of encryption to use. Current options are `'2.0'` or `'1.0'` and\nthe default value is `'1.0'`. Version 1.0 is deprecated, and it is **highly recommended** to use version 2.0.\n* __key_encryption_key__ (object): The user-provided key-encryption-key. The instance must implement the following methods:\n    - `wrap_key(key)`--wraps the specified key using an algorithm of the user's choice.\n    - `get_key_wrap_algorithm()`--returns the algorithm used to wrap the specified symmetric key.\n    - `get_kid()`--returns a string key id for this key-encryption-key.\n* __key_resolver_function__ (callable): The user-provided key resolver. Uses the kid string to return a key-encryption-key\nimplementing the interface defined above.\n\n### Other client / per-operation configuration\n\nOther optional configuration keyword arguments that can be specified on the client or per-operation.\n\n**Client keyword arguments:**\n\n* __connection_timeout__ (int): The number of seconds the client will wait to establish a connection to the server.\nDefaults to 20 seconds.\n* __read_timeout__ (int): The number of seconds the client will wait, between consecutive read operations, for a\nresponse from the server. This is a socket level timeout and is not affected by overall data size. Client-side read \ntimeouts will be automatically retried. Defaults to 60 seconds.\n* __transport__ (Any): User-provided transport to send the HTTP request.\n\n**Per-operation keyword arguments:**\n\n* __raw_response_hook__ (callable): The given callback uses the response returned from the service.\n* __raw_request_hook__ (callable): The given callback uses the request before being sent to service.\n* __client_request_id__ (str): Optional user specified identification of the request.\n* __user_agent__ (str): Appends the custom value to the user-agent header to be sent with the request.\n* __logging_enable__ (bool): Enables logging at the DEBUG level. Defaults to False. Can also be passed in at\nthe client level to enable it for all requests.\n* __logging_body__ (bool): Enables logging the request and response body. Defaults to False. Can also be passed in at\nthe client level to enable it for all requests.\n* __headers__ (dict): Pass in custom headers as key, value pairs. E.g. `headers={'CustomValue': value}`\n\n## Troubleshooting\n### General\nStorage Blob clients raise exceptions defined in [Azure Core](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md).\n\nThis list can be used for reference to catch thrown exceptions. To get the specific error code of the exception, use the `error_code` attribute, i.e, `exception.error_code`.\n\n### Logging\nThis library uses the standard\n[logging](https://docs.python.org/3/library/logging.html) library for logging.\nBasic information about HTTP sessions (URLs, headers, etc.) is logged at INFO\nlevel.\n\nDetailed DEBUG level logging, including request/response bodies and unredacted\nheaders, can be enabled on a client with the `logging_enable` argument:\n```python\nimport sys\nimport logging\nfrom azure.storage.blob import BlobServiceClient\n\n# Create a logger for the 'azure.storage.blob' SDK\nlogger = logging.getLogger('azure.storage.blob')\nlogger.setLevel(logging.DEBUG)\n\n# Configure a console output\nhandler = logging.StreamHandler(stream=sys.stdout)\nlogger.addHandler(handler)\n\n# This client will log detailed information about its HTTP sessions, at DEBUG level\nservice_client = BlobServiceClient.from_connection_string(\"your_connection_string\", logging_enable=True)\n```\n\nSimilarly, `logging_enable` can enable detailed logging for a single operation,\neven when it isn't enabled for the client:\n```python\nservice_client.get_service_stats(logging_enable=True)\n```\n\n## Next steps\n\n### More sample code\n\nGet started with our [Blob samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples).\n\nSeveral Storage Blobs Python SDK samples are available to you in the SDK's GitHub repository. These samples provide example code for additional scenarios commonly encountered while working with Storage Blobs:\n\n* [blob_samples_container_access_policy.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_container_access_policy.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_container_access_policy_async.py)) - Examples to set Access policies:\n    * Set up Access Policy for container\n\n* [blob_samples_hello_world.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_hello_world.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_hello_world_async.py)) - Examples for common Storage Blob tasks:\n    * Set up a container\n    * Create a block, page, or append blob\n    * Upload blobs\n    * Download blobs\n    * Delete blobs\n\n* [blob_samples_authentication.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_authentication.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_authentication_async.py)) - Examples for authenticating and creating the client:\n    * From a connection string\n    * From a shared access key\n    * From a shared access signature token\n    * From active directory\n\n* [blob_samples_service.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_service.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_service_async.py)) - Examples for interacting with the blob service:\n    * Get account information\n    * Get and set service properties\n    * Get service statistics\n    * Create, list, and delete containers\n    * Get the Blob or Container client\n\n* [blob_samples_containers.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_containers.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_containers_async.py)) - Examples for interacting with containers:\n    * Create a container and delete containers\n    * Set metadata on containers\n    * Get container properties\n    * Acquire a lease on container\n    * Set an access policy on a container\n    * Upload, list, delete blobs in container\n    * Get the blob client to interact with a specific blob\n\n* [blob_samples_common.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_common.py) ([async version](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_common_async.py)) - Examples common to all types of blobs:\n    * Create a snapshot\n    * Delete a blob snapshot\n    * Soft delete a blob\n    * Undelete a blob\n    * Acquire a lease on a blob\n    * Copy a blob from a URL\n\n* [blob_samples_directory_interface.py](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob/samples/blob_samples_directory_interface.py) - Examples for interfacing with Blob storage as if it were a directory on a filesystem:\n    * Copy (upload or download) a single file or directory\n    * List files or directories at a single level or recursively\n    * Delete a single file or recursively delete a directory\n\n### Additional documentation\nFor more extensive documentation on Azure Blob storage, see the [Azure Blob storage documentation](https://learn.microsoft.com/azure/storage/blobs/) on learn.microsoft.com.\n\n## Contributing\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "azure",
          "azure sdk"
        ],
        "home_page": "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob",
        "author": "Microsoft Corporation",
        "author_email": "ascl@microsoft.com",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "azure-core>=1.30.0",
          "cryptography>=2.1.4",
          "typing-extensions>=4.6.0",
          "isodate>=0.6.1",
          "azure-core[aio]>=1.30.0; extra == \"aio\""
        ],
        "requires_python": ">=3.9",
        "provides_extra": [
          "aio"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e6/ad/3cc14f097111b4de0040c83a525973216457bbeeb63739ef1ed275c1c021/certifi-2026.1.4-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=9943707519e4add1115f44c2bc244f782c0249876bf51b6599fee1ffbedd685c",
          "hashes": {
            "sha256": "9943707519e4add1115f44c2bc244f782c0249876bf51b6599fee1ffbedd685c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "certifi",
        "version": "2026.1.4",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "project-url",
          "requires-python",
          "summary"
        ],
        "summary": "Python package for providing Mozilla's CA Bundle.",
        "description": "Certifi: Python SSL Certificates\n================================\n\nCertifi provides Mozilla's carefully curated collection of Root Certificates for\nvalidating the trustworthiness of SSL certificates while verifying the identity\nof TLS hosts. It has been extracted from the `Requests`_ project.\n\nInstallation\n------------\n\n``certifi`` is available on PyPI. Simply install it with ``pip``::\n\n    $ pip install certifi\n\nUsage\n-----\n\nTo reference the installed certificate authority (CA) bundle, you can use the\nbuilt-in function::\n\n    >>> import certifi\n\n    >>> certifi.where()\n    '/usr/local/lib/python3.7/site-packages/certifi/cacert.pem'\n\nOr from the command line::\n\n    $ python -m certifi\n    /usr/local/lib/python3.7/site-packages/certifi/cacert.pem\n\nEnjoy!\n\n.. _`Requests`: https://requests.readthedocs.io/en/master/\n\nAddition/Removal of Certificates\n--------------------------------\n\nCertifi does not support any addition/removal or other modification of the\nCA trust store content. This project is intended to provide a reliable and\nhighly portable root of trust to python deployments. Look to upstream projects\nfor methods to use alternate trust.\n",
        "home_page": "https://github.com/certifi/python-certifi",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.com",
        "license": "MPL-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Source, https://github.com/certifi/python-certifi"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=e1cf59446890a00105fe7b7912492ea04b6e6f06d4b742b2c788469e34c82970",
          "hashes": {
            "sha256": "e1cf59446890a00105fe7b7912492ea04b6e6f06d4b742b2c788469e34c82970"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "chardet",
        "version": "5.2.0",
        "summary": "Universal encoding detector for Python 3",
        "description": "Chardet: The Universal Character Encoding Detector\n--------------------------------------------------\n\n.. image:: https://img.shields.io/travis/chardet/chardet/stable.svg\n   :alt: Build status\n   :target: https://travis-ci.org/chardet/chardet\n\n.. image:: https://img.shields.io/coveralls/chardet/chardet/stable.svg\n   :target: https://coveralls.io/r/chardet/chardet\n\n.. image:: https://img.shields.io/pypi/v/chardet.svg\n   :target: https://warehouse.python.org/project/chardet/\n   :alt: Latest version on PyPI\n\n.. image:: https://img.shields.io/pypi/l/chardet.svg\n   :alt: License\n\n\nDetects\n - ASCII, UTF-8, UTF-16 (2 variants), UTF-32 (4 variants)\n - Big5, GB2312, EUC-TW, HZ-GB-2312, ISO-2022-CN (Traditional and Simplified Chinese)\n - EUC-JP, SHIFT_JIS, CP932, ISO-2022-JP (Japanese)\n - EUC-KR, ISO-2022-KR, Johab (Korean)\n - KOI8-R, MacCyrillic, IBM855, IBM866, ISO-8859-5, windows-1251 (Cyrillic)\n - ISO-8859-5, windows-1251 (Bulgarian)\n - ISO-8859-1, windows-1252, MacRoman (Western European languages)\n - ISO-8859-7, windows-1253 (Greek)\n - ISO-8859-8, windows-1255 (Visual and Logical Hebrew)\n - TIS-620 (Thai)\n\n.. note::\n   Our ISO-8859-2 and windows-1250 (Hungarian) probers have been temporarily\n   disabled until we can retrain the models.\n\nRequires Python 3.7+.\n\nInstallation\n------------\n\nInstall from `PyPI <https://pypi.org/project/chardet/>`_::\n\n    pip install chardet\n\nDocumentation\n-------------\n\nFor users, docs are now available at https://chardet.readthedocs.io/.\n\nCommand-line Tool\n-----------------\n\nchardet comes with a command-line script which reports on the encodings of one\nor more files::\n\n    % chardetect somefile someotherfile\n    somefile: windows-1252 with confidence 0.5\n    someotherfile: ascii with confidence 1.0\n\nAbout\n-----\n\nThis is a continuation of Mark Pilgrim's excellent original chardet port from C, and `Ian Cordasco <https://github.com/sigmavirus24>`_'s\n`charade <https://github.com/sigmavirus24/charade>`_ Python 3-compatible fork.\n\n:maintainer: Dan Blanchard\n",
        "keywords": [
          "encoding",
          "i18n",
          "xml"
        ],
        "home_page": "https://github.com/chardet/chardet",
        "author": "Mark Pilgrim",
        "author_email": "mark@diveintomark.org",
        "maintainer": "Daniel Blanchard",
        "maintainer_email": "dan.blanchard@gmail.com",
        "license": "LGPL",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Linguistic"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://chardet.readthedocs.io/",
          "GitHub Project, https://github.com/chardet/chardet",
          "Issue Tracker, https://github.com/chardet/chardet/issues"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/98/78/01c019cdb5d6498122777c1a43056ebb3ebfeef2076d9d026bfe15583b2b/click-8.3.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=981153a64e25f12d547d3426c367a4857371575ee7ad18df2a6183ab0545b2a6",
          "hashes": {
            "sha256": "981153a64e25f12d547d3426c367a4857371575ee7ad18df2a6183ab0545b2a6"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "click",
        "version": "8.3.1",
        "summary": "Composable command line interface toolkit",
        "description": "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/pallets/click/refs/heads/stable/docs/_static/click-name.svg\" alt=\"\" height=\"150\"></div>\n\n# Click\n\nClick is a Python package for creating beautiful command line interfaces\nin a composable way with as little code as necessary. It's the \"Command\nLine Interface Creation Kit\". It's highly configurable but comes with\nsensible defaults out of the box.\n\nIt aims to make the process of writing command line tools quick and fun\nwhile also preventing any frustration caused by the inability to\nimplement an intended CLI API.\n\nClick in three points:\n\n-   Arbitrary nesting of commands\n-   Automatic help page generation\n-   Supports lazy loading of subcommands at runtime\n\n\n## A Simple Example\n\n```python\nimport click\n\n@click.command()\n@click.option(\"--count\", default=1, help=\"Number of greetings.\")\n@click.option(\"--name\", prompt=\"Your name\", help=\"The person to greet.\")\ndef hello(count, name):\n    \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\"\n    for _ in range(count):\n        click.echo(f\"Hello, {name}!\")\n\nif __name__ == '__main__':\n    hello()\n```\n\n```\n$ python hello.py --count=3\nYour name: Click\nHello, Click!\nHello, Click!\nHello, Click!\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Click and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n## Contributing\n\nSee our [detailed contributing documentation][contrib] for many ways to\ncontribute, including reporting issues, requesting features, asking or answering\nquestions, and making PRs.\n\n[contrib]: https://palletsprojects.com/contributing/\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "colorama; platform_system == 'Windows'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Changes, https://click.palletsprojects.com/page/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://click.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/click/"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6",
          "hashes": {
            "sha256": "4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "colorama",
        "version": "0.4.6",
        "summary": "Cross-platform colored terminal text.",
        "description": ".. image:: https://img.shields.io/pypi/v/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Supported Python versions\n\n.. image:: https://github.com/tartley/colorama/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/tartley/colorama/actions/workflows/test.yml\n    :alt: Build Status\n\nColorama\n========\n\nMakes ANSI escape character sequences (for producing colored terminal text and\ncursor positioning) work under MS Windows.\n\n.. |donate| image:: https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif\n  :target: https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=2MZ9D2GMLYCUJ&item_name=Colorama&currency_code=USD\n  :alt: Donate with Paypal\n\n`PyPI for releases <https://pypi.org/project/colorama/>`_ |\n`Github for source <https://github.com/tartley/colorama>`_ |\n`Colorama for enterprise on Tidelift <https://github.com/tartley/colorama/blob/master/ENTERPRISE.md>`_\n\nIf you find Colorama useful, please |donate| to the authors. Thank you!\n\nInstallation\n------------\n\nTested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.\n\nNo requirements other than the standard library.\n\n.. code-block:: bash\n\n    pip install colorama\n    # or\n    conda install -c anaconda colorama\n\nDescription\n-----------\n\nANSI escape character sequences have long been used to produce colored terminal\ntext and cursor positioning on Unix and Macs. Colorama makes this work on\nWindows, too, by wrapping ``stdout``, stripping ANSI sequences it finds (which\nwould appear as gobbledygook in the output), and converting them into the\nappropriate win32 calls to modify the state of the terminal. On other platforms,\nColorama does nothing.\n\nThis has the upshot of providing a simple cross-platform API for printing\ncolored terminal text from Python, and has the happy side-effect that existing\napplications or libraries which use ANSI sequences to produce colored output on\nLinux or Macs can now also work on Windows, simply by calling\n``colorama.just_fix_windows_console()`` (since v0.4.6) or ``colorama.init()``\n(all versions, but may have other side-effects â€“ see below).\n\nAn alternative approach is to install ``ansi.sys`` on Windows machines, which\nprovides the same behaviour for all applications running in terminals. Colorama\nis intended for situations where that isn't easy (e.g., maybe your app doesn't\nhave an installer.)\n\nDemo scripts in the source code repository print some colored text using\nANSI sequences. Compare their output under Gnome-terminal's built in ANSI\nhandling, versus on Windows Command-Prompt using Colorama:\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/ubuntu-demo.png\n    :width: 661\n    :height: 357\n    :alt: ANSI sequences on Ubuntu under gnome-terminal.\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/windows-demo.png\n    :width: 668\n    :height: 325\n    :alt: Same ANSI sequences on Windows, using Colorama.\n\nThese screenshots show that, on Windows, Colorama does not support ANSI 'dim\ntext'; it looks the same as 'normal text'.\n\nUsage\n-----\n\nInitialisation\n..............\n\nIf the only thing you want from Colorama is to get ANSI escapes to work on\nWindows, then run:\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    just_fix_windows_console()\n\nIf you're on a recent version of Windows 10 or better, and your stdout/stderr\nare pointing to a Windows console, then this will flip the magic configuration\nswitch to enable Windows' built-in ANSI support.\n\nIf you're on an older version of Windows, and your stdout/stderr are pointing to\na Windows console, then this will wrap ``sys.stdout`` and/or ``sys.stderr`` in a\nmagic file object that intercepts ANSI escape sequences and issues the\nappropriate Win32 calls to emulate them.\n\nIn all other circumstances, it does nothing whatsoever. Basically the idea is\nthat this makes Windows act like Unix with respect to ANSI escape handling.\n\nIt's safe to call this function multiple times. It's safe to call this function\non non-Windows platforms, but it won't do anything. It's safe to call this\nfunction when one or both of your stdout/stderr are redirected to a file â€“ it\nwon't do anything to those streams.\n\nAlternatively, you can use the older interface with more features (but also more\npotential footguns):\n\n.. code-block:: python\n\n    from colorama import init\n    init()\n\nThis does the same thing as ``just_fix_windows_console``, except for the\nfollowing differences:\n\n- It's not safe to call ``init`` multiple times; you can end up with multiple\n  layers of wrapping and broken ANSI support.\n\n- Colorama will apply a heuristic to guess whether stdout/stderr support ANSI,\n  and if it thinks they don't, then it will wrap ``sys.stdout`` and\n  ``sys.stderr`` in a magic file object that strips out ANSI escape sequences\n  before printing them. This happens on all platforms, and can be convenient if\n  you want to write your code to emit ANSI escape sequences unconditionally, and\n  let Colorama decide whether they should actually be output. But note that\n  Colorama's heuristic is not particularly clever.\n\n- ``init`` also accepts explicit keyword args to enable/disable various\n  functionality â€“ see below.\n\nTo stop using Colorama before your program exits, simply call ``deinit()``.\nThis will restore ``stdout`` and ``stderr`` to their original values, so that\nColorama is disabled. To resume using Colorama again, call ``reinit()``; it is\ncheaper than calling ``init()`` again (but does the same thing).\n\nMost users should depend on ``colorama >= 0.4.6``, and use\n``just_fix_windows_console``. The old ``init`` interface will be supported\nindefinitely for backwards compatibility, but we don't plan to fix any issues\nwith it, also for backwards compatibility.\n\nColored Output\n..............\n\nCross-platform printing of colored text can then be done using Colorama's\nconstant shorthand for ANSI escape sequences. These are deliberately\nrudimentary, see below.\n\n.. code-block:: python\n\n    from colorama import Fore, Back, Style\n    print(Fore.RED + 'some red text')\n    print(Back.GREEN + 'and with a green background')\n    print(Style.DIM + 'and in dim text')\n    print(Style.RESET_ALL)\n    print('back to normal now')\n\n...or simply by manually printing ANSI sequences from your own code:\n\n.. code-block:: python\n\n    print('\\033[31m' + 'some red text')\n    print('\\033[39m') # and reset to default color\n\n...or, Colorama can be used in conjunction with existing ANSI libraries\nsuch as the venerable `Termcolor <https://pypi.org/project/termcolor/>`_\nthe fabulous `Blessings <https://pypi.org/project/blessings/>`_,\nor the incredible `_Rich <https://pypi.org/project/rich/>`_.\n\nIf you wish Colorama's Fore, Back and Style constants were more capable,\nthen consider using one of the above highly capable libraries to generate\ncolors, etc, and use Colorama just for its primary purpose: to convert\nthose ANSI sequences to also work on Windows:\n\nSIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama.\nWe are only interested in converting ANSI codes to win32 API calls, not\nshortcuts like the above to generate ANSI characters.\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    from termcolor import colored\n\n    # use Colorama to make Termcolor work on Windows too\n    just_fix_windows_console()\n\n    # then use Termcolor for all colored text output\n    print(colored('Hello, World!', 'green', 'on_red'))\n\nAvailable formatting constants are::\n\n    Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Style: DIM, NORMAL, BRIGHT, RESET_ALL\n\n``Style.RESET_ALL`` resets foreground, background, and brightness. Colorama will\nperform this reset automatically on program exit.\n\nThese are fairly well supported, but not part of the standard::\n\n    Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n    Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n\nCursor Positioning\n..................\n\nANSI codes to reposition the cursor are supported. See ``demos/demo06.py`` for\nan example of how to generate them.\n\nInit Keyword Args\n.................\n\n``init()`` accepts some ``**kwargs`` to override default behaviour.\n\ninit(autoreset=False):\n    If you find yourself repeatedly sending reset sequences to turn off color\n    changes at the end of every print, then ``init(autoreset=True)`` will\n    automate that:\n\n    .. code-block:: python\n\n        from colorama import init\n        init(autoreset=True)\n        print(Fore.RED + 'some red text')\n        print('automatically back to default color again')\n\ninit(strip=None):\n    Pass ``True`` or ``False`` to override whether ANSI codes should be\n    stripped from the output. The default behaviour is to strip if on Windows\n    or if output is redirected (not a tty).\n\ninit(convert=None):\n    Pass ``True`` or ``False`` to override whether to convert ANSI codes in the\n    output into win32 calls. The default behaviour is to convert if on Windows\n    and output is to a tty (terminal).\n\ninit(wrap=True):\n    On Windows, Colorama works by replacing ``sys.stdout`` and ``sys.stderr``\n    with proxy objects, which override the ``.write()`` method to do their work.\n    If this wrapping causes you problems, then this can be disabled by passing\n    ``init(wrap=False)``. The default behaviour is to wrap if ``autoreset`` or\n    ``strip`` or ``convert`` are True.\n\n    When wrapping is disabled, colored printing on non-Windows platforms will\n    continue to work as normal. To do cross-platform colored output, you can\n    use Colorama's ``AnsiToWin32`` proxy directly:\n\n    .. code-block:: python\n\n        import sys\n        from colorama import init, AnsiToWin32\n        init(wrap=False)\n        stream = AnsiToWin32(sys.stderr).stream\n\n        # Python 2\n        print >>stream, Fore.BLUE + 'blue text on stderr'\n\n        # Python 3\n        print(Fore.BLUE + 'blue text on stderr', file=stream)\n\nRecognised ANSI Sequences\n.........................\n\nANSI sequences generally take the form::\n\n    ESC [ <param> ; <param> ... <command>\n\nWhere ``<param>`` is an integer, and ``<command>`` is a single letter. Zero or\nmore params are passed to a ``<command>``. If no params are passed, it is\ngenerally synonymous with passing a single zero. No spaces exist in the\nsequence; they have been inserted here simply to read more easily.\n\nThe only ANSI sequences that Colorama converts into win32 calls are::\n\n    ESC [ 0 m       # reset all (colors and brightness)\n    ESC [ 1 m       # bright\n    ESC [ 2 m       # dim (looks same as normal brightness)\n    ESC [ 22 m      # normal brightness\n\n    # FOREGROUND:\n    ESC [ 30 m      # black\n    ESC [ 31 m      # red\n    ESC [ 32 m      # green\n    ESC [ 33 m      # yellow\n    ESC [ 34 m      # blue\n    ESC [ 35 m      # magenta\n    ESC [ 36 m      # cyan\n    ESC [ 37 m      # white\n    ESC [ 39 m      # reset\n\n    # BACKGROUND\n    ESC [ 40 m      # black\n    ESC [ 41 m      # red\n    ESC [ 42 m      # green\n    ESC [ 43 m      # yellow\n    ESC [ 44 m      # blue\n    ESC [ 45 m      # magenta\n    ESC [ 46 m      # cyan\n    ESC [ 47 m      # white\n    ESC [ 49 m      # reset\n\n    # cursor positioning\n    ESC [ y;x H     # position cursor at x across, y down\n    ESC [ y;x f     # position cursor at x across, y down\n    ESC [ n A       # move cursor n lines up\n    ESC [ n B       # move cursor n lines down\n    ESC [ n C       # move cursor n characters forward\n    ESC [ n D       # move cursor n characters backward\n\n    # clear the screen\n    ESC [ mode J    # clear the screen\n\n    # clear the line\n    ESC [ mode K    # clear the line\n\nMultiple numeric params to the ``'m'`` command can be combined into a single\nsequence::\n\n    ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background\n\nAll other ANSI sequences of the form ``ESC [ <param> ; <param> ... <command>``\nare silently stripped from the output on Windows.\n\nAny other form of ANSI sequence, such as single-character codes or alternative\ninitial characters, are not recognised or stripped. It would be cool to add\nthem though. Let me know if it would be useful for you, via the Issues on\nGitHub.\n\nStatus & Known Problems\n-----------------------\n\nI've personally only tested it on Windows XP (CMD, Console2), Ubuntu\n(gnome-terminal, xterm), and OS X.\n\nSome valid ANSI sequences aren't recognised.\n\nIf you're hacking on the code, see `README-hacking.md`_. ESPECIALLY, see the\nexplanation there of why we do not want PRs that allow Colorama to generate new\ntypes of ANSI codes.\n\nSee outstanding issues and wish-list:\nhttps://github.com/tartley/colorama/issues\n\nIf anything doesn't work for you, or doesn't do what you expected or hoped for,\nI'd love to hear about it on that issues list, would be delighted by patches,\nand would be happy to grant commit access to anyone who submits a working patch\nor two.\n\n.. _README-hacking.md: README-hacking.md\n\nLicense\n-------\n\nCopyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see\nLICENSE file.\n\nProfessional support\n--------------------\n\n.. |tideliftlogo| image:: https://cdn2.hubspot.net/hubfs/4008838/website/logos/logos_for_download/Tidelift_primary-shorthand-logo.png\n   :alt: Tidelift\n   :target: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\n.. list-table::\n   :widths: 10 100\n\n   * - |tideliftlogo|\n     - Professional support for colorama is available as part of the\n       `Tidelift Subscription`_.\n       Tidelift gives software development teams a single source for purchasing\n       and maintaining their software, with professional grade assurances from\n       the experts who know it best, while seamlessly integrating with existing\n       tools.\n\n.. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\nThanks\n------\n\nSee the CHANGELOG for more thanks!\n\n* Marc Schlaich (schlamar) for a ``setup.py`` fix for Python2.5.\n* Marc Abramowitz, reported & fixed a crash on exit with closed ``stdout``,\n  providing a solution to issue #7's setuptools/distutils debate,\n  and other fixes.\n* User 'eryksun', for guidance on correctly instantiating ``ctypes.windll``.\n* Matthew McCormick for politely pointing out a longstanding crash on non-Win.\n* Ben Hoyt, for a magnificent fix under 64-bit Windows.\n* Jesse at Empty Square for submitting a fix for examples in the README.\n* User 'jamessp', an observant documentation fix for cursor positioning.\n* User 'vaal1239', Dave Mckee & Lackner Kristof for a tiny but much-needed Win7\n  fix.\n* Julien Stuyck, for wisely suggesting Python3 compatible updates to README.\n* Daniel Griffith for multiple fabulous patches.\n* Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty\n  output.\n* Roger Binns, for many suggestions, valuable feedback, & bug reports.\n* Tim Golden for thought and much appreciated feedback on the initial idea.\n* User 'Zearin' for updates to the README file.\n* John Szakmeister for adding support for light colors\n* Charles Merriam for adding documentation to demos\n* Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes\n* Florian Bruhin for a fix when stdout or stderr are None\n* Thomas Weininger for fixing ValueError on Windows\n* Remi Rampin for better Github integration and fixes to the README file\n* Simeon Visser for closing a file handle using 'with' and updating classifiers\n  to include Python 3.3 and 3.4\n* Andy Neff for fixing RESET of LIGHT_EX colors.\n* Jonathan Hartley for the initial idea and implementation.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "ansi",
          "color",
          "colour",
          "crossplatform",
          "terminal",
          "text",
          "windows",
          "xplatform"
        ],
        "author_email": "Jonathan Hartley <tartley@tartley.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Terminals"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7",
        "project_url": [
          "Homepage, https://github.com/tartley/colorama"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e2/0c/dbfafbe90a185943dcfbc766fe0e1909f658811492d79b741523a414a6cc/coverage-7.13.4-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=e6f70dec1cc557e52df5306d051ef56003f74d56e9c4dd7ddb07e07ef32a84dd",
          "hashes": {
            "sha256": "e6f70dec1cc557e52df5306d051ef56003f74d56e9c4dd7ddb07e07ef32a84dd"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "coverage",
        "version": "7.13.4",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-python",
          "summary"
        ],
        "summary": "Code coverage measurement for Python",
        "description": ".. Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\r\n.. For details: https://github.com/coveragepy/coveragepy/blob/main/NOTICE.txt\r\n\r\n===========\r\nCoverage.py\r\n===========\r\n\r\nCode coverage measurement for Python.\r\n\r\n.. image:: https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-direct.svg\r\n    :target: https://vshymanskyy.github.io/StandWithUkraine\r\n    :alt: Stand with Ukraine\r\n\r\n-------------\r\n\r\n|  |kit| |license| |versions|\r\n|  |test-status| |quality-status| |docs| |metacov|\r\n|  |tidelift| |sponsor| |stars| |mastodon-coveragepy| |mastodon-nedbat|\r\n   |bluesky-nedbat|\r\n\r\nCoverage.py measures code coverage, typically during test execution. It uses\r\nthe code analysis tools and tracing hooks provided in the Python standard\r\nlibrary to determine which lines are executable, and which have been executed.\r\n\r\nCoverage.py runs on these versions of Python:\r\n\r\n.. PYVERSIONS\r\n\r\n* Python 3.10 through 3.15 alpha, including free-threading.\r\n* PyPy3 versions 3.10 and 3.11.\r\n\r\nDocumentation is on `Read the Docs`_.  Code repository and issue tracker are on\r\n`GitHub`_.\r\n\r\n.. _Read the Docs: https://coverage.readthedocs.io/en/7.13.4/\r\n.. _GitHub: https://github.com/coveragepy/coveragepy\r\n\r\n\r\nFor Enterprise\r\n--------------\r\n\r\n.. |tideliftlogo| image:: https://nedbatchelder.com/pix/Tidelift_Logo_small.png\r\n   :alt: Tidelift\r\n   :target: https://tidelift.com/subscription/pkg/pypi-coverage?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=readme\r\n\r\n.. list-table::\r\n   :widths: 10 100\r\n\r\n   * - |tideliftlogo|\r\n     - `Available as part of the Tidelift Subscription. <https://tidelift.com/subscription/pkg/pypi-coverage?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=readme>`_\r\n       Coverage and thousands of other packages are working with\r\n       Tidelift to deliver one enterprise subscription that covers all of the open\r\n       source you use.  If you want the flexibility of open source and the confidence\r\n       of commercial-grade software, this is for you.\r\n       `Learn more. <https://tidelift.com/subscription/pkg/pypi-coverage?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=readme>`_\r\n\r\n\r\nGetting Started\r\n---------------\r\n\r\nLooking to run ``coverage`` on your test suite? See the `Quick Start section`_\r\nof the docs.\r\n\r\n.. _Quick Start section: https://coverage.readthedocs.io/en/7.13.4/#quick-start\r\n\r\n\r\nChange history\r\n--------------\r\n\r\nThe complete history of changes is on the `change history page`_.\r\n\r\n.. _change history page: https://coverage.readthedocs.io/en/7.13.4/changes.html\r\n\r\n\r\nCode of Conduct\r\n---------------\r\n\r\nEveryone participating in the coverage.py project is expected to treat other\r\npeople with respect and to follow the guidelines articulated in the `Python\r\nCommunity Code of Conduct`_.\r\n\r\n.. _Python Community Code of Conduct: https://www.python.org/psf/codeofconduct/\r\n\r\n\r\nContributing\r\n------------\r\n\r\nFound a bug? Want to help improve the code or documentation? See the\r\n`Contributing section`_ of the docs.\r\n\r\n.. _Contributing section: https://coverage.readthedocs.io/en/7.13.4/contributing.html\r\n\r\n\r\nSecurity\r\n--------\r\n\r\nTo report a security vulnerability, please use the `Tidelift security\r\ncontact`_.  Tidelift will coordinate the fix and disclosure.\r\n\r\n.. _Tidelift security contact: https://tidelift.com/security\r\n\r\n\r\nLicense\r\n-------\r\n\r\nLicensed under the `Apache 2.0 License`_.  For details, see `NOTICE.txt`_.\r\n\r\n.. _Apache 2.0 License: http://www.apache.org/licenses/LICENSE-2.0\r\n.. _NOTICE.txt: https://github.com/coveragepy/coveragepy/blob/main/NOTICE.txt\r\n\r\n\r\n.. |test-status| image:: https://github.com/coveragepy/coveragepy/actions/workflows/testsuite.yml/badge.svg?branch=main&event=push\r\n    :target: https://github.com/coveragepy/coveragepy/actions/workflows/testsuite.yml\r\n    :alt: Test suite status\r\n.. |quality-status| image:: https://github.com/coveragepy/coveragepy/actions/workflows/quality.yml/badge.svg?branch=main&event=push\r\n    :target: https://github.com/coveragepy/coveragepy/actions/workflows/quality.yml\r\n    :alt: Quality check status\r\n.. |docs| image:: https://readthedocs.org/projects/coverage/badge/?version=latest&style=flat\r\n    :target: https://coverage.readthedocs.io/en/7.13.4/\r\n    :alt: Documentation\r\n.. |kit| image:: https://img.shields.io/pypi/v/coverage\r\n    :target: https://pypi.org/project/coverage/\r\n    :alt: PyPI status\r\n.. |versions| image:: https://img.shields.io/pypi/pyversions/coverage.svg?logo=python&logoColor=FBE072\r\n    :target: https://pypi.org/project/coverage/\r\n    :alt: Python versions supported\r\n.. |license| image:: https://img.shields.io/pypi/l/coverage.svg\r\n    :target: https://github.com/coveragepy/coveragepy/blob/main/LICENSE.txt\r\n    :alt: License\r\n.. |metacov| image:: https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/nedbat/8c6980f77988a327348f9b02bbaf67f5/raw/metacov.json\r\n    :target: https://coveragepy.github.io/metacov-reports/latest.html\r\n    :alt: Coverage reports\r\n.. |tidelift| image:: https://tidelift.com/badges/package/pypi/coverage\r\n    :target: https://tidelift.com/subscription/pkg/pypi-coverage?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=readme\r\n    :alt: Tidelift\r\n.. |stars| image:: https://img.shields.io/github/stars/coveragepy/coveragepy.svg?logo=github&style=flat\r\n    :target: https://github.com/coveragepy/coveragepy/stargazers\r\n    :alt: GitHub stars\r\n.. |mastodon-nedbat| image:: https://img.shields.io/badge/dynamic/json?style=flat&labelColor=450657&logo=mastodon&logoColor=ffffff&label=@nedbat&query=followers_count&url=https%3A%2F%2Fhachyderm.io%2Fapi%2Fv1%2Faccounts%2Flookup%3Facct=nedbat\r\n    :target: https://hachyderm.io/@nedbat\r\n    :alt: nedbat on Mastodon\r\n.. |mastodon-coveragepy| image:: https://img.shields.io/badge/dynamic/json?style=flat&labelColor=450657&logo=mastodon&logoColor=ffffff&label=@coveragepy&query=followers_count&url=https%3A%2F%2Fhachyderm.io%2Fapi%2Fv1%2Faccounts%2Flookup%3Facct=coveragepy\r\n    :target: https://hachyderm.io/@coveragepy\r\n    :alt: coveragepy on Mastodon\r\n.. |bluesky-nedbat| image:: https://img.shields.io/badge/dynamic/json?style=flat&color=96a3b0&labelColor=3686f7&logo=icloud&logoColor=white&label=@nedbat&url=https%3A%2F%2Fpublic.api.bsky.app%2Fxrpc%2Fapp.bsky.actor.getProfile%3Factor=nedbat.com&query=followersCount\r\n    :target: https://bsky.app/profile/nedbat.com\r\n    :alt: nedbat on Bluesky\r\n.. |sponsor| image:: https://img.shields.io/badge/%E2%9D%A4-Sponsor%20me-brightgreen?style=flat&logo=GitHub\r\n    :target: https://github.com/sponsors/nedbat\r\n    :alt: Sponsor me on GitHub\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "code",
          "coverage",
          "testing"
        ],
        "home_page": "https://github.com/coveragepy/coveragepy",
        "author": "Ned Batchelder and 258 others",
        "author_email": "ned@nedbatchelder.com",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3.15",
          "Programming Language :: Python :: Free Threading :: 3 - Stable",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Quality Assurance",
          "Topic :: Software Development :: Testing"
        ],
        "requires_dist": [
          "tomli; python_full_version <= \"3.11.0a6\" and extra == \"toml\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Documentation, https://coverage.readthedocs.io/en/7.13.4",
          "Funding, https://tidelift.com/subscription/pkg/pypi-coverage?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=pypi",
          "Issues, https://github.com/coveragepy/coveragepy/issues",
          "Mastodon, https://hachyderm.io/@coveragepy",
          "Mastodon (nedbat), https://hachyderm.io/@nedbat"
        ],
        "provides_extra": [
          "toml"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e9/5a/ac0f49e48063ab4255d9e3b79f5def51697fce1a95ea1370f03dc9db76f6/cryptography-46.0.5-cp311-abi3-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=38946c54b16c885c72c4f59846be9743d699eee2b69b6988e0a00a01f46a61a4",
          "hashes": {
            "sha256": "38946c54b16c885c72c4f59846be9743d699eee2b69b6988e0a00a01f46a61a4"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "cryptography",
        "version": "46.0.5",
        "summary": "cryptography is a package which provides cryptographic recipes and primitives to Python developers.",
        "description": "pyca/cryptography\n=================\n\n.. image:: https://img.shields.io/pypi/v/cryptography.svg\n    :target: https://pypi.org/project/cryptography/\n    :alt: Latest Version\n\n.. image:: https://readthedocs.org/projects/cryptography/badge/?version=latest\n    :target: https://cryptography.io\n    :alt: Latest Docs\n\n.. image:: https://github.com/pyca/cryptography/actions/workflows/ci.yml/badge.svg\n    :target: https://github.com/pyca/cryptography/actions/workflows/ci.yml?query=branch%3Amain\n\n``cryptography`` is a package which provides cryptographic recipes and\nprimitives to Python developers. Our goal is for it to be your \"cryptographic\nstandard library\". It supports Python 3.8+ and PyPy3 7.3.11+.\n\n``cryptography`` includes both high level recipes and low level interfaces to\ncommon cryptographic algorithms such as symmetric ciphers, message digests, and\nkey derivation functions. For example, to encrypt something with\n``cryptography``'s high level symmetric encryption recipe:\n\n.. code-block:: pycon\n\n    >>> from cryptography.fernet import Fernet\n    >>> # Put this somewhere safe!\n    >>> key = Fernet.generate_key()\n    >>> f = Fernet(key)\n    >>> token = f.encrypt(b\"A really secret message. Not for prying eyes.\")\n    >>> token\n    b'...'\n    >>> f.decrypt(token)\n    b'A really secret message. Not for prying eyes.'\n\nYou can find more information in the `documentation`_.\n\nYou can install ``cryptography`` with:\n\n.. code-block:: console\n\n    $ pip install cryptography\n\nFor full details see `the installation documentation`_.\n\nDiscussion\n~~~~~~~~~~\n\nIf you run into bugs, you can file them in our `issue tracker`_.\n\nWe maintain a `cryptography-dev`_ mailing list for development discussion.\n\nYou can also join ``#pyca`` on ``irc.libera.chat`` to ask questions or get\ninvolved.\n\nSecurity\n~~~~~~~~\n\nNeed to report a security issue? Please consult our `security reporting`_\ndocumentation.\n\n\n.. _`documentation`: https://cryptography.io/\n.. _`the installation documentation`: https://cryptography.io/en/latest/installation/\n.. _`issue tracker`: https://github.com/pyca/cryptography/issues\n.. _`cryptography-dev`: https://mail.python.org/mailman/listinfo/cryptography-dev\n.. _`security reporting`: https://cryptography.io/en/latest/security/\n\n",
        "description_content_type": "text/x-rst; charset=UTF-8",
        "author_email": "The Python Cryptographic Authority and individual contributors <cryptography-dev@python.org>",
        "license_expression": "Apache-2.0 OR BSD-3-Clause",
        "license_file": [
          "LICENSE",
          "LICENSE.APACHE",
          "LICENSE.BSD"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: POSIX",
          "Operating System :: POSIX :: BSD",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python :: Free Threading :: 3 - Stable",
          "Topic :: Security :: Cryptography"
        ],
        "requires_dist": [
          "cffi>=1.14 ; python_full_version == '3.8.*' and platform_python_implementation != 'PyPy'",
          "cffi>=2.0.0 ; python_full_version >= '3.9' and platform_python_implementation != 'PyPy'",
          "typing-extensions>=4.13.2 ; python_full_version < '3.11'",
          "bcrypt>=3.1.5 ; extra == 'ssh'",
          "nox[uv]>=2024.4.15 ; extra == 'nox'",
          "cryptography-vectors==46.0.5 ; extra == 'test'",
          "pytest>=7.4.0 ; extra == 'test'",
          "pytest-benchmark>=4.0 ; extra == 'test'",
          "pytest-cov>=2.10.1 ; extra == 'test'",
          "pytest-xdist>=3.5.0 ; extra == 'test'",
          "pretend>=0.7 ; extra == 'test'",
          "certifi>=2024 ; extra == 'test'",
          "pytest-randomly ; extra == 'test-randomorder'",
          "sphinx>=5.3.0 ; extra == 'docs'",
          "sphinx-rtd-theme>=3.0.0 ; extra == 'docs'",
          "sphinx-inline-tabs ; extra == 'docs'",
          "pyenchant>=3 ; extra == 'docstest'",
          "readme-renderer>=30.0 ; extra == 'docstest'",
          "sphinxcontrib-spelling>=7.3.1 ; extra == 'docstest'",
          "build>=1.0.0 ; extra == 'sdist'",
          "ruff>=0.11.11 ; extra == 'pep8test'",
          "mypy>=1.14 ; extra == 'pep8test'",
          "check-sdist ; extra == 'pep8test'",
          "click>=8.0.1 ; extra == 'pep8test'"
        ],
        "requires_python": ">=3.8, !=3.9.0, !=3.9.1",
        "project_url": [
          "homepage, https://github.com/pyca/cryptography",
          "documentation, https://cryptography.io/",
          "source, https://github.com/pyca/cryptography/",
          "issues, https://github.com/pyca/cryptography/issues",
          "changelog, https://cryptography.io/en/latest/changelog/"
        ],
        "provides_extra": [
          "ssh",
          "nox",
          "test",
          "test-randomorder",
          "docs",
          "docstest",
          "sdist",
          "pep8test"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/37/18/6519e1ee6f5a1e579e04b9ddb6f1676c17368a7aba48299c3759bbc3c8b3/cffi-2.0.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=19f705ada2530c1167abacb171925dd886168931e0a7b78f5bffcae5c6b5be75",
          "hashes": {
            "sha256": "19f705ada2530c1167abacb171925dd886168931e0a7b78f5bffcae5c6b5be75"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "cffi",
        "version": "2.0.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Foreign Function Interface for Python calling C code.",
        "description": "[![GitHub Actions Status](https://github.com/python-cffi/cffi/actions/workflows/ci.yaml/badge.svg?branch=main)](https://github.com/python-cffi/cffi/actions/workflows/ci.yaml?query=branch%3Amain++)\r\n[![PyPI version](https://img.shields.io/pypi/v/cffi.svg)](https://pypi.org/project/cffi)\r\n[![Read the Docs](https://img.shields.io/badge/docs-latest-blue.svg)][Documentation]\r\n\r\n\r\nCFFI\r\n====\r\n\r\nForeign Function Interface for Python calling C code.\r\n\r\nPlease see the [Documentation] or uncompiled in the `doc/` subdirectory.\r\n\r\nDownload\r\n--------\r\n\r\n[Download page](https://github.com/python-cffi/cffi/releases)\r\n\r\nSource Code\r\n-----------\r\n\r\nSource code is publicly available on\r\n[GitHub](https://github.com/python-cffi/cffi).\r\n\r\nContact\r\n-------\r\n\r\n[Mailing list](https://groups.google.com/forum/#!forum/python-cffi)\r\n\r\nTesting/development tips\r\n------------------------\r\n\r\nAfter `git clone` or `wget && tar`, we will get a directory called `cffi` or `cffi-x.x.x`. we call it `repo-directory`. To run tests under CPython, run the following in the `repo-directory`:\r\n\r\n    pip install pytest\r\n    pip install -e .  # editable install of CFFI for local development\r\n    pytest src/c/ testing/\r\n\r\n[Documentation]: http://cffi.readthedocs.org/\r\n",
        "description_content_type": "text/markdown",
        "author": "Armin Rigo, Maciej Fijalkowski",
        "maintainer": "Matt Davis, Matt Clay, Matti Picus",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE",
          "AUTHORS"
        ],
        "classifier": [
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Free Threading :: 2 - Beta",
          "Programming Language :: Python :: Implementation :: CPython"
        ],
        "requires_dist": [
          "pycparser; implementation_name != \"PyPy\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://cffi.readthedocs.io/",
          "Changelog, https://cffi.readthedocs.io/en/latest/whatsnew.html",
          "Downloads, https://github.com/python-cffi/cffi/releases",
          "Contact, https://groups.google.com/forum/#!forum/python-cffi",
          "Source Code, https://github.com/python-cffi/cffi",
          "Issue Tracker, https://github.com/python-cffi/cffi/issues"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/ba/5a/18ad964b0086c6e62e2e7500f7edc89e3faa45033c71c1893d34eed2b2de/dnspython-2.8.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=01d9bbc4a2d76bf0db7c1f729812ded6d912bd318d3b1cf81d30c0f845dbf3af",
          "hashes": {
            "sha256": "01d9bbc4a2d76bf0db7c1f729812ded6d912bd318d3b1cf81d30c0f845dbf3af"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "dnspython",
        "version": "2.8.0",
        "summary": "DNS toolkit",
        "description": "# dnspython\n\n[![Build Status](https://github.com/rthalley/dnspython/actions/workflows/ci.yml/badge.svg)](https://github.com/rthalley/dnspython/actions/)\n[![Documentation Status](https://readthedocs.org/projects/dnspython/badge/?version=latest)](https://dnspython.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/dnspython.svg)](https://badge.fury.io/py/dnspython)\n[![License: ISC](https://img.shields.io/badge/License-ISC-brightgreen.svg)](https://opensource.org/licenses/ISC)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n## INTRODUCTION\n\n`dnspython` is a DNS toolkit for Python. It supports almost all record types. It\ncan be used for queries, zone transfers, and dynamic updates. It supports\nTSIG-authenticated messages and EDNS0.\n\n`dnspython` provides both high- and low-level access to DNS. The high-level\nclasses perform queries for data of a given name, type, and class, and return an\nanswer set. The low-level classes allow direct manipulation of DNS zones,\nmessages, names, and records.\n\nTo see a few of the ways `dnspython` can be used, look in the `examples/`\ndirectory.\n\n`dnspython` is a utility to work with DNS, `/etc/hosts` is thus not used. For\nsimple forward DNS lookups, it's better to use `socket.getaddrinfo()` or\n`socket.gethostbyname()`.\n\n`dnspython` originated at Nominum where it was developed to facilitate the\ntesting of DNS software.\n\n## ABOUT THIS RELEASE\n\nThis is of `dnspython` 2.8.0.\nPlease read\n[What's New](https://dnspython.readthedocs.io/en/stable/whatsnew.html) for\ninformation about the changes in this release.\n\n## INSTALLATION\n\n* Many distributions have dnspython packaged for you, so you should check there\n  first.\n* To use a wheel downloaded from PyPi, run:\n\n```\n    pip install dnspython\n```\n\n* To install from the source code, go into the top-level of the source code\n  and run:\n\n```\n    pip install --upgrade pip build\n    python -m build\n    pip install dist/*.whl\n```\n\n* To install the latest from the main branch, run\n`pip install git+https://github.com/rthalley/dnspython.git`\n\n`dnspython`'s default installation does not depend on any modules other than\nthose in the Python standard library.  To use some features, additional modules\nmust be installed.  For convenience, `pip` options are defined for the\nrequirements.\n\nIf you want to use DNS-over-HTTPS, run\n`pip install dnspython[doh]`.\n\nIf you want to use DNSSEC functionality, run\n`pip install dnspython[dnssec]`.\n\nIf you want to use internationalized domain names (IDNA)\nfunctionality, you must run\n`pip install dnspython[idna]`\n\nIf you want to use the Trio asynchronous I/O package, run\n`pip install dnspython[trio]`.\n\nIf you want to use WMI on Windows to determine the active DNS settings\ninstead of the default registry scanning method, run\n`pip install dnspython[wmi]`.\n\nIf you want to try the experimental DNS-over-QUIC code, run\n`pip install dnspython[doq]`.\n\nNote that you can install any combination of the above, e.g.:\n`pip install dnspython[doh,dnssec,idna]`\n\n### Notices\n\nPython 2.x support ended with the release of 1.16.0.  `dnspython` supports Python 3.10\nand later.  Future support is aligned with the lifetime of the Python 3 versions.\n\nDocumentation has moved to\n[dnspython.readthedocs.io](https://dnspython.readthedocs.io).\n",
        "description_content_type": "text/markdown",
        "author_email": "Bob Halley <halley@dnspython.org>",
        "license": "ISC",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: ISC License (ISCL)",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Internet :: Name Service (DNS)",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "black>=25.1.0; extra == 'dev'",
          "coverage>=7.0; extra == 'dev'",
          "flake8>=7; extra == 'dev'",
          "hypercorn>=0.17.0; extra == 'dev'",
          "mypy>=1.17; extra == 'dev'",
          "pylint>=3; extra == 'dev'",
          "pytest-cov>=6.2.0; extra == 'dev'",
          "pytest>=8.4; extra == 'dev'",
          "quart-trio>=0.12.0; extra == 'dev'",
          "sphinx-rtd-theme>=3.0.0; extra == 'dev'",
          "sphinx>=8.2.0; extra == 'dev'",
          "twine>=6.1.0; extra == 'dev'",
          "wheel>=0.45.0; extra == 'dev'",
          "cryptography>=45; extra == 'dnssec'",
          "h2>=4.2.0; extra == 'doh'",
          "httpcore>=1.0.0; extra == 'doh'",
          "httpx>=0.28.0; extra == 'doh'",
          "aioquic>=1.2.0; extra == 'doq'",
          "idna>=3.10; extra == 'idna'",
          "trio>=0.30; extra == 'trio'",
          "wmi>=1.5.1; (platform_system == 'Windows') and extra == 'wmi'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://www.dnspython.org",
          "repository, https://github.com/rthalley/dnspython.git",
          "documentation, https://dnspython.readthedocs.io/en/stable/",
          "issues, https://github.com/rthalley/dnspython/issues"
        ],
        "provides_extra": [
          "dev",
          "dnssec",
          "doh",
          "doq",
          "idna",
          "trio",
          "wmi"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/d8/cf/174c91dbc9cc49bc7b7aab74d8b734e974d1faa8f191c74af9b7e80848e6/frozenlist-1.8.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=878be833caa6a3821caf85eb39c5ba92d28e85df26d57afb06b35b2efd937231",
          "hashes": {
            "sha256": "878be833caa6a3821caf85eb39c5ba92d28e85df26d57afb06b35b2efd937231"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "frozenlist",
        "version": "1.8.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "A list-like structure which implements collections.abc.MutableSequence",
        "description": "frozenlist\r\n==========\r\n\r\n.. image:: https://github.com/aio-libs/frozenlist/workflows/CI/badge.svg\r\n   :target: https://github.com/aio-libs/frozenlist/actions\r\n   :alt: GitHub status for master branch\r\n\r\n.. image:: https://codecov.io/gh/aio-libs/frozenlist/branch/master/graph/badge.svg?flag=pytest\r\n   :target: https://codecov.io/gh/aio-libs/frozenlist?flags[]=pytest\r\n   :alt: codecov.io status for master branch\r\n\r\n.. image:: https://img.shields.io/pypi/v/frozenlist.svg?logo=Python&logoColor=white\r\n   :target: https://pypi.org/project/frozenlist\r\n   :alt: frozenlist @ PyPI\r\n\r\n.. image:: https://readthedocs.org/projects/frozenlist/badge/?version=latest\r\n   :target: https://frozenlist.aio-libs.org\r\n   :alt: Read The Docs build status badge\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs:matrix.org\r\n   :alt: Matrix Room â€” #aio-libs:matrix.org\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs-space:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs-space%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs-space:matrix.org\r\n   :alt: Matrix Space â€” #aio-libs-space:matrix.org\r\n\r\nIntroduction\r\n------------\r\n\r\n``frozenlist.FrozenList`` is a list-like structure which implements\r\n``collections.abc.MutableSequence``. The list is *mutable* until ``FrozenList.freeze``\r\nis called, after which list modifications raise ``RuntimeError``:\r\n\r\n\r\n>>> from frozenlist import FrozenList\r\n>>> fl = FrozenList([17, 42])\r\n>>> fl.append('spam')\r\n>>> fl.append('Vikings')\r\n>>> fl\r\n<FrozenList(frozen=False, [17, 42, 'spam', 'Vikings'])>\r\n>>> fl.freeze()\r\n>>> fl\r\n<FrozenList(frozen=True, [17, 42, 'spam', 'Vikings'])>\r\n>>> fl.frozen\r\nTrue\r\n>>> fl.append(\"Monty\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"frozenlist/_frozenlist.pyx\", line 97, in frozenlist._frozenlist.FrozenList.append\r\n    self._check_frozen()\r\n  File \"frozenlist/_frozenlist.pyx\", line 19, in frozenlist._frozenlist.FrozenList._check_frozen\r\n    raise RuntimeError(\"Cannot modify frozen list.\")\r\nRuntimeError: Cannot modify frozen list.\r\n\r\n\r\nFrozenList is also hashable, but only when frozen. Otherwise it also throws a RuntimeError:\r\n\r\n\r\n>>> fl = FrozenList([17, 42, 'spam'])\r\n>>> hash(fl)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"frozenlist/_frozenlist.pyx\", line 111, in frozenlist._frozenlist.FrozenList.__hash__\r\n    raise RuntimeError(\"Cannot hash unfrozen list.\")\r\nRuntimeError: Cannot hash unfrozen list.\r\n>>> fl.freeze()\r\n>>> hash(fl)\r\n3713081631934410656\r\n>>> dictionary = {fl: 'Vikings'} # frozen fl can be a dict key\r\n>>> dictionary\r\n{<FrozenList(frozen=True, [1, 2])>: 'Vikings'}\r\n\r\n\r\nInstallation\r\n------------\r\n\r\n::\r\n\r\n   $ pip install frozenlist\r\n\r\n\r\nDocumentation\r\n-------------\r\n\r\nhttps://frozenlist.aio-libs.org\r\n\r\nCommunication channels\r\n----------------------\r\n\r\nWe have a *Matrix Space* `#aio-libs-space:matrix.org\r\n<https://matrix.to/#/%23aio-libs-space:matrix.org>`_ which is\r\nalso accessible via Gitter.\r\n\r\nLicense\r\n-------\r\n\r\n``frozenlist`` is offered under the Apache 2 license.\r\n\r\nSource code\r\n-----------\r\n\r\nThe project is hosted on GitHub_\r\n\r\nPlease file an issue in the `bug tracker\r\n<https://github.com/aio-libs/frozenlist/issues>`_ if you have found a bug\r\nor have some suggestions to improve the library.\r\n\r\n.. _GitHub: https://github.com/aio-libs/frozenlist\r\n\r\n=========\r\nChangelog\r\n=========\r\n\r\n..\r\n    You should *NOT* be adding new change log entries to this file, this\r\n    file is managed by towncrier. You *may* edit previous change logs to\r\n    fix problems like typo corrections or such.\r\n    To add a new change log entry, please see\r\n    https://pip.pypa.io/en/latest/development/contributing/#news-entries\r\n    we named the news folder \"changes\".\r\n\r\n    WARNING: Don't drop the next directive!\r\n\r\n.. towncrier release notes start\r\n\r\nv1.8.0\r\n======\r\n\r\n*(2025-10-05)*\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- The ``reusable-cibuildwheel.yml`` workflow has been refactored to\r\n  be more generic and ``ci-cd.yml`` now holds all the configuration\r\n  toggles -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#668 <https://github.com/aio-libs/frozenlist/issues/668>`__.\r\n\r\n- When building wheels, the source distribution is now passed directly\r\n  to the ``cibuildwheel`` invocation -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#669 <https://github.com/aio-libs/frozenlist/issues/669>`__.\r\n\r\n- Builds and tests have been added to\r\n  ``ci-cd.yml`` for arm64 Windows wheels -- by `@finnagin <https://github.com/sponsors/finnagin>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#677 <https://github.com/aio-libs/frozenlist/issues/677>`__.\r\n\r\n- Started building wheels for CPython 3.14 -- by `@kumaraditya303 <https://github.com/sponsors/kumaraditya303>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#681 <https://github.com/aio-libs/frozenlist/issues/681>`__, `#682 <https://github.com/aio-libs/frozenlist/issues/682>`__.\r\n\r\n- Removed ``--config-settings=pure-python=false`` from ``requirements/dev.txt``.\r\n  Developers on CPython still get accelerated builds by default. To explicitly build\r\n  a pure Python wheel, use ``pip install -e . --config-settings=pure-python=true``\r\n  -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#687 <https://github.com/aio-libs/frozenlist/issues/687>`__.\r\n\r\n\r\n----\r\n\r\n\r\nv1.7.0\r\n======\r\n\r\n*(2025-06-09)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added deepcopy support to FrozenList -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#659 <https://github.com/aio-libs/frozenlist/issues/659>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Fixed an issue where ``frozenlist`` binary wheels would be built with debugging symbols and line tracing enabled, which significantly impacted performance. Line tracing is now disabled by default and can only be enabled explicitly -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  This change ensures that production builds are optimized for performance. Developers who need line tracing for debugging purposes can still enable it by:\r\n\r\n  1. Setting the ``FROZENLIST_CYTHON_TRACING`` environment variable\r\n  2. Using the ``--config-setting=with-cython-tracing=true`` option with pip\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#660 <https://github.com/aio-libs/frozenlist/issues/660>`__.\r\n\r\n- Enabled ``PIP_CONSTRAINT`` environment variable in the build configuration to ensure the pinned Cython version from ``requirements/cython.txt`` is used during wheel builds.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#661 <https://github.com/aio-libs/frozenlist/issues/661>`__.\r\n\r\n\r\n----\r\n\r\n\r\nv1.6.2\r\n======\r\n\r\n*(2025-06-03)*\r\n\r\n\r\nNo significant changes.\r\n\r\n\r\n----\r\n\r\n\r\nv1.6.1\r\n======\r\n\r\n*(2025-06-02)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Correctly use ``cimport`` for including ``PyBool_FromLong`` -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#653 <https://github.com/aio-libs/frozenlist/issues/653>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Exclude ``_frozenlist.cpp`` from bdists/wheels -- by `@musicinmybrain <https://github.com/sponsors/musicinmybrain>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#649 <https://github.com/aio-libs/frozenlist/issues/649>`__.\r\n\r\n- Updated to use Cython 3.1 universally across the build path -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#654 <https://github.com/aio-libs/frozenlist/issues/654>`__.\r\n\r\n\r\n----\r\n\r\n\r\nv1.6.0\r\n======\r\n\r\n*(2025-04-17)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related commits on GitHub:*\r\n  `41591f2 <https://github.com/aio-libs/frozenlist/commit/41591f2>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Implemented support for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#618 <https://github.com/aio-libs/frozenlist/issues/618>`__.\r\n\r\n- Started building armv7l wheels -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#642 <https://github.com/aio-libs/frozenlist/issues/642>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related commits on GitHub:*\r\n  `41591f2 <https://github.com/aio-libs/frozenlist/commit/41591f2>`__.\r\n\r\n- Started building wheels for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#618 <https://github.com/aio-libs/frozenlist/issues/618>`__.\r\n\r\n- The packaging metadata switched to including an SPDX license identifier introduced in `PEP 639 <https://peps.python.org/pep-639>`__ -- by `@cdce8p <https://github.com/sponsors/cdce8p>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#639 <https://github.com/aio-libs/frozenlist/issues/639>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- GitHub Actions CI/CD is now configured to manage caching pip-ecosystem\r\n  dependencies using `re-actors/cache-python-deps`_ -- an action by\r\n  `@webknjaz <https://github.com/sponsors/webknjaz>`__ that takes into account ABI stability and the exact\r\n  version of Python runtime.\r\n\r\n  .. _`re-actors/cache-python-deps`:\r\n     https://github.com/marketplace/actions/cache-python-deps\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#633 <https://github.com/aio-libs/frozenlist/issues/633>`__.\r\n\r\n- Organized dependencies into test and lint dependencies so that no\r\n  unnecessary ones are installed during CI runs -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#636 <https://github.com/aio-libs/frozenlist/issues/636>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.5.0 (2024-10-22)\r\n==================\r\n\r\nBug fixes\r\n---------\r\n\r\n- An incorrect signature of the ``__class_getitem__`` class method\r\n  has been fixed, adding a missing ``class_item`` argument under\r\n  Python 3.8 and older.\r\n\r\n  This change also improves the code coverage of this method that\r\n  was previously missing -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#567 <https://github.com/aio-libs/frozenlist/issues/567>`__, `#571 <https://github.com/aio-libs/frozenlist/issues/571>`__.\r\n\r\n\r\nImproved documentation\r\n----------------------\r\n\r\n- Rendered issue, PR, and commit links now lead to\r\n  ``frozenlist``'s repo instead of ``yarl``'s repo.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#573 <https://github.com/aio-libs/frozenlist/issues/573>`__.\r\n\r\n- On the ``Contributing docs`` page,\r\n  a link to the ``Towncrier philosophy`` has been fixed.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#574 <https://github.com/aio-libs/frozenlist/issues/574>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- A name of a temporary building directory now reflects\r\n  that it's related to ``frozenlist``, not ``yarl``.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#573 <https://github.com/aio-libs/frozenlist/issues/573>`__.\r\n\r\n- Declared Python 3.13 supported officially in the distribution package metadata.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#595 <https://github.com/aio-libs/frozenlist/issues/595>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.4.1 (2023-12-15)\r\n==================\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Declared Python 3.12 and PyPy 3.8-3.10 supported officially\r\n  in the distribution package metadata.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#553 <https://github.com/aio-libs/frozenlist/issues/553>`__.\r\n\r\n- Replaced the packaging is replaced from an old-fashioned ``setup.py`` to an\r\n  in-tree `PEP 517 <https://peps.python.org/pep-517>`__ build backend -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  Whenever the end-users or downstream packagers need to build ``frozenlist``\r\n  from source (a Git checkout or an sdist), they may pass a ``config_settings``\r\n  flag ``pure-python``. If this flag is not set, a C-extension will be built\r\n  and included into the distribution.\r\n\r\n  Here is how this can be done with ``pip``:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python3 -m pip install . --config-settings=pure-python=\r\n\r\n  This will also work with ``-e | --editable``.\r\n\r\n  The same can be achieved via ``pypa/build``:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python3 -m build --config-setting=pure-python=\r\n\r\n  Adding ``-w | --wheel`` can force ``pypa/build`` produce a wheel from source\r\n  directly, as opposed to building an ``sdist`` and then building from it.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#560 <https://github.com/aio-libs/frozenlist/issues/560>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- It is now possible to request line tracing in Cython builds using the\r\n  ``with-cython-tracing`` `PEP 517 <https://peps.python.org/pep-517>`__ config setting\r\n  -- `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  This can be used in CI and development environment to measure coverage\r\n  on Cython modules, but is not normally useful to the end-users or\r\n  downstream packagers.\r\n\r\n  Here's a usage example:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python3 -Im pip install . --config-settings=with-cython-tracing=true\r\n\r\n  For editable installs, this setting is on by default. Otherwise, it's\r\n  off unless requested explicitly.\r\n\r\n  The following produces C-files required for the Cython coverage\r\n  plugin to map the measurements back to the PYX-files:\r\n\r\n  .. code-block:: console\r\n\r\n      $ python -Im pip install -e .\r\n\r\n  Alternatively, the ``FROZENLIST_CYTHON_TRACING=1`` environment variable\r\n  can be set to do the same as the `PEP 517 <https://peps.python.org/pep-517>`__ config setting.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#560 <https://github.com/aio-libs/frozenlist/issues/560>`__.\r\n\r\n- Coverage collection has been implemented for the Cython modules\r\n  -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  It will also be reported to Codecov from any non-release CI jobs.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#561 <https://github.com/aio-libs/frozenlist/issues/561>`__.\r\n\r\n- A step-by-step ``Release Guide`` guide has\r\n  been added, describing how to release *frozenlist* -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n  This is primarily targeting the maintainers.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#563 <https://github.com/aio-libs/frozenlist/issues/563>`__.\r\n\r\n- Detailed ``Contributing Guidelines`` on\r\n  authoring the changelog fragments have been published in the\r\n  documentation -- by `@webknjaz <https://github.com/sponsors/webknjaz>`__.\r\n\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#564 <https://github.com/aio-libs/frozenlist/issues/564>`__.\r\n\r\n\r\n----\r\n\r\n\r\n1.4.0 (2023-07-12)\r\n==================\r\n\r\nThe published source distribution package became buildable\r\nunder Python 3.12.\r\n\r\n\r\n----\r\n\r\n\r\nBugfixes\r\n--------\r\n\r\n- Removed an unused ``typing.Tuple`` import\r\n  `#411 <https://github.com/aio-libs/frozenlist/issues/411>`_\r\n\r\n\r\nDeprecations and Removals\r\n-------------------------\r\n\r\n- Dropped Python 3.7 support.\r\n  `#413 <https://github.com/aio-libs/frozenlist/issues/413>`_\r\n\r\n\r\nMisc\r\n----\r\n\r\n- `#410 <https://github.com/aio-libs/frozenlist/issues/410>`_, `#433 <https://github.com/aio-libs/frozenlist/issues/433>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.3.3 (2022-11-08)\r\n==================\r\n\r\n- Fixed CI runs when creating a new release, where new towncrier versions\r\n  fail when the current version section is already present.\r\n\r\n\r\n----\r\n\r\n\r\n1.3.2 (2022-11-08)\r\n==================\r\n\r\nMisc\r\n----\r\n\r\n- Updated the CI runs to better check for test results and to avoid deprecated syntax. `#327 <https://github.com/aio-libs/frozenlist/issues/327>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.3.1 (2022-08-02)\r\n==================\r\n\r\nThe published source distribution package became buildable\r\nunder Python 3.11.\r\n\r\n\r\n----\r\n\r\n\r\n1.3.0 (2022-01-18)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Do not install C sources with binary distributions.\r\n  `#250 <https://github.com/aio-libs/frozenlist/issues/250>`_\r\n\r\n\r\nDeprecations and Removals\r\n-------------------------\r\n\r\n- Dropped Python 3.6 support\r\n  `#274 <https://github.com/aio-libs/frozenlist/issues/274>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.2.0 (2021-10-16)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- ``FrozenList`` now supports being used as a generic type as per PEP 585, e.g. ``frozen_int_list: FrozenList[int]`` (requires Python 3.9 or newer).\r\n  `#172 <https://github.com/aio-libs/frozenlist/issues/172>`_\r\n- Added support for Python 3.10.\r\n  `#227 <https://github.com/aio-libs/frozenlist/issues/227>`_\r\n- Started shipping platform-specific wheels with the ``musl`` tag targeting typical Alpine Linux runtimes.\r\n  `#227 <https://github.com/aio-libs/frozenlist/issues/227>`_\r\n- Started shipping platform-specific arm64 wheels for Apple Silicon.\r\n  `#227 <https://github.com/aio-libs/frozenlist/issues/227>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.1.1 (2020-11-14)\r\n==================\r\n\r\nBugfixes\r\n--------\r\n\r\n- Provide x86 Windows wheels.\r\n  `#169 <https://github.com/aio-libs/frozenlist/issues/169>`_\r\n\r\n\r\n----\r\n\r\n\r\n1.1.0 (2020-10-13)\r\n==================\r\n\r\nFeatures\r\n--------\r\n\r\n- Add support for hashing of a frozen list.\r\n  `#136 <https://github.com/aio-libs/frozenlist/issues/136>`_\r\n\r\n- Support Python 3.8 and 3.9.\r\n\r\n- Provide wheels for ``aarch64``, ``i686``, ``ppc64le``, ``s390x`` architectures on\r\n  Linux as well as ``x86_64``.\r\n\r\n\r\n----\r\n\r\n\r\n1.0.0 (2019-11-09)\r\n==================\r\n\r\nDeprecations and Removals\r\n-------------------------\r\n\r\n- Dropped support for Python 3.5; only 3.6, 3.7 and 3.8 are supported going forward.\r\n  `#24 <https://github.com/aio-libs/frozenlist/issues/24>`_\r\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/aio-libs/frozenlist",
        "maintainer": "aiohttp team <team@aiohttp.org>",
        "maintainer_email": "team@aiohttp.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: POSIX",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat: Matrix, https://matrix.to/#/#aio-libs:matrix.org",
          "Chat: Matrix Space, https://matrix.to/#/#aio-libs-space:matrix.org",
          "CI: Github Actions, https://github.com/aio-libs/frozenlist/actions",
          "Code of Conduct, https://github.com/aio-libs/.github/blob/master/CODE_OF_CONDUCT.md",
          "Coverage: codecov, https://codecov.io/github/aio-libs/frozenlist",
          "Docs: Changelog, https://github.com/aio-libs/frozenlist/blob/master/CHANGES.rst#changelog",
          "Docs: RTD, https://frozenlist.aio-libs.org",
          "GitHub: issues, https://github.com/aio-libs/frozenlist/issues",
          "GitHub: repo, https://github.com/aio-libs/frozenlist"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/92/b1/d3cbd4d988afb3d8e4db94ca953df429ed6db7282ed0e700d25e6c7bfc8d/google_crc32c-1.8.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=57a50a9035b75643996fbf224d6661e386c7162d1dfdab9bc4ca790947d1007f",
          "hashes": {
            "sha256": "57a50a9035b75643996fbf224d6661e386c7162d1dfdab9bc4ca790947d1007f"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "google-crc32c",
        "version": "1.8.0",
        "dynamic": [
          "license-file"
        ],
        "platform": [
          "Posix",
          "MacOS X",
          "Windows"
        ],
        "summary": "A python wrapper of the C library 'Google CRC32C'",
        "description": "# `google-crc32c`\r\n![GA](https://img.shields.io/badge/support-GA-gold.svg) [<img src=\"https://img.shields.io/pypi/v/google-crc32c.svg\">](https://pypi.org/project/google-crc32c) ![Python Versions](https://img.shields.io/pypi/pyversions/google-crc32c)\r\n\r\nThis package wraps the [`google/crc32c`](https://github.com/google/crc32c)\r\nhardware-based implementation of the CRC32C hashing algorithm. Multiple wheels\r\nare distributed as well as source. If a wheel is not published for the python\r\nversion and platform you are using, you will need to compile crc32c using a\r\nC toolchain.\r\n\r\n# Currently Published Wheels\r\n\r\nWheels are currently published for CPython 3.9, 3.10, 3.11, 3.12, 3.13 and 3.14\r\nfor multiple architectures. PyPy 3.9 and 3.10 are also supported for Linux.\r\nFor information on building your own wheels please view [BUILDING.md](BUILDING.md).\r\n\r\n\r\n## Linux\r\n\r\nWheels are published for the following platforms / architectures:\r\n\r\n- `manylinux2010` platform, `x86_64` and `1686` architectures\r\n- `manylinux2014` platform, `aarch64` architecture\r\n\r\n### Unsupported Platforms\r\n\r\n- `manylinux1` platform, `x86_64` architecture support has ended.\r\n\r\nSee https://github.com/pypa/manylinux/issues/994.\r\n\r\n## Mac OS\r\n\r\nWheels are published for `x86_64` and `arm64` architectures.\r\n\r\n\r\n## Windows\r\n\r\nWheels are published for the `win_amd64` architecture.\r\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/googleapis/python-crc32c",
        "author": "Google LLC",
        "author_email": "googleapis-packages@google.com",
        "license_file": [
          "LICENSE"
        ],
        "requires_python": ">=3.9"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86",
          "hashes": {
            "sha256": "63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "h11",
        "version": "0.16.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "requires-python",
          "summary"
        ],
        "summary": "A pure-Python, bring-your-own-I/O implementation of HTTP/1.1",
        "description": "h11\n===\n\n.. image:: https://travis-ci.org/python-hyper/h11.svg?branch=master\n   :target: https://travis-ci.org/python-hyper/h11\n   :alt: Automated test status\n\n.. image:: https://codecov.io/gh/python-hyper/h11/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/python-hyper/h11\n   :alt: Test coverage\n\n.. image:: https://readthedocs.org/projects/h11/badge/?version=latest\n   :target: http://h11.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n\nThis is a little HTTP/1.1 library written from scratch in Python,\nheavily inspired by `hyper-h2 <https://hyper-h2.readthedocs.io/>`_.\n\nIt's a \"bring-your-own-I/O\" library; h11 contains no IO code\nwhatsoever. This means you can hook h11 up to your favorite network\nAPI, and that could be anything you want: synchronous, threaded,\nasynchronous, or your own implementation of `RFC 6214\n<https://tools.ietf.org/html/rfc6214>`_ -- h11 won't judge you.\n(Compare this to the current state of the art, where every time a `new\nnetwork API <https://trio.readthedocs.io/>`_ comes along then someone\ngets to start over reimplementing the entire HTTP protocol from\nscratch.) Cory Benfield made an `excellent blog post describing the\nbenefits of this approach\n<https://lukasa.co.uk/2015/10/The_New_Hyper/>`_, or if you like video\nthen here's his `PyCon 2016 talk on the same theme\n<https://www.youtube.com/watch?v=7cC3_jGwl_U>`_.\n\nThis also means that h11 is not immediately useful out of the box:\nit's a toolkit for building programs that speak HTTP, not something\nthat could directly replace ``requests`` or ``twisted.web`` or\nwhatever. But h11 makes it much easier to implement something like\n``requests`` or ``twisted.web``.\n\nAt a high level, working with h11 goes like this:\n\n1) First, create an ``h11.Connection`` object to track the state of a\n   single HTTP/1.1 connection.\n\n2) When you read data off the network, pass it to\n   ``conn.receive_data(...)``; you'll get back a list of objects\n   representing high-level HTTP \"events\".\n\n3) When you want to send a high-level HTTP event, create the\n   corresponding \"event\" object and pass it to ``conn.send(...)``;\n   this will give you back some bytes that you can then push out\n   through the network.\n\nFor example, a client might instantiate and then send a\n``h11.Request`` object, then zero or more ``h11.Data`` objects for the\nrequest body (e.g., if this is a POST), and then a\n``h11.EndOfMessage`` to indicate the end of the message. Then the\nserver would then send back a ``h11.Response``, some ``h11.Data``, and\nits own ``h11.EndOfMessage``. If either side violates the protocol,\nyou'll get a ``h11.ProtocolError`` exception.\n\nh11 is suitable for implementing both servers and clients, and has a\npleasantly symmetric API: the events you send as a client are exactly\nthe ones that you receive as a server and vice-versa.\n\n`Here's an example of a tiny HTTP client\n<https://github.com/python-hyper/h11/blob/master/examples/basic-client.py>`_\n\nIt also has `a fine manual <https://h11.readthedocs.io/>`_.\n\nFAQ\n---\n\n*Whyyyyy?*\n\nI wanted to play with HTTP in `Curio\n<https://curio.readthedocs.io/en/latest/tutorial.html>`__ and `Trio\n<https://trio.readthedocs.io>`__, which at the time didn't have any\nHTTP libraries. So I thought, no big deal, Python has, like, a dozen\ndifferent implementations of HTTP, surely I can find one that's\nreusable. I didn't find one, but I did find Cory's call-to-arms\nblog-post. So I figured, well, fine, if I have to implement HTTP from\nscratch, at least I can make sure no-one *else* has to ever again.\n\n*Should I use it?*\n\nMaybe. You should be aware that it's a very young project. But, it's\nfeature complete and has an exhaustive test-suite and complete docs,\nso the next step is for people to try using it and see how it goes\n:-). If you do then please let us know -- if nothing else we'll want\nto talk to you before making any incompatible changes!\n\n*What are the features/limitations?*\n\nRoughly speaking, it's trying to be a robust, complete, and non-hacky\nimplementation of the first \"chapter\" of the HTTP/1.1 spec: `RFC 7230:\nHTTP/1.1 Message Syntax and Routing\n<https://tools.ietf.org/html/rfc7230>`_. That is, it mostly focuses on\nimplementing HTTP at the level of taking bytes on and off the wire,\nand the headers related to that, and tries to be anal about spec\nconformance. It doesn't know about higher-level concerns like URL\nrouting, conditional GETs, cross-origin cookie policies, or content\nnegotiation. But it does know how to take care of framing,\ncross-version differences in keep-alive handling, and the \"obsolete\nline folding\" rule, so you can focus your energies on the hard /\ninteresting parts for your application, and it tries to support the\nfull specification in the sense that any useful HTTP/1.1 conformant\napplication should be able to use h11.\n\nIt's pure Python, and has no dependencies outside of the standard\nlibrary.\n\nIt has a test suite with 100.0% coverage for both statements and\nbranches.\n\nCurrently it supports Python 3 (testing on 3.8-3.12) and PyPy 3.\nThe last Python 2-compatible version was h11 0.11.x.\n(Originally it had a Cython wrapper for `http-parser\n<https://github.com/nodejs/http-parser>`_ and a beautiful nested state\nmachine implemented with ``yield from`` to postprocess the output. But\nI had to take these out -- the new *parser* needs fewer lines-of-code\nthan the old *parser wrapper*, is written in pure Python, uses no\nexotic language syntax, and has more features. It's sad, really; that\nold state machine was really slick. I just need a few sentences here\nto mourn that.)\n\nI don't know how fast it is. I haven't benchmarked or profiled it yet,\nso it's probably got a few pointless hot spots, and I've been trying\nto err on the side of simplicity and robustness instead of\nmicro-optimization. But at the architectural level I tried hard to\navoid fundamentally bad decisions, e.g., I believe that all the\nparsing algorithms remain linear-time even in the face of pathological\ninput like slowloris, and there are no byte-by-byte loops. (I also\nbelieve that it maintains bounded memory usage in the face of\narbitrary/pathological input.)\n\nThe whole library is ~800 lines-of-code. You can read and understand\nthe whole thing in less than an hour. Most of the energy invested in\nthis so far has been spent on trying to keep things simple by\nminimizing special-cases and ad hoc state manipulation; even though it\nis now quite small and simple, I'm still annoyed that I haven't\nfigured out how to make it even smaller and simpler. (Unfortunately,\nHTTP does not lend itself to simplicity.)\n\nThe API is ~feature complete and I don't expect the general outlines\nto change much, but you can't judge an API's ergonomics until you\nactually document and use it, so I'd expect some changes in the\ndetails.\n\n*How do I try it?*\n\n.. code-block:: sh\n\n  $ pip install h11\n  $ git clone git@github.com:python-hyper/h11\n  $ cd h11/examples\n  $ python basic-client.py\n\nand go from there.\n\n*License?*\n\nMIT\n\n*Code of conduct?*\n\nContributors are requested to follow our `code of conduct\n<https://github.com/python-hyper/h11/blob/master/CODE_OF_CONDUCT.md>`_ in\nall project spaces.\n",
        "home_page": "https://github.com/python-hyper/h11",
        "author": "Nathaniel J. Smith",
        "author_email": "njs@pobox.com",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: System :: Networking"
        ],
        "requires_python": ">=3.8"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/9c/1f/19ebc343cc71a7ffa78f17018535adc5cbdd87afb31d7c34874680148b32/ifaddr-0.2.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=085e0305cfe6f16ab12d72e2024030f5d52674afad6911bb1eee207177b8a748",
          "hashes": {
            "sha256": "085e0305cfe6f16ab12d72e2024030f5d52674afad6911bb1eee207177b8a748"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "ifaddr",
        "version": "0.2.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Cross-platform network interface and IP address enumeration library",
        "description": "ifaddr - Enumerate network interfaces/adapters and their IP addresses\n=====================================================================\n\n.. image:: https://github.com/pydron/ifaddr/workflows/CI/badge.svg\n    :target: https://github.com/pydron/ifaddr/actions?query=workflow%3ACI+branch%3Amaster\n\n.. image:: https://img.shields.io/pypi/v/ifaddr.svg\n    :target: https://pypi.python.org/pypi/ifaddr\n\n.. image:: https://codecov.io/gh/pydron/ifaddr/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/pydron/ifaddr\n\n`ifaddr` is a small Python library that allows you to find all the Ethernet and\nIP addresses of the computer. It is tested on **Linux**, **OS X**, and\n**Windows**. Other BSD derivatives like **OpenBSD**, **FreeBSD**, and\n**NetBSD** should work too, but I haven't personally tested those.\n**Solaris/Illumos** should also work.\n\nThis library is open source and released under the MIT License. It works\nwith Python 3.7+.\n\nYou can install it with `pip install ifaddr`. It doesn't need to\ncompile anything, so there shouldn't be any surprises. Even on Windows.\n\nProject links:\n\n* `ifaddr GitHub page <https://github.com/smurn/ifaddr>`_\n* `ifaddr documentation (although there isn't much to document) <http://pythonhosted.org/ifaddr/>`_\n* `ifaddr on PyPI <https://pypi.org/project/ifaddr/>`_\n\n\n----------------------\nLet's get going!\n----------------------\n\n.. code-block:: python\n\n    import ifaddr\n\n    adapters = ifaddr.get_adapters()\n\n    for adapter in adapters:\n        print(\"IPs of network adapter \" + adapter.nice_name)\n        for ip in adapter.ips:\n            print(\"   %s/%s\" % (ip.ip, ip.network_prefix))\n\nThis will print::\n\n    IPs of network adapter H5321 gw Mobile Broadband Driver\n       IP ('fe80::9:ebdf:30ab:39a3', 0L, 17L)/64\n       IP 169.254.57.163/16\n    IPs of network adapter Intel(R) Centrino(R) Advanced-N 6205\n       IP ('fe80::481f:3c9d:c3f6:93f8', 0L, 12L)/64\n       IP 192.168.0.51/24\n    IPs of network adapter Intel(R) 82579LM Gigabit Network Connection\n       IP ('fe80::85cd:e07e:4f7a:6aa6', 0L, 11L)/64\n       IP 192.168.0.53/24\n    IPs of network adapter Software Loopback Interface 1\n       IP ('::1', 0L, 0L)/128\n       IP 127.0.0.1/8\n\nYou get both IPv4 and IPv6 addresses. The later complete with\nflowinfo and scope_id.\n\nIf you wish to include network interfaces that do not have a configured IP\naddresss, pass the `include_unconfigured` parameter to `get_adapters()`.\nAdapters with no configured IP addresses will have an zero-length `ips`\nproperty.  For example:\n\n.. code-block:: python\n\n    import ifaddr\n\n    adapters = ifaddr.get_adapters(include_unconfigured=True)\n\n    for adapter in adapters:\n        print(\"IPs of network adapter \" + adapter.nice_name)\n        if adapter.ips:\n            for ip in adapter.ips:\n                print(\"   %s/%s\" % (ip.ip, ip.network_prefix))\n        else:\n            print(\"  No IPs configured\")\n\n\n---------\nChangelog\n---------\n\n0.2.0\n-----\n\n* Added an option to include IP-less adapters, thanks to memory\n* Fixed a bug where an interface's name was `bytes`, not `str`, on Windows\n* Added an implementation of `netifaces.interfaces()` (available through\n  `ifaddr.netifaces.interfaces()`)\n* Added type hints\n\nBackwards incompatible/breaking changes:\n\n* Dropped Python 3.6 support\n\n0.1.7\n-----\n\n* Fixed Python 3 compatibility in the examples, thanks to Tristan Stenner and Josef Schlehofer\n* Exposed network interface indexes in Adapter.index, thanks to Dmitry Tantsur\n* Added the license file to distributions on PyPI, thanks to TomÃ¡Å¡ ChvÃ¡tal\n* Fixed Illumos/Solaris compatibility based on a patch proposed by Jorge Schrauwen\n* Set up universal wheels, ifaddr will have both source and wheel distributions on PyPI from now on\n\n------------\nAlternatives\n------------\n\nAlastair Houghton develops `netifaces  <https://pypi.python.org/pypi/netifaces>`_\nwhich can do  everything this library can, and more. The only drawback is that it needs\nto be compiled, which can make the installation difficult.\n\nAs of ifaddr 0.2.0 we implement the equivalent of `netifaces.interfaces()`. It's available through\n`ifaddr.netifaces.interfaces()`.\n\n\n",
        "keywords": [
          "network interfaces",
          "network adapters",
          "network addresses",
          "IP addresses"
        ],
        "home_page": "https://github.com/pydron/ifaddr",
        "author": "Stefan C. Mueller",
        "author_email": "scm@smurn.org",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Topic :: System :: Networking",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/cb/b1/3846dd7f199d53cb17f49cba7e651e9ce294d8497c8c150530ed11865bb8/iniconfig-2.3.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f631c04d2c48c52b84d0d0549c99ff3859c98df65b3101406327ecc7d53fbf12",
          "hashes": {
            "sha256": "f631c04d2c48c52b84d0d0549c99ff3859c98df65b3101406327ecc7d53fbf12"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "iniconfig",
        "version": "2.3.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "brain-dead simple config-ini parsing",
        "description": "iniconfig: brain-dead simple parsing of ini files\n=======================================================\n\niniconfig is a small and simple INI-file parser module\nhaving a unique set of features:\n\n* maintains order of sections and entries\n* supports multi-line values with or without line-continuations\n* supports \"#\" comments everywhere\n* raises errors with proper line-numbers\n* no bells and whistles like automatic substitutions\n* iniconfig raises an Error if two sections have the same name.\n\nIf you encounter issues or have feature wishes please report them to:\n\n    https://github.com/RonnyPfannschmidt/iniconfig/issues\n\nBasic Example\n===================================\n\nIf you have an ini file like this:\n\n.. code-block:: ini\n\n    # content of example.ini\n    [section1] # comment\n    name1=value1  # comment\n    name1b=value1,value2  # comment\n\n    [section2]\n    name2=\n        line1\n        line2\n\nthen you can do:\n\n.. code-block:: pycon\n\n    >>> import iniconfig\n    >>> ini = iniconfig.IniConfig(\"example.ini\")\n    >>> ini['section1']['name1'] # raises KeyError if not exists\n    'value1'\n    >>> ini.get('section1', 'name1b', [], lambda x: x.split(\",\"))\n    ['value1', 'value2']\n    >>> ini.get('section1', 'notexist', [], lambda x: x.split(\",\"))\n    []\n    >>> [x.name for x in list(ini)]\n    ['section1', 'section2']\n    >>> list(list(ini)[0].items())\n    [('name1', 'value1'), ('name1b', 'value1,value2')]\n    >>> 'section1' in ini\n    True\n    >>> 'inexistendsection' in ini\n    False\n",
        "description_content_type": "text/x-rst",
        "author_email": "Ronny Pfannschmidt <opensource@ronnypfannschmidt.de>, Holger Krekel <holger.krekel@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/pytest-dev/iniconfig"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/15/aa/0aca39a37d3c7eb941ba736ede56d689e7be91cab5d9ca846bde3999eba6/isodate-0.7.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=28009937d8031054830160fce6d409ed342816b543597cece116d966c6d99e15",
          "hashes": {
            "sha256": "28009937d8031054830160fce6d409ed342816b543597cece116d966c6d99e15"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "isodate",
        "version": "0.7.2",
        "summary": "An ISO 8601 date/time/duration parser and formatter",
        "description": "\nISO 8601 date/time parser\n=========================\n\n.. image:: https://travis-ci.org/gweis/isodate.svg?branch=master\n    :target: https://travis-ci.org/gweis/isodate\n    :alt: Travis-CI\n.. image:: https://coveralls.io/repos/gweis/isodate/badge.svg?branch=master\n    :target: https://coveralls.io/r/gweis/isodate?branch=master\n    :alt: Coveralls\n.. image:: https://img.shields.io/pypi/v/isodate.svg\n    :target: https://pypi.python.org/pypi/isodate/\n    :alt: Latest Version\n.. image:: https://img.shields.io/pypi/l/isodate.svg\n    :target: https://pypi.python.org/pypi/isodate/\n    :alt: License\n\n\nThis module implements ISO 8601 date, time and duration parsing.\nThe implementation follows ISO8601:2004 standard, and implements only\ndate/time representations mentioned in the standard. If something is not\nmentioned there, then it is treated as non existent, and not as an allowed\noption.\n\nFor instance, ISO8601:2004 never mentions 2 digit years. So, it is not\nintended by this module to support 2 digit years. (while it may still\nbe valid as ISO date, because it is not explicitly forbidden.)\nAnother example is, when no time zone information is given for a time,\nthen it should be interpreted as local time, and not UTC.\n\nAs this module maps ISO 8601 dates/times to standard Python data types, like\n*date*, *time*, *datetime* and *timedelta*, it is not possible to convert\nall possible ISO 8601 dates/times. For instance, dates before 0001-01-01 are\nnot allowed by the Python *date* and *datetime* classes. Additionally\nfractional seconds are limited to microseconds. That means if the parser finds\nfor instance nanoseconds it will round it down to microseconds.\n\nDocumentation\n-------------\n\nThe following parsing methods are available.\n   * parse_time:\n        parses an ISO 8601 time string into a *time* object\n   * parse_date:\n        parses an ISO 8601 date string into a *date* object\n   * parse_datetime:\n        parses an ISO 8601 date-time string into a *datetime* object\n   * parse_duration:\n        parses an ISO 8601 duration string into a *timedelta* or *Duration*\n        object.\n   * parse_tzinfo:\n        parses the time zone info part of an ISO 8601 string into a\n        *tzinfo* object.\n\nAs ISO 8601 allows to define durations in years and months, and *timedelta*\ndoes not handle years and months, this module provides a *Duration* class,\nwhich can be used almost like a *timedelta* object (with some limitations).\nHowever, a *Duration* object can be converted into a *timedelta* object.\n\nThere are also ISO formatting methods for all supported data types. Each\n*xxx_isoformat* method accepts a format parameter. The default format is\nalways the ISO 8601 expanded format. This is the same format used by\n*datetime.isoformat*:\n\n    * time_isoformat:\n        Intended to create ISO time strings with default format\n        *hh:mm:ssZ*.\n    * date_isoformat:\n        Intended to create ISO date strings with default format\n        *yyyy-mm-dd*.\n    * datetime_isoformat:\n        Intended to create ISO date-time strings with default format\n        *yyyy-mm-ddThh:mm:ssZ*.\n    * duration_isoformat:\n        Intended to create ISO duration strings with default format\n        *PnnYnnMnnDTnnHnnMnnS*.\n    * tz_isoformat:\n        Intended to create ISO time zone strings with default format\n        *hh:mm*.\n    * strftime:\n        A re-implementation mostly compatible with Python's *strftime*, but\n        supports only those format strings, which can also be used for dates\n        prior 1900. This method also understands how to format *datetime* and\n        *Duration* instances.\n\nInstallation\n------------\n\nThis module can easily be installed with Python standard installation methods.\n\nUse *pip install isodate*.\n\nLimitations\n-----------\n\n   * The parser accepts several date/time representation which should be invalid\n     according to ISO 8601 standard.\n\n     1. for date and time together, this parser accepts a mixture of basic and extended format.\n        e.g. the date could be in basic format, while the time is accepted in extended format.\n        It also allows short dates and times in date-time strings.\n     2. For incomplete dates, the first day is chosen. e.g. 19th century results in a date of\n        1901-01-01.\n     3. negative *Duration* and *timedelta* value are not fully supported yet.\n\nFurther information\n-------------------\n\nThe doc strings and unit tests should provide rather detailed information about\nthe methods and their limitations.\n\nThe source release provides a *setup.py* script,\nwhich can be used to run the unit tests included.\n\nSource code is available at `<https://github.com/gweis/isodate>`_.\n\n\nCHANGES\n=======\n\n0.7.3 (unreleased)\n------------------\n\n- no changes yet\n\n\n0.7.2 (2024-10-08)\n------------------\n\n- drop end of life python versions\n- Don't match garbage characters at the end of parsed strings #16 (Gabriel de Perthuis)\n\n\nPotentially breaking changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Fractional seconds are cut off to microseconds (always round down)\n- Allow control over return type of parse_duration #64 (Felix Claessen)\n- Python >= 3.7 required\n\n\n0.6.1 (2021-12-13)\n------------------\n\n- support python 3.10 (Hugo van Kemenade)\n- last version to support py 2.7\n\n\n0.6.0 (2017-10-13)\n------------------\n\n- support incomplete month date (Fabien Loffredo)\n- rely on duck typing when doing duration maths\n- support ':' as separator in fractional time zones (usrenmae)\n\n\n0.5.4 (2015-08-06)\n------------------\n\n- Fix parsing of Periods (Fabien Bochu)\n- Make Duration objects hashable (Geoffrey Fairchild)\n- Add multiplication to duration (Reinoud Elhorst)\n\n\n0.5.1 (2014-11-07)\n------------------\n\n- fixed pickling of Duration objects\n- raise ISO8601Error when there is no 'T' separator in datetime strings (Adrian Coveney)\n\n\n0.5.0 (2014-02-23)\n------------------\n\n- ISO8601Error are subclasses of ValueError now (Michael Hrivnak)\n- improve compatibility across various python variants and versions\n- raise exceptions when using fractional years and months in date\n  maths with durations\n- renamed method todatetime on Duraction objects to totimedelta\n\n\n0.4.9 (2012-10-30)\n------------------\n\n- support pickling FixedOffset instances\n- make sure parsed fractional seconds are in microseconds\n- add leading zeros when formattig microseconds (Jarom Loveridge)\n\n\n0.4.8 (2012-05-04)\n------------------\n\n- fixed incompatibility of unittests with python 2.5 and 2.6 (runs fine on 2.7\n  and 3.2)\n\n\n0.4.7 (2012-01-26)\n------------------\n\n- fixed tzinfo formatting (never pass None into tzinfo.utcoffset())\n\n\n0.4.6 (2012-01-06)\n------------------\n\n- added Python 3 compatibility via 2to3\n\n0.4.5 (2012-01-06)\n------------------\n\n- made setuptools dependency optional\n\n0.4.4 (2011-04-16)\n------------------\n\n- Fixed formatting of microseconds for datetime objects\n\n0.4.3 (2010-10-29)\n------------------\n\n- Fixed problem with %P formatting and fractions (supplied by David Brooks)\n\n0.4.2 (2010-10-28)\n------------------\n\n- Implemented unary - for Duration (supplied by David Brooks)\n- Output fractional seconds with '%P' format. (partly supplied by David Brooks)\n\n0.4.1 (2010-10-13)\n------------------\n\n- fixed bug in comparison between timedelta and Duration.\n- fixed precision problem with microseconds (reported by Tommi Virtanen)\n\n0.4.0 (2009-02-09)\n------------------\n\n- added method to parse ISO 8601 time zone strings\n- added methods to create ISO 8601 conforming strings\n\n0.3.0 (2009-1-05)\n------------------\n\n- Initial release\n\n\nTODOs\n=====\n\nThis to do list contains some thoughts and ideas about missing features, and\nparts to think about, whether to implement them or not. This list is probably\nnot complete.\n\nMissing features:\n-----------------\n\n    * time formatting does not allow to create fractional representations.\n    * parser for ISO intervals.\n    * currently microseconds are always padded to a length of 6 characters.\n      trailing 0s should be optional\n\nDocumentation:\n--------------\n\n    * parse_datetime:\n       - complete documentation to show what this function allows, but ISO forbids.\n         and vice verse.\n       - support other separators between date and time than 'T'\n\n    * parse_date:\n       - yeardigits should be always greater than 4\n       - dates before 0001-01-01 are not supported\n\n    * parse_duration:\n       - alternative formats are not fully supported due to parse_date restrictions\n       - standard duration format is fully supported but not very restrictive.\n\n    * Duration:\n       - support fractional years and month in calculations\n       - implement w3c order relation? (`<http://www.w3.org/TR/xmlschema-2/#duration-order>`_)\n       - refactor to have duration mathematics only at one place.\n       - localize __str__ method (does timedelta do this?)\n       - when is a Duration negative?\n       - normalize Durations. months [00-12] and years ]-inf,+inf[\n",
        "description_content_type": "text/x-rst",
        "author": "Gerhard Weis",
        "license": "Copyright (c) 2021, Hugo van Kemenade and contributors\nCopyright (c) 2009-2018, Gerhard Weis and contributors\nCopyright (c) 2009, Gerhard Weis\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the <organization> nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Homepage, https://github.com/gweis/isodate/"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/41/45/1a4ed80516f02155c51f51e8cedb3c1902296743db0bbc66608a0db2814f/jsonschema_specifications-2025.9.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=98802fee3a11ee76ecaca44429fda8a41bff98b00a0f2838151b113f210cc6fe",
          "hashes": {
            "sha256": "98802fee3a11ee76ecaca44429fda8a41bff98b00a0f2838151b113f210cc6fe"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "jsonschema-specifications",
        "version": "2025.9.1",
        "summary": "The JSON Schema meta-schemas and vocabularies, exposed as a Registry",
        "description": "=============================\n``jsonschema-specifications``\n=============================\n\n|PyPI| |Pythons| |CI| |ReadTheDocs|\n\nJSON support files from the `JSON Schema Specifications <https://json-schema.org/specification.html>`_ (metaschemas, vocabularies, etc.), packaged for runtime access from Python as a `referencing-based Schema Registry <https://referencing.readthedocs.io/en/stable/api/#referencing.Registry>`_.\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema-specifications.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema-specifications.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema-specifications/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema-specifications/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/jsonschema-specifications/badge/?version=stable&style=flat\n  :alt: ReadTheDocs status\n  :target: https://jsonschema-specifications.readthedocs.io/en/stable/\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author_email": "Julian Berman <Julian+jsonschema-specifications@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "referencing>=0.31.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://jsonschema-specifications.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/jsonschema-specifications",
          "Issues, https://github.com/python-jsonschema/jsonschema-specifications/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema-specifications?utm_source=pypi-jsonschema-specifications&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/python-jsonschema/jsonschema-specifications"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/05/73/c4abe620b841b6b791f2edc248f556900667a5a1cf023a6646967ae98335/markupsafe-3.0.3-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=9a1abfdc021a164803f4d485104931fb8f8c1efd55bc6b748d2f5774e78b62c5",
          "hashes": {
            "sha256": "9a1abfdc021a164803f4d485104931fb8f8c1efd55bc6b748d2f5774e78b62c5"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "MarkupSafe",
        "version": "3.0.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Safely add untrusted strings to HTML/XML markup.",
        "description": "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/pallets/markupsafe/refs/heads/stable/docs/_static/markupsafe-name.svg\" alt=\"\" height=\"150\"></div>\r\n\r\n# MarkupSafe\r\n\r\nMarkupSafe implements a text object that escapes characters so it is\r\nsafe to use in HTML and XML. Characters that have special meanings are\r\nreplaced so that they display as the actual characters. This mitigates\r\ninjection attacks, meaning untrusted user input can safely be displayed\r\non a page.\r\n\r\n\r\n## Examples\r\n\r\n```pycon\r\n>>> from markupsafe import Markup, escape\r\n\r\n>>> # escape replaces special characters and wraps in Markup\r\n>>> escape(\"<script>alert(document.cookie);</script>\")\r\nMarkup('&lt;script&gt;alert(document.cookie);&lt;/script&gt;')\r\n\r\n>>> # wrap in Markup to mark text \"safe\" and prevent escaping\r\n>>> Markup(\"<strong>Hello</strong>\")\r\nMarkup('<strong>hello</strong>')\r\n\r\n>>> escape(Markup(\"<strong>Hello</strong>\"))\r\nMarkup('<strong>hello</strong>')\r\n\r\n>>> # Markup is a str subclass\r\n>>> # methods and operators escape their arguments\r\n>>> template = Markup(\"Hello <em>{name}</em>\")\r\n>>> template.format(name='\"World\"')\r\nMarkup('Hello <em>&#34;World&#34;</em>')\r\n```\r\n\r\n## Donate\r\n\r\nThe Pallets organization develops and supports MarkupSafe and other\r\npopular packages. In order to grow the community of contributors and\r\nusers, and allow the maintainers to devote more time to the projects,\r\n[please donate today][].\r\n\r\n[please donate today]: https://palletsprojects.com/donate\r\n\r\n## Contributing\r\n\r\nSee our [detailed contributing documentation][contrib] for many ways to\r\ncontribute, including reporting issues, requesting features, asking or answering\r\nquestions, and making PRs.\r\n\r\n[contrib]: https://palletsprojects.com/contributing/\r\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Donate, https://palletsprojects.com/donate",
          "Documentation, https://markupsafe.palletsprojects.com/",
          "Changes, https://markupsafe.palletsprojects.com/page/changes/",
          "Source, https://github.com/pallets/markupsafe/",
          "Chat, https://discord.gg/pallets"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c2/dc/18d48843499e278538890dc709e9ee3dea8375f8be8e82682851df1b48b5/msal-1.34.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=f669b1644e4950115da7a176441b0e13ec2975c29528d8b9e81316023676d6e1",
          "hashes": {
            "sha256": "f669b1644e4950115da7a176441b0e13ec2975c29528d8b9e81316023676d6e1"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "msal",
        "version": "1.34.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "The Microsoft Authentication Library (MSAL) for Python library enables your app to access the Microsoft Cloud by supporting authentication of users with Microsoft Azure Active Directory accounts (AAD) and Microsoft Accounts (MSA) using industry standard OAuth2 and OpenID Connect.",
        "description": "# Microsoft Authentication Library (MSAL) for Python\n\n| `dev` branch | Reference Docs | # of Downloads per different platforms | # of Downloads per recent MSAL versions | Benchmark Diagram |\n|:------------:|:--------------:|:--------------------------------------:|:---------------------------------------:|:-----------------:|\n [![Build status](https://github.com/AzureAD/microsoft-authentication-library-for-python/actions/workflows/python-package.yml/badge.svg?branch=dev)](https://github.com/AzureAD/microsoft-authentication-library-for-python/actions) | [![Documentation Status](https://readthedocs.org/projects/msal-python/badge/?version=latest)](https://msal-python.readthedocs.io/en/latest/?badge=latest) | [![Downloads](https://static.pepy.tech/badge/msal)](https://pypistats.org/packages/msal) | [![Download monthly](https://static.pepy.tech/badge/msal/month)](https://pepy.tech/project/msal) | [ðŸ“‰](https://azuread.github.io/microsoft-authentication-library-for-python/dev/bench/)\n\nThe Microsoft Authentication Library for Python enables applications to integrate with the [Microsoft identity platform](https://aka.ms/aaddevv2). It allows you to sign in users or apps with Microsoft identities ([Microsoft Entra ID](https://www.microsoft.com/security/business/identity-access/microsoft-entra-id), [External identities](https://www.microsoft.com/security/business/identity-access/microsoft-entra-external-id), [Microsoft Accounts](https://account.microsoft.com) and [Azure AD B2C](https://azure.microsoft.com/services/active-directory-b2c/) accounts) and obtain tokens to call Microsoft APIs such as [Microsoft Graph](https://graph.microsoft.io/) or your own APIs registered with the Microsoft identity platform. It is built using industry standard OAuth2 and OpenID Connect protocols\n\nNot sure whether this is the SDK you are looking for your app? There are other Microsoft Identity SDKs\n[here](https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki/Microsoft-Authentication-Client-Libraries).\n\nQuick links:\n\n| [Getting Started](https://learn.microsoft.com/azure/active-directory/develop/web-app-quickstart?pivots=devlang-python)| [Docs](https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki) | [Samples](https://aka.ms/aaddevsamplesv2) | [Support](README.md#community-help-and-support) | [Feedback](https://forms.office.com/r/TMjZkDbzjY) |\n| --- | --- | --- | --- | --- |\n\n## Scenarios supported\n\nClick on the following thumbnail to visit a large map with clickable links to proper samples.\n\n[![Map effect won't work inside github's markdown file, so we have to use a thumbnail here to lure audience to a real static website](https://raw.githubusercontent.com/AzureAD/microsoft-authentication-library-for-python/dev/docs/thumbnail.png)](https://msal-python.readthedocs.io/en/latest/)\n\n## Installation\n\nYou can find MSAL Python on [Pypi](https://pypi.org/project/msal/).\n\n1. If you haven't already, [install and/or upgrade the pip](https://pip.pypa.io/en/stable/installing/)\n   of your Python environment to a recent version. We tested with pip 18.1.\n1. As usual, just run `pip install msal`.\n\n## Versions\n\nThis library follows [Semantic Versioning](http://semver.org/).\n\nYou can find the changes for each version under\n[Releases](https://github.com/AzureAD/microsoft-authentication-library-for-python/releases).\n\n## Usage\n\nBefore using MSAL Python (or any MSAL SDKs, for that matter), you will have to\n[register your application with the Microsoft identity platform](https://docs.microsoft.com/azure/active-directory/develop/quickstart-v2-register-an-app).\n\nAcquiring tokens with MSAL Python follows this 3-step pattern.\n(Note: That is the high level conceptual pattern.\nThere will be some variations for different flows. They are demonstrated in\n[runnable samples hosted right in this repo](https://github.com/AzureAD/microsoft-authentication-library-for-python/tree/dev/sample).\n)\n\n\n1. MSAL proposes a clean separation between\n   [public client applications, and confidential client applications](https://tools.ietf.org/html/rfc6749#section-2.1).\n   So you will first create either a `PublicClientApplication` or a `ConfidentialClientApplication` instance,\n   and ideally reuse it during the lifecycle of your app. The following example shows a `PublicClientApplication`:\n\n   ```python\n   from msal import PublicClientApplication\n   app = PublicClientApplication(\n       \"your_client_id\",\n       authority=\"https://login.microsoftonline.com/Enter_the_Tenant_Name_Here\")\n   ```\n\n   Later, each time you would want an access token, you start by:\n   ```python\n   result = None  # It is just an initial value. Please follow instructions below.\n   ```\n\n2. The API model in MSAL provides you explicit control on how to utilize token cache.\n   This cache part is technically optional, but we highly recommend you to harness the power of MSAL cache.\n   It will automatically handle the token refresh for you.\n\n   ```python\n   # We now check the cache to see\n   # whether we already have some accounts that the end user already used to sign in before.\n   accounts = app.get_accounts()\n   if accounts:\n       # If so, you could then somehow display these accounts and let end user choose\n       print(\"Pick the account you want to use to proceed:\")\n       for a in accounts:\n           print(a[\"username\"])\n       # Assuming the end user chose this one\n       chosen = accounts[0]\n       # Now let's try to find a token in cache for this account\n       result = app.acquire_token_silent([\"your_scope\"], account=chosen)\n   ```\n\n3. Either there is no suitable token in the cache, or you chose to skip the previous step,\n   now it is time to actually send a request to AAD to obtain a token.\n   There are different methods based on your client type and scenario. Here we demonstrate a placeholder flow.\n\n   ```python\n   if not result:\n       # So no suitable token exists in cache. Let's get a new one from AAD.\n       result = app.acquire_token_by_one_of_the_actual_method(..., scopes=[\"User.Read\"])\n   if \"access_token\" in result:\n       print(result[\"access_token\"])  # Yay!\n   else:\n       print(result.get(\"error\"))\n       print(result.get(\"error_description\"))\n       print(result.get(\"correlation_id\"))  # You may need this when reporting a bug\n   ```\n\nRefer the [Wiki](https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki) pages for more details on the MSAL Python functionality and usage.\n\n## Migrating from ADAL\n\nIf your application is using ADAL Python, we recommend you to update to use MSAL Python. No new feature work will be done in ADAL Python.\n\nSee the [ADAL to MSAL migration](https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki/Migrate-to-MSAL-Python) guide.\n\n## Roadmap\n\nYou can follow the latest updates and plans for MSAL Python in the [Roadmap](https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki/Roadmap) published on our Wiki.\n\n## Samples and Documentation\n\nMSAL Python supports multiple [application types and authentication scenarios](https://docs.microsoft.com/azure/active-directory/develop/authentication-flows-app-scenarios).\nThe generic documents on\n[Auth Scenarios](https://docs.microsoft.com/azure/active-directory/develop/authentication-scenarios)\nand\n[Auth protocols](https://docs.microsoft.com/azure/active-directory/develop/active-directory-v2-protocols)\nare recommended reading.\n\nWe provide a [full suite of sample applications](https://aka.ms/aaddevsamplesv2) and [documentation](https://aka.ms/aaddevv2) to help you get started with learning the Microsoft identity platform.\n\n## Community Help and Support\n\nWe leverage Stack Overflow to work with the community on supporting Microsoft Entra and its SDKs, including this one!\nWe highly recommend you ask your questions on Stack Overflow (we're all on there!)\nAlso browser existing issues to see if someone has had your question before.\n\nWe recommend you use the \"msal\" tag so we can see it!\nHere is the latest Q&A on Stack Overflow for MSAL:\n[http://stackoverflow.com/questions/tagged/msal](http://stackoverflow.com/questions/tagged/msal)\n\n## Submit Feedback\n\nWe'd like your thoughts on this library. Please complete [this short survey.](https://forms.office.com/r/TMjZkDbzjY)\n\n## Security Reporting\n\nIf you find a security issue with our libraries or services please report it to [secure@microsoft.com](mailto:secure@microsoft.com) with as much detail as possible. Your submission may be eligible for a bounty through the [Microsoft Bounty](http://aka.ms/bugbounty) program. Please do not post security issues to GitHub Issues or any other public site. We will contact you shortly upon receiving the information. We encourage you to get notifications of when security incidents occur by visiting [this page](https://technet.microsoft.com/security/dd252948) and subscribing to Security Advisory Alerts.\n\n## Contributing\n\nAll code is licensed under the MIT license and we triage actively on GitHub. We enthusiastically welcome contributions and feedback. Please read the [contributing guide](./contributing.md) before starting.\n\n## We Value and Adhere to the Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/AzureAD/microsoft-authentication-library-for-python",
        "author": "Microsoft Corporation",
        "author_email": "nugetaad@microsoft.com",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "requests<3,>=2.0.0",
          "PyJWT[crypto]<3,>=1.0.0",
          "cryptography<49,>=2.5",
          "pymsalruntime<0.19,>=0.14; (python_version >= \"3.6\" and platform_system == \"Windows\") and extra == \"broker\"",
          "pymsalruntime<0.19,>=0.17; (python_version >= \"3.8\" and platform_system == \"Darwin\") and extra == \"broker\"",
          "pymsalruntime<0.19,>=0.18; (python_version >= \"3.8\" and platform_system == \"Linux\") and extra == \"broker\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/AzureAD/microsoft-authentication-library-for-python/releases",
          "Documentation, https://msal-python.readthedocs.io/",
          "Questions, https://stackoverflow.com/questions/tagged/azure-ad-msal+python",
          "Feature/Bug Tracker, https://github.com/AzureAD/microsoft-authentication-library-for-python/issues"
        ],
        "provides_extra": [
          "broker"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/6f/01/c26ce75ba460d5cd503da9e13b21a33804d38c2165dec7b716d06b13010c/pyjwt-2.11.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=94a6bde30eb5c8e04fee991062b534071fd1439ef58d2adc9ccb823e7bcd0469",
          "hashes": {
            "sha256": "94a6bde30eb5c8e04fee991062b534071fd1439ef58d2adc9ccb823e7bcd0469"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "PyJWT",
        "version": "2.11.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "JSON Web Token implementation in Python",
        "description": "PyJWT\n=====\n\n.. image:: https://github.com/jpadilla/pyjwt/workflows/CI/badge.svg\n   :target: https://github.com/jpadilla/pyjwt/actions?query=workflow%3ACI\n\n.. image:: https://img.shields.io/pypi/v/pyjwt.svg\n   :target: https://pypi.python.org/pypi/pyjwt\n\n.. image:: https://codecov.io/gh/jpadilla/pyjwt/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/jpadilla/pyjwt\n\n.. image:: https://readthedocs.org/projects/pyjwt/badge/?version=stable\n   :target: https://pyjwt.readthedocs.io/en/stable/\n\nA Python implementation of `RFC 7519 <https://tools.ietf.org/html/rfc7519>`_. Original implementation was written by `@progrium <https://github.com/progrium>`_.\n\nSponsor\n-------\n\n.. |auth0-logo| image:: https://github.com/user-attachments/assets/ee98379e-ee76-4bcb-943a-e25c4ea6d174\n   :width: 160px\n\n+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| |auth0-logo| | If you want to quickly add secure token-based authentication to Python projects, feel free to check Auth0's Python SDK and free plan at `auth0.com/signup <https://auth0.com/signup?utm_source=external_sites&utm_medium=pyjwt&utm_campaign=devn_signup>`_. |\n+--------------+-----------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\nInstalling\n----------\n\nInstall with **pip**:\n\n.. code-block:: console\n\n    $ pip install PyJWT\n\n\nUsage\n-----\n\n.. code-block:: pycon\n\n    >>> import jwt\n    >>> encoded = jwt.encode({\"some\": \"payload\"}, \"secret\", algorithm=\"HS256\")\n    >>> print(encoded)\n    eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb21lIjoicGF5bG9hZCJ9.4twFt5NiznN84AWoo1d7KO1T_yoc0Z6XOpOVswacPZg\n    >>> jwt.decode(encoded, \"secret\", algorithms=[\"HS256\"])\n    {'some': 'payload'}\n\nDocumentation\n-------------\n\nView the full docs online at https://pyjwt.readthedocs.io/en/stable/\n\n\nTests\n-----\n\nYou can run tests from the project root after cloning with:\n\n.. code-block:: console\n\n    $ tox\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "json",
          "jwt",
          "security",
          "signing",
          "token",
          "web"
        ],
        "author_email": "Jose Padilla <hello@jpadilla.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "cryptography>=3.4.0; extra == \"crypto\"",
          "coverage[toml]==7.10.7; extra == \"dev\"",
          "cryptography>=3.4.0; extra == \"dev\"",
          "pre-commit; extra == \"dev\"",
          "pytest<9.0.0,>=8.4.2; extra == \"dev\"",
          "sphinx; extra == \"dev\"",
          "sphinx-rtd-theme; extra == \"dev\"",
          "zope.interface; extra == \"dev\"",
          "sphinx; extra == \"docs\"",
          "sphinx-rtd-theme; extra == \"docs\"",
          "zope.interface; extra == \"docs\"",
          "coverage[toml]==7.10.7; extra == \"tests\"",
          "pytest<9.0.0,>=8.4.2; extra == \"tests\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/jpadilla/pyjwt"
        ],
        "provides_extra": [
          "crypto",
          "dev",
          "docs",
          "tests"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/5e/75/bd9b7bb966668920f06b200e84454c8f3566b102183bc55c5473d96cb2b9/msal_extensions-1.3.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=96d3de4d034504e969ac5e85bae8106c8373b5c6568e4c8fa7af2eca9dbe6bca",
          "hashes": {
            "sha256": "96d3de4d034504e969ac5e85bae8106c8373b5c6568e4c8fa7af2eca9dbe6bca"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.2",
        "name": "msal-extensions",
        "version": "1.3.1",
        "dynamic": [
          "description",
          "description-content-type",
          "provides-extra",
          "requires-dist",
          "requires-python"
        ],
        "summary": "Microsoft Authentication Library extensions (MSAL EX) provides a persistence API that can save your data on disk, encrypted on Windows, macOS and Linux. Concurrent data access will be coordinated by a file lock mechanism.",
        "description": "\n# Microsoft Authentication Extensions for Python\n\nThe Microsoft Authentication Extensions for Python offers secure mechanisms for client applications to perform cross-platform token cache serialization and persistence. It gives additional support to the [Microsoft Authentication Library for Python (MSAL)](https://github.com/AzureAD/microsoft-authentication-library-for-python).\n\nMSAL Python supports an in-memory cache by default and provides the [SerializableTokenCache](https://msal-python.readthedocs.io/en/latest/#msal.SerializableTokenCache) to perform cache serialization. You can read more about this in the MSAL Python [documentation](https://docs.microsoft.com/en-us/azure/active-directory/develop/msal-python-token-cache-serialization). Developers are required to implement their own cache persistence across multiple platforms and Microsoft Authentication Extensions makes this simpler.\n\nThe supported platforms are Windows, Mac and Linux.\n- Windows - [DPAPI](https://docs.microsoft.com/en-us/dotnet/standard/security/how-to-use-data-protection) is used for encryption.\n- MAC - The MAC KeyChain is used.\n- Linux - [LibSecret](https://wiki.gnome.org/Projects/Libsecret) is used for encryption.\n\n> Note: It is recommended to use this library for cache persistance support for Public client applications such as Desktop apps only. In web applications, this may lead to scale and performance issues. Web applications are recommended to persist the cache in session. Take a look at this [webapp sample](https://github.com/Azure-Samples/ms-identity-python-webapp).\n\n## Installation\n\nYou can find Microsoft Authentication Extensions for Python on [Pypi](https://pypi.org/project/msal-extensions/).\n1. If you haven't already, [install and/or upgrade the pip](https://pip.pypa.io/en/stable/installing/)\n   of your Python environment to a recent version. We tested with pip 18.1.\n2. Run `pip install msal-extensions`.\n\n## Versions\n\nThis library follows [Semantic Versioning](http://semver.org/).\n\nYou can find the changes for each version under\n[Releases](https://github.com/AzureAD/microsoft-authentication-extensions-for-python/releases).\n\n## Usage\n\n### Creating an encrypted token cache file to be used by MSAL\n\nThe Microsoft Authentication Extensions library provides the `PersistedTokenCache` which accepts a platform-dependent persistence instance. This token cache can then be used to instantiate the `PublicClientApplication` in MSAL Python.\n\nThe token cache includes a file lock, and auto-reload behavior under the hood.\n\n\n\nHere is an example of this pattern for multiple platforms (taken from the complete [sample here](https://github.com/AzureAD/microsoft-authentication-extensions-for-python/blob/dev/sample/token_cache_sample.py)):\n\n```python\ndef build_persistence(location, fallback_to_plaintext=False):\n    \"\"\"Build a suitable persistence instance based your current OS\"\"\"\n    try:\n        return build_encrypted_persistence(location)\n    except:\n        if not fallback_to_plaintext:\n            raise\n        logging.warning(\"Encryption unavailable. Opting in to plain text.\")\n        return FilePersistence(location)\n\npersistence = build_persistence(\"token_cache.bin\")\nprint(\"Type of persistence: {}\".format(persistence.__class__.__name__))\nprint(\"Is this persistence encrypted?\", persistence.is_encrypted)\n\ncache = PersistedTokenCache(persistence)\n```\nNow you can use it in an MSAL application like this:\n```python\napp = msal.PublicClientApplication(\"my_client_id\", token_cache=cache)\n```\n\n### Creating an encrypted persistence file to store your own data\n\nHere is an example of this pattern for multiple platforms (taken from the complete [sample here](https://github.com/AzureAD/microsoft-authentication-extensions-for-python/blob/dev/sample/persistence_sample.py)):\n\n```python\ndef build_persistence(location, fallback_to_plaintext=False):\n    \"\"\"Build a suitable persistence instance based your current OS\"\"\"\n    try:\n        return build_encrypted_persistence(location)\n    except:  # pylint: disable=bare-except\n        if not fallback_to_plaintext:\n            raise\n        logging.warning(\"Encryption unavailable. Opting in to plain text.\")\n        return FilePersistence(location)\n\npersistence = build_persistence(\"storage.bin\", fallback_to_plaintext=False)\nprint(\"Type of persistence: {}\".format(persistence.__class__.__name__))\nprint(\"Is this persistence encrypted?\", persistence.is_encrypted)\n\ndata = {  # It can be anything, here we demonstrate an arbitrary json object\n    \"foo\": \"hello world\",\n    \"bar\": \"\",\n    \"service_principle_1\": \"blah blah...\",\n    }\n\npersistence.save(json.dumps(data))\nassert json.loads(persistence.load()) == data\n```\n\n## Python version support policy\n\nPython versions which are 6 months older than their\n[end-of-life cycle defined by Python Software Foundation (PSF)](https://devguide.python.org/versions/#versions)\nwill not receive new feature updates from this library.\n\n\n## Community Help and Support\n\nWe leverage Stack Overflow to work with the community on supporting Azure Active Directory and its SDKs, including this one!\nWe highly recommend you ask your questions on Stack Overflow (we're all on there!).\nAlso browse existing issues to see if someone has had your question before.\n\nWe recommend you use the \"msal\" tag so we can see it!\nHere is the latest Q&A on Stack Overflow for MSAL:\n[http://stackoverflow.com/questions/tagged/msal](http://stackoverflow.com/questions/tagged/msal)\n\n\n## Contributing\n\nAll code is licensed under the MIT license and we triage actively on GitHub.\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\n\n## We value and adhere to the Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
        "description_content_type": "text/markdown",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "msal<2,>=1.29",
          "portalocker<4,>=1.4; extra == \"portalocker\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://github.com/AzureAD/microsoft-authentication-extensions-for-python/releases"
        ],
        "provides_extra": [
          "portalocker"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/15/cf/f2966a2638144491f8696c27320d5219f48a072715075d168b31d3237720/msrest-0.7.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=21120a810e1233e5e6cc7fe40b474eeb4ec6f757a15d7cf86702c369f9567c32",
          "hashes": {
            "sha256": "21120a810e1233e5e6cc7fe40b474eeb4ec6f757a15d7cf86702c369f9567c32"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "msrest",
        "version": "0.7.1",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "AutoRest swagger generator Python client runtime.",
        "description": "AutoRest: Python Client Runtime\n===============================\n\n.. image:: https://travis-ci.org/Azure/msrest-for-python.svg?branch=master\n :target: https://travis-ci.org/Azure/msrest-for-python\n\n.. image:: https://codecov.io/gh/azure/msrest-for-python/branch/master/graph/badge.svg\n :target: https://codecov.io/gh/azure/msrest-for-python\n\nInstallation\n------------\n\nTo install:\n\n.. code-block:: bash\n\n    $ pip install msrest\n\n\nRelease History\n---------------\n\n2022-06-10 Version 0.7.1\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Declare correctly msrest as Python 3.6 and more only for clarity  #251\n\n\n2022-06-07 Version 0.7.0\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add `azure-core` as installation requirement #247\n- Replace `SerializationError` and `DeserializationError` in `msrest.exceptions` with those in `azure.core` #247\n\n**Bugfixes**\n\n- Typing annotation in LROPoller (thanks to akx)  #242\n\nThanks to kianmeng for typo fixes in the documentation.\n\n2021-01-26 Version 0.6.21\n+++++++++++++++++++++++++\n\n**Bug Fixes**\n\n- Fixes `failsafe_deserialize` introduced in `0.6.20` #232\n\n2021-01-25 Version 0.6.20\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add `failsafe_deserialize` method to the `Deserializer` object. #232\n- Serialize `datetime`, `date`, `time`, `timedelta` and `Decimal` correctly when serializing `object` . #224\n\n2020-09-08 Version 0.6.19\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix serialization of random Model object  #220\n- Fix serialization of unicode string in Py2 and object mode #221\n\n\n2020-07-27 Version 0.6.18\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add support for attributes/text in the same XML node  #218\n\n\n2020-06-25 Version 0.6.17\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix XML and discriminator  #214\n\n\n2020-06-09 Version 0.6.16\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix XML parsing with namespaces and attributes  #209\n\n**Features**\n\n- Add py.typed for mypy support\n\n\n2020-06-04 Version 0.6.15\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix RFC regression introduced in 0.6.14 (RFC parse date are no longer pickable)  #208\n- Fix XML parsing with namespaces  #206\n\nThanks to ivanst0 for the contribution\n\n\n2020-05-18 Version 0.6.14\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix \"from_dict\" in some complex flattening scenario  #204\n- Fix RFC date parsing if machine locale is not English  #201\n\n\n2020-04-07 Version 0.6.13\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix deserializer and flattening if intermediate node is None  #198\n- Fix validation exception message for minimum/maximum checks  #199\n\n\n2020-04-06 Version 0.6.12\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add \"time\" serializer/deserializer  #196\n\n2020-01-30 Version 0.6.11\n+++++++++++++++++++++++++\n\n**Features**\n\n- XML mode can now be enabled even if the given Model has no XML metadata  #184\n- Add Kerberos Authentication  #186\n- Improve error message if expected type is dictionary and something else is provided  #188\n\n**Bugfixes**\n\n- Fix comma separated serialization of array in query  #186\n- Fix validation of basic types in some complex scenario  #189\n\nThanks to catatonicprime for the contribution\n\n2019-09-04 Version 0.6.10\n+++++++++++++++++++++++++\n\n**Features**\n\n- XML mode now supports OpenAPI additional properties  # 174\n\n**Bugfixes**\n\n- Accept \"is_xml\" kwargs to force XML serialization  #178\n- Disable XML deserialization if received element is not an ElementTree  #178\n- A \"null\" enum deserialize as None, and not \"None\" anymore  #173\n- Fix some UTF8 encoding issue in Python 2.7 and XML mode  #172\n\n\n2019-07-24 Version 0.6.9\n++++++++++++++++++++++++\n\n**Features**\n\n- Accept extensions of JSON mimetype as valid JSON  #167\n\n2019-06-24 Version 0.6.8\n++++++++++++++++++++++++\n\n**BugFixes**\n\n- Impossible to serialize XML if model contains UTF8 characters on Python 2.7  #165\n- Impossible to deserialize a HTTP response as XML if body contains UTF8 characters on Python 2.7  #165\n- Loading a serialized configuration fails with NameError on NoOptionError  #162\n\nThanks to cclauss for the contribution\n\n2019-06-12 Version 0.6.7\n++++++++++++++++++++++++\n\n**Features**\n\n- Add DomainCredentials credentials for EventGrid\n\nThanks to kalyanaj for the contribution\n\n2019-03-21 Version 0.6.6\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Make 0.6.x series compatible with pyinstaller again\n- sdist now includes tests\n\nThanks to dotlambda for the contribution\n\n2019-03-11 Version 0.6.5\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix list of integers serialization if div is provided #151\n- Fix parsing of UTF8 with BOM #145\n\nThanks to eduardomourar for the contribution\n\n2019-01-09 Version 0.6.4\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix regression on credentials configuration if used outside of Autorest scope #135\n\n2019-01-08 Version 0.6.3\n++++++++++++++++++++++++\n\n**Features**\n\n- Updated **experimental** async support. Requires Autorest.Python 4.0.64.\n\n2018-11-19 Version 0.6.2\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix circular dependency in TYPE_CHECKING mode #128\n\n2018-10-15 Version 0.6.1\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Remove unnecessary verbose \"warnings\" log #126\n\n2018-10-02 Version 0.6.0\n++++++++++++++++++++++++\n\n**Features**\n\n- The environment variable AZURE_HTTP_USER_AGENT, if present, is now injected part of the UserAgent\n- New **preview** msrest.universal_http module. Provide tools to generic HTTP management (sync/async, requests/aiohttp, etc.)\n- New **preview** msrest.pipeline implementation:\n\n  - A Pipeline is an ordered list of Policies than can process an HTTP request and response in a generic way.\n  - More details in the wiki page about Pipeline: https://github.com/Azure/msrest-for-python/wiki/msrest-0.6.0---Pipeline\n\n- Adding new attributes to Configuration instance:\n\n  - http_logger_policy - Policy to handle HTTP logging\n  - user_agent_policy - Policy to handle UserAgent\n  - pipeline - The current pipeline used by the SDK client\n  - async_pipeline - The current async pipeline used by the async SDK client\n\n- Installing \"msrest[async]\" now installs the **experimental** async support. Works ONLY for Autorest.Python 4.0.63.\n\n**Breaking changes**\n\n- The HTTPDriver API introduced in 0.5.0 has been replaced by the Pipeline implementation.\n\n- The following classes have been moved from \"msrest.pipeline\" to \"msrest.universal_http\":\n\n  - ClientRedirectPolicy\n  - ClientProxies\n  - ClientConnection\n\n- The following classes have been moved from \"msrest.pipeline\" to \"msrest.universal_http.requests\":\n\n  - ClientRetryPolicy\n\n**Bugfixes**\n\n- Fix \"long\" on Python 2 if used with the \"object\" type  #121\n\nThanks to robgolding for the contribution\n\n2018-09-04 Version 0.5.5\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix a serialization issue if additional_properties is declared, and \"automatic model\" syntax is used\n  (\"automatic model\" being the ability to pass a dict to command and have the model auto-created)  # 120\n\n2018-07-12 Version 0.5.4\n++++++++++++++++++++++++\n\n**Features**\n\n- Support additionalProperties and XML\n\n**BugFixes**\n\n- Better parse empty node and not string types\n- Improve \"object\" XML parsing\n\n2018-07-10 Version 0.5.3\n++++++++++++++++++++++++\n\n**BugFixes**\n\n- Fix some XML serialization subtle scenarios\n\n2018-07-09 Version 0.5.2\n++++++++++++++++++++++++\n\n**Features**\n\n- deserialize/from_dict now accepts a content-type parameter to parse XML strings\n\n**Bugfixes**\n\n- Fix some complex XML Swagger definitions.\n\nThis release likely breaks already generated XML SDKs, that needs to be regenerated with autorest.python 3.0.58\n\n2018-06-21 Version 0.5.1\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Lower Accept header overwrite logging message #110\n- Fix 'object' type and XML format\n\nThanks to dharmab for the contribution\n\n2018-06-12 Version 0.5.0\n++++++++++++++++++++++++\n\n**Disclaimer**\n\nThis released is designed to be backward compatible with 0.4.x, but there is too many internal refactoring\nand new features to continue with 0.4.x versioning\n\n**Features**\n\n- Add XML support\n- Add many type hints, and MyPY testing on CI.\n- HTTP calls are made through a HTTPDriver API. Only implementation is `requests` for now. This driver API is *not* considered stable\n  and you should pin your msrest version if you want to provide a personal implementation.\n\n**Bugfixes**\n\n- Incorrect milliseconds serialization for some datetime object #94\n\n**Deprecation**\n\nThat will trigger a DeprecationWarning if an old Autorest generated code is used.\n\n- _client.add_header is deprecated, and config.headers should be used instead\n- _client.send_formdata is deprecated, and _client.put/get/delete/post + _client.send should be used instead\n\n2018-04-30 Version 0.4.29\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Improve `SDKClient.__exit__` to take exc_details as optional parameters and not required #93\n- refresh_session should also use the permanent HTTP session if available #91\n\n2018-04-18 Version 0.4.28\n+++++++++++++++++++++++++\n\n**Features**\n\n- msrest is now able to keep the \"requests.Session\" alive for performance. To activate this behavior:\n\n  - Use the final Client as a context manager (requires generation with Autorest.Python 3.0.50 at least)\n  - Use `client.config.keep_alive = True` and `client.close()` (requires generation with Autorest.Python 3.0.50 at least)\n  - Use `client.config.keep_alive = True` and client._client.close() (not recommended, but available in old releases of SDK)\n\n- All Authentication classes now define `signed_session` and `refresh_session` with an optional `session` parameter.\n  To take benefits of the session improvement, a subclass of Authentication *MUST* add this optional parameter\n  and use it if it's not `None`:\n\n     def signed_session(self, session=None):\n         session = session or requests.Session()\n\n         # As usual from here.\n\n2018-03-07 Version 0.4.27\n+++++++++++++++++++++++++\n\n**Features**\n\n- Disable HTTP log by default (security), add `enable_http_log` to restore it #86\n\n**BugFixes**\n\n- Fix incorrect date parsing if ms precision is over 6 digits #82\n\n2018-01-30 Version 0.4.26\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add TopicCredentials for EventGrid client\n\n**Bugfixes**\n\n- Fix minimal dependency of isodate\n- Fix serialisation from dict if datetime provided\n\n2018-01-08 Version 0.4.25\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add LROPoller class. This is a customizable LRO engine.\n  This is the poller engine of Autorest.Python 3.0, and is not used by code generated by previous Autorest version.\n\n2018-01-03 Version 0.4.24\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Date parsing is now compliant with Autorest / Swagger 2.0 specification (less lenient)\n\n**Internal optimisation**\n\n- Call that does not return a streamable object are now executed in requests stream mode False (was True whatever the type of the call).\n  This should reduce the number of leaked opened session and allow urllib3 to manage connection pooling more efficiently.\n  Only clients generated with Autorest.Python >= 2.1.31 (not impacted otherwise, fully backward compatible)\n\n2017-12-21 Version 0.4.23\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Accept to deserialize enum of different type if content string match #75\n- Stop failing on deserialization if enum string is unkwon. Return the string instead.\n\n**Features**\n\n- Model now accept kwargs in constructor for future kwargs models\n\n2017-12-15 Version 0.4.22\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Do not validate additional_properties #73\n- Improve validation error if expected type is dict, but actual type is not #73\n\n2017-12-14 Version 0.4.21\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix additional_properties if Swagger was flatten #72\n\n2017-12-13 Version 0.4.20\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add support for additional_properties\n\n  - By default, all additional_properties are kept.\n  - Additional properties are sent to the server only if it was specified in the Swagger,\n    or if \"enable_additional_properties_sending\" is called on the model we want it.\n    This is a class method that enables it for all instance of this model.\n\n2017-11-20 Version 0.4.19\n+++++++++++++++++++++++++\n\n**Features**\n\n- The interpretation of Swagger 2.0 \"discriminator\" is now lenient. This means for these two scenarios:\n\n  - Discriminator value is missing from the received payload\n  - Discriminator value is not defined in the Swagger\n\n  Instead of failing with an exception, this now returns the base type for this \"discriminator\".\n\n  Note that this is not a contradiction of the Swagger 2.0 spec, that specifies\n  \"validation SHOULD fail [...] there may exist valid reasons in particular circumstances to ignore a particular item,\n  but the full implications must be understood and carefully weighed before choosing a different course.\"\n\n  This cannot be configured for now and is the new default behvaior, but can be in the future if needed.\n\n**Bugfixes**\n\n- Optional formdata parameters were raising an exception (#65)\n- \"application/x-www-form-urlencoded\" form was sent using \"multipart/form-data\".\n  This causes problems if the server does not support \"multipart/form-data\" (#66)\n\n2017-10-26 Version 0.4.18\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add ApiKeyCredentials class. This can be used to support OpenAPI ApiKey feature.\n- Add CognitiveServicesAuthentication class. Pre-declared ApiKeyCredentials class for Cognitive Services.\n\n2017-10-12 Version 0.4.17\n+++++++++++++++++++++++++\n\n**Features**\n\nThis make Authentication classes more consistent:\n\n- OAuthTokenAuthentication is now a subclass of BasicTokenAuthentication (was Authentication)\n- BasicTokenAuthentication has now a \"set_token\" methods that does nothing.\n\nThis allows test like \"isintance(o, BasicTokenAuthentication)\" to be guaranteed that the following attributes exists:\n\n- token\n- set_token()\n- signed_session()\n\nThis means for users of \"msrestazure\", that they are guaranteed that all AD classes somehow inherits from \"BasicTokenAuthentication\"\n\n2017-10-05 Version 0.4.16\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix regression: accept \"set<str>\" as a valid \"[str]\" (#60)\n\n2017-09-28 Version 0.4.15\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Always log response body (#16)\n- Improved exception message if error JSON is Odata v4 (#55)\n- Refuse \"str\" as a valid \"[str]\" type (#41)\n- Better exception handling if input from server is not JSON valid\n\n**Features**\n\n- Add Configuration.session_configuration_callback to customize the requests.Session if necessary (#52)\n- Add a flag to Serializer to disable client-side-validation (#51)\n- Remove \"import requests\" from \"exceptions.py\" for apps that require fast loading time (#23)\n\nThank you to jayden-at-arista for the contribution\n\n2017-08-23 Version 0.4.14\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix regression introduced in msrest 0.4.12 - dict syntax with enum modeled as string and enum used\n\n2017-08-22 Version 0.4.13\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix regression introduced in msrest 0.4.12 - dict syntax using isodate.Duration (#42)\n\n2017-08-21 Version 0.4.12\n+++++++++++++++++++++++++\n\n**Features**\n\n- Input is now more lenient\n- Model have a \"validate\" method to check content constraints\n- Model have now 4 new methods:\n\n  - \"serialize\" that gives the RestAPI that will be sent\n  - \"as_dict\" that returns a dict version of the Model. Callbacks are available.\n  - \"deserialize\" the parses the RestAPI JSON into a Model\n  - \"from_dict\" that parses several dict syntax into a Model. Callbacks are available.\n\nMore details and examples in the Wiki article on Github:\nhttps://github.com/Azure/msrest-for-python/wiki/msrest-0.4.12---Serialization-change\n\n**Bugfixes**\n\n- Better Enum checking (#38)\n\n2017-06-21 Version 0.4.11\n+++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix incorrect dependency to \"requests\" 2.14.x, instead of 2.x meant in 0.4.8\n\n2017-06-15 Version 0.4.10\n+++++++++++++++++++++++++\n\n**Features**\n\n- Add requests hooks to configuration\n\n2017-06-08 Version 0.4.9\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Accept \"null\" value for paging array as an empty list and do not raise (#30)\n\n2017-05-22 Version 0.4.8\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix random \"pool is closed\" error (#29)\n- Fix requests dependency to version 2.x, since version 3.x is annunced to be breaking.\n\n2017-04-04 Version 0.4.7\n++++++++++++++++++++++++\n\n**BugFixes**\n\n- Refactor paging #22:\n\n   - \"next\" is renamed \"advance_page\" and \"next\" returns only 1 element (Python 2 expected behavior)\n   - paging objects are now real generator and support the \"next()\" built-in function without need for \"iter()\"\n\n- Raise accurate DeserialisationError on incorrect RestAPI discriminator usage #27\n- Fix discriminator usage of the base class name #27\n- Remove default mutable arguments in Clients #20\n- Fix object comparison in some scenarios #24\n\n2017-03-06 Version 0.4.6\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Allow Model sub-classes to be serialized if type is \"object\"\n\n2017-02-13 Version 0.4.5\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix polymorphic deserialization #11\n- Fix regexp validation if '\\\\w' is used in Python 2.7 #13\n- Fix dict deserialization if keys are unicode in Python 2.7\n\n**Improvements**\n\n- Add polymorphic serialisation from dict objects\n- Remove chardet and use HTTP charset declaration (fallback to utf8)\n\n2016-09-14 Version 0.4.4\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Remove paging URL validation, part of fix https://github.com/Azure/autorest/pull/1420\n\n**Disclaimer**\n\nIn order to get paging fixes for impacted clients, you need this package and Autorest > 0.17.0 Nightly 20160913\n\n2016-09-01 Version 0.4.3\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Better exception message (https://github.com/Azure/autorest/pull/1300)\n\n2016-08-15 Version 0.4.2\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix serialization if \"object\" type contains None (https://github.com/Azure/autorest/issues/1353)\n\n2016-08-08 Version 0.4.1\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fix compatibility issues with requests 2.11.0 (https://github.com/Azure/autorest/issues/1337)\n- Allow url of ClientRequest to have parameters (https://github.com/Azure/autorest/issues/1217)\n\n2016-05-25 Version 0.4.0\n++++++++++++++++++++++++\n\nThis version has no bug fixes, but implements new features of Autorest:\n- Base64 url type\n- unixtime type\n- x-ms-enum modelAsString flag\n\n**Behaviour changes**\n\n- Add Platform information in UserAgent\n- Needs Autorest > 0.17.0 Nightly 20160525\n\n2016-04-26 Version 0.3.0\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Read only values are no longer in __init__ or sent to the server (https://github.com/Azure/autorest/pull/959)\n- Useless kwarg removed\n\n**Behaviour changes**\n\n- Needs Autorest > 0.16.0 Nightly 20160426\n\n\n2016-03-25 Version 0.2.0\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Manage integer enum values (https://github.com/Azure/autorest/pull/879)\n- Add missing application/json Accept HTTP header (https://github.com/Azure/azure-sdk-for-python/issues/553)\n\n**Behaviour changes**\n\n- Needs Autorest > 0.16.0 Nightly 20160324\n\n\n2016-03-21 Version 0.1.3\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Deserialisation of generic resource if null in JSON (https://github.com/Azure/azure-sdk-for-python/issues/544)\n\n\n2016-03-14 Version 0.1.2\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- urllib3 side effect (https://github.com/Azure/autorest/issues/824)\n\n\n2016-03-04 Version 0.1.1\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Source package corrupted in Pypi (https://github.com/Azure/autorest/issues/799)\n\n2016-03-04 Version 0.1.0\n+++++++++++++++++++++++++\n\n**Behavioural Changes**\n\n- Removed custom logging set up and configuration. All loggers are now children of the root logger 'msrest' with no pre-defined configurations.\n- Replaced _required attribute in Model class with more extensive _validation dict.\n\n**Improvement**\n\n- Removed hierarchy scanning for attribute maps from base Model class - relies on generator to populate attribute\n  maps according to hierarchy.\n- Base class Paged now inherits from collections.Iterable.\n- Data validation during serialization using custom parameters (e.g. max, min etc).\n- Added ValidationError to be raised if invalid data encountered during serialization.\n\n2016-02-29 Version 0.0.3\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Source package corrupted in Pypi (https://github.com/Azure/autorest/issues/718)\n\n2016-02-19 Version 0.0.2\n++++++++++++++++++++++++\n\n**Bugfixes**\n\n- Fixed bug in exception logging before logger configured.\n\n2016-02-19 Version 0.0.1\n++++++++++++++++++++++++\n\n- Initial release.\n\n\n",
        "home_page": "https://github.com/Azure/msrest-for-python",
        "author": "Microsoft Corporation",
        "license": "MIT License",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "License :: OSI Approved :: MIT License",
          "Topic :: Software Development"
        ],
        "requires_dist": [
          "azure-core (>=1.24.0)",
          "certifi (>=2017.4.17)",
          "isodate (>=0.6.0)",
          "requests-oauthlib (>=0.5.0)",
          "requests (~=2.16)",
          "aiodns ; (python_version>='3.5') and extra == 'async'",
          "aiohttp (>=3.0) ; (python_version>='3.5') and extra == 'async'"
        ],
        "requires_python": ">=3.6",
        "provides_extra": [
          "async"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/60/90/81ac364ef94209c100e12579629dc92bf7a709a84af32f8c551b02c07e94/nltk-3.9.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=1e209d2b3009110635ed9709a67a1a3e33a10f799490fa71cf4bec218c11c88a",
          "hashes": {
            "sha256": "1e209d2b3009110635ed9709a67a1a3e33a10f799490fa71cf4bec218c11c88a"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "nltk",
        "version": "3.9.2",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Natural Language Toolkit",
        "description": "The Natural Language Toolkit (NLTK) is a Python package for\nnatural language processing.  NLTK requires Python 3.9, 3.10, 3.11, 3.12, or 3.13.\n",
        "keywords": [
          "NLP",
          "CL",
          "natural language processing",
          "computational linguistics",
          "parsing",
          "tagging",
          "tokenizing",
          "syntax",
          "linguistics",
          "language",
          "natural language",
          "text analytics"
        ],
        "home_page": "https://www.nltk.org/",
        "author": "NLTK Team",
        "author_email": "nltk.team@gmail.com",
        "maintainer": "NLTK Team",
        "maintainer_email": "nltk.team@gmail.com",
        "license": "Apache License, Version 2.0",
        "license_file": [
          "LICENSE.txt",
          "AUTHORS.md",
          "README.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Education",
          "Intended Audience :: Information Technology",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Scientific/Engineering",
          "Topic :: Scientific/Engineering :: Artificial Intelligence",
          "Topic :: Scientific/Engineering :: Human Machine Interfaces",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Text Processing",
          "Topic :: Text Processing :: Filters",
          "Topic :: Text Processing :: General",
          "Topic :: Text Processing :: Indexing",
          "Topic :: Text Processing :: Linguistic"
        ],
        "requires_dist": [
          "click",
          "joblib",
          "regex>=2021.8.3",
          "tqdm",
          "numpy; extra == \"machine-learning\"",
          "python-crfsuite; extra == \"machine-learning\"",
          "scikit-learn; extra == \"machine-learning\"",
          "scipy; extra == \"machine-learning\"",
          "matplotlib; extra == \"plot\"",
          "pyparsing; extra == \"tgrep\"",
          "twython; extra == \"twitter\"",
          "requests; extra == \"corenlp\"",
          "matplotlib; extra == \"all\"",
          "numpy; extra == \"all\"",
          "scipy; extra == \"all\"",
          "twython; extra == \"all\"",
          "requests; extra == \"all\"",
          "python-crfsuite; extra == \"all\"",
          "pyparsing; extra == \"all\"",
          "scikit-learn; extra == \"all\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://www.nltk.org/",
          "Source Code, https://github.com/nltk/nltk",
          "Issue Tracker, https://github.com/nltk/nltk/issues"
        ],
        "provides_extra": [
          "machine-learning",
          "plot",
          "tgrep",
          "twitter",
          "corenlp",
          "all"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/43/bc/6352f343522fcb2c04dbaf94cb30cca6fd32c1a750c06ad6231b4293708c/numpy-2.4.2-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=7df2de1e4fba69a51c06c28f5a3de36731eb9639feb8e1cf7e4a7b0daf4cf622",
          "hashes": {
            "sha256": "7df2de1e4fba69a51c06c28f5a3de36731eb9639feb8e1cf7e4a7b0daf4cf622"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "numpy",
        "version": "2.4.2",
        "summary": "Fundamental package for array computing in Python",
        "description": "<h1 align=\"center\">\n<img src=\"https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg\" width=\"300\">\n</h1><br>\n\n\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](\nhttps://numfocus.org)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads)](\nhttps://pypi.org/project/numpy/)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads)](\nhttps://anaconda.org/conda-forge/numpy)\n[![Stack Overflow](https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg)](\nhttps://stackoverflow.com/questions/tagged/numpy)\n[![Nature Paper](https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue)](\nhttps://doi.org/10.1038/s41586-020-2649-2)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=numpy)](https://insights.linuxfoundation.org/project/numpy)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy)\n[![Typing](https://img.shields.io/pypi/types/numpy)](https://pypi.org/project/numpy/)\n\n\nNumPy is the fundamental package for scientific computing with Python.\n\n- **Website:** https://numpy.org\n- **Documentation:** https://numpy.org/doc\n- **Mailing list:** https://mail.python.org/mailman/listinfo/numpy-discussion\n- **Source code:** https://github.com/numpy/numpy\n- **Contributing:** https://numpy.org/devdocs/dev/index.html\n- **Bug reports:** https://github.com/numpy/numpy/issues\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n\nIt provides:\n\n- a powerful N-dimensional array object\n- sophisticated (broadcasting) functions\n- tools for integrating C/C++ and Fortran code\n- useful linear algebra, Fourier transform, and random number capabilities\n\nTesting:\n\nNumPy requires `pytest` and `hypothesis`.  Tests can then be run after installation with:\n\n    python -c \"import numpy, sys; sys.exit(numpy.test() is False)\"\n\nCode of Conduct\n----------------------\n\nNumPy is a community-driven open source project developed by a diverse group of\n[contributors](https://numpy.org/teams/). The NumPy leadership has made a strong\ncommitment to creating an open, inclusive, and positive community. Please read the\n[NumPy Code of Conduct](https://numpy.org/code-of-conduct/) for guidance on how to interact\nwith others in a way that makes our community thrive.\n\nCall for Contributions\n----------------------\n\nThe NumPy project welcomes your expertise and enthusiasm!\n\nSmall improvements or fixes are always appreciated. If you are considering larger contributions\nto the source code, please contact us through the [mailing\nlist](https://mail.python.org/mailman/listinfo/numpy-discussion) first.\n\nWriting code isnâ€™t the only way to contribute to NumPy. You can also:\n- review pull requests\n- help us stay on top of new and old issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve [our website](https://github.com/numpy/numpy.org)\n- develop graphic design for our brand assets and promotional materials\n- translate website content\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nFor more information about the ways you can contribute to NumPy, visit [our website](https://numpy.org/contribute/). \nIf youâ€™re unsure where to start or how your skills fit in, reach out! You can\nask on the mailing list or here, on GitHub, by opening a new issue or leaving a\ncomment on a relevant issue that is already open.\n\nOur preferred channels of communication are all public, but if youâ€™d like to\nspeak to us in private first, contact our community coordinators at\nnumpy-team@googlegroups.com or on Slack (write numpy-team@googlegroups.com for\nan invitation).\n\nWe also have a biweekly community call, details of which are announced on the\nmailing list. You are very welcome to join.\n\nIf you are new to contributing to open source, [this\nguide](https://opensource.guide/how-to-contribute/) helps explain why, what,\nand how to successfully get involved.\n",
        "description_content_type": "text/markdown",
        "author": "Travis E. Oliphant et al.",
        "maintainer_email": "NumPy Developers <numpy-discussion@python.org>",
        "license_expression": "BSD-3-Clause AND 0BSD AND MIT AND Zlib AND CC0-1.0",
        "license_file": [
          "LICENSE.txt",
          "numpy/_core/include/numpy/libdivide/LICENSE.txt",
          "numpy/_core/src/common/pythoncapi-compat/COPYING",
          "numpy/_core/src/highway/LICENSE",
          "numpy/_core/src/multiarray/dragon4_LICENSE.txt",
          "numpy/_core/src/npysort/x86-simd-sort/LICENSE.md",
          "numpy/_core/src/umath/svml/LICENSE",
          "numpy/fft/pocketfft/LICENSE.md",
          "numpy/linalg/lapack_lite/LICENSE.txt",
          "numpy/ma/LICENSE",
          "numpy/random/LICENSE.md",
          "numpy/random/src/distributions/LICENSE.md",
          "numpy/random/src/mt19937/LICENSE.md",
          "numpy/random/src/pcg64/LICENSE.md",
          "numpy/random/src/philox/LICENSE.md",
          "numpy/random/src/sfc64/LICENSE.md",
          "numpy/random/src/splitmix64/LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Developers",
          "Programming Language :: C",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development",
          "Topic :: Scientific/Engineering",
          "Typing :: Typed",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Operating System :: MacOS"
        ],
        "requires_python": ">=3.11",
        "project_url": [
          "homepage, https://numpy.org",
          "documentation, https://numpy.org/doc/",
          "source, https://github.com/numpy/numpy",
          "download, https://pypi.org/project/numpy/#files",
          "tracker, https://github.com/numpy/numpy/issues",
          "release notes, https://numpy.org/doc/stable/release"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b7/b9/c538f279a4e237a006a2c98387d081e9eb060d203d8ed34467cc0f0b9b53/packaging-26.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b36f1fef9334a5588b4166f8bcd26a14e521f2b55e6b9de3aaa80d3ff7a37529",
          "hashes": {
            "sha256": "b36f1fef9334a5588b4166f8bcd26a14e521f2b55e6b9de3aaa80d3ff7a37529"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "packaging",
        "version": "26.0",
        "summary": "Core utilities for Python packages",
        "description": "packaging\n=========\n\n.. start-intro\n\nReusable core utilities for various Python Packaging\n`interoperability specifications <https://packaging.python.org/specifications/>`_.\n\nThis library provides utilities that implement the interoperability\nspecifications which have clearly one correct behaviour (eg: :pep:`440`)\nor benefit greatly from having a single shared implementation (eg: :pep:`425`).\n\n.. end-intro\n\nThe ``packaging`` project includes the following: version handling, specifiers,\nmarkers, requirements, tags, metadata, lockfiles, utilities.\n\nDocumentation\n-------------\n\nThe `documentation`_ provides information and the API for the following:\n\n- Version Handling\n- Specifiers\n- Markers\n- Requirements\n- Tags\n- Metadata\n- Lockfiles\n- Utilities\n\nInstallation\n------------\n\nUse ``pip`` to install these utilities::\n\n    pip install packaging\n\nThe ``packaging`` library uses calendar-based versioning (``YY.N``).\n\nDiscussion\n----------\n\nIf you run into bugs, you can file them in our `issue tracker`_.\n\nYou can also join ``#pypa`` on Freenode to ask questions or get involved.\n\n\n.. _`documentation`: https://packaging.pypa.io/\n.. _`issue tracker`: https://github.com/pypa/packaging/issues\n\n\nCode of Conduct\n---------------\n\nEveryone interacting in the packaging project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n\nContributing\n------------\n\nThe ``CONTRIBUTING.rst`` file outlines how to contribute to this project as\nwell as how to report a potential security issue. The documentation for this\nproject also covers information about `project development`_ and `security`_.\n\n.. _`project development`: https://packaging.pypa.io/en/latest/development/\n.. _`security`: https://packaging.pypa.io/en/latest/security/\n\nProject History\n---------------\n\nPlease review the ``CHANGELOG.rst`` file or the `Changelog documentation`_ for\nrecent changes and project history.\n\n.. _`Changelog documentation`: https://packaging.pypa.io/en/latest/changelog/\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Donald Stufft <donald@stufft.io>",
        "license_expression": "Apache-2.0 OR BSD-2-Clause",
        "license_file": [
          "LICENSE",
          "LICENSE.APACHE",
          "LICENSE.BSD"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://packaging.pypa.io/",
          "Source, https://github.com/pypa/packaging"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/f5/ab/f76ec3c3627c883215b5c8080debb4394ef5a7a29be811f786415fc1e6fd/propcache-0.4.1-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=381914df18634f5494334d201e98245c0596067504b9372d8cf93f4bb23e025e",
          "hashes": {
            "sha256": "381914df18634f5494334d201e98245c0596067504b9372d8cf93f4bb23e025e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "propcache",
        "version": "0.4.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "Accelerated property cache",
        "description": "propcache\r\n=========\r\n\r\nThe module provides a fast implementation of cached properties for Python 3.9+.\r\n\r\n.. image:: https://github.com/aio-libs/propcache/actions/workflows/ci-cd.yml/badge.svg\r\n  :target: https://github.com/aio-libs/propcache/actions?query=workflow%3ACI\r\n  :align: right\r\n\r\n.. image:: https://codecov.io/gh/aio-libs/propcache/branch/master/graph/badge.svg\r\n  :target: https://codecov.io/gh/aio-libs/propcache\r\n\r\n.. image:: https://badge.fury.io/py/propcache.svg\r\n    :target: https://badge.fury.io/py/propcache\r\n\r\n\r\n.. image:: https://readthedocs.org/projects/propcache/badge/?version=latest\r\n    :target: https://propcache.readthedocs.io\r\n\r\n\r\n.. image:: https://img.shields.io/pypi/pyversions/propcache.svg\r\n    :target: https://pypi.python.org/pypi/propcache\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs:matrix.org\r\n   :alt: Matrix Room â€” #aio-libs:matrix.org\r\n\r\n.. image:: https://img.shields.io/matrix/aio-libs-space:matrix.org?label=Discuss%20on%20Matrix%20at%20%23aio-libs-space%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\r\n   :target: https://matrix.to/#/%23aio-libs-space:matrix.org\r\n   :alt: Matrix Space â€” #aio-libs-space:matrix.org\r\n\r\nIntroduction\r\n------------\r\n\r\nThe API is designed to be nearly identical to the built-in ``functools.cached_property`` class,\r\nexcept for the additional ``under_cached_property`` class which uses ``self._cache``\r\ninstead of ``self.__dict__`` to store the cached values and prevents ``__set__`` from being called.\r\n\r\nFor full documentation please read https://propcache.readthedocs.io.\r\n\r\nInstallation\r\n------------\r\n\r\n::\r\n\r\n   $ pip install propcache\r\n\r\nThe library is Python 3 only!\r\n\r\nPyPI contains binary wheels for Linux, Windows and MacOS.  If you want to install\r\n``propcache`` on another operating system where wheels are not provided,\r\nthe the tarball will be used to compile the library from\r\nthe source code. It requires a C compiler and and Python headers installed.\r\n\r\nTo skip the compilation you must explicitly opt-in by using a PEP 517\r\nconfiguration setting ``pure-python``, or setting the ``PROPCACHE_NO_EXTENSIONS``\r\nenvironment variable to a non-empty value, e.g.:\r\n\r\n.. code-block:: console\r\n\r\n   $ pip install propcache --config-settings=pure-python=false\r\n\r\nPlease note that the pure-Python (uncompiled) version is much slower. However,\r\nPyPy always uses a pure-Python implementation, and, as such, it is unaffected\r\nby this variable.\r\n\r\n\r\nAPI documentation\r\n------------------\r\n\r\nThe documentation is located at https://propcache.readthedocs.io.\r\n\r\nSource code\r\n-----------\r\n\r\nThe project is hosted on GitHub_\r\n\r\nPlease file an issue on the `bug tracker\r\n<https://github.com/aio-libs/propcache/issues>`_ if you have found a bug\r\nor have some suggestion in order to improve the library.\r\n\r\nDiscussion list\r\n---------------\r\n\r\n*aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs\r\n\r\nFeel free to post your questions and ideas here.\r\n\r\n\r\nAuthors and License\r\n-------------------\r\n\r\nThe ``propcache`` package is derived from ``yarl`` which is written by Andrew Svetlov.\r\n\r\nIt's *Apache 2* licensed and freely available.\r\n\r\n\r\n.. _GitHub: https://github.com/aio-libs/propcache\r\n\r\n=========\r\nChangelog\r\n=========\r\n\r\n..\r\n    You should *NOT* be adding new change log entries to this file, this\r\n    file is managed by towncrier. You *may* edit previous change logs to\r\n    fix problems like typo corrections or such.\r\n    To add a new change log entry, please see\r\n    https://pip.pypa.io/en/latest/development/#adding-a-news-entry\r\n    we named the news folder \"changes\".\r\n\r\n    WARNING: Don't drop the next directive!\r\n\r\n.. towncrier release notes start\r\n\r\n0.4.1\r\n=====\r\n\r\n*(2025-10-08)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed reference leak caused by ``Py_INCREF`` because Cython has its own reference counter systems -- by `@Vizonex <https://github.com/sponsors/Vizonex>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#162 <https://github.com/aio-libs/propcache/issues/162>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Fixes the default value for the ``os``\r\n  parameter in ``reusable-build-wheel.yml``\r\n  to be ``ubuntu-latest`` instead of\r\n  ``ubuntu``.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#155 <https://github.com/aio-libs/propcache/issues/155>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.4.0\r\n=====\r\n\r\n*(2025-10-04)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Optimized propcache by replacing sentinel ``object`` for checking if\r\n  the ``object`` is ``NULL`` and changed ``dict`` API for\r\n  Python C-API -- by `@Vizonex <https://github.com/sponsors/Vizonex>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#121 <https://github.com/aio-libs/propcache/issues/121>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- Builds have been added for arm64 Windows\r\n  wheels and the ``reusable-build-wheel.yml``\r\n  workflow has been modified to allow for\r\n  an OS value (``windows-11-arm``) which\r\n  does not include the ``-latest`` postfix\r\n  -- by `@finnagin <https://github.com/sponsors/finnagin>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#133 <https://github.com/aio-libs/propcache/issues/133>`__.\r\n\r\n- Added CI for CPython 3.14 -- by `@kumaraditya303 <https://github.com/sponsors/kumaraditya303>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#140 <https://github.com/aio-libs/propcache/issues/140>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.3.2\r\n=====\r\n\r\n*(2025-06-09)*\r\n\r\n\r\nImproved documentation\r\n----------------------\r\n\r\n- Fixed incorrect decorator usage in the ``~propcache.api.under_cached_property`` example code -- by `@meanmail <https://github.com/sponsors/meanmail>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#109 <https://github.com/aio-libs/propcache/issues/109>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Updated to use Cython 3.1 universally across the build path -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#117 <https://github.com/aio-libs/propcache/issues/117>`__.\r\n\r\n- Made Cython line tracing opt-in via the ``with-cython-tracing`` build config setting -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Previously, line tracing was enabled by default in ``pyproject.toml``, which caused build issues for some users and made wheels nearly twice as slow.\r\n\r\n  Now line tracing is only enabled when explicitly requested via ``pip install . --config-setting=with-cython-tracing=true`` or by setting the ``PROPCACHE_CYTHON_TRACING`` environment variable.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#118 <https://github.com/aio-libs/propcache/issues/118>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.3.1\r\n=====\r\n\r\n*(2025-03-25)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Improved typing annotations, fixing some type errors under correct usage\r\n  and improving typing robustness generally -- by `@Dreamsorcerer <https://github.com/sponsors/Dreamsorcerer>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#103 <https://github.com/aio-libs/propcache/issues/103>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.3.0\r\n=====\r\n\r\n*(2025-02-20)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Implemented support for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#84 <https://github.com/aio-libs/propcache/issues/84>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Started building wheels for the free-threaded build of CPython 3.13 -- by `@lysnikolaou <https://github.com/sponsors/lysnikolaou>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#84 <https://github.com/aio-libs/propcache/issues/84>`__.\r\n\r\n\r\nContributor-facing changes\r\n--------------------------\r\n\r\n- GitHub Actions CI/CD is now configured to manage caching pip-ecosystem\r\n  dependencies using `re-actors/cache-python-deps`_ -- an action by\r\n  `@webknjaz <https://github.com/sponsors/webknjaz>`__ that takes into account ABI stability and the exact\r\n  version of Python runtime.\r\n\r\n  .. _`re-actors/cache-python-deps`:\r\n     https://github.com/marketplace/actions/cache-python-deps\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#93 <https://github.com/aio-libs/propcache/issues/93>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.2.1\r\n=====\r\n\r\n*(2024-12-01)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related commits on GitHub:*\r\n  `64df0a6 <https://github.com/aio-libs/propcache/commit/64df0a6>`__.\r\n\r\n- Fixed ``wrapped`` and ``func`` not being accessible in the Cython versions of ``propcache.api.cached_property`` and ``propcache.api.under_cached_property`` decorators -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#72 <https://github.com/aio-libs/propcache/issues/72>`__.\r\n\r\n\r\nRemovals and backward incompatible breaking changes\r\n---------------------------------------------------\r\n\r\n- Removed support for Python 3.8 as it has reached end of life -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#57 <https://github.com/aio-libs/propcache/issues/57>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Stopped implicitly allowing the use of Cython pre-release versions when\r\n  building the distribution package -- by `@ajsanchezsanz <https://github.com/sponsors/ajsanchezsanz>`__ and\r\n  `@markgreene74 <https://github.com/sponsors/markgreene74>`__.\r\n\r\n  *Related commits on GitHub:*\r\n  `64df0a6 <https://github.com/aio-libs/propcache/commit/64df0a6>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.2.0\r\n=====\r\n\r\n*(2024-10-07)*\r\n\r\n\r\nBug fixes\r\n---------\r\n\r\n- Fixed loading the C-extensions on Python 3.8 -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#26 <https://github.com/aio-libs/propcache/issues/26>`__.\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Improved typing for the ``propcache.api.under_cached_property`` decorator -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#38 <https://github.com/aio-libs/propcache/issues/38>`__.\r\n\r\n\r\nImproved documentation\r\n----------------------\r\n\r\n- Added API documentation for the ``propcache.api.cached_property`` and ``propcache.api.under_cached_property`` decorators -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#16 <https://github.com/aio-libs/propcache/issues/16>`__.\r\n\r\n\r\nPackaging updates and notes for downstreams\r\n-------------------------------------------\r\n\r\n- Moved ``propcache.api.under_cached_property`` and ``propcache.api.cached_property`` to `propcache.api` -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  Both decorators remain importable from the top-level package, however importing from `propcache.api` is now the recommended way to use them.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#19 <https://github.com/aio-libs/propcache/issues/19>`__, `#24 <https://github.com/aio-libs/propcache/issues/24>`__, `#32 <https://github.com/aio-libs/propcache/issues/32>`__.\r\n\r\n- Converted project to use a src layout -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#22 <https://github.com/aio-libs/propcache/issues/22>`__, `#29 <https://github.com/aio-libs/propcache/issues/29>`__, `#37 <https://github.com/aio-libs/propcache/issues/37>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.1.0\r\n=====\r\n\r\n*(2024-10-03)*\r\n\r\n\r\nFeatures\r\n--------\r\n\r\n- Added ``armv7l`` wheels -- by `@bdraco <https://github.com/sponsors/bdraco>`__.\r\n\r\n  *Related issues and pull requests on GitHub:*\r\n  `#5 <https://github.com/aio-libs/propcache/issues/5>`__.\r\n\r\n\r\n----\r\n\r\n\r\n0.0.0\r\n=====\r\n\r\n*(2024-10-02)*\r\n\r\n\r\n- Initial release.\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "cython",
          "cext",
          "propcache"
        ],
        "home_page": "https://github.com/aio-libs/propcache",
        "author": "Andrew Svetlov",
        "author_email": "andrew.svetlov@gmail.com",
        "maintainer": "aiohttp team <team@aiohttp.org>",
        "maintainer_email": "team@aiohttp.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE",
          "NOTICE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat: Matrix, https://matrix.to/#/#aio-libs:matrix.org",
          "Chat: Matrix Space, https://matrix.to/#/#aio-libs-space:matrix.org",
          "CI: GitHub Workflows, https://github.com/aio-libs/propcache/actions?query=branch:master",
          "Code of Conduct, https://github.com/aio-libs/.github/blob/master/CODE_OF_CONDUCT.md",
          "Coverage: codecov, https://codecov.io/github/aio-libs/propcache",
          "Docs: Changelog, https://propcache.readthedocs.io/en/latest/changes/",
          "Docs: RTD, https://propcache.readthedocs.io",
          "GitHub: issues, https://github.com/aio-libs/propcache/issues",
          "GitHub: repo, https://github.com/aio-libs/propcache"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/9b/4d/b9add7c84060d4c1906abe9a7e5359f2a60f7a9a4f67268b2766673427d8/pyee-13.0.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=48195a3cddb3b1515ce0695ed76036b5ccc2ef3a9f963ff9f77aec0139845498",
          "hashes": {
            "sha256": "48195a3cddb3b1515ce0695ed76036b5ccc2ef3a9f963ff9f77aec0139845498"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.2",
        "name": "pyee",
        "version": "13.0.0",
        "summary": "A rough port of Node.js's EventEmitter to Python with a few tricks of its own",
        "description": "# pyee\n\n[![Documentation Status](https://readthedocs.org/projects/pyee/badge/?version=latest)](https://pyee.readthedocs.io/en/latest/?badge=latest)\n\npyee supplies a `EventEmitter` object that is similar to the\n`EventEmitter` class from Node.js. It also supplies a number of subclasses\nwith added support for async and threaded programming in python, such as\nasync/await.\n\n## Docs\n\nAutogenerated API docs, including basic installation directions and examples,\ncan be found at <https://pyee.readthedocs.io>.\n\n## Development\n\nSee [DEVELOPMENT.md](./DEVELOPMENT.md).\n\n## Changelog\n\nSee [CHANGELOG.md](./CHANGELOG.md).\n\n## Contributors\n\nSee [CONTRIBUTORS.md](./CONTRIBUTORS.md).\n\n## License\n\nMIT/X11, see [LICENSE](./LICENSE).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "events",
          "emitter",
          "node.js",
          "node",
          "eventemitter",
          "event_emitter"
        ],
        "author_email": "Josh Holbrook <josh.holbrook@gmail.com>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Programming Language :: Python",
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Other/Nonlisted Topic"
        ],
        "requires_dist": [
          "typing-extensions",
          "build; extra == \"dev\"",
          "flake8; extra == \"dev\"",
          "flake8-black; extra == \"dev\"",
          "pytest; extra == \"dev\"",
          "pytest-asyncio; python_version >= \"3.4\" and extra == \"dev\"",
          "pytest-trio; python_version >= \"3.7\" and extra == \"dev\"",
          "black; extra == \"dev\"",
          "isort; extra == \"dev\"",
          "jupyter-console; extra == \"dev\"",
          "mkdocs; extra == \"dev\"",
          "mkdocs-include-markdown-plugin; extra == \"dev\"",
          "mkdocstrings[python]; extra == \"dev\"",
          "mypy; extra == \"dev\"",
          "sphinx; extra == \"dev\"",
          "toml; extra == \"dev\"",
          "tox; extra == \"dev\"",
          "trio; extra == \"dev\"",
          "trio; python_version > \"3.6\" and extra == \"dev\"",
          "trio-typing; python_version > \"3.6\" and extra == \"dev\"",
          "twine; extra == \"dev\"",
          "twisted; extra == \"dev\"",
          "validate-pyproject[all]; extra == \"dev\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Repository, https://github.com/jfhbrook/pyee",
          "Documentation, https://pyee.readthedocs.io"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c7/21/705964c7812476f378728bdf590ca4b771ec72385c533964653c68e86bdc/pygments-2.19.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=86540386c03d588bb81d44bc3928634ff26449851e99741617ecb9037ee5ec0b",
          "hashes": {
            "sha256": "86540386c03d588bb81d44bc3928634ff26449851e99741617ecb9037ee5ec0b"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "Pygments",
        "version": "2.19.2",
        "summary": "Pygments is a syntax highlighting package written in Python.",
        "description": "Pygments\n~~~~~~~~\n\nPygments is a syntax highlighting package written in Python.\n\nIt is a generic syntax highlighter suitable for use in code hosting, forums,\nwikis or other applications that need to prettify source code.  Highlights\nare:\n\n* a wide range of over 500 languages and other text formats is supported\n* special attention is paid to details, increasing quality by a fair amount\n* support for new languages and formats are added easily\n* a number of output formats, presently HTML, LaTeX, RTF, SVG, all image\n  formats that PIL supports and ANSI sequences\n* it is usable as a command-line tool and as a library\n\nCopyright 2006-2025 by the Pygments team, see ``AUTHORS``.\nLicensed under the BSD, see ``LICENSE`` for details.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "syntax",
          "highlighting"
        ],
        "author_email": "Georg Brandl <georg@python.org>",
        "maintainer": "MatthÃ¤us G. Chajdas",
        "maintainer_email": "Georg Brandl <georg@python.org>, Jean Abou Samra <jean@abou-samra.fr>",
        "license": "BSD-2-Clause",
        "license_file": [
          "AUTHORS",
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "Intended Audience :: End Users/Desktop",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Filters",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "colorama>=0.4.6; extra == 'windows-terminal'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://pygments.org",
          "Documentation, https://pygments.org/docs",
          "Source, https://github.com/pygments/pygments",
          "Bug Tracker, https://github.com/pygments/pygments/issues",
          "Changelog, https://github.com/pygments/pygments/blob/master/CHANGES"
        ],
        "provides_extra": [
          "plugins",
          "windows-terminal"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c3/70/43db21af194580aba2d9a6d4c7bd8c1a6e887fa52cd810b88f89096ecad2/pylibsrtp-1.0.0-cp310-abi3-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=8d6527c4a78a39a8d397f8862a8b7cdad4701ee866faf9de4ab8c70be61fd34d",
          "hashes": {
            "sha256": "8d6527c4a78a39a8d397f8862a8b7cdad4701ee866faf9de4ab8c70be61fd34d"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pylibsrtp",
        "version": "1.0.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Python wrapper around the libsrtp library",
        "description": "pylibsrtp\r\n=========\r\n\r\n.. image:: https://img.shields.io/pypi/l/pylibsrtp.svg\r\n   :target: https://pypi.python.org/pypi/pylibsrtp\r\n   :alt: License\r\n\r\n.. image:: https://img.shields.io/pypi/v/pylibsrtp.svg\r\n   :target: https://pypi.python.org/pypi/pylibsrtp\r\n   :alt: Version\r\n\r\n.. image:: https://img.shields.io/pypi/pyversions/pylibsrtp.svg\r\n   :target: https://pypi.python.org/pypi/pylibsrtp\r\n   :alt: Python versions\r\n\r\n.. image:: https://github.com/aiortc/pylibsrtp/workflows/tests/badge.svg\r\n   :target: https://github.com/aiortc/pylibsrtp/actions\r\n   :alt: Tests\r\n\r\n.. image:: https://img.shields.io/codecov/c/github/aiortc/pylibsrtp.svg\r\n   :target: https://codecov.io/gh/aiortc/pylibsrtp\r\n   :alt: Coverage\r\n\r\n.. image:: https://readthedocs.org/projects/pylibsrtp/badge/?version=latest\r\n   :target: https://pylibsrtp.readthedocs.io/\r\n   :alt: Documentation\r\n\r\nWhat is ``pylibsrtp``?\r\n----------------------\r\n\r\n``pylibsrtp`` is a Python wrapper around `libsrtp`_, making it possible to\r\nencrypt and decrypt Secure Real-time Transport Protocol (SRTP) packets from\r\nPython code.\r\n\r\nSRTP is a profile of the Real-time Transport Protocol (RTP) which provides\r\nconfidentiality, message authentication, and replay protection. It is defined\r\nby `RFC 3711`_.\r\n\r\nYou can install ``pylibsrtp`` with ``pip``:\r\n\r\n.. code-block:: console\r\n\r\n    $ pip install pylibsrtp\r\n\r\nTo learn more about ``pylibsrtp`` please `read the documentation`_.\r\n\r\n.. _libsrtp: https://github.com/cisco/libsrtp\r\n\r\n.. _RFC 3711: https://tools.ietf.org/html/rfc3711\r\n\r\n.. _read the documentation: https://pylibsrtp.readthedocs.io/en/stable/\r\n\r\nExample\r\n-------\r\n\r\n.. code:: python\r\n\r\n    #!/usr/bin/env python\r\n\r\n    from pylibsrtp import Policy, Session\r\n\r\n    key = (b'\\x00' * 30)\r\n    rtp = b'\\x80\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' + (b'\\xd4' * 160)\r\n\r\n    # protect RTP\r\n    tx_policy = Policy(key=key, ssrc_type=Policy.SSRC_ANY_OUTBOUND)\r\n    tx_session = Session(policy=tx_policy)\r\n    srtp = tx_session.protect(rtp)\r\n\r\n    # unprotect RTP\r\n    rx_policy = Policy(key=key, ssrc_type=Policy.SSRC_ANY_INBOUND)\r\n    rx_session = Session(policy=rx_policy)\r\n    rtp2 = rx_session.unprotect(srtp)\r\n\r\n    # check roundtrip worked!\r\n    assert rtp2 == rtp\r\n\r\nBuilding pylibsrtp\r\n------------------\r\n\r\nIf you wish to build pylibsrtp yourself, you will need libsrtp version 2.0 or better.\r\n\r\nLinux\r\n.....\r\n\r\nOn Debian/Ubuntu run:\r\n\r\n.. code-block:: console\r\n\r\n    $ apt install libsrtp2-dev\r\n\r\nOn Fedora/CentOS run:\r\n\r\n.. code-block:: console\r\n\r\n    $ dnf install libsrtp-devel\r\n\r\nmacOS\r\n.....\r\n\r\nOn macOS run:\r\n\r\n.. code-block:: console\r\n\r\n    $ brew install srtp\r\n\r\nYou will need to set some environment variables to link against libsrtp:\r\n\r\n.. code-block:: console\r\n\r\n   export CFLAGS=-I$(brew --prefix openssl)/include -I$(brew --prefix srtp)/include\r\n   export LDFLAGS=-L$(brew --prefix openssl)/lib -L$(brew --prefix srtp)/lib\r\n\r\nLicense\r\n-------\r\n\r\n``pylibsrtp`` is released under the `BSD license`_.\r\n\r\n.. _BSD license: https://pylibsrtp.readthedocs.io/en/stable/license.html\r\n",
        "description_content_type": "text/x-rst",
        "author_email": "Jeremy LainÃ© <jeremy.laine@m4x.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Communications :: Telephony",
          "Topic :: Security :: Cryptography"
        ],
        "requires_dist": [
          "cffi>=1.0.0",
          "coverage[toml]>=7.2.2; extra == \"dev\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://github.com/aiortc/pylibsrtp",
          "documentation, https://pylibsrtp.readthedocs.io/"
        ],
        "provides_extra": [
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/ce/af/409edba35fc597f1e386e3860303791ab5a28d6cc9a8aecbc567051b19a9/PyMeta3-0.5.1.tar.gz",
        "archive_info": {
          "hash": "sha256=18bda326d9a9bbf587bfc0ee0bc96864964d78b067288bcf55d4d98681d05bcb",
          "hashes": {
            "sha256": "18bda326d9a9bbf587bfc0ee0bc96864964d78b067288bcf55d4d98681d05bcb"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "PyMeta3",
        "version": "0.5.1",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "summary"
        ],
        "summary": "Pattern-matching language based on OMeta for Python 3 and 2",
        "description": "========\r\nPyMeta3\r\n========\r\n\r\n--------------------------------------------\r\nA Pattern-Matching Language Based on Python\r\n--------------------------------------------\r\n\r\nThis is a fork of PyMeta 0.5.0 that supports Python 2 and 3.\r\n\r\n\r\nInstallation\r\n============\r\n\r\npip install PyMeta3\r\n\r\n\r\nSummary\r\n=======\r\n\r\nPyMeta is an implementation of OMeta, an object-oriented pattern-matching\r\nlanguage developed by Alessandro Warth\r\n(http://www.cs.ucla.edu/~awarth/ometa/). PyMeta provides a compact syntax based\r\non Parsing Expression Grammars (PEGs) for common lexing, parsing and\r\ntree-transforming activities in a way that's easy to reason about for Python\r\nprogrammers.\r\n\r\n\r\nHow It Works\r\n============\r\n\r\nPyMeta compiles a grammar to a Python class, with the rules as methods. The\r\nrules specify parsing expressions, which consume input and return values if\r\nthey succeed in matching.\r\n\r\nBasic syntax\r\n~~~~~~~~~~~~~~~~\r\n\r\n``foo ::= ....``\r\n   Define a rule named foo.\r\n``expr1 expr2``\r\n   Match expr1, and then match expr2 if it succeeds, returning the value of\r\n   expr2. Like Python's ``and``.\r\n``expr1 | expr2``\r\n  Try to match expr1 --- if it fails, match expr2 instead. Like Python's\r\n  ``or``.\r\n``expr*``\r\n  Match expr zero or more times, returning a list of matches.\r\n``expr+``\r\n  Match expr one or more times, returning a list of matches.\r\n``expr?``\r\n  Try to match expr. Returns None if it fails to match.\r\n``~expr``\r\n  Fail if the next item in the input matches expr.\r\n``<ruleName>``\r\n  Call the rule ``ruleName``.\r\n``'x'``\r\n  Match the literal character 'x'.\r\n``expr:name``\r\n  Bind the result of expr to the local variable ``name``.\r\n``=> pythonExpression``\r\n  Evaluate the given Python expression and return its result.\r\n\r\nComments like Python comments are supported as well, starting with #\r\nand extending to the end of the line.\r\n\r\nInterface\r\n=========\r\n\r\nThe starting point for defining a new grammar is\r\n``pymeta.grammar.OMeta.makeGrammar``, which takes a grammar definition and a\r\ndict of variable bindings for its embedded expressions and produces a Python\r\nclass. Grammars can be subclassed as usual, and makeGrammar can be called on\r\nthese classes to override rules and provide new ones. To invoke a grammar rule,\r\ncall ``grammarObject.apply()`` with its name.\r\n\r\nExample Usage\r\n=============\r\n\r\n>>> from pymeta.grammar import OMeta\r\n>>> exampleGrammar = \"\"\"\r\nones ::= '1' '1' => 1\r\ntwos ::= '2' '2' => 2\r\nstuff ::= (<ones> | <twos>)+\r\n\"\"\"\r\n>>> Example = OMeta.makeGrammar(exampleGrammar, {})\r\n>>> g = Example(\"11221111\")\r\n>>> result, error = g.apply(\"stuff\")\r\n>>> result\r\n[1, 2, 1, 1]\r\n",
        "home_page": "https://github.com/wbond/pymeta3",
        "author": "wbond",
        "author_email": "will@wbond.net",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/d1/81/ef2b1dfd1862567d573a4fdbc9f969067621764fbb74338496840a1d2977/pyopenssl-25.3.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=1fda6fc034d5e3d179d39e59c1895c9faeaf40a79de5fc4cbbfbe0d36f4a77b6",
          "hashes": {
            "sha256": "1fda6fc034d5e3d179d39e59c1895c9faeaf40a79de5fc4cbbfbe0d36f4a77b6"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pyOpenSSL",
        "version": "25.3.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Python wrapper module around the OpenSSL library",
        "description": "========================================================\npyOpenSSL -- A Python wrapper around the OpenSSL library\n========================================================\n\n.. image:: https://readthedocs.org/projects/pyopenssl/badge/?version=stable\n   :target: https://pyopenssl.org/en/stable/\n   :alt: Stable Docs\n\n.. image:: https://github.com/pyca/pyopenssl/workflows/CI/badge.svg?branch=main\n   :target: https://github.com/pyca/pyopenssl/actions?query=workflow%3ACI+branch%3Amain\n\n**Note:** The Python Cryptographic Authority **strongly suggests** the use of `pyca/cryptography`_\nwhere possible. If you are using pyOpenSSL for anything other than making a TLS connection\n**you should move to cryptography and drop your pyOpenSSL dependency**.\n\nHigh-level wrapper around a subset of the OpenSSL library. Includes\n\n* ``SSL.Connection`` objects, wrapping the methods of Python's portable sockets\n* Callbacks written in Python\n* Extensive error-handling mechanism, mirroring OpenSSL's error codes\n\n... and much more.\n\nYou can find more information in the documentation_.\nDevelopment takes place on GitHub_.\n\n\nDiscussion\n==========\n\nIf you run into bugs, you can file them in our `issue tracker`_.\n\nWe maintain a cryptography-dev_ mailing list for both user and development discussions.\n\nYou can also join ``#pyca`` on ``irc.libera.chat`` to ask questions or get involved.\n\n\n.. _documentation: https://pyopenssl.org/\n.. _`issue tracker`: https://github.com/pyca/pyopenssl/issues\n.. _cryptography-dev: https://mail.python.org/mailman/listinfo/cryptography-dev\n.. _GitHub: https://github.com/pyca/pyopenssl\n.. _`pyca/cryptography`: https://github.com/pyca/cryptography\n\n\nRelease Information\n===================\n\n25.4.0 (UNRELEASED)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n25.3.0 (2025-09-16)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Maximum supported ``cryptography`` version is now 46.x.\n\n\n25.2.0 (2025-09-14)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The minimum ``cryptography`` version is now 45.0.7.\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- pyOpenSSL now sets ``SSL_MODE_ACCEPT_MOVING_WRITE_BUFFER`` on connections by default, matching CPython's behavior.\n- Added ``OpenSSL.SSL.Context.clear_mode``.\n- Added ``OpenSSL.SSL.Context.set_tls13_ciphersuites`` to set the allowed TLS 1.3 ciphers.\n- Added ``OpenSSL.SSL.Connection.set_info_callback``\n\n25.1.0 (2025-05-17)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Attempting using any methods that mutate an ``OpenSSL.SSL.Context`` after it\n  has been used to create an ``OpenSSL.SSL.Connection`` will emit a warning. In\n  a future release, this will raise an exception.\n\nChanges:\n^^^^^^^^\n\n* ``cryptography`` maximum version has been increased to 45.0.x.\n\n\n25.0.0 (2025-01-12)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Corrected type annotations on ``Context.set_alpn_select_callback``, ``Context.set_session_cache_mode``, ``Context.set_options``, ``Context.set_mode``, ``X509.subject_name_hash``, and ``X509Store.load_locations``.\n- Deprecated APIs are now marked using ``warnings.deprecated``. ``mypy`` will emit deprecation notices for them when used with ``--enable-error-code deprecated``.\n\n24.3.0 (2024-11-27)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removed the deprecated ``OpenSSL.crypto.CRL``, ``OpenSSL.crypto.Revoked``, ``OpenSSL.crypto.dump_crl``, and ``OpenSSL.crypto.load_crl``. ``cryptography.x509``'s CRL functionality should be used instead.\n- Removed the deprecated ``OpenSSL.crypto.sign`` and ``OpenSSL.crypto.verify``. ``cryptography.hazmat.primitives.asymmetric``'s signature APIs should be used instead.\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Deprecated ``OpenSSL.rand`` - callers should use ``os.urandom()`` instead.\n- Deprecated ``add_extensions`` and ``get_extensions`` on ``OpenSSL.crypto.X509Req`` and ``OpenSSL.crypto.X509``. These should have been deprecated at the same time ``X509Extension`` was. Users should use pyca/cryptography's X.509 APIs instead.\n- Deprecated ``OpenSSL.crypto.get_elliptic_curves`` and ``OpenSSL.crypto.get_elliptic_curve``, as well as passing the reult of them to ``OpenSSL.SSL.Context.set_tmp_ecdh``, users should instead pass curves from ``cryptography``.\n- Deprecated passing ``X509`` objects to ``OpenSSL.SSL.Context.use_certificate``, ``OpenSSL.SSL.Connection.use_certificate``, ``OpenSSL.SSL.Context.add_extra_chain_cert``, and ``OpenSSL.SSL.Context.add_client_ca``, users should instead pass ``cryptography.x509.Certificate`` instances. This is in preparation for deprecating pyOpenSSL's ``X509`` entirely.\n- Deprecated passing ``PKey`` objects to ``OpenSSL.SSL.Context.use_privatekey`` and ``OpenSSL.SSL.Connection.use_privatekey``, users should instead pass ``cryptography`` priate key instances. This is in preparation for deprecating pyOpenSSL's ``PKey`` entirely.\n\nChanges:\n^^^^^^^^\n\n* ``cryptography`` maximum version has been increased to 44.0.x.\n* ``OpenSSL.SSL.Connection.get_certificate``, ``OpenSSL.SSL.Connection.get_peer_certificate``, ``OpenSSL.SSL.Connection.get_peer_cert_chain``, and ``OpenSSL.SSL.Connection.get_verified_chain`` now take an ``as_cryptography`` keyword-argument. When ``True`` is passed then ``cryptography.x509.Certificate`` are returned, instead of ``OpenSSL.crypto.X509``. In the future, passing ``False`` (the default) will be deprecated.\n\n\n24.2.1 (2024-07-20)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Fixed changelog to remove sphinx specific restructured text strings.\n\n\n24.2.0 (2024-07-20)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Deprecated ``OpenSSL.crypto.X509Req``, ``OpenSSL.crypto.load_certificate_request``, ``OpenSSL.crypto.dump_certificate_request``. Instead, ``cryptography.x509.CertificateSigningRequest``, ``cryptography.x509.CertificateSigningRequestBuilder``, ``cryptography.x509.load_der_x509_csr``, or ``cryptography.x509.load_pem_x509_csr`` should be used.\n\nChanges:\n^^^^^^^^\n\n- Added type hints for the ``SSL`` module.\n  `#1308 <https://github.com/pyca/pyopenssl/pull/1308>`_.\n- Changed ``OpenSSL.crypto.PKey.from_cryptography_key`` to accept public and private EC, ED25519, ED448 keys.\n  `#1310 <https://github.com/pyca/pyopenssl/pull/1310>`_.\n\n24.1.0 (2024-03-09)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n* Removed the deprecated ``OpenSSL.crypto.PKCS12`` and\n  ``OpenSSL.crypto.NetscapeSPKI``. ``OpenSSL.crypto.PKCS12`` may be replaced\n  by the PKCS#12 APIs in the ``cryptography`` package.\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n24.0.0 (2024-01-22)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Added ``OpenSSL.SSL.Connection.get_selected_srtp_profile`` to determine which SRTP profile was negotiated.\n  `#1279 <https://github.com/pyca/pyopenssl/pull/1279>`_.\n\n23.3.0 (2023-10-25)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Dropped support for Python 3.6.\n- The minimum ``cryptography`` version is now 41.0.5.\n- Removed ``OpenSSL.crypto.load_pkcs7`` and ``OpenSSL.crypto.load_pkcs12`` which had been deprecated for 3 years.\n- Added ``OpenSSL.SSL.OP_LEGACY_SERVER_CONNECT`` to allow legacy insecure renegotiation between OpenSSL and unpatched servers.\n  `#1234 <https://github.com/pyca/pyopenssl/pull/1234>`_.\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Deprecated ``OpenSSL.crypto.PKCS12`` (which was intended to have been deprecated at the same time as ``OpenSSL.crypto.load_pkcs12``).\n- Deprecated ``OpenSSL.crypto.NetscapeSPKI``.\n- Deprecated ``OpenSSL.crypto.CRL``\n- Deprecated ``OpenSSL.crypto.Revoked``\n- Deprecated ``OpenSSL.crypto.load_crl`` and ``OpenSSL.crypto.dump_crl``\n- Deprecated ``OpenSSL.crypto.sign`` and ``OpenSSL.crypto.verify``\n- Deprecated ``OpenSSL.crypto.X509Extension``\n\nChanges:\n^^^^^^^^\n\n- Changed ``OpenSSL.crypto.X509Store.add_crl`` to also accept\n  ``cryptography``'s ``x509.CertificateRevocationList`` arguments in addition\n  to the now deprecated ``OpenSSL.crypto.CRL`` arguments.\n- Fixed ``test_set_default_verify_paths`` test so that it is skipped if no\n  network connection is available.\n\n23.2.0 (2023-05-30)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removed ``X509StoreFlags.NOTIFY_POLICY``.\n  `#1213 <https://github.com/pyca/pyopenssl/pull/1213>`_.\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- ``cryptography`` maximum version has been increased to 41.0.x.\n- Invalid versions are now rejected in ``OpenSSL.crypto.X509Req.set_version``.\n- Added ``X509VerificationCodes`` to ``OpenSSL.SSL``.\n  `#1202 <https://github.com/pyca/pyopenssl/pull/1202>`_.\n\n23.1.1 (2023-03-28)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Worked around an issue in OpenSSL 3.1.0 which caused `X509Extension.get_short_name` to raise an exception when no short name was known to OpenSSL.\n  `#1204 <https://github.com/pyca/pyopenssl/pull/1204>`_.\n\n23.1.0 (2023-03-24)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- ``cryptography`` maximum version has been increased to 40.0.x.\n- Add ``OpenSSL.SSL.Connection.DTLSv1_get_timeout`` and ``OpenSSL.SSL.Connection.DTLSv1_handle_timeout``\n  to support DTLS timeouts `#1180 <https://github.com/pyca/pyopenssl/pull/1180>`_.\n\n23.0.0 (2023-01-01)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Add ``OpenSSL.SSL.X509StoreFlags.PARTIAL_CHAIN`` constant to allow for users\n  to perform certificate verification on partial certificate chains.\n  `#1166 <https://github.com/pyca/pyopenssl/pull/1166>`_\n- ``cryptography`` maximum version has been increased to 39.0.x.\n\n22.1.0 (2022-09-25)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Remove support for SSLv2 and SSLv3.\n- The minimum ``cryptography`` version is now 38.0.x (and we now pin releases\n  against ``cryptography`` major versions to prevent future breakage)\n- The ``OpenSSL.crypto.X509StoreContextError`` exception has been refactored,\n  changing its internal attributes.\n  `#1133 <https://github.com/pyca/pyopenssl/pull/1133>`_\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- ``OpenSSL.SSL.SSLeay_version`` is deprecated in favor of\n  ``OpenSSL.SSL.OpenSSL_version``. The constants ``OpenSSL.SSL.SSLEAY_*`` are\n  deprecated in favor of ``OpenSSL.SSL.OPENSSL_*``.\n\nChanges:\n^^^^^^^^\n\n- Add ``OpenSSL.SSL.Connection.set_verify`` and ``OpenSSL.SSL.Connection.get_verify_mode``\n  to override the context object's verification flags.\n  `#1073 <https://github.com/pyca/pyopenssl/pull/1073>`_\n- Add ``OpenSSL.SSL.Connection.use_certificate`` and ``OpenSSL.SSL.Connection.use_privatekey``\n  to set a certificate per connection (and not just per context) `#1121 <https://github.com/pyca/pyopenssl/pull/1121>`_.\n\n22.0.0 (2022-01-29)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Drop support for Python 2.7.\n  `#1047 <https://github.com/pyca/pyopenssl/pull/1047>`_\n- The minimum ``cryptography`` version is now 35.0.\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Expose wrappers for some `DTLS\n  <https://en.wikipedia.org/wiki/Datagram_Transport_Layer_Security>`_\n  primitives. `#1026 <https://github.com/pyca/pyopenssl/pull/1026>`_\n\n21.0.0 (2021-09-28)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The minimum ``cryptography`` version is now 3.3.\n- Drop support for Python 3.5\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Raise an error when an invalid ALPN value is set.\n  `#993 <https://github.com/pyca/pyopenssl/pull/993>`_\n- Added ``OpenSSL.SSL.Context.set_min_proto_version`` and ``OpenSSL.SSL.Context.set_max_proto_version``\n  to set the minimum and maximum supported TLS version `#985 <https://github.com/pyca/pyopenssl/pull/985>`_.\n- Updated ``to_cryptography`` and ``from_cryptography`` methods to support an upcoming release of ``cryptography`` without raising deprecation warnings.\n  `#1030 <https://github.com/pyca/pyopenssl/pull/1030>`_\n\n20.0.1 (2020-12-15)\n-------------------\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecations:\n^^^^^^^^^^^^^\n\nChanges:\n^^^^^^^^\n\n- Fixed compatibility with OpenSSL 1.1.0.\n\n20.0.0 (2020-11-27)\n-------------------\n\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The minimum ``cryptography`` version is now 3.2.\n- Remove deprecated ``OpenSSL.tsafe`` module.\n- Removed deprecated ``OpenSSL.SSL.Context.set_npn_advertise_callback``, ``OpenSSL.SSL.Context.set_npn_select_callback``, and ``OpenSSL.SSL.Connection.get_next_proto_negotiated``.\n- Drop support for Python 3.4\n- Drop support for OpenSSL 1.0.1 and 1.0.2\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Deprecated ``OpenSSL.crypto.load_pkcs7`` and ``OpenSSL.crypto.load_pkcs12``.\n\nChanges:\n^^^^^^^^\n\n- Added a new optional ``chain`` parameter to ``OpenSSL.crypto.X509StoreContext()``\n  where additional untrusted certificates can be specified to help chain building.\n  `#948 <https://github.com/pyca/pyopenssl/pull/948>`_\n- Added ``OpenSSL.crypto.X509Store.load_locations`` to set trusted\n  certificate file bundles and/or directories for verification.\n  `#943 <https://github.com/pyca/pyopenssl/pull/943>`_\n- Added ``Context.set_keylog_callback`` to log key material.\n  `#910 <https://github.com/pyca/pyopenssl/pull/910>`_\n- Added ``OpenSSL.SSL.Connection.get_verified_chain`` to retrieve the\n  verified certificate chain of the peer.\n  `#894 <https://github.com/pyca/pyopenssl/pull/894>`_.\n- Make verification callback optional in ``Context.set_verify``.\n  If omitted, OpenSSL's default verification is used.\n  `#933 <https://github.com/pyca/pyopenssl/pull/933>`_\n- Fixed a bug that could truncate or cause a zero-length key error due to a\n  null byte in private key passphrase in ``OpenSSL.crypto.load_privatekey``\n  and ``OpenSSL.crypto.dump_privatekey``.\n  `#947 <https://github.com/pyca/pyopenssl/pull/947>`_\n\n19.1.0 (2019-11-18)\n-------------------\n\n\nBackward-incompatible changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removed deprecated ``ContextType``, ``ConnectionType``, ``PKeyType``, ``X509NameType``, ``X509ReqType``, ``X509Type``, ``X509StoreType``, ``CRLType``, ``PKCS7Type``, ``PKCS12Type``, and ``NetscapeSPKIType`` aliases.\n  Use the classes without the ``Type`` suffix instead.\n  `#814 <https://github.com/pyca/pyopenssl/pull/814>`_\n- The minimum ``cryptography`` version is now 2.8 due to issues on macOS with a transitive dependency.\n  `#875 <https://github.com/pyca/pyopenssl/pull/875>`_\n\nDeprecations:\n^^^^^^^^^^^^^\n\n- Deprecated ``OpenSSL.SSL.Context.set_npn_advertise_callback``, ``OpenSSL.SSL.Context.set_npn_select_callback``, and ``OpenSSL.SSL.Connection.get_next_proto_negotiated``.\n  ALPN should be used instead.\n  `#820 <https://github.com/pyca/pyopenssl/pull/820>`_\n\n\nChanges:\n^^^^^^^^\n\n- Support ``bytearray`` in ``SSL.Connection.send()`` by using cffi's from_buffer.\n  `#852 <https://github.com/pyca/pyopenssl/pull/852>`_\n- The ``OpenSSL.SSL.Context.set_alpn_select_callback`` can return a new ``NO_OVERLAPPING_PROTOCOLS`` sentinel value\n  to allow a TLS handshake to complete without an application protocol.\n\n`Full changelog <https://pyopenssl.org/en/stable/changelog.html>`_.\n\n",
        "home_page": "https://pyopenssl.org/",
        "author": "The pyOpenSSL developers",
        "author_email": "cryptography-dev@python.org",
        "license": "Apache License, Version 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Security :: Cryptography",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: System :: Networking"
        ],
        "requires_dist": [
          "cryptography<47,>=45.0.7",
          "typing-extensions>=4.9; python_version < \"3.13\" and python_version >= \"3.8\"",
          "pytest-rerunfailures; extra == \"test\"",
          "pretend; extra == \"test\"",
          "pytest>=3.0.1; extra == \"test\"",
          "sphinx!=5.2.0,!=5.2.0.post0,!=7.2.5; extra == \"docs\"",
          "sphinx_rtd_theme; extra == \"docs\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Source, https://github.com/pyca/pyopenssl"
        ],
        "provides_extra": [
          "test",
          "docs"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427",
          "hashes": {
            "sha256": "a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "python-dateutil",
        "version": "2.9.0.post0",
        "summary": "Extensions to the standard Python datetime module",
        "description": "dateutil - powerful extensions to datetime\n==========================================\n\n|pypi| |support| |licence|\n\n|gitter| |readthedocs|\n\n|travis| |appveyor| |pipelines| |coverage|\n\n.. |pypi| image:: https://img.shields.io/pypi/v/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: pypi version\n\n.. |support| image:: https://img.shields.io/pypi/pyversions/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: supported Python version\n\n.. |travis| image:: https://img.shields.io/travis/dateutil/dateutil/master.svg?style=flat-square&label=Travis%20Build\n    :target: https://travis-ci.org/dateutil/dateutil\n    :alt: travis build status\n\n.. |appveyor| image:: https://img.shields.io/appveyor/ci/dateutil/dateutil/master.svg?style=flat-square&logo=appveyor\n    :target: https://ci.appveyor.com/project/dateutil/dateutil\n    :alt: appveyor build status\n\n.. |pipelines| image:: https://dev.azure.com/pythondateutilazure/dateutil/_apis/build/status/dateutil.dateutil?branchName=master\n    :target: https://dev.azure.com/pythondateutilazure/dateutil/_build/latest?definitionId=1&branchName=master\n    :alt: azure pipelines build status\n\n.. |coverage| image:: https://codecov.io/gh/dateutil/dateutil/branch/master/graphs/badge.svg?branch=master\n    :target: https://codecov.io/gh/dateutil/dateutil?branch=master\n    :alt: Code coverage\n\n.. |gitter| image:: https://badges.gitter.im/dateutil/dateutil.svg\n   :alt: Join the chat at https://gitter.im/dateutil/dateutil\n   :target: https://gitter.im/dateutil/dateutil\n\n.. |licence| image:: https://img.shields.io/pypi/l/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: licence\n\n.. |readthedocs| image:: https://img.shields.io/readthedocs/dateutil/latest.svg?style=flat-square&label=Read%20the%20Docs\n   :alt: Read the documentation at https://dateutil.readthedocs.io/en/latest/\n   :target: https://dateutil.readthedocs.io/en/latest/\n\nThe `dateutil` module provides powerful extensions to\nthe standard `datetime` module, available in Python.\n\nInstallation\n============\n`dateutil` can be installed from PyPI using `pip` (note that the package name is\ndifferent from the importable name)::\n\n    pip install python-dateutil\n\nDownload\n========\ndateutil is available on PyPI\nhttps://pypi.org/project/python-dateutil/\n\nThe documentation is hosted at:\nhttps://dateutil.readthedocs.io/en/stable/\n\nCode\n====\nThe code and issue tracker are hosted on GitHub:\nhttps://github.com/dateutil/dateutil/\n\nFeatures\n========\n\n* Computing of relative deltas (next month, next year,\n  next Monday, last week of month, etc);\n* Computing of relative deltas between two given\n  date and/or datetime objects;\n* Computing of dates based on very flexible recurrence rules,\n  using a superset of the `iCalendar <https://www.ietf.org/rfc/rfc2445.txt>`_\n  specification. Parsing of RFC strings is supported as well.\n* Generic parsing of dates in almost any string format;\n* Timezone (tzinfo) implementations for tzfile(5) format\n  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ\n  environment string (in all known formats), iCalendar\n  format files, given ranges (with help from relative deltas),\n  local machine timezone, fixed offset timezone, UTC timezone,\n  and Windows registry-based time zones.\n* Internal up-to-date world timezone information based on\n  Olson's database.\n* Computing of Easter Sunday dates for any given year,\n  using Western, Orthodox or Julian algorithms;\n* A comprehensive test suite.\n\nQuick example\n=============\nHere's a snapshot, just to give an idea about the power of the\npackage. For more examples, look at the documentation.\n\nSuppose you want to know how much time is left, in\nyears/months/days/etc, before the next easter happening on a\nyear with a Friday 13th in August, and you want to get today's\ndate out of the \"date\" unix system command. Here is the code:\n\n.. code-block:: python3\n\n    >>> from dateutil.relativedelta import *\n    >>> from dateutil.easter import *\n    >>> from dateutil.rrule import *\n    >>> from dateutil.parser import *\n    >>> from datetime import *\n    >>> now = parse(\"Sat Oct 11 17:13:46 UTC 2003\")\n    >>> today = now.date()\n    >>> year = rrule(YEARLY,dtstart=now,bymonth=8,bymonthday=13,byweekday=FR)[0].year\n    >>> rdelta = relativedelta(easter(year), today)\n    >>> print(\"Today is: %s\" % today)\n    Today is: 2003-10-11\n    >>> print(\"Year with next Aug 13th on a Friday is: %s\" % year)\n    Year with next Aug 13th on a Friday is: 2004\n    >>> print(\"How far is the Easter of that year: %s\" % rdelta)\n    How far is the Easter of that year: relativedelta(months=+6)\n    >>> print(\"And the Easter of that year is: %s\" % (today+rdelta))\n    And the Easter of that year is: 2004-04-11\n\nBeing exactly 6 months ahead was **really** a coincidence :)\n\nContributing\n============\n\nWe welcome many types of contributions - bug reports, pull requests (code, infrastructure or documentation fixes). For more information about how to contribute to the project, see the ``CONTRIBUTING.md`` file in the repository.\n\n\nAuthor\n======\nThe dateutil module was written by Gustavo Niemeyer <gustavo@niemeyer.net>\nin 2003.\n\nIt is maintained by:\n\n* Gustavo Niemeyer <gustavo@niemeyer.net> 2003-2011\n* Tomi PievilÃ¤inen <tomi.pievilainen@iki.fi> 2012-2014\n* Yaron de Leeuw <me@jarondl.net> 2014-2016\n* Paul Ganssle <paul@ganssle.io> 2015-\n\nStarting with version 2.4.1 and running until 2.8.2, all source and binary\ndistributions will be signed by a PGP key that has, at the very least, been\nsigned by the key which made the previous release. A table of release signing\nkeys can be found below:\n\n===========  ============================\nReleases     Signing key fingerprint\n===========  ============================\n2.4.1-2.8.2  `6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB`_\n===========  ============================\n\nNew releases *may* have signed tags, but binary and source distributions\nuploaded to PyPI will no longer have GPG signatures attached.\n\nContact\n=======\nOur mailing list is available at `dateutil@python.org <https://mail.python.org/mailman/listinfo/dateutil>`_. As it is hosted by the PSF, it is subject to the `PSF code of\nconduct <https://www.python.org/psf/conduct/>`_.\n\nLicense\n=======\n\nAll contributions after December 1, 2017 released under dual license - either `Apache 2.0 License <https://www.apache.org/licenses/LICENSE-2.0>`_ or the `BSD 3-Clause License <https://opensource.org/licenses/BSD-3-Clause>`_. Contributions before December 1, 2017 - except those those explicitly relicensed - are released only under the BSD 3-Clause License.\n\n\n.. _6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB:\n   https://pgp.mit.edu/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/dateutil/dateutil",
        "author": "Gustavo Niemeyer",
        "author_email": "gustavo@niemeyer.net",
        "maintainer": "Paul Ganssle",
        "maintainer_email": "dateutil@python.org",
        "license": "Dual License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "six >=1.5"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,>=2.7",
        "project_url": [
          "Documentation, https://dateutil.readthedocs.io/en/stable/",
          "Source, https://github.com/dateutil/dateutil"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5ddf76296dd8c44c26eb8f4b6f35488f3ccbf6fbbd7adee0b7262d43f0ec2f00",
          "hashes": {
            "sha256": "5ddf76296dd8c44c26eb8f4b6f35488f3ccbf6fbbd7adee0b7262d43f0ec2f00"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "pytz",
        "version": "2025.2",
        "platform": [
          "Independent"
        ],
        "summary": "World timezone definitions, modern and historical",
        "description": "pytz - World Timezone Definitions for Python\n============================================\n\n:Author: Stuart Bishop <stuart@stuartbishop.net>\n\nIntroduction\n~~~~~~~~~~~~\n\npytz brings the Olson tz database into Python. This library allows\naccurate and cross platform timezone calculations using Python 2.4\nor higher. It also solves the issue of ambiguous times at the end\nof daylight saving time, which you can read more about in the Python\nLibrary Reference (``datetime.tzinfo``).\n\nAlmost all of the Olson timezones are supported.\n\n.. note::\n\n    Projects using Python 3.9 or later should be using the support\n    now included as part of the standard library, and third party\n    packages work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n    pytz offers no advantages beyond backwards compatibility with\n    code written for earlier versions of Python.\n\n.. note::\n\n    This library differs from the documented Python API for\n    tzinfo implementations; if you want to create local wallclock\n    times you need to use the ``localize()`` method documented in this\n    document. In addition, if you perform date arithmetic on local\n    times that cross DST boundaries, the result may be in an incorrect\n    timezone (ie. subtract 1 minute from 2002-10-27 1:00 EST and you get\n    2002-10-27 0:59 EST instead of the correct 2002-10-27 1:59 EDT). A\n    ``normalize()`` method is provided to correct this. Unfortunately these\n    issues cannot be resolved without modifying the Python datetime\n    implementation (see PEP-431).\n\n\nInstallation\n~~~~~~~~~~~~\n\nThis package can either be installed using ``pip`` or from a tarball using the\nstandard Python distutils.\n\nIf you are installing using ``pip``, you don't need to download anything as the\nlatest version will be downloaded for you from PyPI::\n\n    pip install pytz\n\nIf you are installing from a tarball, run the following command as an\nadministrative user::\n\n    python setup.py install\n\n\npytz for Enterprise\n~~~~~~~~~~~~~~~~~~~\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of pytz and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-pytz?utm_source=pypi-pytz&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_.\n\n\nExample & Usage\n~~~~~~~~~~~~~~~\n\nLocalized times and date arithmetic\n-----------------------------------\n\n>>> from datetime import datetime, timedelta\n>>> from pytz import timezone\n>>> import pytz\n>>> utc = pytz.utc\n>>> utc.zone\n'UTC'\n>>> eastern = timezone('US/Eastern')\n>>> eastern.zone\n'US/Eastern'\n>>> amsterdam = timezone('Europe/Amsterdam')\n>>> fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n\nThis library only supports two ways of building a localized time. The\nfirst is to use the ``localize()`` method provided by the pytz library.\nThis is used to localize a naive datetime (datetime with no timezone\ninformation):\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 6, 0, 0))\n>>> print(loc_dt.strftime(fmt))\n2002-10-27 06:00:00 EST-0500\n\nThe second way of building a localized time is by converting an existing\nlocalized time using the standard ``astimezone()`` method:\n\n>>> ams_dt = loc_dt.astimezone(amsterdam)\n>>> ams_dt.strftime(fmt)\n'2002-10-27 12:00:00 CET+0100'\n\nUnfortunately using the tzinfo argument of the standard datetime\nconstructors ''does not work'' with pytz for many timezones.\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=amsterdam).strftime(fmt)  # /!\\ Does not work this way!\n'2002-10-27 12:00:00 LMT+0018'\n\nIt is safe for timezones without daylight saving transitions though, such\nas UTC:\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=pytz.utc).strftime(fmt)  # /!\\ Not recommended except for UTC\n'2002-10-27 12:00:00 UTC+0000'\n\nThe preferred way of dealing with times is to always work in UTC,\nconverting to localtime only when generating output to be read\nby humans.\n\n>>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)\n>>> loc_dt = utc_dt.astimezone(eastern)\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:00:00 EST-0500'\n\nThis library also allows you to do date arithmetic using local\ntimes, although it is more complicated than working in UTC as you\nneed to use the ``normalize()`` method to handle daylight saving time\nand other timezone transitions. In this example, ``loc_dt`` is set\nto the instant when daylight saving time ends in the US/Eastern\ntimezone.\n\n>>> before = loc_dt - timedelta(minutes=10)\n>>> before.strftime(fmt)\n'2002-10-27 00:50:00 EST-0500'\n>>> eastern.normalize(before).strftime(fmt)\n'2002-10-27 01:50:00 EDT-0400'\n>>> after = eastern.normalize(before + timedelta(minutes=20))\n>>> after.strftime(fmt)\n'2002-10-27 01:10:00 EST-0500'\n\nCreating local times is also tricky, and the reason why working with\nlocal times is not recommended. Unfortunately, you cannot just pass\na ``tzinfo`` argument when constructing a datetime (see the next\nsection for more details)\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 0)\n>>> dt1 = eastern.localize(dt, is_dst=True)\n>>> dt1.strftime(fmt)\n'2002-10-27 01:30:00 EDT-0400'\n>>> dt2 = eastern.localize(dt, is_dst=False)\n>>> dt2.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nConverting between timezones is more easily done, using the\nstandard astimezone method.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = utc_dt.astimezone(au_tz)\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> utc_dt == utc_dt2\nTrue\n\nYou can take shortcuts when dealing with the UTC side of timezone\nconversions. ``normalize()`` and ``localize()`` are not really\nnecessary when there are no daylight saving time transitions to\ndeal with.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n\n\n``tzinfo`` API\n--------------\n\nThe ``tzinfo`` instances returned by the ``timezone()`` function have\nbeen extended to cope with ambiguous times by adding an ``is_dst``\nparameter to the ``utcoffset()``, ``dst()`` && ``tzname()`` methods.\n\n>>> tz = timezone('America/St_Johns')\n\n>>> normal = datetime(2009, 9, 1)\n>>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\nThe ``is_dst`` parameter is ignored for most timestamps. It is only used\nduring DST transition ambiguous periods to resolve that ambiguity.\n\n>>> print(tz.utcoffset(normal, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(normal, is_dst=True))\n1:00:00\n>>> tz.tzname(normal, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(ambiguous, is_dst=True))\n1:00:00\n>>> tz.tzname(ambiguous, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(normal, is_dst=False))\n-1 day, 21:30:00\n>>> tz.dst(normal, is_dst=False).seconds\n3600\n>>> tz.tzname(normal, is_dst=False)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=False))\n-1 day, 20:30:00\n>>> tz.dst(ambiguous, is_dst=False)\ndatetime.timedelta(0)\n>>> tz.tzname(ambiguous, is_dst=False)\n'NST'\n\nIf ``is_dst`` is not specified, ambiguous timestamps will raise\nan ``pytz.exceptions.AmbiguousTimeError`` exception.\n\n>>> print(tz.utcoffset(normal))\n-1 day, 21:30:00\n>>> print(tz.dst(normal))\n1:00:00\n>>> tz.tzname(normal)\n'NDT'\n\n>>> import pytz.exceptions\n>>> try:\n...     tz.utcoffset(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.dst(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.tzname(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n\n\nProblems with Localtime\n~~~~~~~~~~~~~~~~~~~~~~~\n\nThe major problem we have to deal with is that certain datetimes\nmay occur twice in a year. For example, in the US/Eastern timezone\non the last Sunday morning in October, the following sequence\nhappens:\n\n    - 01:00 EDT occurs\n    - 1 hour later, instead of 2:00am the clock is turned back 1 hour\n      and 01:00 happens again (this time 01:00 EST)\n\nIn fact, every instant between 01:00 and 02:00 occurs twice. This means\nthat if you try and create a time in the 'US/Eastern' timezone\nthe standard datetime syntax, there is no way to specify if you meant\nbefore of after the end-of-daylight-saving-time transition. Using the\npytz custom syntax, the best you can do is make an educated guess:\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 1, 30, 00))\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nAs you can see, the system has chosen one for you and there is a 50%\nchance of it being out by one hour. For some applications, this does\nnot matter. However, if you are trying to schedule meetings with people\nin different timezones or analyze log files it is not acceptable.\n\nThe best and simplest solution is to stick with using UTC.  The pytz\npackage encourages using UTC for internal timezone representation by\nincluding a special UTC implementation based on the standard Python\nreference implementation in the Python documentation.\n\nThe UTC timezone unpickles to be the same instance, and pickles to a\nsmaller size than other pytz tzinfo instances.  The UTC implementation\ncan be obtained as pytz.utc, pytz.UTC, or pytz.timezone('UTC').\n\n>>> import pickle, pytz\n>>> dt = datetime(2005, 3, 1, 14, 13, 21, tzinfo=utc)\n>>> naive = dt.replace(tzinfo=None)\n>>> p = pickle.dumps(dt, 1)\n>>> naive_p = pickle.dumps(naive, 1)\n>>> len(p) - len(naive_p)\n17\n>>> new = pickle.loads(p)\n>>> new == dt\nTrue\n>>> new is dt\nFalse\n>>> new.tzinfo is dt.tzinfo\nTrue\n>>> pytz.utc is pytz.UTC is pytz.timezone('UTC')\nTrue\n\nNote that some other timezones are commonly thought of as the same (GMT,\nGreenwich, Universal, etc.). The definition of UTC is distinct from these\nother timezones, and they are not equivalent. For this reason, they will\nnot compare the same in Python.\n\n>>> utc == pytz.timezone('GMT')\nFalse\n\nSee the section `What is UTC`_, below.\n\nIf you insist on working with local times, this library provides a\nfacility for constructing them unambiguously:\n\n>>> loc_dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> est_dt = eastern.localize(loc_dt, is_dst=True)\n>>> edt_dt = eastern.localize(loc_dt, is_dst=False)\n>>> print(est_dt.strftime(fmt) + ' / ' + edt_dt.strftime(fmt))\n2002-10-27 01:30:00 EDT-0400 / 2002-10-27 01:30:00 EST-0500\n\nIf you pass None as the is_dst flag to localize(), pytz will refuse to\nguess and raise exceptions if you try to build ambiguous or non-existent\ntimes.\n\nFor example, 1:30am on 27th Oct 2002 happened twice in the US/Eastern\ntimezone when the clocks where put back at the end of Daylight Saving\nTime:\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % dt)\npytz.exceptions.AmbiguousTimeError: 2002-10-27 01:30:00\n\nSimilarly, 2:30am on 7th April 2002 never happened at all in the\nUS/Eastern timezone, as the clocks where put forward at 2:00am skipping\nthe entire hour:\n\n>>> dt = datetime(2002, 4, 7, 2, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.NonExistentTimeError:\n...     print('pytz.exceptions.NonExistentTimeError: %s' % dt)\npytz.exceptions.NonExistentTimeError: 2002-04-07 02:30:00\n\nBoth of these exceptions share a common base class to make error handling\neasier:\n\n>>> isinstance(pytz.AmbiguousTimeError(), pytz.InvalidTimeError)\nTrue\n>>> isinstance(pytz.NonExistentTimeError(), pytz.InvalidTimeError)\nTrue\n\n\nA special case is where countries change their timezone definitions\nwith no daylight savings time switch. For example, in 1915 Warsaw\nswitched from Warsaw time to Central European time with no daylight savings\ntransition. So at the stroke of midnight on August 5th 1915 the clocks\nwere wound back 24 minutes creating an ambiguous time period that cannot\nbe specified without referring to the timezone abbreviation or the\nactual UTC offset. In this case midnight happened twice, neither time\nduring a daylight saving time period. pytz handles this transition by\ntreating the ambiguous period before the switch as daylight savings\ntime, and the ambiguous period after as standard time.\n\n\n>>> warsaw = pytz.timezone('Europe/Warsaw')\n>>> amb_dt1 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=True)\n>>> amb_dt1.strftime(fmt)\n'1915-08-04 23:59:59 WMT+0124'\n>>> amb_dt2 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=False)\n>>> amb_dt2.strftime(fmt)\n'1915-08-04 23:59:59 CET+0100'\n>>> switch_dt = warsaw.localize(datetime(1915, 8, 5, 00, 00, 00), is_dst=False)\n>>> switch_dt.strftime(fmt)\n'1915-08-05 00:00:00 CET+0100'\n>>> str(switch_dt - amb_dt1)\n'0:24:01'\n>>> str(switch_dt - amb_dt2)\n'0:00:01'\n\nThe best way of creating a time during an ambiguous time period is\nby converting from another timezone such as UTC:\n\n>>> utc_dt = datetime(1915, 8, 4, 22, 36, tzinfo=pytz.utc)\n>>> utc_dt.astimezone(warsaw).strftime(fmt)\n'1915-08-04 23:36:00 CET+0100'\n\nThe standard Python way of handling all these ambiguities is not to\nhandle them, such as demonstrated in this example using the US/Eastern\ntimezone definition from the Python documentation (Note that this\nimplementation only works for dates between 1987 and 2006 - it is\nincluded for tests only!):\n\n>>> from pytz.reference import Eastern # pytz.reference only for tests\n>>> dt = datetime(2002, 10, 27, 0, 30, tzinfo=Eastern)\n>>> str(dt)\n'2002-10-27 00:30:00-04:00'\n>>> str(dt + timedelta(hours=1))\n'2002-10-27 01:30:00-05:00'\n>>> str(dt + timedelta(hours=2))\n'2002-10-27 02:30:00-05:00'\n>>> str(dt + timedelta(hours=3))\n'2002-10-27 03:30:00-05:00'\n\nNotice the first two results? At first glance you might think they are\ncorrect, but taking the UTC offset into account you find that they are\nactually two hours appart instead of the 1 hour we asked for.\n\n>>> from pytz.reference import UTC # pytz.reference only for tests\n>>> str(dt.astimezone(UTC))\n'2002-10-27 04:30:00+00:00'\n>>> str((dt + timedelta(hours=1)).astimezone(UTC))\n'2002-10-27 06:30:00+00:00'\n\n\nCountry Information\n~~~~~~~~~~~~~~~~~~~\n\nA mechanism is provided to access the timezones commonly in use\nfor a particular country, looked up using the ISO 3166 country code.\nIt returns a list of strings that can be used to retrieve the relevant\ntzinfo instance using ``pytz.timezone()``:\n\n>>> print(' '.join(pytz.country_timezones['nz']))\nPacific/Auckland Pacific/Chatham\n\nThe Olson database comes with a ISO 3166 country code to English country\nname mapping that pytz exposes as a dictionary:\n\n>>> print(pytz.country_names['nz'])\nNew Zealand\n\n\nWhat is UTC\n~~~~~~~~~~~\n\n'UTC' is `Coordinated Universal Time`_. It is a successor to, but distinct\nfrom, Greenwich Mean Time (GMT) and the various definitions of Universal\nTime. UTC is now the worldwide standard for regulating clocks and time\nmeasurement.\n\nAll other timezones are defined relative to UTC, and include offsets like\nUTC+0800 - hours to add or subtract from UTC to derive the local time. No\ndaylight saving time occurs in UTC, making it a useful timezone to perform\ndate arithmetic without worrying about the confusion and ambiguities caused\nby daylight saving time transitions, your country changing its timezone, or\nmobile computers that roam through multiple timezones.\n\n..  _Coordinated Universal Time: https://en.wikipedia.org/wiki/Coordinated_Universal_Time\n\n\nHelpers\n~~~~~~~\n\nThere are two lists of timezones provided.\n\n``all_timezones`` is the exhaustive list of the timezone names that can\nbe used.\n\n>>> from pytz import all_timezones\n>>> len(all_timezones) >= 500\nTrue\n>>> 'Etc/Greenwich' in all_timezones\nTrue\n\n``common_timezones`` is a list of useful, current timezones. It doesn't\ncontain deprecated zones or historical zones, except for a few I've\ndeemed in common usage, such as US/Eastern (open a bug report if you\nthink other timezones are deserving of being included here). It is also\na sequence of strings.\n\n>>> from pytz import common_timezones\n>>> len(common_timezones) < len(all_timezones)\nTrue\n>>> 'Etc/Greenwich' in common_timezones\nFalse\n>>> 'Australia/Melbourne' in common_timezones\nTrue\n>>> 'US/Eastern' in common_timezones\nTrue\n>>> 'Canada/Eastern' in common_timezones\nTrue\n>>> 'Australia/Yancowinna' in all_timezones\nTrue\n>>> 'Australia/Yancowinna' in common_timezones\nFalse\n\nBoth ``common_timezones`` and ``all_timezones`` are alphabetically\nsorted:\n\n>>> common_timezones_dupe = common_timezones[:]\n>>> common_timezones_dupe.sort()\n>>> common_timezones == common_timezones_dupe\nTrue\n>>> all_timezones_dupe = all_timezones[:]\n>>> all_timezones_dupe.sort()\n>>> all_timezones == all_timezones_dupe\nTrue\n\n``all_timezones`` and ``common_timezones`` are also available as sets.\n\n>>> from pytz import all_timezones_set, common_timezones_set\n>>> 'US/Eastern' in all_timezones_set\nTrue\n>>> 'US/Eastern' in common_timezones_set\nTrue\n>>> 'Australia/Victoria' in common_timezones_set\nFalse\n\nYou can also retrieve lists of timezones used by particular countries\nusing the ``country_timezones()`` function. It requires an ISO-3166\ntwo letter country code.\n\n>>> from pytz import country_timezones\n>>> print(' '.join(country_timezones('ch')))\nEurope/Zurich\n>>> print(' '.join(country_timezones('CH')))\nEurope/Zurich\n\n\nInternationalization - i18n/l10n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPytz is an interface to the IANA database, which uses ASCII names. The `Unicode  Consortium's Unicode Locales (CLDR) <http://cldr.unicode.org>`_\nproject provides translations. Python packages such as\n`Babel <https://babel.pocoo.org/en/latest/api/dates.html#timezone-functionality>`_\nand Thomas Khyn's `l18n <https://pypi.org/project/l18n/>`_ package can be used\nto access these translations from Python.\n\n\nLicense\n~~~~~~~\n\nMIT license.\n\nThis code is also available as part of Zope 3 under the Zope Public\nLicense,  Version 2.1 (ZPL).\n\nI'm happy to relicense this code if necessary for inclusion in other\nopen source projects.\n\n\nLatest Versions\n~~~~~~~~~~~~~~~\n\nThis package will be updated after releases of the Olson timezone\ndatabase.  The latest version can be downloaded from the `Python Package\nIndex <https://pypi.org/project/pytz/>`_.  The code that is used\nto generate this distribution is hosted on Github and available\nusing git::\n\n    git clone https://github.com/stub42/pytz.git\n\nAnnouncements of new releases are made on\n`Launchpad <https://launchpad.net/pytz>`_, and the\n`Atom feed <http://feeds.launchpad.net/pytz/announcements.atom>`_\nhosted there.\n\n\nBugs, Feature Requests & Patches\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBugs should be reported on `Github <https://github.com/stub42/pytz/issues>`_.\nFeature requests are unlikely to be considered, and efforts instead directed\nto timezone support now built into Python or packages that work with it.\n\n\nSecurity Issues\n~~~~~~~~~~~~~~~\n\nReports about security issues can be made via `Tidelift <https://tidelift.com/security>`_.\n\n\nIssues & Limitations\n~~~~~~~~~~~~~~~~~~~~\n\n- This project is in maintenance mode. Projects using Python 3.9 or later\n  are best served by using the timezone functionaly now included in core\n  Python and packages that work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n\n- Offsets from UTC are rounded to the nearest whole minute, so timezones\n  such as Europe/Amsterdam pre 1937 will be up to 30 seconds out. This\n  was a limitation of the Python datetime library.\n\n- If you think a timezone definition is incorrect, I probably can't fix\n  it. pytz is a direct translation of the Olson timezone database, and\n  changes to the timezone definitions need to be made to this source.\n  If you find errors they should be reported to the time zone mailing\n  list, linked from http://www.iana.org/time-zones.\n\n\nFurther Reading\n~~~~~~~~~~~~~~~\n\nMore info than you want to know about timezones:\nhttps://data.iana.org/time-zones/tz-link.html\n\n\nContact\n~~~~~~~\n\nStuart Bishop <stuart@stuartbishop.net>\n",
        "keywords": [
          "timezone",
          "tzinfo",
          "datetime",
          "olson",
          "time"
        ],
        "home_page": "http://pythonhosted.org/pytz",
        "download_url": "https://pypi.org/project/pytz/",
        "author": "Stuart Bishop",
        "author_email": "stuart@stuartbishop.net",
        "maintainer": "Stuart Bishop",
        "maintainer_email": "stuart@stuartbishop.net",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.4",
          "Programming Language :: Python :: 2.5",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.1",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/97/c9/39d5b874e8b28845e4ec2202b5da735d0199dbe5b8fb85f91398814a9a46/pyyaml-6.0.3-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=79005a0d97d5ddabfeeea4cf676af11e647e41d81c9a7722a193022accdb6b7c",
          "hashes": {
            "sha256": "79005a0d97d5ddabfeeea4cf676af11e647e41d81c9a7722a193022accdb6b7c"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "PyYAML",
        "version": "6.0.3",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "download-url",
          "home-page",
          "license",
          "license-file",
          "platform",
          "project-url",
          "requires-python",
          "summary"
        ],
        "platform": [
          "Any"
        ],
        "summary": "YAML parser and emitter for Python",
        "description": "YAML is a data serialization format designed for human readability\r\nand interaction with scripting languages.  PyYAML is a YAML parser\r\nand emitter for Python.\r\n\r\nPyYAML features a complete YAML 1.1 parser, Unicode support, pickle\r\nsupport, capable extension API, and sensible error messages.  PyYAML\r\nsupports standard YAML tags and provides Python-specific tags that\r\nallow to represent an arbitrary Python object.\r\n\r\nPyYAML is applicable for a broad range of tasks from complex\r\nconfiguration files to object serialization and persistence.\r\n",
        "home_page": "https://pyyaml.org/",
        "download_url": "https://pypi.org/project/PyYAML/",
        "author": "Kirill Simonov",
        "author_email": "xi@resolvent.net",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Markup"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Bug Tracker, https://github.com/yaml/pyyaml/issues",
          "CI, https://github.com/yaml/pyyaml/actions",
          "Documentation, https://pyyaml.org/wiki/PyYAMLDocumentation",
          "Mailing lists, http://lists.sourceforge.net/lists/listinfo/yaml-core",
          "Source Code, https://github.com/yaml/pyyaml"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/4f/16/5bfbb89e435897bff28cf0352a992ca719d9e55ebf8b629203c96b6ce4f7/regex-2026.1.15-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=febd38857b09867d3ed3f4f1af7d241c5c50362e25ef43034995b77a50df494e",
          "hashes": {
            "sha256": "febd38857b09867d3ed3f4f1af7d241c5c50362e25ef43034995b77a50df494e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "regex",
        "version": "2026.1.15",
        "dynamic": [
          "license-file"
        ],
        "summary": "Alternative regular expression module, to replace re.",
        "description": "Introduction\r\n------------\r\n\r\nThis regex implementation is backwards-compatible with the standard 're' module, but offers additional functionality.\r\n\r\nPython 2\r\n--------\r\n\r\nPython 2 is no longer supported. The last release that supported Python 2 was 2021.11.10.\r\n\r\nPyPy\r\n----\r\n\r\nThis module is targeted at CPython. It expects that all codepoints are the same width, so it won't behave properly with PyPy outside U+0000..U+007F because PyPy stores strings as UTF-8.\r\n\r\nMultithreading\r\n--------------\r\n\r\nThe regex module releases the GIL during matching on instances of the built-in (immutable) string classes, enabling other Python threads to run concurrently. It is also possible to force the regex module to release the GIL during matching by calling the matching methods with the keyword argument ``concurrent=True``. The behaviour is undefined if the string changes during matching, so use it *only* when it is guaranteed that that won't happen.\r\n\r\nUnicode\r\n-------\r\n\r\nThis module supports Unicode 17.0.0. Full Unicode case-folding is supported.\r\n\r\nFlags\r\n-----\r\n\r\nThere are 2 kinds of flag: scoped and global. Scoped flags can apply to only part of a pattern and can be turned on or off; global flags apply to the entire pattern and can only be turned on.\r\n\r\nThe scoped flags are: ``ASCII (?a)``, ``FULLCASE (?f)``, ``IGNORECASE (?i)``, ``LOCALE (?L)``, ``MULTILINE (?m)``, ``DOTALL (?s)``, ``UNICODE (?u)``, ``VERBOSE (?x)``, ``WORD (?w)``.\r\n\r\nThe global flags are: ``BESTMATCH (?b)``, ``ENHANCEMATCH (?e)``, ``POSIX (?p)``, ``REVERSE (?r)``, ``VERSION0 (?V0)``, ``VERSION1 (?V1)``.\r\n\r\nIf neither the ``ASCII``, ``LOCALE`` nor ``UNICODE`` flag is specified, it will default to ``UNICODE`` if the regex pattern is a Unicode string and ``ASCII`` if it's a bytestring.\r\n\r\nThe ``ENHANCEMATCH`` flag makes fuzzy matching attempt to improve the fit of the next match that it finds.\r\n\r\nThe ``BESTMATCH`` flag makes fuzzy matching search for the best match instead of the next match.\r\n\r\nOld vs new behaviour\r\n--------------------\r\n\r\nIn order to be compatible with the re module, this module has 2 behaviours:\r\n\r\n* **Version 0** behaviour (old behaviour, compatible with the re module):\r\n\r\n  Please note that the re module's behaviour may change over time, and I'll endeavour to match that behaviour in version 0.\r\n\r\n  * Indicated by the ``VERSION0`` flag.\r\n\r\n  * Zero-width matches are not handled correctly in the re module before Python 3.7. The behaviour in those earlier versions is:\r\n\r\n    * ``.split`` won't split a string at a zero-width match.\r\n\r\n    * ``.sub`` will advance by one character after a zero-width match.\r\n\r\n  * Inline flags apply to the entire pattern, and they can't be turned off.\r\n\r\n  * Only simple sets are supported.\r\n\r\n  * Case-insensitive matches in Unicode use simple case-folding by default.\r\n\r\n* **Version 1** behaviour (new behaviour, possibly different from the re module):\r\n\r\n  * Indicated by the ``VERSION1`` flag.\r\n\r\n  * Zero-width matches are handled correctly.\r\n\r\n  * Inline flags apply to the end of the group or pattern, and they can be turned off.\r\n\r\n  * Nested sets and set operations are supported.\r\n\r\n  * Case-insensitive matches in Unicode use full case-folding by default.\r\n\r\nIf no version is specified, the regex module will default to ``regex.DEFAULT_VERSION``.\r\n\r\nCase-insensitive matches in Unicode\r\n-----------------------------------\r\n\r\nThe regex module supports both simple and full case-folding for case-insensitive matches in Unicode. Use of full case-folding can be turned on using the ``FULLCASE`` flag. Please note that this flag affects how the ``IGNORECASE`` flag works; the ``FULLCASE`` flag itself does not turn on case-insensitive matching.\r\n\r\nVersion 0 behaviour: the flag is off by default.\r\n\r\nVersion 1 behaviour: the flag is on by default.\r\n\r\nNested sets and set operations\r\n------------------------------\r\n\r\nIt's not possible to support both simple sets, as used in the re module, and nested sets at the same time because of a difference in the meaning of an unescaped ``\"[\"`` in a set.\r\n\r\nFor example, the pattern ``[[a-z]--[aeiou]]`` is treated in the version 0 behaviour (simple sets, compatible with the re module) as:\r\n\r\n* Set containing \"[\" and the letters \"a\" to \"z\"\r\n\r\n* Literal \"--\"\r\n\r\n* Set containing letters \"a\", \"e\", \"i\", \"o\", \"u\"\r\n\r\n* Literal \"]\"\r\n\r\nbut in the version 1 behaviour (nested sets, enhanced behaviour) as:\r\n\r\n* Set which is:\r\n\r\n  * Set containing the letters \"a\" to \"z\"\r\n\r\n* but excluding:\r\n\r\n  * Set containing the letters \"a\", \"e\", \"i\", \"o\", \"u\"\r\n\r\nVersion 0 behaviour: only simple sets are supported.\r\n\r\nVersion 1 behaviour: nested sets and set operations are supported.\r\n\r\nNotes on named groups\r\n---------------------\r\n\r\nAll groups have a group number, starting from 1.\r\n\r\nGroups with the same group name will have the same group number, and groups with a different group name will have a different group number.\r\n\r\nThe same name can be used by more than one group, with later captures 'overwriting' earlier captures. All the captures of the group will be available from the ``captures`` method of the match object.\r\n\r\nGroup numbers will be reused across different branches of a branch reset, eg. ``(?|(first)|(second))`` has only group 1. If groups have different group names then they will, of course, have different group numbers, eg. ``(?|(?P<foo>first)|(?P<bar>second))`` has group 1 (\"foo\") and group 2 (\"bar\").\r\n\r\nIn the regex ``(\\s+)(?|(?P<foo>[A-Z]+)|(\\w+) (?P<foo>[0-9]+)`` there are 2 groups:\r\n\r\n* ``(\\s+)`` is group 1.\r\n\r\n* ``(?P<foo>[A-Z]+)`` is group 2, also called \"foo\".\r\n\r\n* ``(\\w+)`` is group 2 because of the branch reset.\r\n\r\n* ``(?P<foo>[0-9]+)`` is group 2 because it's called \"foo\".\r\n\r\nIf you want to prevent ``(\\w+)`` from being group 2, you need to name it (different name, different group number).\r\n\r\nAdditional features\r\n-------------------\r\n\r\nThe issue numbers relate to the Python bug tracker, except where listed otherwise.\r\n\r\nAdded ``\\p{Horiz_Space}`` and ``\\p{Vert_Space}`` (`GitHub issue 477 <https://github.com/mrabarnett/mrab-regex/issues/477#issuecomment-1216779547>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``\\p{Horiz_Space}`` or ``\\p{H}`` matches horizontal whitespace and ``\\p{Vert_Space}`` or ``\\p{V}`` matches vertical whitespace.\r\n\r\nAdded support for lookaround in conditional pattern (`Hg issue 163 <https://github.com/mrabarnett/mrab-regex/issues/163>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe test of a conditional pattern can be a lookaround.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', '123abc')\r\n  <regex.Match object; span=(0, 3), match='123'>\r\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', 'abc123')\r\n  <regex.Match object; span=(0, 6), match='abc123'>\r\n\r\nThis is not quite the same as putting a lookaround in the first branch of a pair of alternatives.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> print(regex.match(r'(?:(?=\\d)\\d+\\b|\\w+)', '123abc'))\r\n  <regex.Match object; span=(0, 6), match='123abc'>\r\n  >>> print(regex.match(r'(?(?=\\d)\\d+\\b|\\w+)', '123abc'))\r\n  None\r\n\r\nIn the first example, the lookaround matched, but the remainder of the first branch failed to match, and so the second branch was attempted, whereas in the second example, the lookaround matched, and the first branch failed to match, but the second branch was **not** attempted.\r\n\r\nAdded POSIX matching (leftmost longest) (`Hg issue 150 <https://github.com/mrabarnett/mrab-regex/issues/150>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe POSIX standard for regex is to return the leftmost longest match. This can be turned on using the ``POSIX`` flag.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> # Normal matching.\r\n  >>> regex.search(r'Mr|Mrs', 'Mrs')\r\n  <regex.Match object; span=(0, 2), match='Mr'>\r\n  >>> regex.search(r'one(self)?(selfsufficient)?', 'oneselfsufficient')\r\n  <regex.Match object; span=(0, 7), match='oneself'>\r\n  >>> # POSIX matching.\r\n  >>> regex.search(r'(?p)Mr|Mrs', 'Mrs')\r\n  <regex.Match object; span=(0, 3), match='Mrs'>\r\n  >>> regex.search(r'(?p)one(self)?(selfsufficient)?', 'oneselfsufficient')\r\n  <regex.Match object; span=(0, 17), match='oneselfsufficient'>\r\n\r\nNote that it will take longer to find matches because when it finds a match at a certain position, it won't return that immediately, but will keep looking to see if there's another longer match there.\r\n\r\nAdded ``(?(DEFINE)...)`` (`Hg issue 152 <https://github.com/mrabarnett/mrab-regex/issues/152>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nIf there's no group called \"DEFINE\", then ... will be ignored except that any groups defined within it can be called and that the normal rules for numbering groups still apply.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.search(r'(?(DEFINE)(?P<quant>\\d+)(?P<item>\\w+))(?&quant) (?&item)', '5 elephants')\r\n  <regex.Match object; span=(0, 11), match='5 elephants'>\r\n\r\nAdded ``(*PRUNE)``, ``(*SKIP)`` and ``(*FAIL)`` (`Hg issue 153 <https://github.com/mrabarnett/mrab-regex/issues/153>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``(*PRUNE)`` discards the backtracking info up to that point. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\r\n\r\n``(*SKIP)`` is similar to ``(*PRUNE)``, except that it also sets where in the text the next attempt to match will start. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\r\n\r\n``(*FAIL)`` causes immediate backtracking. ``(*F)`` is a permitted abbreviation.\r\n\r\nAdded ``\\K`` (`Hg issue 151 <https://github.com/mrabarnett/mrab-regex/issues/151>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nKeeps the part of the entire match after the position where ``\\K`` occurred; the part before it is discarded.\r\n\r\nIt does not affect what groups return.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.search(r'(\\w\\w\\K\\w\\w\\w)', 'abcdef')\r\n  >>> m[0]\r\n  'cde'\r\n  >>> m[1]\r\n  'abcde'\r\n  >>>\r\n  >>> m = regex.search(r'(?r)(\\w\\w\\K\\w\\w\\w)', 'abcdef')\r\n  >>> m[0]\r\n  'bc'\r\n  >>> m[1]\r\n  'bcdef'\r\n\r\nAdded capture subscripting for ``expandf`` and ``subf``/``subfn`` (`Hg issue 133 <https://github.com/mrabarnett/mrab-regex/issues/133>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nYou can use subscripting to get the captures of a repeated group.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.match(r\"(\\w)+\", \"abc\")\r\n  >>> m.expandf(\"{1}\")\r\n  'c'\r\n  >>> m.expandf(\"{1[0]} {1[1]} {1[2]}\")\r\n  'a b c'\r\n  >>> m.expandf(\"{1[-1]} {1[-2]} {1[-3]}\")\r\n  'c b a'\r\n  >>>\r\n  >>> m = regex.match(r\"(?P<letter>\\w)+\", \"abc\")\r\n  >>> m.expandf(\"{letter}\")\r\n  'c'\r\n  >>> m.expandf(\"{letter[0]} {letter[1]} {letter[2]}\")\r\n  'a b c'\r\n  >>> m.expandf(\"{letter[-1]} {letter[-2]} {letter[-3]}\")\r\n  'c b a'\r\n\r\nAdded support for referring to a group by number using ``(?P=...)``\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThis is in addition to the existing ``\\g<...>``.\r\n\r\nFixed the handling of locale-sensitive regexes\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe ``LOCALE`` flag is intended for legacy code and has limited support. You're still recommended to use Unicode instead.\r\n\r\nAdded partial matches (`Hg issue 102 <https://github.com/mrabarnett/mrab-regex/issues/102>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA partial match is one that matches up to the end of string, but that string has been truncated and you want to know whether a complete match could be possible if the string had not been truncated.\r\n\r\nPartial matches are supported by ``match``, ``search``, ``fullmatch`` and ``finditer`` with the ``partial`` keyword argument.\r\n\r\nMatch objects have a ``partial`` attribute, which is ``True`` if it's a partial match.\r\n\r\nFor example, if you wanted a user to enter a 4-digit number and check it character by character as it was being entered:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> pattern = regex.compile(r'\\d{4}')\r\n\r\n  >>> # Initially, nothing has been entered:\r\n  >>> print(pattern.fullmatch('', partial=True))\r\n  <regex.Match object; span=(0, 0), match='', partial=True>\r\n\r\n  >>> # An empty string is OK, but it's only a partial match.\r\n  >>> # The user enters a letter:\r\n  >>> print(pattern.fullmatch('a', partial=True))\r\n  None\r\n  >>> # It'll never match.\r\n\r\n  >>> # The user deletes that and enters a digit:\r\n  >>> print(pattern.fullmatch('1', partial=True))\r\n  <regex.Match object; span=(0, 1), match='1', partial=True>\r\n  >>> # It matches this far, but it's only a partial match.\r\n\r\n  >>> # The user enters 2 more digits:\r\n  >>> print(pattern.fullmatch('123', partial=True))\r\n  <regex.Match object; span=(0, 3), match='123', partial=True>\r\n  >>> # It matches this far, but it's only a partial match.\r\n\r\n  >>> # The user enters another digit:\r\n  >>> print(pattern.fullmatch('1234', partial=True))\r\n  <regex.Match object; span=(0, 4), match='1234'>\r\n  >>> # It's a complete match.\r\n\r\n  >>> # If the user enters another digit:\r\n  >>> print(pattern.fullmatch('12345', partial=True))\r\n  None\r\n  >>> # It's no longer a match.\r\n\r\n  >>> # This is a partial match:\r\n  >>> pattern.match('123', partial=True).partial\r\n  True\r\n\r\n  >>> # This is a complete match:\r\n  >>> pattern.match('1233', partial=True).partial\r\n  False\r\n\r\n``*`` operator not working correctly with sub() (`Hg issue 106 <https://github.com/mrabarnett/mrab-regex/issues/106>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nSometimes it's not clear how zero-width matches should be handled. For example, should ``.*`` match 0 characters directly after matching >0 characters?\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.sub('.*', 'x', 'test')\r\n  'xx'\r\n  >>> regex.sub('.*?', '|', 'test')\r\n  '|||||||||'\r\n\r\nAdded ``capturesdict`` (`Hg issue 86 <https://github.com/mrabarnett/mrab-regex/issues/86>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``capturesdict`` is a combination of ``groupdict`` and ``captures``:\r\n\r\n``groupdict`` returns a dict of the named groups and the last capture of those groups.\r\n\r\n``captures`` returns a list of all the captures of a group\r\n\r\n``capturesdict`` returns a dict of the named groups and lists of all the captures of those groups.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.match(r\"(?:(?P<word>\\w+) (?P<digits>\\d+)\\n)+\", \"one 1\\ntwo 2\\nthree 3\\n\")\r\n  >>> m.groupdict()\r\n  {'word': 'three', 'digits': '3'}\r\n  >>> m.captures(\"word\")\r\n  ['one', 'two', 'three']\r\n  >>> m.captures(\"digits\")\r\n  ['1', '2', '3']\r\n  >>> m.capturesdict()\r\n  {'word': ['one', 'two', 'three'], 'digits': ['1', '2', '3']}\r\n\r\nAdded ``allcaptures`` and ``allspans`` (`Git issue 474 <https://github.com/mrabarnett/mrab-regex/issues/474>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``allcaptures`` returns a list of all the captures of all the groups.\r\n\r\n``allspans`` returns a list of all the spans of the all captures of all the groups.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.match(r\"(?:(?P<word>\\w+) (?P<digits>\\d+)\\n)+\", \"one 1\\ntwo 2\\nthree 3\\n\")\r\n  >>> m.allcaptures()\r\n  (['one 1\\ntwo 2\\nthree 3\\n'], ['one', 'two', 'three'], ['1', '2', '3'])\r\n  >>> m.allspans()\r\n  ([(0, 20)], [(0, 3), (6, 9), (12, 17)], [(4, 5), (10, 11), (18, 19)])\r\n\r\nAllow duplicate names of groups (`Hg issue 87 <https://github.com/mrabarnett/mrab-regex/issues/87>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nGroup names can be duplicated.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> # With optional groups:\r\n  >>>\r\n  >>> # Both groups capture, the second capture 'overwriting' the first.\r\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or second\")\r\n  >>> m.group(\"item\")\r\n  'second'\r\n  >>> m.captures(\"item\")\r\n  ['first', 'second']\r\n  >>> # Only the second group captures.\r\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \" or second\")\r\n  >>> m.group(\"item\")\r\n  'second'\r\n  >>> m.captures(\"item\")\r\n  ['second']\r\n  >>> # Only the first group captures.\r\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or \")\r\n  >>> m.group(\"item\")\r\n  'first'\r\n  >>> m.captures(\"item\")\r\n  ['first']\r\n  >>>\r\n  >>> # With mandatory groups:\r\n  >>>\r\n  >>> # Both groups capture, the second capture 'overwriting' the first.\r\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)?\", \"first or second\")\r\n  >>> m.group(\"item\")\r\n  'second'\r\n  >>> m.captures(\"item\")\r\n  ['first', 'second']\r\n  >>> # Again, both groups capture, the second capture 'overwriting' the first.\r\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \" or second\")\r\n  >>> m.group(\"item\")\r\n  'second'\r\n  >>> m.captures(\"item\")\r\n  ['', 'second']\r\n  >>> # And yet again, both groups capture, the second capture 'overwriting' the first.\r\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \"first or \")\r\n  >>> m.group(\"item\")\r\n  ''\r\n  >>> m.captures(\"item\")\r\n  ['first', '']\r\n\r\nAdded ``fullmatch`` (`issue #16203 <https://bugs.python.org/issue16203>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``fullmatch`` behaves like ``match``, except that it must match all of the string.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> print(regex.fullmatch(r\"abc\", \"abc\").span())\r\n  (0, 3)\r\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\"))\r\n  None\r\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\", endpos=3).span())\r\n  (0, 3)\r\n  >>> print(regex.fullmatch(r\"abc\", \"xabcy\", pos=1, endpos=4).span())\r\n  (1, 4)\r\n  >>>\r\n  >>> regex.match(r\"a.*?\", \"abcd\").group(0)\r\n  'a'\r\n  >>> regex.fullmatch(r\"a.*?\", \"abcd\").group(0)\r\n  'abcd'\r\n\r\nAdded ``subf`` and ``subfn``\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``subf`` and ``subfn`` are alternatives to ``sub`` and ``subn`` respectively. When passed a replacement string, they treat it as a format string.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.subf(r\"(\\w+) (\\w+)\", \"{0} => {2} {1}\", \"foo bar\")\r\n  'foo bar => bar foo'\r\n  >>> regex.subf(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"{word2} {word1}\", \"foo bar\")\r\n  'bar foo'\r\n\r\nAdded ``expandf`` to match object\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``expandf`` is an alternative to ``expand``. When passed a replacement string, it treats it as a format string.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.match(r\"(\\w+) (\\w+)\", \"foo bar\")\r\n  >>> m.expandf(\"{0} => {2} {1}\")\r\n  'foo bar => bar foo'\r\n  >>>\r\n  >>> m = regex.match(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"foo bar\")\r\n  >>> m.expandf(\"{word2} {word1}\")\r\n  'bar foo'\r\n\r\nDetach searched string\r\n^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA match object contains a reference to the string that was searched, via its ``string`` attribute. The ``detach_string`` method will 'detach' that string, making it available for garbage collection, which might save valuable memory if that string is very large.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.search(r\"\\w+\", \"Hello world\")\r\n  >>> print(m.group())\r\n  Hello\r\n  >>> print(m.string)\r\n  Hello world\r\n  >>> m.detach_string()\r\n  >>> print(m.group())\r\n  Hello\r\n  >>> print(m.string)\r\n  None\r\n\r\nRecursive patterns (`Hg issue 27 <https://github.com/mrabarnett/mrab-regex/issues/27>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nRecursive and repeated patterns are supported.\r\n\r\n``(?R)`` or ``(?0)`` tries to match the entire regex recursively. ``(?1)``, ``(?2)``, etc, try to match the relevant group.\r\n\r\n``(?&name)`` tries to match the named group.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Tarzan loves Jane\").groups()\r\n  ('Tarzan',)\r\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Jane loves Tarzan\").groups()\r\n  ('Jane',)\r\n\r\n  >>> m = regex.search(r\"(\\w)(?:(?R)|(\\w?))\\1\", \"kayak\")\r\n  >>> m.group(0, 1, 2)\r\n  ('kayak', 'k', None)\r\n\r\nThe first two examples show how the subpattern within the group is reused, but is _not_ itself a group. In other words, ``\"(Tarzan|Jane) loves (?1)\"`` is equivalent to ``\"(Tarzan|Jane) loves (?:Tarzan|Jane)\"``.\r\n\r\nIt's possible to backtrack into a recursed or repeated group.\r\n\r\nYou can't call a group if there is more than one group with that group name or group number (``\"ambiguous group reference\"``).\r\n\r\nThe alternative forms ``(?P>name)`` and ``(?P&name)`` are also supported.\r\n\r\nFull Unicode case-folding is supported\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nIn version 1 behaviour, the regex module uses full case-folding when performing case-insensitive matches in Unicode.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.match(r\"(?iV1)strasse\", \"stra\\N{LATIN SMALL LETTER SHARP S}e\").span()\r\n  (0, 6)\r\n  >>> regex.match(r\"(?iV1)stra\\N{LATIN SMALL LETTER SHARP S}e\", \"STRASSE\").span()\r\n  (0, 7)\r\n\r\nIn version 0 behaviour, it uses simple case-folding for backward compatibility with the re module.\r\n\r\nApproximate \"fuzzy\" matching (`Hg issue 12 <https://github.com/mrabarnett/mrab-regex/issues/12>`_, `Hg issue 41 <https://github.com/mrabarnett/mrab-regex/issues/41>`_, `Hg issue 109 <https://github.com/mrabarnett/mrab-regex/issues/109>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nRegex usually attempts an exact match, but sometimes an approximate, or \"fuzzy\", match is needed, for those cases where the text being searched may contain errors in the form of inserted, deleted or substituted characters.\r\n\r\nA fuzzy regex specifies which types of errors are permitted, and, optionally, either the minimum and maximum or only the maximum permitted number of each type. (You cannot specify only a minimum.)\r\n\r\nThe 3 types of error are:\r\n\r\n* Insertion, indicated by \"i\"\r\n\r\n* Deletion, indicated by \"d\"\r\n\r\n* Substitution, indicated by \"s\"\r\n\r\nIn addition, \"e\" indicates any type of error.\r\n\r\nThe fuzziness of a regex item is specified between \"{\" and \"}\" after the item.\r\n\r\nExamples:\r\n\r\n* ``foo`` match \"foo\" exactly\r\n\r\n* ``(?:foo){i}`` match \"foo\", permitting insertions\r\n\r\n* ``(?:foo){d}`` match \"foo\", permitting deletions\r\n\r\n* ``(?:foo){s}`` match \"foo\", permitting substitutions\r\n\r\n* ``(?:foo){i,s}`` match \"foo\", permitting insertions and substitutions\r\n\r\n* ``(?:foo){e}`` match \"foo\", permitting errors\r\n\r\nIf a certain type of error is specified, then any type not specified will **not** be permitted.\r\n\r\nIn the following examples I'll omit the item and write only the fuzziness:\r\n\r\n* ``{d<=3}`` permit at most 3 deletions, but no other types\r\n\r\n* ``{i<=1,s<=2}`` permit at most 1 insertion and at most 2 substitutions, but no deletions\r\n\r\n* ``{1<=e<=3}`` permit at least 1 and at most 3 errors\r\n\r\n* ``{i<=2,d<=2,e<=3}`` permit at most 2 insertions, at most 2 deletions, at most 3 errors in total, but no substitutions\r\n\r\nIt's also possible to state the costs of each type of error and the maximum permitted total cost.\r\n\r\nExamples:\r\n\r\n* ``{2i+2d+1s<=4}`` each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\r\n\r\n* ``{i<=1,d<=1,s<=1,2i+2d+1s<=4}`` at most 1 insertion, at most 1 deletion, at most 1 substitution; each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\r\n\r\nYou can also use \"<\" instead of \"<=\" if you want an exclusive minimum or maximum.\r\n\r\nYou can add a test to perform on a character that's substituted or inserted.\r\n\r\nExamples:\r\n\r\n* ``{s<=2:[a-z]}`` at most 2 substitutions, which must be in the character set ``[a-z]``.\r\n\r\n* ``{s<=2,i<=3:\\d}`` at most 2 substitutions, at most 3 insertions, which must be digits.\r\n\r\nBy default, fuzzy matching searches for the first match that meets the given constraints. The ``ENHANCEMATCH`` flag will cause it to attempt to improve the fit (i.e. reduce the number of errors) of the match that it has found.\r\n\r\nThe ``BESTMATCH`` flag will make it search for the best match instead.\r\n\r\nFurther examples to note:\r\n\r\n* ``regex.search(\"(dog){e}\", \"cat and dog\")[1]`` returns ``\"cat\"`` because that matches ``\"dog\"`` with 3 errors (an unlimited number of errors is permitted).\r\n\r\n* ``regex.search(\"(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\" dog\"`` (with a leading space) because that matches ``\"dog\"`` with 1 error, which is within the limit.\r\n\r\n* ``regex.search(\"(?e)(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\"dog\"`` (without a leading space) because the fuzzy search matches ``\" dog\"`` with 1 error, which is within the limit, and the ``(?e)`` then it attempts a better fit.\r\n\r\nIn the first two examples there are perfect matches later in the string, but in neither case is it the first possible match.\r\n\r\nThe match object has an attribute ``fuzzy_counts`` which gives the total number of substitutions, insertions and deletions.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> # A 'raw' fuzzy match:\r\n  >>> regex.fullmatch(r\"(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\r\n  (0, 0, 1)\r\n  >>> # 0 substitutions, 0 insertions, 1 deletion.\r\n\r\n  >>> # A better match might be possible if the ENHANCEMATCH flag used:\r\n  >>> regex.fullmatch(r\"(?e)(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\r\n  (0, 0, 0)\r\n  >>> # 0 substitutions, 0 insertions, 0 deletions.\r\n\r\nThe match object also has an attribute ``fuzzy_changes`` which gives a tuple of the positions of the substitutions, insertions and deletions.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.search('(fuu){i<=2,d<=2,e<=5}', 'anaconda foo bar')\r\n  >>> m\r\n  <regex.Match object; span=(7, 10), match='a f', fuzzy_counts=(0, 2, 2)>\r\n  >>> m.fuzzy_changes\r\n  ([], [7, 8], [10, 11])\r\n\r\nWhat this means is that if the matched part of the string had been:\r\n\r\n.. sourcecode:: python\r\n\r\n  'anacondfuuoo bar'\r\n\r\nit would've been an exact match.\r\n\r\nHowever, there were insertions at positions 7 and 8:\r\n\r\n.. sourcecode:: python\r\n\r\n  'anaconda fuuoo bar'\r\n          ^^\r\n\r\nand deletions at positions 10 and 11:\r\n\r\n.. sourcecode:: python\r\n\r\n  'anaconda f~~oo bar'\r\n             ^^\r\n\r\nSo the actual string was:\r\n\r\n.. sourcecode:: python\r\n\r\n  'anaconda foo bar'\r\n\r\nNamed lists ``\\L<name>`` (`Hg issue 11 <https://github.com/mrabarnett/mrab-regex/issues/11>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThere are occasions where you may want to include a list (actually, a set) of options in a regex.\r\n\r\nOne way is to build the pattern like this:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> p = regex.compile(r\"first|second|third|fourth|fifth\")\r\n\r\nbut if the list is large, parsing the resulting regex can take considerable time, and care must also be taken that the strings are properly escaped and properly ordered, for example, \"cats\" before \"cat\".\r\n\r\nThe new alternative is to use a named list:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\r\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set)\r\n\r\nThe order of the items is irrelevant, they are treated as a set. The named lists are available as the ``.named_lists`` attribute of the pattern object :\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> print(p.named_lists)\r\n  {'options': frozenset({'third', 'first', 'fifth', 'fourth', 'second'})}\r\n\r\nIf there are any unused keyword arguments, ``ValueError`` will be raised unless you tell it otherwise:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\r\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[])\r\n  Traceback (most recent call last):\r\n    File \"<stdin>\", line 1, in <module>\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 353, in compile\r\n      return _compile(pattern, flags, ignore_unused, kwargs, cache_pattern)\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 500, in _compile\r\n      complain_unused_args()\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 483, in complain_unused_args\r\n      raise ValueError('unused keyword argument {!a}'.format(any_one))\r\n  ValueError: unused keyword argument 'other_options'\r\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[], ignore_unused=True)\r\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[], ignore_unused=False)\r\n  Traceback (most recent call last):\r\n    File \"<stdin>\", line 1, in <module>\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 353, in compile\r\n      return _compile(pattern, flags, ignore_unused, kwargs, cache_pattern)\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 500, in _compile\r\n      complain_unused_args()\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 483, in complain_unused_args\r\n      raise ValueError('unused keyword argument {!a}'.format(any_one))\r\n  ValueError: unused keyword argument 'other_options'\r\n  >>>\r\n\r\nStart and end of word\r\n^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``\\m`` matches at the start of a word.\r\n\r\n``\\M`` matches at the end of a word.\r\n\r\nCompare with ``\\b``, which matches at the start or end of a word.\r\n\r\nUnicode line separators\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nNormally the only line separator is ``\\n`` (``\\x0A``), but if the ``WORD`` flag is turned on then the line separators are ``\\x0D\\x0A``, ``\\x0A``, ``\\x0B``, ``\\x0C`` and ``\\x0D``, plus ``\\x85``, ``\\u2028`` and ``\\u2029`` when working with Unicode.\r\n\r\nThis affects the regex dot ``\".\"``, which, with the ``DOTALL`` flag turned off, matches any character except a line separator. It also affects the line anchors ``^`` and ``$`` (in multiline mode).\r\n\r\nSet operators\r\n^^^^^^^^^^^^^\r\n\r\n**Version 1 behaviour only**\r\n\r\nSet operators have been added, and a set ``[...]`` can include nested sets.\r\n\r\nThe operators, in order of increasing precedence, are:\r\n\r\n* ``||`` for union (\"x||y\" means \"x or y\")\r\n\r\n* ``~~`` (double tilde) for symmetric difference (\"x~~y\" means \"x or y, but not both\")\r\n\r\n* ``&&`` for intersection (\"x&&y\" means \"x and y\")\r\n\r\n* ``--`` (double dash) for difference (\"x--y\" means \"x but not y\")\r\n\r\nImplicit union, ie, simple juxtaposition like in ``[ab]``, has the highest precedence. Thus, ``[ab&&cd]`` is the same as ``[[a||b]&&[c||d]]``.\r\n\r\nExamples:\r\n\r\n* ``[ab]`` # Set containing 'a' and 'b'\r\n\r\n* ``[a-z]`` # Set containing 'a' .. 'z'\r\n\r\n* ``[[a-z]--[qw]]`` # Set containing 'a' .. 'z', but not 'q' or 'w'\r\n\r\n* ``[a-z--qw]`` # Same as above\r\n\r\n* ``[\\p{L}--QW]`` # Set containing all letters except 'Q' and 'W'\r\n\r\n* ``[\\p{N}--[0-9]]`` # Set containing all numbers except '0' .. '9'\r\n\r\n* ``[\\p{ASCII}&&\\p{Letter}]`` # Set containing all characters which are ASCII and letter\r\n\r\nregex.escape (`issue #2650 <https://bugs.python.org/issue2650>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nregex.escape has an additional keyword parameter ``special_only``. When True, only 'special' regex characters, such as '?', are escaped.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.escape(\"foo!?\", special_only=False)\r\n  'foo\\\\!\\\\?'\r\n  >>> regex.escape(\"foo!?\", special_only=True)\r\n  'foo!\\\\?'\r\n\r\nregex.escape (`Hg issue 249 <https://github.com/mrabarnett/mrab-regex/issues/249>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nregex.escape has an additional keyword parameter ``literal_spaces``. When True, spaces are not escaped.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.escape(\"foo bar!?\", literal_spaces=False)\r\n  'foo\\\\ bar!\\\\?'\r\n  >>> regex.escape(\"foo bar!?\", literal_spaces=True)\r\n  'foo bar!\\\\?'\r\n\r\nRepeated captures (`issue #7132 <https://bugs.python.org/issue7132>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA match object has additional methods which return information on all the successful matches of a repeated group. These methods are:\r\n\r\n* ``matchobject.captures([group1, ...])``\r\n\r\n  * Returns a list of the strings matched in a group or groups. Compare with ``matchobject.group([group1, ...])``.\r\n\r\n* ``matchobject.starts([group])``\r\n\r\n  * Returns a list of the start positions. Compare with ``matchobject.start([group])``.\r\n\r\n* ``matchobject.ends([group])``\r\n\r\n  * Returns a list of the end positions. Compare with ``matchobject.end([group])``.\r\n\r\n* ``matchobject.spans([group])``\r\n\r\n  * Returns a list of the spans. Compare with ``matchobject.span([group])``.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.search(r\"(\\w{3})+\", \"123456789\")\r\n  >>> m.group(1)\r\n  '789'\r\n  >>> m.captures(1)\r\n  ['123', '456', '789']\r\n  >>> m.start(1)\r\n  6\r\n  >>> m.starts(1)\r\n  [0, 3, 6]\r\n  >>> m.end(1)\r\n  9\r\n  >>> m.ends(1)\r\n  [3, 6, 9]\r\n  >>> m.span(1)\r\n  (6, 9)\r\n  >>> m.spans(1)\r\n  [(0, 3), (3, 6), (6, 9)]\r\n\r\nAtomic grouping ``(?>...)`` (`issue #433030 <https://bugs.python.org/issue433030>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nIf the following pattern subsequently fails, then the subpattern as a whole will fail.\r\n\r\nPossessive quantifiers\r\n^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``(?:...)?+`` ; ``(?:...)*+`` ; ``(?:...)++`` ; ``(?:...){min,max}+``\r\n\r\nThe subpattern is matched up to 'max' times. If the following pattern subsequently fails, then all the repeated subpatterns will fail as a whole. For example, ``(?:...)++`` is equivalent to ``(?>(?:...)+)``.\r\n\r\nScoped flags (`issue #433028 <https://bugs.python.org/issue433028>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``(?flags-flags:...)``\r\n\r\nThe flags will apply only to the subpattern. Flags can be turned on or off.\r\n\r\nDefinition of 'word' character (`issue #1693050 <https://bugs.python.org/issue1693050>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe definition of a 'word' character has been expanded for Unicode. It conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\r\n\r\nVariable-length lookbehind\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA lookbehind can match a variable-length string.\r\n\r\nFlags argument for regex.split, regex.sub and regex.subn (`issue #3482 <https://bugs.python.org/issue3482>`_)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``regex.split``, ``regex.sub`` and ``regex.subn`` support a 'flags' argument.\r\n\r\nPos and endpos arguments for regex.sub and regex.subn\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``regex.sub`` and ``regex.subn`` support 'pos' and 'endpos' arguments.\r\n\r\n'Overlapped' argument for regex.findall and regex.finditer\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``regex.findall`` and ``regex.finditer`` support an 'overlapped' flag which permits overlapped matches.\r\n\r\nSplititer\r\n^^^^^^^^^\r\n\r\n``regex.splititer`` has been added. It's a generator equivalent of ``regex.split``.\r\n\r\nSubscripting match objects for groups\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA match object accepts access to the groups via subscripting and slicing:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> m = regex.search(r\"(?P<before>.*?)(?P<num>\\d+)(?P<after>.*)\", \"pqr123stu\")\r\n  >>> print(m[\"before\"])\r\n  pqr\r\n  >>> print(len(m))\r\n  4\r\n  >>> print(m[:])\r\n  ('pqr123stu', 'pqr', '123', 'stu')\r\n\r\nNamed groups\r\n^^^^^^^^^^^^\r\n\r\nGroups can be named with ``(?<name>...)`` as well as the existing ``(?P<name>...)``.\r\n\r\nGroup references\r\n^^^^^^^^^^^^^^^^\r\n\r\nGroups can be referenced within a pattern with ``\\g<name>``. This also allows there to be more than 99 groups.\r\n\r\nNamed characters ``\\N{name}``\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nNamed characters are supported. Note that only those known by Python's Unicode database will be recognised.\r\n\r\nUnicode codepoint properties, including scripts and blocks\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``\\p{property=value}``; ``\\P{property=value}``; ``\\p{value}`` ; ``\\P{value}``\r\n\r\nMany Unicode properties are supported, including blocks and scripts. ``\\p{property=value}`` or ``\\p{property:value}`` matches a character whose property ``property`` has value ``value``. The inverse of ``\\p{property=value}`` is ``\\P{property=value}`` or ``\\p{^property=value}``.\r\n\r\nIf the short form ``\\p{value}`` is used, the properties are checked in the order: ``General_Category``, ``Script``, ``Block``, binary property:\r\n\r\n* ``Latin``, the 'Latin' script (``Script=Latin``).\r\n\r\n* ``BasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\r\n\r\n* ``Alphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\r\n\r\nA short form starting with ``Is`` indicates a script or binary property:\r\n\r\n* ``IsLatin``, the 'Latin' script (``Script=Latin``).\r\n\r\n* ``IsAlphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\r\n\r\nA short form starting with ``In`` indicates a block property:\r\n\r\n* ``InBasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\r\n\r\nPOSIX character classes\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n``[[:alpha:]]``; ``[[:^alpha:]]``\r\n\r\nPOSIX character classes are supported. These are normally treated as an alternative form of ``\\p{...}``.\r\n\r\nThe exceptions are ``alnum``, ``digit``, ``punct`` and ``xdigit``, whose definitions are different from those of Unicode.\r\n\r\n``[[:alnum:]]`` is equivalent to ``\\p{posix_alnum}``.\r\n\r\n``[[:digit:]]`` is equivalent to ``\\p{posix_digit}``.\r\n\r\n``[[:punct:]]`` is equivalent to ``\\p{posix_punct}``.\r\n\r\n``[[:xdigit:]]`` is equivalent to ``\\p{posix_xdigit}``.\r\n\r\nSearch anchor ``\\G``\r\n^^^^^^^^^^^^^^^^^^^^\r\n\r\nA search anchor has been added. It matches at the position where each search started/continued and can be used for contiguous matches or in negative variable-length lookbehinds to limit how far back the lookbehind goes:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.findall(r\"\\w{2}\", \"abcd ef\")\r\n  ['ab', 'cd', 'ef']\r\n  >>> regex.findall(r\"\\G\\w{2}\", \"abcd ef\")\r\n  ['ab', 'cd']\r\n\r\n* The search starts at position 0 and matches 'ab'.\r\n\r\n* The search continues at position 2 and matches 'cd'.\r\n\r\n* The search continues at position 4 and fails to match any letters.\r\n\r\n* The anchor stops the search start position from being advanced, so there are no more results.\r\n\r\nReverse searching\r\n^^^^^^^^^^^^^^^^^\r\n\r\nSearches can also work backwards:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.findall(r\".\", \"abc\")\r\n  ['a', 'b', 'c']\r\n  >>> regex.findall(r\"(?r).\", \"abc\")\r\n  ['c', 'b', 'a']\r\n\r\nNote that the result of a reverse search is not necessarily the reverse of a forward search:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.findall(r\"..\", \"abcde\")\r\n  ['ab', 'cd']\r\n  >>> regex.findall(r\"(?r)..\", \"abcde\")\r\n  ['de', 'bc']\r\n\r\nMatching a single grapheme ``\\X``\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe grapheme matcher is supported. It conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\r\n\r\nBranch reset ``(?|...|...)``\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nGroup numbers will be reused across the alternatives, but groups with different names will have different group numbers.\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> regex.match(r\"(?|(first)|(second))\", \"first\").groups()\r\n  ('first',)\r\n  >>> regex.match(r\"(?|(first)|(second))\", \"second\").groups()\r\n  ('second',)\r\n\r\nNote that there is only one group.\r\n\r\nDefault Unicode word boundary\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe ``WORD`` flag changes the definition of a 'word boundary' to that of a default Unicode word boundary. This applies to ``\\b`` and ``\\B``.\r\n\r\nTimeout\r\n^^^^^^^\r\n\r\nThe matching methods and functions support timeouts. The timeout (in seconds) applies to the entire operation:\r\n\r\n.. sourcecode:: python\r\n\r\n  >>> from time import sleep\r\n  >>>\r\n  >>> def fast_replace(m):\r\n  ...     return 'X'\r\n  ...\r\n  >>> def slow_replace(m):\r\n  ...     sleep(0.5)\r\n  ...     return 'X'\r\n  ...\r\n  >>> regex.sub(r'[a-z]', fast_replace, 'abcde', timeout=2)\r\n  'XXXXX'\r\n  >>> regex.sub(r'[a-z]', slow_replace, 'abcde', timeout=2)\r\n  Traceback (most recent call last):\r\n    File \"<stdin>\", line 1, in <module>\r\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 278, in sub\r\n      return pat.sub(repl, string, count, pos, endpos, concurrent, timeout)\r\n  TimeoutError: regex timed out\r\n",
        "description_content_type": "text/x-rst",
        "author_email": "Matthew Barnett <regex@mrabarnett.plus.com>",
        "license_expression": "Apache-2.0 AND CNRI-Python",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing",
          "Topic :: Text Processing :: General"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/mrabarnett/mrab-regex"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=7dd8a5c40426b779b0868c404bdef9768deccf22749cde15852df527e6269b36",
          "hashes": {
            "sha256": "7dd8a5c40426b779b0868c404bdef9768deccf22749cde15852df527e6269b36"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "requests-oauthlib",
        "version": "2.0.0",
        "summary": "OAuthlib authentication support for Requests.",
        "description": "Requests-OAuthlib |build-status| |coverage-status| |docs|\n=========================================================\n\nThis project provides first-class OAuth library support for `Requests <https://requests.readthedocs.io>`_.\n\nThe OAuth 1 workflow\n--------------------\n\nOAuth 1 can seem overly complicated and it sure has its quirks. Luckily,\nrequests_oauthlib hides most of these and let you focus at the task at hand.\n\nAccessing protected resources using requests_oauthlib is as simple as:\n\n.. code-block:: pycon\n\n    >>> from requests_oauthlib import OAuth1Session\n    >>> twitter = OAuth1Session('client_key',\n                                client_secret='client_secret',\n                                resource_owner_key='resource_owner_key',\n                                resource_owner_secret='resource_owner_secret')\n    >>> url = 'https://api.twitter.com/1/account/settings.json'\n    >>> r = twitter.get(url)\n\nBefore accessing resources you will need to obtain a few credentials from your\nprovider (e.g. Twitter) and authorization from the user for whom you wish to\nretrieve resources for. You can read all about this in the full\n`OAuth 1 workflow guide on RTD <https://requests-oauthlib.readthedocs.io/en/latest/oauth1_workflow.html>`_.\n\nThe OAuth 2 workflow\n--------------------\n\nOAuth 2 is generally simpler than OAuth 1 but comes in more flavours. The most\ncommon being the Authorization Code Grant, also known as the WebApplication\nflow.\n\nFetching a protected resource after obtaining an access token can be extremely\nsimple. However, before accessing resources you will need to obtain a few\ncredentials from your provider (e.g. Google) and authorization from the user\nfor whom you wish to retrieve resources for. You can read all about this in the\nfull `OAuth 2 workflow guide on RTD <https://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html>`_.\n\nInstallation\n-------------\n\nTo install requests and requests_oauthlib you can use pip:\n\n.. code-block:: bash\n\n    pip install requests requests-oauthlib\n\n.. |build-status| image:: https://github.com/requests/requests-oauthlib/actions/workflows/run-tests.yml/badge.svg\n   :target: https://github.com/requests/requests-oauthlib/actions\n.. |coverage-status| image:: https://img.shields.io/coveralls/requests/requests-oauthlib.svg\n   :target: https://coveralls.io/r/requests/requests-oauthlib\n.. |docs| image:: https://readthedocs.org/projects/requests-oauthlib/badge/\n   :alt: Documentation Status\n   :scale: 100%\n   :target: https://requests-oauthlib.readthedocs.io/\n\n\nHistory\n-------\n\nv2.0.0 (22 March 2024)\n++++++++++++++++++++++++\n\nFull set of changes are in [github](https://github.com/requests/requests-oauthlib/milestone/4?closed=1).\n\nAdditions & changes:\n\n- ``OAuth2Session`` now correctly uses the ``self.verify`` value if ``verify``\n  is not overridden in ``fetch_token`` and ``refresh_token``. Fixes `#404\n  <https://github.com/requests/requests-oauthlib/issues/404>`_.\n- ``OAuth2Session`` constructor now uses its ``client.scope`` when a ``client``\n  is provided and ``scope`` is not overridden. Fixes `#408\n  <https://github.com/requests/requests-oauthlib/issues/408>`_\n- Add ``refresh_token_request`` and ``access_token_request`` compliance hooks\n- Add PKCE support and Auth0 example\n- Add support for Python 3.8-3.12\n- Remove support of Python 2.x, <3.7\n- Migrated to Github Action\n- Updated dependencies\n- Cleanup some docs and examples\n\nv1.4.0 (27 Feb 2024)\n++++++++++++++++++++++++\n\n- Version 2.0.0 published initially as 1.4.0, it was yanked eventually.\n\nv1.3.1 (21 January 2022)\n++++++++++++++++++++++++\n\n- Add initial support for OAuth Mutual TLS (draft-ietf-oauth-mtls)\n- Removed outdated LinkedIn Compliance Fixes\n- Add eBay compliance fix\n- Add Spotify OAuth 2 Tutorial\n- Add support for python 3.8, 3.9\n- Fixed LinkedIn Compliance Fixes\n- Fixed ReadTheDocs Documentation and sphinx errors\n- Moved pipeline to GitHub Actions\n\nv1.3.0 (6 November 2019)\n++++++++++++++++++++++++\n\n- Instagram compliance fix\n- Added ``force_querystring`` argument to fetch_token() method on OAuth2Session\n\nv1.2.0 (14 January 2019)\n++++++++++++++++++++++++\n\n- This project now depends on OAuthlib 3.0.0 and above. It does **not** support\n  versions of OAuthlib before 3.0.0.\n- Updated oauth2 tests to use 'sess' for an OAuth2Session instance instead of `auth`\n  because OAuth2Session objects and methods acceept an `auth` paramether which is\n  typically an instance of `requests.auth.HTTPBasicAuth`\n- `OAuth2Session.fetch_token` previously tried to guess how and where to provide\n  \"client\" and \"user\" credentials incorrectly. This was incompatible with some\n  OAuth servers and incompatible with breaking changes in oauthlib that seek to\n  correctly provide the `client_id`. The older implementation also did not raise\n  the correct exceptions when username and password are not present on Legacy\n  clients.\n- Avoid automatic netrc authentication for OAuth2Session.\n\nv1.1.0 (9 January 2019)\n+++++++++++++++++++++++\n\n- Adjusted version specifier for ``oauthlib`` dependency: this project is\n  not yet compatible with ``oauthlib`` 3.0.0.\n- Dropped dependency on ``nose``.\n- Minor changes to clean up the code and make it more readable/maintainable.\n\nv1.0.0 (4 June 2018)\n++++++++++++++++++++\n\n- **Removed support for Python 2.6 and Python 3.3.**\n  This project now supports Python 2.7, and Python 3.4 and above.\n- Added several examples to the documentation.\n- Added plentymarkets compliance fix.\n- Added a ``token`` property to OAuth1Session, to match the corresponding\n  ``token`` property on OAuth2Session.\n\nv0.8.0 (14 February 2017)\n+++++++++++++++++++++++++\n\n- Added Fitbit compliance fix.\n- Fixed an issue where newlines in the response body for the access token\n  request would cause errors when trying to extract the token.\n- Fixed an issue introduced in v0.7.0 where users passing ``auth`` to several\n  methods would encounter conflicts with the ``client_id`` and\n  ``client_secret``-derived auth. The user-supplied ``auth`` argument is now\n  used in preference to those options.\n\nv0.7.0 (22 September 2016)\n++++++++++++++++++++++++++\n\n- Allowed ``OAuth2Session.request`` to take the ``client_id`` and\n  ``client_secret`` parameters for the purposes of automatic token refresh,\n  which may need them.\n\nv0.6.2 (12 July 2016)\n+++++++++++++++++++++\n\n- Use ``client_id`` and ``client_secret`` for the Authorization header if\n  provided.\n- Allow explicit bypass of the Authorization header by setting ``auth=False``.\n- Pass through the ``proxies`` kwarg when refreshing tokens.\n- Miscellaneous cleanups.\n\nv0.6.1 (19 February 2016)\n+++++++++++++++++++++++++\n\n- Fixed a bug when sending authorization in headers with no username and\n  password present.\n- Make sure we clear the session token before obtaining a new one.\n- Some improvements to the Slack compliance fix.\n- Avoid timing problems around token refresh.\n- Allow passing arbitrary arguments to requests when calling\n  ``fetch_request_token`` and ``fetch_access_token``.\n\nv0.6.0 (14 December 2015)\n+++++++++++++++++++++++++\n\n- Add compliance fix for Slack.\n- Add compliance fix for Mailchimp.\n- ``TokenRequestDenied`` exceptions now carry the entire response, not just the\n  status code.\n- Pass through keyword arguments when refreshing tokens automatically.\n- Send authorization in headers, not just body, to maximize compatibility.\n- More getters/setters available for OAuth2 session client values.\n- Allow sending custom headers when refreshing tokens, and set some defaults.\n\n\nv0.5.0 (4 May 2015)\n+++++++++++++++++++\n- Fix ``TypeError`` being raised instead of ``TokenMissing`` error.\n- Raise requests exceptions on 4XX and 5XX responses in the OAuth2 flow.\n- Avoid ``AttributeError`` when initializing the ``OAuth2Session`` class\n  without complete client information.\n\nv0.4.2 (16 October 2014)\n++++++++++++++++++++++++\n- New ``authorized`` property on OAuth1Session and OAuth2Session, which allows\n  you to easily determine if the session is already authorized with OAuth tokens\n  or not.\n- New ``TokenMissing`` and ``VerifierMissing`` exception classes for OAuth1Session:\n  this will make it easier to catch and identify these exceptions.\n\nv0.4.1 (6 June 2014)\n++++++++++++++++++++\n- New install target ``[rsa]`` for people using OAuth1 RSA-SHA1 signature\n  method.\n- Fixed bug in OAuth2 where supplied state param was not used in auth url.\n- OAuth2 HTTPS checking can be disabled by setting environment variable\n  ``OAUTHLIB_INSECURE_TRANSPORT``.\n- OAuth1 now re-authorize upon redirects.\n- OAuth1 token fetching now raise a detailed error message when the\n  response body is incorrectly encoded or the request was denied.\n- Added support for custom OAuth1 clients.\n- OAuth2 compliance fix for Sina Weibo.\n- Multiple fixes to facebook compliance fix.\n- Compliance fixes now re-encode body properly as bytes in Python 3.\n- Logging now properly done under ``requests_oauthlib`` namespace instead\n  of piggybacking on oauthlib namespace.\n- Logging introduced for OAuth1 auth and session.\n\nv0.4.0 (29 September 2013)\n++++++++++++++++++++++++++\n- OAuth1Session methods only return unicode strings. #55.\n- Renamed requests_oauthlib.core to requests_oauthlib.oauth1_auth for consistency. #79.\n- Added Facebook compliance fix and access_token_response hook to OAuth2Session. #63.\n- Added LinkedIn compliance fix.\n- Added refresh_token_response compliance hook, invoked before parsing the refresh token.\n- Correctly limit compliance hooks to running only once!\n- Content type guessing should only be done when no content type is given\n- OAuth1 now updates r.headers instead of replacing it with non case insensitive dict\n- Remove last use of Response.content (in OAuth1Session). #44.\n- State param can now be supplied in OAuth2Session.authorize_url\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/requests/requests-oauthlib",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.com",
        "license": "ISC",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "oauthlib >=3.0.0",
          "requests >=2.0.0",
          "oauthlib[signedtoken] >=3.0.0 ; extra == 'rsa'"
        ],
        "requires_python": ">=3.4",
        "provides_extra": [
          "rsa"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=88119c938d2b8fb88561af5f6ee0eec8cc8d552b7bb1f712743136eb7523b7a1",
          "hashes": {
            "sha256": "88119c938d2b8fb88561af5f6ee0eec8cc8d552b7bb1f712743136eb7523b7a1"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "oauthlib",
        "version": "3.3.1",
        "dynamic": [
          "author",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "platform",
          "provides-extra",
          "requires-python",
          "summary"
        ],
        "platform": [
          "any"
        ],
        "summary": "A generic, spec-compliant, thorough implementation of the OAuth request-signing logic",
        "description": "OAuthLib - Python Framework for OAuth1 & OAuth2\n===============================================\n\n*A generic, spec-compliant, thorough implementation of the OAuth request-signing\nlogic for Python 3.8+*\n\n.. image:: https://github.com/oauthlib/oauthlib/actions/workflows/python-build.yml/badge.svg\n  :target: https://github.com/oauthlib/oauthlib/actions\n  :alt: GitHub Actions\n.. image:: https://coveralls.io/repos/oauthlib/oauthlib/badge.svg?branch=master\n  :target: https://coveralls.io/r/oauthlib/oauthlib\n  :alt: Coveralls\n.. image:: https://img.shields.io/pypi/pyversions/oauthlib.svg\n  :target: https://pypi.org/project/oauthlib/\n  :alt: Download from PyPI\n.. image:: https://img.shields.io/pypi/l/oauthlib.svg\n  :target: https://pypi.org/project/oauthlib/\n  :alt: License\n.. image:: https://app.fossa.io/api/projects/git%2Bgithub.com%2Foauthlib%2Foauthlib.svg?type=shield\n   :target: https://app.fossa.io/projects/git%2Bgithub.com%2Foauthlib%2Foauthlib?ref=badge_shield\n   :alt: FOSSA Status\n.. image:: https://img.shields.io/readthedocs/oauthlib.svg\n  :target: https://oauthlib.readthedocs.io/en/latest/index.html\n  :alt: Read the Docs\n.. image:: https://badges.gitter.im/oauthlib/oauthlib.svg\n  :target: https://gitter.im/oauthlib/Lobby\n  :alt: Chat on Gitter\n\n\n.. image:: https://raw.githubusercontent.com/oauthlib/oauthlib/8d71b161fd145d11c40d55c9ab66ac134a303253/docs/logo/oauthlib-banner-700x192.png\n  :target: https://github.com/oauthlib/oauthlib/\n  :alt: OAuth + Python = OAuthlib Python Framework\n\n\nOAuth often seems complicated and difficult-to-implement. There are several\nprominent libraries for handling OAuth requests, but they all suffer from one or\nboth of the following:\n\n1. They predate the `OAuth 1.0 spec`_, AKA RFC 5849.\n2. They predate the `OAuth 2.0 spec`_, AKA RFC 6749.\n3. They assume the usage of a specific HTTP request library.\n\n.. _`OAuth 1.0 spec`: https://tools.ietf.org/html/rfc5849\n.. _`OAuth 2.0 spec`: https://tools.ietf.org/html/rfc6749\n\nOAuthLib is a framework which implements the logic of OAuth1 or OAuth2 without\nassuming a specific HTTP request object or web framework. Use it to graft OAuth\nclient support onto your favorite HTTP library, or provide support onto your\nfavourite web framework. If you're a maintainer of such a library, write a thin\nveneer on top of OAuthLib and get OAuth support for very little effort.\n\n\nDocumentation\n--------------\n\nFull documentation is available on `Read the Docs`_. All contributions are very\nwelcome! The documentation is still quite sparse, please open an issue for what\nyou'd like to know, or discuss it in our `Gitter community`_, or even better, send a\npull request!\n\n.. _`Gitter community`: https://gitter.im/oauthlib/Lobby\n.. _`Read the Docs`: https://oauthlib.readthedocs.io/en/latest/index.html\n\nInterested in making OAuth requests?\n------------------------------------\n\nThen you might be more interested in using `requests`_ which has OAuthLib\npowered OAuth support provided by the `requests-oauthlib`_ library.\n\n.. _`requests`: https://github.com/requests/requests\n.. _`requests-oauthlib`: https://github.com/requests/requests-oauthlib\n\nWhich web frameworks are supported?\n-----------------------------------\n\nThe following packages provide OAuth support using OAuthLib.\n\n- For Django there is:\n  - `django-oauth-toolkit`_, which includes `Django REST framework`_ support.\n  - `django-allauth`_, which includes `Django REST framework`_ as well as `Django Ninja`_ support.\n- For Flask there is `flask-oauthlib`_ and `Flask-Dance`_.\n- For Pyramid there is `pyramid-oauthlib`_.\n- For Bottle there is `bottle-oauthlib`_.\n\nIf you have written an OAuthLib package that supports your favorite framework,\nplease open a Pull Request, updating the documentation.\n\n.. _`django-oauth-toolkit`: https://github.com/evonove/django-oauth-toolkit\n.. _`flask-oauthlib`: https://github.com/lepture/flask-oauthlib\n.. _`Django REST framework`: http://django-rest-framework.org\n.. _`Flask-Dance`: https://github.com/singingwolfboy/flask-dance\n.. _`pyramid-oauthlib`: https://github.com/tilgovi/pyramid-oauthlib\n.. _`bottle-oauthlib`: https://github.com/thomsonreuters/bottle-oauthlib\n.. _`django-allauth`: https://allauth.org/\n.. _`Django Ninja`: https://django-ninja.dev/\n\nUsing OAuthLib? Please get in touch!\n------------------------------------\nPatching OAuth support onto an http request framework? Creating an OAuth\nprovider extension for a web framework? Simply using OAuthLib to Get Things Done\nor to learn?\n\nNo matter which we'd love to hear from you in our `Gitter community`_ or if you have\nanything in particular you would like to have, change or comment on don't\nhesitate for a second to send a pull request or open an issue. We might be quite\nbusy and therefore slow to reply but we love feedback!\n\nChances are you have run into something annoying that you wish there was\ndocumentation for, if you wish to gain eternal fame and glory, and a drink if we\nhave the pleasure to run into each other, please send a docs pull request =)\n\n.. _`Gitter community`: https://gitter.im/oauthlib/Lobby\n\nLicense\n-------\n\nOAuthLib is yours to use and abuse according to the terms of the BSD-3-Clause license.\nCheck the LICENSE file for full details.\n\nCredits\n-------\n\nOAuthLib has been started and maintained several years by Idan Gazit and other\namazing `AUTHORS`_. Thanks to their wonderful work, the open-source `community`_\ncreation has been possible and the project can stay active and reactive to users\nrequests.\n\n\n.. _`AUTHORS`: https://github.com/oauthlib/oauthlib/blob/master/AUTHORS\n.. _`community`: https://github.com/oauthlib/\n\nChangelog\n---------\n\n*OAuthLib is in active development, with the core of both OAuth1 and OAuth2\ncompleted, for providers as well as clients.* See `supported features`_ for\ndetails.\n\n.. _`supported features`: https://oauthlib.readthedocs.io/en/latest/feature_matrix.html\n\nFor a full changelog see ``CHANGELOG.rst``.\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/oauthlib/oauthlib",
        "author": "The OAuthlib Community",
        "maintainer": "Jonathan Huot",
        "maintainer_email": "jonathan.huot@gmail.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: MacOS",
          "Operating System :: POSIX",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "cryptography>=3.0.0; extra == \"rsa\"",
          "cryptography>=3.0.0; extra == \"signedtoken\"",
          "pyjwt<3,>=2.0.0; extra == \"signedtoken\"",
          "blinker>=1.4.0; extra == \"signals\""
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "rsa",
          "signedtoken",
          "signals"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/f2/e1/485132437d20aa4d3e1d8b3fb5a5e65aa8139f1e097080c2a8443201742c/rpds_py-0.30.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=806f36b1b605e2d6a72716f321f20036b9489d29c51c91f4dd29a3e3afb73b15",
          "hashes": {
            "sha256": "806f36b1b605e2d6a72716f321f20036b9489d29c51c91f4dd29a3e3afb73b15"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "rpds-py",
        "version": "0.30.0",
        "summary": "Python bindings to Rust's persistent data structures (rpds)",
        "description": "===========\r\n``rpds.py``\r\n===========\r\n\r\n|PyPI| |Pythons| |CI|\r\n\r\n.. |PyPI| image:: https://img.shields.io/pypi/v/rpds-py.svg\r\n  :alt: PyPI version\r\n  :target: https://pypi.org/project/rpds-py/\r\n\r\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/rpds-py.svg\r\n  :alt: Supported Python versions\r\n  :target: https://pypi.org/project/rpds-py/\r\n\r\n.. |CI| image:: https://github.com/crate-py/rpds/workflows/CI/badge.svg\r\n  :alt: Build status\r\n  :target: https://github.com/crate-py/rpds/actions?query=workflow%3ACI\r\n\r\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\r\n   :alt: ReadTheDocs status\r\n   :target: https://referencing.readthedocs.io/en/stable/\r\n\r\n\r\nPython bindings to the `Rust rpds crate <https://docs.rs/rpds/>`_ for persistent data structures.\r\n\r\nWhat's here is quite minimal (in transparency, it was written initially to support replacing ``pyrsistent`` in the `referencing library <https://github.com/python-jsonschema/referencing>`_).\r\nIf you see something missing (which is very likely), a PR is definitely welcome to add it.\r\n\r\nInstallation\r\n------------\r\n\r\nThe distribution on PyPI is named ``rpds.py`` (equivalently ``rpds-py``), and thus can be installed via e.g.:\r\n\r\n.. code:: sh\r\n\r\n    $ pip install rpds-py\r\n\r\nNote that if you install ``rpds-py`` from source, you will need a Rust toolchain installed, as it is a build-time dependency.\r\nAn example of how to do so in a ``Dockerfile`` can be found `here <https://github.com/bowtie-json-schema/bowtie/blob/e77fd93598cb6e7dc1b8b1f53c00e5aa410c201a/implementations/python-jsonschema/Dockerfile#L1-L8>`_.\r\n\r\nIf you believe you are on a common platform which should have wheels built (i.e. and not need to compile from source), feel free to file an issue or pull request modifying the GitHub action used here to build wheels via ``maturin``.\r\n\r\nUsage\r\n-----\r\n\r\nMethods in general are named similarly to their ``rpds`` counterparts (rather than ``pyrsistent``\\ 's conventions, though probably a full drop-in ``pyrsistent``\\ -compatible wrapper module is a good addition at some point).\r\n\r\n.. code:: python\r\n\r\n    >>> from rpds import HashTrieMap, HashTrieSet, List\r\n\r\n    >>> m = HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\"})\r\n    >>> m.insert(\"spam\", 37) == HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\", \"spam\": 37})\r\n    True\r\n    >>> m.remove(\"foo\") == HashTrieMap({\"baz\": \"quux\"})\r\n    True\r\n\r\n    >>> s = HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\"})\r\n    >>> s.insert(\"spam\") == HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\", \"spam\"})\r\n    True\r\n    >>> s.remove(\"foo\") == HashTrieSet({\"bar\", \"baz\", \"quux\"})\r\n    True\r\n\r\n    >>> L = List([1, 3, 5])\r\n    >>> L.push_front(-1) == List([-1, 1, 3, 5])\r\n    True\r\n    >>> L.rest == List([3, 5])\r\n    True\r\n\n",
        "description_content_type": "text/x-rst; charset=UTF-8",
        "keywords": [
          "data structures",
          "rust",
          "persistent"
        ],
        "author_email": "Julian Berman <Julian+rpds@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Rust",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Documentation, https://rpds.readthedocs.io/",
          "Homepage, https://github.com/crate-py/rpds",
          "Issues, https://github.com/crate-py/rpds/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-rpds-py?utm_source=pypi-rpds-py&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/crate-py/rpds",
          "Upstream, https://github.com/orium/rpds"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b9/b6/8ac583d6da79e7b9e520579f03007cb006f063642afd6b2eeb16b890bf93/scipy-1.17.0-cp313-cp313-win_amd64.whl",
        "archive_info": {
          "hash": "sha256=87b411e42b425b84777718cc41516b8a7e0795abfa8e8e1d573bf0ef014f0812",
          "hashes": {
            "sha256": "87b411e42b425b84777718cc41516b8a7e0795abfa8e8e1d573bf0ef014f0812"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "scipy",
        "version": "1.17.0",
        "summary": "Fundamental algorithms for scientific computing in Python",
        "description": ".. image:: https://raw.githubusercontent.com/scipy/scipy/main/doc/source/_static/logo.svg\n  :target: https://scipy.org\n  :width: 110\n  :height: 110\n  :align: left \n\n.. image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n  :target: https://numfocus.org\n\n.. image:: https://img.shields.io/pypi/dm/scipy.svg?label=Pypi%20downloads\n  :target: https://pypi.org/project/scipy/\n\n.. image:: https://img.shields.io/conda/dn/conda-forge/scipy.svg?label=Conda%20downloads\n  :target: https://anaconda.org/conda-forge/scipy\n\n.. image:: https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg\n  :target: https://stackoverflow.com/questions/tagged/scipy\n\n.. image:: https://img.shields.io/badge/DOI-10.1038%2Fs41592--019--0686--2-blue.svg\n  :target: https://www.nature.com/articles/s41592-019-0686-2\n\n.. image:: https://insights.linuxfoundation.org/api/badge/health-score?project=scipy\n  :target: https://insights.linuxfoundation.org/project/scipy\n\nSciPy (pronounced \"Sigh Pie\") is an open-source software for mathematics,\nscience, and engineering. It includes modules for statistics, optimization,\nintegration, linear algebra, Fourier transforms, signal and image processing,\nODE solvers, and more.\n\n- **Website:** https://scipy.org\n- **Documentation:** https://docs.scipy.org/doc/scipy/\n- **Development version of the documentation:** https://scipy.github.io/devdocs\n- **SciPy development forum:** https://discuss.scientific-python.org/c/contributor/scipy\n- **Stack Overflow:** https://stackoverflow.com/questions/tagged/scipy\n- **Source code:** https://github.com/scipy/scipy\n- **Contributing:** https://scipy.github.io/devdocs/dev/index.html\n- **Bug reports:** https://github.com/scipy/scipy/issues\n- **Code of Conduct:** https://docs.scipy.org/doc/scipy/dev/conduct/code_of_conduct.html\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n- **Citing in your work:** https://www.scipy.org/citing-scipy/\n\nSciPy is built to work with\nNumPy arrays, and provides many user-friendly and efficient numerical routines,\nsuch as routines for numerical integration and optimization. Together, they\nrun on all popular operating systems, are quick to install, and are free of\ncharge. NumPy and SciPy are easy to use, but powerful enough to be depended\nupon by some of the world's leading scientists and engineers. If you need to\nmanipulate numbers on a computer and display or publish the results, give\nSciPy a try!\n\nFor the installation instructions, see `our install\nguide <https://scipy.org/install/>`__.\n\n\nCall for Contributions\n----------------------\n\nWe appreciate and welcome contributions. Small improvements or fixes are always appreciated; issues labeled as \"good\nfirst issue\" may be a good starting point. Have a look at `our contributing\nguide <https://scipy.github.io/devdocs/dev/index.html>`__.\n\nWriting code isnâ€™t the only way to contribute to SciPy. You can also:\n\n- review pull requests\n- triage issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve `our website <https://github.com/scipy/scipy.org>`__\n- develop graphic design for our brand assets and promotional materials\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nIf youâ€™re unsure where to start or how your skills fit in, reach out! You can\nask on the `forum <https://discuss.scientific-python.org/c/contributor/scipy>`__\nor here, on GitHub, by leaving a comment on a relevant issue that is already\nopen.\n\nIf you are new to contributing to open source, `this\nguide <https://opensource.guide/how-to-contribute/>`__ helps explain why, what,\nand how to get involved.\n",
        "description_content_type": "text/x-rst",
        "maintainer_email": "SciPy Developers <scipy-dev@python.org>",
        "license": "Copyright (c) 2001-2002 Enthought, Inc. 2003, SciPy Developers.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions\n are met:\n\n 1. Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n 2. Redistributions in binary form must reproduce the above\n    copyright notice, this list of conditions and the following\n    disclaimer in the documentation and/or other materials provided\n    with the distribution.\n\n 3. Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived\n    from this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n ----\n\n This binary distribution of SciPy can also bundle the following software\n (depending on the build):\n\n\n Name: OpenBLAS\n Files: scipy.libs\\libscipy_openblas*.dll\n Description: bundled as a dynamically linked library\n Availability: https://github.com/OpenMathLib/OpenBLAS/\n License: BSD-3-Clause\n   Copyright (c) 2011-2014, The OpenBLAS Project\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n      1. Redistributions of source code must retain the above copyright\n         notice, this list of conditions and the following disclaimer.\n\n      2. Redistributions in binary form must reproduce the above copyright\n         notice, this list of conditions and the following disclaimer in\n         the documentation and/or other materials provided with the\n         distribution.\n      3. Neither the name of the OpenBLAS project nor the names of \n         its contributors may be used to endorse or promote products \n         derived from this software without specific prior written \n         permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n   ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n   LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n   SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n   CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n   USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n Name: LAPACK\n Files: scipy.libs\\libscipy_openblas*.dll\n Description: bundled in OpenBLAS\n Availability: https://github.com/OpenMathLib/OpenBLAS/\n License: BSD-3-Clause-Open-MPI\n   Copyright (c) 1992-2013 The University of Tennessee and The University\n                           of Tennessee Research Foundation.  All rights\n                           reserved.\n   Copyright (c) 2000-2013 The University of California Berkeley. All\n                           rights reserved.\n   Copyright (c) 2006-2013 The University of Colorado Denver.  All rights\n                           reserved.\n\n   $COPYRIGHT$\n\n   Additional copyrights may follow\n\n   $HEADER$\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n   - Redistributions of source code must retain the above copyright\n     notice, this list of conditions and the following disclaimer.\n\n   - Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer listed\n     in this license in the documentation and/or other materials\n     provided with the distribution.\n\n   - Neither the name of the copyright holders nor the names of its\n     contributors may be used to endorse or promote products derived from\n     this software without specific prior written permission.\n\n   The copyright holders provide no reassurances that the source code\n   provided does not infringe any patent, copyright, or any other\n   intellectual property rights of third parties.  The copyright holders\n   disclaim any liability to any recipient for claims brought against\n   recipient by any third party for infringement of that parties\n   intellectual property rights.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n Name: GCC runtime library\n Files: scipy.libs\\libscipy_openblas*.dll\n Description: statically linked to files compiled with gcc\n Availability: https://gcc.gnu.org/git/?p=gcc.git;a=tree;f=libgfortran\n License: GPL-3.0-or-later WITH GCC-exception-3.1\n   Copyright (C) 2002-2017 Free Software Foundation, Inc.\n\n   Libgfortran is free software; you can redistribute it and/or modify\n   it under the terms of the GNU General Public License as published by\n   the Free Software Foundation; either version 3, or (at your option)\n   any later version.\n\n   Libgfortran is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   Under Section 7 of GPL version 3, you are granted additional\n   permissions described in the GCC Runtime Library Exception, version\n   3.1, as published by the Free Software Foundation.\n\n   You should have received a copy of the GNU General Public License and\n   a copy of the GCC Runtime Library Exception along with this program;\n   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n   <http://www.gnu.org/licenses/>.\n\n\n ----\n\n Full text of license texts referred to above follows (that they are\n listed below does not necessarily imply the conditions apply to the\n present binary release):\n\n ----\n\n GCC RUNTIME LIBRARY EXCEPTION\n\n Version 3.1, 31 March 2009\n\n Copyright (C) 2009 Free Software Foundation, Inc. <http://fsf.org/>\n\n Everyone is permitted to copy and distribute verbatim copies of this\n license document, but changing it is not allowed.\n\n This GCC Runtime Library Exception (\"Exception\") is an additional\n permission under section 7 of the GNU General Public License, version\n 3 (\"GPLv3\"). It applies to a given file (the \"Runtime Library\") that\n bears a notice placed by the copyright holder of the file stating that\n the file is governed by GPLv3 along with this Exception.\n\n When you use GCC to compile a program, GCC may combine portions of\n certain GCC header files and runtime libraries with the compiled\n program. The purpose of this Exception is to allow compilation of\n non-GPL (including proprietary) programs to use, in this way, the\n header files and runtime libraries covered by this Exception.\n\n 0. Definitions.\n\n A file is an \"Independent Module\" if it either requires the Runtime\n Library for execution after a Compilation Process, or makes use of an\n interface provided by the Runtime Library, but is not otherwise based\n on the Runtime Library.\n\n \"GCC\" means a version of the GNU Compiler Collection, with or without\n modifications, governed by version 3 (or a specified later version) of\n the GNU General Public License (GPL) with the option of using any\n subsequent versions published by the FSF.\n\n \"GPL-compatible Software\" is software whose conditions of propagation,\n modification and use would permit combination with GCC in accord with\n the license of GCC.\n\n \"Target Code\" refers to output from any compiler for a real or virtual\n target processor architecture, in executable form or suitable for\n input to an assembler, loader, linker and/or execution\n phase. Notwithstanding that, Target Code does not include data in any\n format that is used as a compiler intermediate representation, or used\n for producing a compiler intermediate representation.\n\n The \"Compilation Process\" transforms code entirely represented in\n non-intermediate languages designed for human-written code, and/or in\n Java Virtual Machine byte code, into Target Code. Thus, for example,\n use of source code generators and preprocessors need not be considered\n part of the Compilation Process, since the Compilation Process can be\n understood as starting with the output of the generators or\n preprocessors.\n\n A Compilation Process is \"Eligible\" if it is done using GCC, alone or\n with other GPL-compatible software, or if it is done without using any\n work based on GCC. For example, using non-GPL-compatible Software to\n optimize any GCC intermediate representations would not qualify as an\n Eligible Compilation Process.\n\n 1. Grant of Additional Permission.\n\n You have permission to propagate a work of Target Code formed by\n combining the Runtime Library with Independent Modules, even if such\n propagation would otherwise violate the terms of GPLv3, provided that\n all Target Code was generated by Eligible Compilation Processes. You\n may then convey such a combination under terms of your choice,\n consistent with the licensing of the Independent Modules.\n\n 2. No Weakening of GCC Copyleft.\n\n The availability of this Exception does not imply any general\n presumption that third-party software is unaffected by the copyleft\n requirements of the license of GCC.\n\n ----\n\n                     GNU GENERAL PUBLIC LICENSE\n                        Version 3, 29 June 2007\n\n  Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n  Everyone is permitted to copy and distribute verbatim copies\n  of this license document, but changing it is not allowed.\n\n                             Preamble\n\n   The GNU General Public License is a free, copyleft license for\n software and other kinds of works.\n\n   The licenses for most software and other practical works are designed\n to take away your freedom to share and change the works.  By contrast,\n the GNU General Public License is intended to guarantee your freedom to\n share and change all versions of a program--to make sure it remains free\n software for all its users.  We, the Free Software Foundation, use the\n GNU General Public License for most of our software; it applies also to\n any other work released this way by its authors.  You can apply it to\n your programs, too.\n\n   When we speak of free software, we are referring to freedom, not\n price.  Our General Public Licenses are designed to make sure that you\n have the freedom to distribute copies of free software (and charge for\n them if you wish), that you receive source code or can get it if you\n want it, that you can change the software or use pieces of it in new\n free programs, and that you know you can do these things.\n\n   To protect your rights, we need to prevent others from denying you\n these rights or asking you to surrender the rights.  Therefore, you have\n certain responsibilities if you distribute copies of the software, or if\n you modify it: responsibilities to respect the freedom of others.\n\n   For example, if you distribute copies of such a program, whether\n gratis or for a fee, you must pass on to the recipients the same\n freedoms that you received.  You must make sure that they, too, receive\n or can get the source code.  And you must show them these terms so they\n know their rights.\n\n   Developers that use the GNU GPL protect your rights with two steps:\n (1) assert copyright on the software, and (2) offer you this License\n giving you legal permission to copy, distribute and/or modify it.\n\n   For the developers' and authors' protection, the GPL clearly explains\n that there is no warranty for this free software.  For both users' and\n authors' sake, the GPL requires that modified versions be marked as\n changed, so that their problems will not be attributed erroneously to\n authors of previous versions.\n\n   Some devices are designed to deny users access to install or run\n modified versions of the software inside them, although the manufacturer\n can do so.  This is fundamentally incompatible with the aim of\n protecting users' freedom to change the software.  The systematic\n pattern of such abuse occurs in the area of products for individuals to\n use, which is precisely where it is most unacceptable.  Therefore, we\n have designed this version of the GPL to prohibit the practice for those\n products.  If such problems arise substantially in other domains, we\n stand ready to extend this provision to those domains in future versions\n of the GPL, as needed to protect the freedom of users.\n\n   Finally, every program is threatened constantly by software patents.\n States should not allow patents to restrict development and use of\n software on general-purpose computers, but in those that do, we wish to\n avoid the special danger that patents applied to a free program could\n make it effectively proprietary.  To prevent this, the GPL assures that\n patents cannot be used to render the program non-free.\n\n   The precise terms and conditions for copying, distribution and\n modification follow.\n\n                        TERMS AND CONDITIONS\n\n   0. Definitions.\n\n   \"This License\" refers to version 3 of the GNU General Public License.\n\n   \"Copyright\" also means copyright-like laws that apply to other kinds of\n works, such as semiconductor masks.\n\n   \"The Program\" refers to any copyrightable work licensed under this\n License.  Each licensee is addressed as \"you\".  \"Licensees\" and\n \"recipients\" may be individuals or organizations.\n\n   To \"modify\" a work means to copy from or adapt all or part of the work\n in a fashion requiring copyright permission, other than the making of an\n exact copy.  The resulting work is called a \"modified version\" of the\n earlier work or a work \"based on\" the earlier work.\n\n   A \"covered work\" means either the unmodified Program or a work based\n on the Program.\n\n   To \"propagate\" a work means to do anything with it that, without\n permission, would make you directly or secondarily liable for\n infringement under applicable copyright law, except executing it on a\n computer or modifying a private copy.  Propagation includes copying,\n distribution (with or without modification), making available to the\n public, and in some countries other activities as well.\n\n   To \"convey\" a work means any kind of propagation that enables other\n parties to make or receive copies.  Mere interaction with a user through\n a computer network, with no transfer of a copy, is not conveying.\n\n   An interactive user interface displays \"Appropriate Legal Notices\"\n to the extent that it includes a convenient and prominently visible\n feature that (1) displays an appropriate copyright notice, and (2)\n tells the user that there is no warranty for the work (except to the\n extent that warranties are provided), that licensees may convey the\n work under this License, and how to view a copy of this License.  If\n the interface presents a list of user commands or options, such as a\n menu, a prominent item in the list meets this criterion.\n\n   1. Source Code.\n\n   The \"source code\" for a work means the preferred form of the work\n for making modifications to it.  \"Object code\" means any non-source\n form of a work.\n\n   A \"Standard Interface\" means an interface that either is an official\n standard defined by a recognized standards body, or, in the case of\n interfaces specified for a particular programming language, one that\n is widely used among developers working in that language.\n\n   The \"System Libraries\" of an executable work include anything, other\n than the work as a whole, that (a) is included in the normal form of\n packaging a Major Component, but which is not part of that Major\n Component, and (b) serves only to enable use of the work with that\n Major Component, or to implement a Standard Interface for which an\n implementation is available to the public in source code form.  A\n \"Major Component\", in this context, means a major essential component\n (kernel, window system, and so on) of the specific operating system\n (if any) on which the executable work runs, or a compiler used to\n produce the work, or an object code interpreter used to run it.\n\n   The \"Corresponding Source\" for a work in object code form means all\n the source code needed to generate, install, and (for an executable\n work) run the object code and to modify the work, including scripts to\n control those activities.  However, it does not include the work's\n System Libraries, or general-purpose tools or generally available free\n programs which are used unmodified in performing those activities but\n which are not part of the work.  For example, Corresponding Source\n includes interface definition files associated with source files for\n the work, and the source code for shared libraries and dynamically\n linked subprograms that the work is specifically designed to require,\n such as by intimate data communication or control flow between those\n subprograms and other parts of the work.\n\n   The Corresponding Source need not include anything that users\n can regenerate automatically from other parts of the Corresponding\n Source.\n\n   The Corresponding Source for a work in source code form is that\n same work.\n\n   2. Basic Permissions.\n\n   All rights granted under this License are granted for the term of\n copyright on the Program, and are irrevocable provided the stated\n conditions are met.  This License explicitly affirms your unlimited\n permission to run the unmodified Program.  The output from running a\n covered work is covered by this License only if the output, given its\n content, constitutes a covered work.  This License acknowledges your\n rights of fair use or other equivalent, as provided by copyright law.\n\n   You may make, run and propagate covered works that you do not\n convey, without conditions so long as your license otherwise remains\n in force.  You may convey covered works to others for the sole purpose\n of having them make modifications exclusively for you, or provide you\n with facilities for running those works, provided that you comply with\n the terms of this License in conveying all material for which you do\n not control copyright.  Those thus making or running the covered works\n for you must do so exclusively on your behalf, under your direction\n and control, on terms that prohibit them from making any copies of\n your copyrighted material outside their relationship with you.\n\n   Conveying under any other circumstances is permitted solely under\n the conditions stated below.  Sublicensing is not allowed; section 10\n makes it unnecessary.\n\n   3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n   No covered work shall be deemed part of an effective technological\n measure under any applicable law fulfilling obligations under article\n 11 of the WIPO copyright treaty adopted on 20 December 1996, or\n similar laws prohibiting or restricting circumvention of such\n measures.\n\n   When you convey a covered work, you waive any legal power to forbid\n circumvention of technological measures to the extent such circumvention\n is effected by exercising rights under this License with respect to\n the covered work, and you disclaim any intention to limit operation or\n modification of the work as a means of enforcing, against the work's\n users, your or third parties' legal rights to forbid circumvention of\n technological measures.\n\n   4. Conveying Verbatim Copies.\n\n   You may convey verbatim copies of the Program's source code as you\n receive it, in any medium, provided that you conspicuously and\n appropriately publish on each copy an appropriate copyright notice;\n keep intact all notices stating that this License and any\n non-permissive terms added in accord with section 7 apply to the code;\n keep intact all notices of the absence of any warranty; and give all\n recipients a copy of this License along with the Program.\n\n   You may charge any price or no price for each copy that you convey,\n and you may offer support or warranty protection for a fee.\n\n   5. Conveying Modified Source Versions.\n\n   You may convey a work based on the Program, or the modifications to\n produce it from the Program, in the form of source code under the\n terms of section 4, provided that you also meet all of these conditions:\n\n     a) The work must carry prominent notices stating that you modified\n     it, and giving a relevant date.\n\n     b) The work must carry prominent notices stating that it is\n     released under this License and any conditions added under section\n     7.  This requirement modifies the requirement in section 4 to\n     \"keep intact all notices\".\n\n     c) You must license the entire work, as a whole, under this\n     License to anyone who comes into possession of a copy.  This\n     License will therefore apply, along with any applicable section 7\n     additional terms, to the whole of the work, and all its parts,\n     regardless of how they are packaged.  This License gives no\n     permission to license the work in any other way, but it does not\n     invalidate such permission if you have separately received it.\n\n     d) If the work has interactive user interfaces, each must display\n     Appropriate Legal Notices; however, if the Program has interactive\n     interfaces that do not display Appropriate Legal Notices, your\n     work need not make them do so.\n\n   A compilation of a covered work with other separate and independent\n works, which are not by their nature extensions of the covered work,\n and which are not combined with it such as to form a larger program,\n in or on a volume of a storage or distribution medium, is called an\n \"aggregate\" if the compilation and its resulting copyright are not\n used to limit the access or legal rights of the compilation's users\n beyond what the individual works permit.  Inclusion of a covered work\n in an aggregate does not cause this License to apply to the other\n parts of the aggregate.\n\n   6. Conveying Non-Source Forms.\n\n   You may convey a covered work in object code form under the terms\n of sections 4 and 5, provided that you also convey the\n machine-readable Corresponding Source under the terms of this License,\n in one of these ways:\n\n     a) Convey the object code in, or embodied in, a physical product\n     (including a physical distribution medium), accompanied by the\n     Corresponding Source fixed on a durable physical medium\n     customarily used for software interchange.\n\n     b) Convey the object code in, or embodied in, a physical product\n     (including a physical distribution medium), accompanied by a\n     written offer, valid for at least three years and valid for as\n     long as you offer spare parts or customer support for that product\n     model, to give anyone who possesses the object code either (1) a\n     copy of the Corresponding Source for all the software in the\n     product that is covered by this License, on a durable physical\n     medium customarily used for software interchange, for a price no\n     more than your reasonable cost of physically performing this\n     conveying of source, or (2) access to copy the\n     Corresponding Source from a network server at no charge.\n\n     c) Convey individual copies of the object code with a copy of the\n     written offer to provide the Corresponding Source.  This\n     alternative is allowed only occasionally and noncommercially, and\n     only if you received the object code with such an offer, in accord\n     with subsection 6b.\n\n     d) Convey the object code by offering access from a designated\n     place (gratis or for a charge), and offer equivalent access to the\n     Corresponding Source in the same way through the same place at no\n     further charge.  You need not require recipients to copy the\n     Corresponding Source along with the object code.  If the place to\n     copy the object code is a network server, the Corresponding Source\n     may be on a different server (operated by you or a third party)\n     that supports equivalent copying facilities, provided you maintain\n     clear directions next to the object code saying where to find the\n     Corresponding Source.  Regardless of what server hosts the\n     Corresponding Source, you remain obligated to ensure that it is\n     available for as long as needed to satisfy these requirements.\n\n     e) Convey the object code using peer-to-peer transmission, provided\n     you inform other peers where the object code and Corresponding\n     Source of the work are being offered to the general public at no\n     charge under subsection 6d.\n\n   A separable portion of the object code, whose source code is excluded\n from the Corresponding Source as a System Library, need not be\n included in conveying the object code work.\n\n   A \"User Product\" is either (1) a \"consumer product\", which means any\n tangible personal property which is normally used for personal, family,\n or household purposes, or (2) anything designed or sold for incorporation\n into a dwelling.  In determining whether a product is a consumer product,\n doubtful cases shall be resolved in favor of coverage.  For a particular\n product received by a particular user, \"normally used\" refers to a\n typical or common use of that class of product, regardless of the status\n of the particular user or of the way in which the particular user\n actually uses, or expects or is expected to use, the product.  A product\n is a consumer product regardless of whether the product has substantial\n commercial, industrial or non-consumer uses, unless such uses represent\n the only significant mode of use of the product.\n\n   \"Installation Information\" for a User Product means any methods,\n procedures, authorization keys, or other information required to install\n and execute modified versions of a covered work in that User Product from\n a modified version of its Corresponding Source.  The information must\n suffice to ensure that the continued functioning of the modified object\n code is in no case prevented or interfered with solely because\n modification has been made.\n\n   If you convey an object code work under this section in, or with, or\n specifically for use in, a User Product, and the conveying occurs as\n part of a transaction in which the right of possession and use of the\n User Product is transferred to the recipient in perpetuity or for a\n fixed term (regardless of how the transaction is characterized), the\n Corresponding Source conveyed under this section must be accompanied\n by the Installation Information.  But this requirement does not apply\n if neither you nor any third party retains the ability to install\n modified object code on the User Product (for example, the work has\n been installed in ROM).\n\n   The requirement to provide Installation Information does not include a\n requirement to continue to provide support service, warranty, or updates\n for a work that has been modified or installed by the recipient, or for\n the User Product in which it has been modified or installed.  Access to a\n network may be denied when the modification itself materially and\n adversely affects the operation of the network or violates the rules and\n protocols for communication across the network.\n\n   Corresponding Source conveyed, and Installation Information provided,\n in accord with this section must be in a format that is publicly\n documented (and with an implementation available to the public in\n source code form), and must require no special password or key for\n unpacking, reading or copying.\n\n   7. Additional Terms.\n\n   \"Additional permissions\" are terms that supplement the terms of this\n License by making exceptions from one or more of its conditions.\n Additional permissions that are applicable to the entire Program shall\n be treated as though they were included in this License, to the extent\n that they are valid under applicable law.  If additional permissions\n apply only to part of the Program, that part may be used separately\n under those permissions, but the entire Program remains governed by\n this License without regard to the additional permissions.\n\n   When you convey a copy of a covered work, you may at your option\n remove any additional permissions from that copy, or from any part of\n it.  (Additional permissions may be written to require their own\n removal in certain cases when you modify the work.)  You may place\n additional permissions on material, added by you to a covered work,\n for which you have or can give appropriate copyright permission.\n\n   Notwithstanding any other provision of this License, for material you\n add to a covered work, you may (if authorized by the copyright holders of\n that material) supplement the terms of this License with terms:\n\n     a) Disclaiming warranty or limiting liability differently from the\n     terms of sections 15 and 16 of this License; or\n\n     b) Requiring preservation of specified reasonable legal notices or\n     author attributions in that material or in the Appropriate Legal\n     Notices displayed by works containing it; or\n\n     c) Prohibiting misrepresentation of the origin of that material, or\n     requiring that modified versions of such material be marked in\n     reasonable ways as different from the original version; or\n\n     d) Limiting the use for publicity purposes of names of licensors or\n     authors of the material; or\n\n     e) Declining to grant rights under trademark law for use of some\n     trade names, trademarks, or service marks; or\n\n     f) Requiring indemnification of licensors and authors of that\n     material by anyone who conveys the material (or modified versions of\n     it) with contractual assumptions of liability to the recipient, for\n     any liability that these contractual assumptions directly impose on\n     those licensors and authors.\n\n   All other non-permissive additional terms are considered \"further\n restrictions\" within the meaning of section 10.  If the Program as you\n received it, or any part of it, contains a notice stating that it is\n governed by this License along with a term that is a further\n restriction, you may remove that term.  If a license document contains\n a further restriction but permits relicensing or conveying under this\n License, you may add to a covered work material governed by the terms\n of that license document, provided that the further restriction does\n not survive such relicensing or conveying.\n\n   If you add terms to a covered work in accord with this section, you\n must place, in the relevant source files, a statement of the\n additional terms that apply to those files, or a notice indicating\n where to find the applicable terms.\n\n   Additional terms, permissive or non-permissive, may be stated in the\n form of a separately written license, or stated as exceptions;\n the above requirements apply either way.\n\n   8. Termination.\n\n   You may not propagate or modify a covered work except as expressly\n provided under this License.  Any attempt otherwise to propagate or\n modify it is void, and will automatically terminate your rights under\n this License (including any patent licenses granted under the third\n paragraph of section 11).\n\n   However, if you cease all violation of this License, then your\n license from a particular copyright holder is reinstated (a)\n provisionally, unless and until the copyright holder explicitly and\n finally terminates your license, and (b) permanently, if the copyright\n holder fails to notify you of the violation by some reasonable means\n prior to 60 days after the cessation.\n\n   Moreover, your license from a particular copyright holder is\n reinstated permanently if the copyright holder notifies you of the\n violation by some reasonable means, this is the first time you have\n received notice of violation of this License (for any work) from that\n copyright holder, and you cure the violation prior to 30 days after\n your receipt of the notice.\n\n   Termination of your rights under this section does not terminate the\n licenses of parties who have received copies or rights from you under\n this License.  If your rights have been terminated and not permanently\n reinstated, you do not qualify to receive new licenses for the same\n material under section 10.\n\n   9. Acceptance Not Required for Having Copies.\n\n   You are not required to accept this License in order to receive or\n run a copy of the Program.  Ancillary propagation of a covered work\n occurring solely as a consequence of using peer-to-peer transmission\n to receive a copy likewise does not require acceptance.  However,\n nothing other than this License grants you permission to propagate or\n modify any covered work.  These actions infringe copyright if you do\n not accept this License.  Therefore, by modifying or propagating a\n covered work, you indicate your acceptance of this License to do so.\n\n   10. Automatic Licensing of Downstream Recipients.\n\n   Each time you convey a covered work, the recipient automatically\n receives a license from the original licensors, to run, modify and\n propagate that work, subject to this License.  You are not responsible\n for enforcing compliance by third parties with this License.\n\n   An \"entity transaction\" is a transaction transferring control of an\n organization, or substantially all assets of one, or subdividing an\n organization, or merging organizations.  If propagation of a covered\n work results from an entity transaction, each party to that\n transaction who receives a copy of the work also receives whatever\n licenses to the work the party's predecessor in interest had or could\n give under the previous paragraph, plus a right to possession of the\n Corresponding Source of the work from the predecessor in interest, if\n the predecessor has it or can get it with reasonable efforts.\n\n   You may not impose any further restrictions on the exercise of the\n rights granted or affirmed under this License.  For example, you may\n not impose a license fee, royalty, or other charge for exercise of\n rights granted under this License, and you may not initiate litigation\n (including a cross-claim or counterclaim in a lawsuit) alleging that\n any patent claim is infringed by making, using, selling, offering for\n sale, or importing the Program or any portion of it.\n\n   11. Patents.\n\n   A \"contributor\" is a copyright holder who authorizes use under this\n License of the Program or a work on which the Program is based.  The\n work thus licensed is called the contributor's \"contributor version\".\n\n   A contributor's \"essential patent claims\" are all patent claims\n owned or controlled by the contributor, whether already acquired or\n hereafter acquired, that would be infringed by some manner, permitted\n by this License, of making, using, or selling its contributor version,\n but do not include claims that would be infringed only as a\n consequence of further modification of the contributor version.  For\n purposes of this definition, \"control\" includes the right to grant\n patent sublicenses in a manner consistent with the requirements of\n this License.\n\n   Each contributor grants you a non-exclusive, worldwide, royalty-free\n patent license under the contributor's essential patent claims, to\n make, use, sell, offer for sale, import and otherwise run, modify and\n propagate the contents of its contributor version.\n\n   In the following three paragraphs, a \"patent license\" is any express\n agreement or commitment, however denominated, not to enforce a patent\n (such as an express permission to practice a patent or covenant not to\n sue for patent infringement).  To \"grant\" such a patent license to a\n party means to make such an agreement or commitment not to enforce a\n patent against the party.\n\n   If you convey a covered work, knowingly relying on a patent license,\n and the Corresponding Source of the work is not available for anyone\n to copy, free of charge and under the terms of this License, through a\n publicly available network server or other readily accessible means,\n then you must either (1) cause the Corresponding Source to be so\n available, or (2) arrange to deprive yourself of the benefit of the\n patent license for this particular work, or (3) arrange, in a manner\n consistent with the requirements of this License, to extend the patent\n license to downstream recipients.  \"Knowingly relying\" means you have\n actual knowledge that, but for the patent license, your conveying the\n covered work in a country, or your recipient's use of the covered work\n in a country, would infringe one or more identifiable patents in that\n country that you have reason to believe are valid.\n\n   If, pursuant to or in connection with a single transaction or\n arrangement, you convey, or propagate by procuring conveyance of, a\n covered work, and grant a patent license to some of the parties\n receiving the covered work authorizing them to use, propagate, modify\n or convey a specific copy of the covered work, then the patent license\n you grant is automatically extended to all recipients of the covered\n work and works based on it.\n\n   A patent license is \"discriminatory\" if it does not include within\n the scope of its coverage, prohibits the exercise of, or is\n conditioned on the non-exercise of one or more of the rights that are\n specifically granted under this License.  You may not convey a covered\n work if you are a party to an arrangement with a third party that is\n in the business of distributing software, under which you make payment\n to the third party based on the extent of your activity of conveying\n the work, and under which the third party grants, to any of the\n parties who would receive the covered work from you, a discriminatory\n patent license (a) in connection with copies of the covered work\n conveyed by you (or copies made from those copies), or (b) primarily\n for and in connection with specific products or compilations that\n contain the covered work, unless you entered into that arrangement,\n or that patent license was granted, prior to 28 March 2007.\n\n   Nothing in this License shall be construed as excluding or limiting\n any implied license or other defenses to infringement that may\n otherwise be available to you under applicable patent law.\n\n   12. No Surrender of Others' Freedom.\n\n   If conditions are imposed on you (whether by court order, agreement or\n otherwise) that contradict the conditions of this License, they do not\n excuse you from the conditions of this License.  If you cannot convey a\n covered work so as to satisfy simultaneously your obligations under this\n License and any other pertinent obligations, then as a consequence you may\n not convey it at all.  For example, if you agree to terms that obligate you\n to collect a royalty for further conveying from those to whom you convey\n the Program, the only way you could satisfy both those terms and this\n License would be to refrain entirely from conveying the Program.\n\n   13. Use with the GNU Affero General Public License.\n\n   Notwithstanding any other provision of this License, you have\n permission to link or combine any covered work with a work licensed\n under version 3 of the GNU Affero General Public License into a single\n combined work, and to convey the resulting work.  The terms of this\n License will continue to apply to the part which is the covered work,\n but the special requirements of the GNU Affero General Public License,\n section 13, concerning interaction through a network will apply to the\n combination as such.\n\n   14. Revised Versions of this License.\n\n   The Free Software Foundation may publish revised and/or new versions of\n the GNU General Public License from time to time.  Such new versions will\n be similar in spirit to the present version, but may differ in detail to\n address new problems or concerns.\n\n   Each version is given a distinguishing version number.  If the\n Program specifies that a certain numbered version of the GNU General\n Public License \"or any later version\" applies to it, you have the\n option of following the terms and conditions either of that numbered\n version or of any later version published by the Free Software\n Foundation.  If the Program does not specify a version number of the\n GNU General Public License, you may choose any version ever published\n by the Free Software Foundation.\n\n   If the Program specifies that a proxy can decide which future\n versions of the GNU General Public License can be used, that proxy's\n public statement of acceptance of a version permanently authorizes you\n to choose that version for the Program.\n\n   Later license versions may give you additional or different\n permissions.  However, no additional obligations are imposed on any\n author or copyright holder as a result of your choosing to follow a\n later version.\n\n   15. Disclaimer of Warranty.\n\n   THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\n APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\n HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\n OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\n THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\n IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\n ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n   16. Limitation of Liability.\n\n   IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\n WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\n THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\n GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\n USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\n DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\n PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\n EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\n SUCH DAMAGES.\n\n   17. Interpretation of Sections 15 and 16.\n\n   If the disclaimer of warranty and limitation of liability provided\n above cannot be given local legal effect according to their terms,\n reviewing courts shall apply local law that most closely approximates\n an absolute waiver of all civil liability in connection with the\n Program, unless a warranty or assumption of liability accompanies a\n copy of the Program in return for a fee.\n\n                      END OF TERMS AND CONDITIONS\n\n             How to Apply These Terms to Your New Programs\n\n   If you develop a new program, and you want it to be of the greatest\n possible use to the public, the best way to achieve this is to make it\n free software which everyone can redistribute and change under these terms.\n\n   To do so, attach the following notices to the program.  It is safest\n to attach them to the start of each source file to most effectively\n state the exclusion of warranty; and each file should have at least\n the \"copyright\" line and a pointer to where the full notice is found.\n\n     <one line to give the program's name and a brief idea of what it does.>\n     Copyright (C) <year>  <name of author>\n\n     This program is free software: you can redistribute it and/or modify\n     it under the terms of the GNU General Public License as published by\n     the Free Software Foundation, either version 3 of the License, or\n     (at your option) any later version.\n\n     This program is distributed in the hope that it will be useful,\n     but WITHOUT ANY WARRANTY; without even the implied warranty of\n     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n     GNU General Public License for more details.\n\n     You should have received a copy of the GNU General Public License\n     along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n Also add information on how to contact you by electronic and paper mail.\n\n   If the program does terminal interaction, make it output a short\n notice like this when it starts in an interactive mode:\n\n     <program>  Copyright (C) <year>  <name of author>\n     This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n     This is free software, and you are welcome to redistribute it\n     under certain conditions; type `show c' for details.\n\n The hypothetical commands `show w' and `show c' should show the appropriate\n parts of the General Public License.  Of course, your program's commands\n might be different; for a GUI interface, you would use an \"about box\".\n\n   You should also get your employer (if you work as a programmer) or school,\n if any, to sign a \"copyright disclaimer\" for the program, if necessary.\n For more information on this, and how to apply and follow the GNU GPL, see\n <http://www.gnu.org/licenses/>.\n\n   The GNU General Public License does not permit incorporating your program\n into proprietary programs.  If your program is a subroutine library, you\n may consider it more useful to permit linking proprietary applications with\n the library.  If this is what you want to do, use the GNU Lesser General\n Public License instead of this License.  But first, please read\n <http://www.gnu.org/philosophy/why-not-lgpl.html>.\n",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: C",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development :: Libraries",
          "Topic :: Scientific/Engineering",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Operating System :: MacOS"
        ],
        "requires_dist": [
          "numpy<2.7,>=1.26.4",
          "pytest>=8.0.0; extra == \"test\"",
          "pytest-cov; extra == \"test\"",
          "pytest-timeout; extra == \"test\"",
          "pytest-xdist; extra == \"test\"",
          "asv; extra == \"test\"",
          "mpmath; extra == \"test\"",
          "gmpy2; extra == \"test\"",
          "threadpoolctl; extra == \"test\"",
          "scikit-umfpack; extra == \"test\"",
          "pooch; extra == \"test\"",
          "hypothesis>=6.30; extra == \"test\"",
          "array-api-strict>=2.3.1; extra == \"test\"",
          "Cython; extra == \"test\"",
          "meson; extra == \"test\"",
          "ninja; sys_platform != \"emscripten\" and extra == \"test\"",
          "sphinx<8.2.0,>=5.0.0; extra == \"doc\"",
          "intersphinx_registry; extra == \"doc\"",
          "pydata-sphinx-theme>=0.15.2; extra == \"doc\"",
          "sphinx-copybutton; extra == \"doc\"",
          "sphinx-design>=0.4.0; extra == \"doc\"",
          "matplotlib>=3.5; extra == \"doc\"",
          "numpydoc; extra == \"doc\"",
          "jupytext; extra == \"doc\"",
          "myst-nb>=1.2.0; extra == \"doc\"",
          "pooch; extra == \"doc\"",
          "jupyterlite-sphinx>=0.19.1; extra == \"doc\"",
          "jupyterlite-pyodide-kernel; extra == \"doc\"",
          "linkify-it-py; extra == \"doc\"",
          "tabulate; extra == \"doc\"",
          "click<8.3.0; extra == \"dev\"",
          "spin; extra == \"dev\"",
          "mypy==1.10.0; extra == \"dev\"",
          "typing_extensions; extra == \"dev\"",
          "types-psutil; extra == \"dev\"",
          "pycodestyle; extra == \"dev\"",
          "ruff>=0.12.0; extra == \"dev\"",
          "cython-lint>=0.12.2; extra == \"dev\""
        ],
        "requires_python": ">=3.11",
        "project_url": [
          "homepage, https://scipy.org/",
          "documentation, https://docs.scipy.org/doc/scipy/",
          "source, https://github.com/scipy/scipy",
          "download, https://github.com/scipy/scipy/releases",
          "tracker, https://github.com/scipy/scipy/issues"
        ],
        "provides_extra": [
          "test",
          "doc",
          "dev"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274",
          "hashes": {
            "sha256": "4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "six",
        "version": "1.17.0",
        "summary": "Python 2 and 3 compatibility utilities",
        "description": ".. image:: https://img.shields.io/pypi/v/six.svg\n   :target: https://pypi.org/project/six/\n   :alt: six on PyPI\n\n.. image:: https://readthedocs.org/projects/six/badge/?version=latest\n   :target: https://six.readthedocs.io/\n   :alt: six's documentation on Read the Docs\n\n.. image:: https://img.shields.io/badge/license-MIT-green.svg\n   :target: https://github.com/benjaminp/six/blob/master/LICENSE\n   :alt: MIT License badge\n\nSix is a Python 2 and 3 compatibility library.  It provides utility functions\nfor smoothing over the differences between the Python versions with the goal of\nwriting Python code that is compatible on both Python versions.  See the\ndocumentation for more information on what is provided.\n\nSix supports Python 2.7 and 3.3+.  It is contained in only one Python\nfile, so it can be easily copied into your project. (The copyright and license\nnotice must be retained.)\n\nOnline documentation is at https://six.readthedocs.io/.\n\nBugs can be reported to https://github.com/benjaminp/six.  The code can also\nbe found there.\n",
        "home_page": "https://github.com/benjaminp/six",
        "author": "Benjamin Peterson",
        "author_email": "benjamin@python.org",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/16/e1/3079a9ff9b8e11b846c6ac5c8b5bfb7ff225eee721825310c91b3b50304f/tqdm-4.67.3-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=ee1e4c0e59148062281c49d80b25b67771a127c85fc9676d3be5f243206826bf",
          "hashes": {
            "sha256": "ee1e4c0e59148062281c49d80b25b67771a127c85fc9676d3be5f243206826bf"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "tqdm",
        "version": "4.67.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Fast, Extensible Progress Meter",
        "description": "|Logo|\n\ntqdm\n====\n\n|Py-Versions| |Versions| |Conda-Forge-Status| |Docker| |Snapcraft|\n\n|Build-Status| |Coverage-Status| |Branch-Coverage-Status| |Codacy-Grade| |Libraries-Rank| |PyPI-Downloads|\n\n|LICENCE| |OpenHub-Status| |binder-demo| |awesome-python|\n\n``tqdm`` derives from the Arabic word *taqaddum* (ØªÙ‚Ø¯Ù‘Ù…) which can mean \"progress,\"\nand is an abbreviation for \"I love you so much\" in Spanish (*te quiero demasiado*).\n\nInstantly make your loops show a smart progress meter - just wrap any\niterable with ``tqdm(iterable)``, and you're done!\n\n.. code:: python\n\n    from tqdm import tqdm\n    for i in tqdm(range(10000)):\n        ...\n\n``76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Â Â Â Â Â Â  | 7568/10000 [00:33<00:10, 229.00it/s]``\n\n``trange(N)`` can be also used as a convenient shortcut for\n``tqdm(range(N))``.\n\n|Screenshot|\n    |Video| |Slides| |Merch|\n\nIt can also be executed as a module with pipes:\n\n.. code:: sh\n\n    $ seq 9999999 | tqdm --bytes | wc -l\n    75.2MB [00:00, 217MB/s]\n    9999999\n\n    $ tar -zcf - docs/ | tqdm --bytes --total `du -sb docs/ | cut -f1` \\\n        > backup.tgz\n     32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 8.89G/27.9G [00:42<01:31, 223MB/s]\n\nOverhead is low -- about 60ns per iteration (80ns with ``tqdm.gui``), and is\nunit tested against performance regression.\nBy comparison, the well-established\n`ProgressBar <https://github.com/niltonvolpato/python-progressbar>`__ has\nan 800ns/iter overhead.\n\nIn addition to its low overhead, ``tqdm`` uses smart algorithms to predict\nthe remaining time and to skip unnecessary iteration displays, which allows\nfor a negligible overhead in most cases.\n\n``tqdm`` works on any platform\n(Linux, Windows, Mac, FreeBSD, NetBSD, Solaris/SunOS),\nin any console or in a GUI, and is also friendly with IPython/Jupyter notebooks.\n\n``tqdm`` does not require any dependencies (not even ``curses``!), just\nPython and an environment supporting ``carriage return \\r`` and\n``line feed \\n`` control characters.\n\n------------------------------------------\n\n.. contents:: Table of contents\n   :backlinks: top\n   :local:\n\n\nInstallation\n------------\n\nLatest PyPI stable release\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n|Versions| |PyPI-Downloads| |Libraries-Dependents|\n\n.. code:: sh\n\n    pip install tqdm\n\nLatest development release on GitHub\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n|GitHub-Status| |GitHub-Stars| |GitHub-Commits| |GitHub-Forks| |GitHub-Updated|\n\nPull and install pre-release ``devel`` branch:\n\n.. code:: sh\n\n    pip install \"git+https://github.com/tqdm/tqdm.git@devel#egg=tqdm\"\n\nLatest Conda release\n~~~~~~~~~~~~~~~~~~~~\n\n|Conda-Forge-Status|\n\n.. code:: sh\n\n    conda install -c conda-forge tqdm\n\nLatest Snapcraft release\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n|Snapcraft|\n\nThere are 3 channels to choose from:\n\n.. code:: sh\n\n    snap install tqdm  # implies --stable, i.e. latest tagged release\n    snap install tqdm  --candidate  # master branch\n    snap install tqdm  --edge  # devel branch\n\nNote that ``snap`` binaries are purely for CLI use (not ``import``-able), and\nautomatically set up ``bash`` tab-completion.\n\nLatest Docker release\n~~~~~~~~~~~~~~~~~~~~~\n\n|Docker|\n\n.. code:: sh\n\n    docker pull tqdm/tqdm\n    docker run -i --rm tqdm/tqdm --help\n\nOther\n~~~~~\n\nThere are other (unofficial) places where ``tqdm`` may be downloaded, particularly for CLI use:\n\n|Repology|\n\n.. |Repology| image:: https://repology.org/badge/tiny-repos/python:tqdm.svg\n   :target: https://repology.org/project/python:tqdm/versions\n\nChangelog\n---------\n\nThe list of all changes is available either on GitHub's Releases:\n|GitHub-Status|, on the\n`wiki <https://github.com/tqdm/tqdm/wiki/Releases>`__, or on the\n`website <https://tqdm.github.io/releases>`__.\n\n\nUsage\n-----\n\n``tqdm`` is very versatile and can be used in a number of ways.\nThe three main ones are given below.\n\nIterable-based\n~~~~~~~~~~~~~~\n\nWrap ``tqdm()`` around any iterable:\n\n.. code:: python\n\n    from tqdm import tqdm\n    from time import sleep\n\n    text = \"\"\n    for char in tqdm([\"a\", \"b\", \"c\", \"d\"]):\n        sleep(0.25)\n        text = text + char\n\n``trange(i)`` is a special optimised instance of ``tqdm(range(i))``:\n\n.. code:: python\n\n    from tqdm import trange\n\n    for i in trange(100):\n        sleep(0.01)\n\nInstantiation outside of the loop allows for manual control over ``tqdm()``:\n\n.. code:: python\n\n    pbar = tqdm([\"a\", \"b\", \"c\", \"d\"])\n    for char in pbar:\n        sleep(0.25)\n        pbar.set_description(\"Processing %s\" % char)\n\nManual\n~~~~~~\n\nManual control of ``tqdm()`` updates using a ``with`` statement:\n\n.. code:: python\n\n    with tqdm(total=100) as pbar:\n        for i in range(10):\n            sleep(0.1)\n            pbar.update(10)\n\nIf the optional variable ``total`` (or an iterable with ``len()``) is\nprovided, predictive stats are displayed.\n\n``with`` is also optional (you can just assign ``tqdm()`` to a variable,\nbut in this case don't forget to ``del`` or ``close()`` at the end:\n\n.. code:: python\n\n    pbar = tqdm(total=100)\n    for i in range(10):\n        sleep(0.1)\n        pbar.update(10)\n    pbar.close()\n\nModule\n~~~~~~\n\nPerhaps the most wonderful use of ``tqdm`` is in a script or on the command\nline. Simply inserting ``tqdm`` (or ``python -m tqdm``) between pipes will pass\nthrough all ``stdin`` to ``stdout`` while printing progress to ``stderr``.\n\nThe example below demonstrate counting the number of lines in all Python files\nin the current directory, with timing information included.\n\n.. code:: sh\n\n    $ time find . -name '*.py' -type f -exec cat \\{} \\; | wc -l\n    857365\n\n    real    0m3.458s\n    user    0m0.274s\n    sys     0m3.325s\n\n    $ time find . -name '*.py' -type f -exec cat \\{} \\; | tqdm | wc -l\n    857366it [00:03, 246471.31it/s]\n    857365\n\n    real    0m3.585s\n    user    0m0.862s\n    sys     0m3.358s\n\nNote that the usual arguments for ``tqdm`` can also be specified.\n\n.. code:: sh\n\n    $ find . -name '*.py' -type f -exec cat \\{} \\; |\n        tqdm --unit loc --unit_scale --total 857366 >> /dev/null\n    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 857K/857K [00:04<00:00, 246Kloc/s]\n\nBacking up a large directory?\n\n.. code:: sh\n\n    $ tar -zcf - docs/ | tqdm --bytes --total `du -sb docs/ | cut -f1` \\\n      > backup.tgz\n     44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 153M/352M [00:14<00:18, 11.0MB/s]\n\nThis can be beautified further:\n\n.. code:: sh\n\n    $ BYTES=$(du -sb docs/ | cut -f1)\n    $ tar -cf - docs/ \\\n      | tqdm --bytes --total \"$BYTES\" --desc Processing | gzip \\\n      | tqdm --bytes --total \"$BYTES\" --desc Compressed --position 1 \\\n      > ~/backup.tgz\n    Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352M/352M [00:14<00:00, 30.2MB/s]\n    Compressed:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 148M/352M [00:14<00:19, 10.9MB/s]\n\nOr done on a file level using 7-zip:\n\n.. code:: sh\n\n    $ 7z a -bd -r backup.7z docs/ | grep Compressing \\\n      | tqdm --total $(find docs/ -type f | wc -l) --unit files \\\n      | grep -v Compressing\n    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 15327/15327 [01:00<00:00, 712.96files/s]\n\nPre-existing CLI programs already outputting basic progress information will\nbenefit from ``tqdm``'s ``--update`` and ``--update_to`` flags:\n\n.. code:: sh\n\n    $ seq 3 0.1 5 | tqdm --total 5 --update_to --null\n    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.0/5 [00:00<00:00, 9673.21it/s]\n    $ seq 10 | tqdm --update --null  # 1 + 2 + ... + 10 = 55 iterations\n    55it [00:00, 90006.52it/s]\n\nFAQ and Known Issues\n--------------------\n\n|GitHub-Issues|\n\nThe most common issues relate to excessive output on multiple lines, instead\nof a neat one-line progress bar.\n\n- Consoles in general: require support for carriage return (``CR``, ``\\r``).\n\n  * Some cloud logging consoles which don't support ``\\r`` properly\n    (`cloudwatch <https://github.com/tqdm/tqdm/issues/966>`__,\n    `K8s <https://github.com/tqdm/tqdm/issues/1319>`__) may benefit from\n    ``export TQDM_POSITION=-1``.\n\n- Nested progress bars:\n\n  * Consoles in general: require support for moving cursors up to the\n    previous line. For example,\n    `IDLE <https://github.com/tqdm/tqdm/issues/191#issuecomment-230168030>`__,\n    `ConEmu <https://github.com/tqdm/tqdm/issues/254>`__ and\n    `PyCharm <https://github.com/tqdm/tqdm/issues/203>`__ (also\n    `here <https://github.com/tqdm/tqdm/issues/208>`__,\n    `here <https://github.com/tqdm/tqdm/issues/307>`__, and\n    `here <https://github.com/tqdm/tqdm/issues/454#issuecomment-335416815>`__)\n    lack full support.\n  * Windows: additionally may require the Python module ``colorama``\n    to ensure nested bars stay within their respective lines.\n\n- Unicode:\n\n  * Environments which report that they support unicode will have solid smooth\n    progressbars. The fallback is an ``ascii``-only bar.\n  * Windows consoles often only partially support unicode and thus\n    `often require explicit ascii=True <https://github.com/tqdm/tqdm/issues/454#issuecomment-335416815>`__\n    (also `here <https://github.com/tqdm/tqdm/issues/499>`__). This is due to\n    either normal-width unicode characters being incorrectly displayed as\n    \"wide\", or some unicode characters not rendering.\n\n- Wrapping generators:\n\n  * Generator wrapper functions tend to hide the length of iterables.\n    ``tqdm`` does not.\n  * Replace ``tqdm(enumerate(...))`` with ``enumerate(tqdm(...))`` or\n    ``tqdm(enumerate(x), total=len(x), ...)``.\n    The same applies to ``numpy.ndenumerate``.\n  * Replace ``tqdm(zip(a, b))`` with ``zip(tqdm(a), b)`` or even\n    ``zip(tqdm(a), tqdm(b))``.\n  * The same applies to ``itertools``.\n  * Some useful convenience functions can be found under ``tqdm.contrib``.\n\n- `No intermediate output in docker-compose <https://github.com/tqdm/tqdm/issues/771>`__:\n  use ``docker-compose run`` instead of ``docker-compose up`` and ``tty: true``.\n\n- Overriding defaults via environment variables:\n  e.g. in CI/cloud jobs, ``export TQDM_MININTERVAL=5`` to avoid log spam.\n  This override logic is handled by the ``tqdm.utils.envwrap`` decorator\n  (useful independent of ``tqdm``).\n\nIf you come across any other difficulties, browse and file |GitHub-Issues|.\n\nDocumentation\n-------------\n\n|Py-Versions| |README-Hits| (Since 19 May 2016)\n\n.. code:: python\n\n    class tqdm():\n      \"\"\"\n      Decorate an iterable object, returning an iterator which acts exactly\n      like the original iterable, but prints a dynamically updating\n      progressbar every time a value is requested.\n      \"\"\"\n\n      @envwrap(\"TQDM_\")  # override defaults via env vars\n      def __init__(self, iterable=None, desc=None, total=None, leave=True,\n                   file=None, ncols=None, mininterval=0.1,\n                   maxinterval=10.0, miniters=None, ascii=None, disable=False,\n                   unit='it', unit_scale=False, dynamic_ncols=False,\n                   smoothing=0.3, bar_format=None, initial=0, position=None,\n                   postfix=None, unit_divisor=1000, write_bytes=False,\n                   lock_args=None, nrows=None, colour=None, delay=0):\n\nParameters\n~~~~~~~~~~\n\n* iterable  : iterable, optional  \n    Iterable to decorate with a progressbar.\n    Leave blank to manually manage the updates.\n* desc  : str, optional  \n    Prefix for the progressbar.\n* total  : int or float, optional  \n    The number of expected iterations. If unspecified,\n    len(iterable) is used if possible. If float(\"inf\") or as a last\n    resort, only basic progress statistics are displayed\n    (no ETA, no progressbar).\n    If ``gui`` is True and this parameter needs subsequent updating,\n    specify an initial arbitrary large positive number,\n    e.g. 9e9.\n* leave  : bool, optional  \n    If [default: True], keeps all traces of the progressbar\n    upon termination of iteration.\n    If ``None``, will leave only if ``position`` is ``0``.\n* file  : ``io.TextIOWrapper`` or ``io.StringIO``, optional  \n    Specifies where to output the progress messages\n    (default: sys.stderr). Uses ``file.write(str)`` and ``file.flush()``\n    methods.  For encoding, see ``write_bytes``.\n* ncols  : int, optional  \n    The width of the entire output message. If specified,\n    dynamically resizes the progressbar to stay within this bound.\n    If unspecified, attempts to use environment width. The\n    fallback is a meter width of 10 and no limit for the counter and\n    statistics. If 0, will not print any meter (only stats).\n* mininterval  : float, optional  \n    Minimum progress display update interval [default: 0.1] seconds.\n* maxinterval  : float, optional  \n    Maximum progress display update interval [default: 10] seconds.\n    Automatically adjusts ``miniters`` to correspond to ``mininterval``\n    after long display update lag. Only works if ``dynamic_miniters``\n    or monitor thread is enabled.\n* miniters  : int or float, optional  \n    Minimum progress display update interval, in iterations.\n    If 0 and ``dynamic_miniters``, will automatically adjust to equal\n    ``mininterval`` (more CPU efficient, good for tight loops).\n    If > 0, will skip display of specified number of iterations.\n    Tweak this and ``mininterval`` to get very efficient loops.\n    If your progress is erratic with both fast and slow iterations\n    (network, skipping items, etc) you should set miniters=1.\n* ascii  : bool or str, optional  \n    If unspecified or False, use unicode (smooth blocks) to fill\n    the meter. The fallback is to use ASCII characters \" 123456789#\".\n* disable  : bool, optional  \n    Whether to disable the entire progressbar wrapper\n    [default: False]. If set to None, disable on non-TTY.\n* unit  : str, optional  \n    String that will be used to define the unit of each iteration\n    [default: it].\n* unit_scale  : bool or int or float, optional  \n    If 1 or True, the number of iterations will be reduced/scaled\n    automatically and a metric prefix following the\n    International System of Units standard will be added\n    (kilo, mega, etc.) [default: False]. If any other non-zero\n    number, will scale ``total`` and ``n``.\n* dynamic_ncols  : bool, optional  \n    If set, constantly alters ``ncols`` and ``nrows`` to the\n    environment (allowing for window resizes) [default: False].\n* smoothing  : float, optional  \n    Exponential moving average smoothing factor for speed estimates\n    (ignored in GUI mode). Ranges from 0 (average speed) to 1\n    (current/instantaneous speed) [default: 0.3].\n* bar_format  : str, optional  \n    Specify a custom bar string formatting. May impact performance.\n    [default: '{l_bar}{bar}{r_bar}'], where\n    l_bar='{desc}: {percentage:3.0f}%|' and\n    r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n    '{rate_fmt}{postfix}]'\n    Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n    percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n    rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n    rate_inv, rate_inv_fmt, postfix, unit_divisor,\n    remaining, remaining_s, eta.\n    Note that a trailing \": \" is automatically removed after {desc}\n    if the latter is empty.\n* initial  : int or float, optional  \n    The initial counter value. Useful when restarting a progress\n    bar [default: 0]. If using float, consider specifying ``{n:.3f}``\n    or similar in ``bar_format``, or specifying ``unit_scale``.\n* position  : int, optional  \n    Specify the line offset to print this bar (starting from 0)\n    Automatic if unspecified.\n    Useful to manage multiple bars at once (eg, from threads).\n* postfix  : dict or ``*``, optional  \n    Specify additional stats to display at the end of the bar.\n    Calls ``set_postfix(**postfix)`` if possible (dict).\n* unit_divisor  : float, optional  \n    [default: 1000], ignored unless ``unit_scale`` is True.\n* write_bytes  : bool, optional  \n    Whether to write bytes. If (default: False) will write unicode.\n* lock_args  : tuple, optional  \n    Passed to ``refresh`` for intermediate output\n    (initialisation, iterating, and updating).\n* nrows  : int, optional  \n    The screen height. If specified, hides nested bars outside this\n    bound. If unspecified, attempts to use environment height.\n    The fallback is 20.\n* colour  : str, optional  \n    Bar colour (e.g. 'green', '#00ff00').\n* delay  : float, optional  \n    Don't display until [default: 0] seconds have elapsed.\n\nExtra CLI Options\n~~~~~~~~~~~~~~~~~\n\n* delim  : chr, optional  \n    Delimiting character [default: '\\n']. Use '\\0' for null.\n    N.B.: on Windows systems, Python converts '\\n' to '\\r\\n'.\n* buf_size  : int, optional  \n    String buffer size in bytes [default: 256]\n    used when ``delim`` is specified.\n* bytes  : bool, optional  \n    If true, will count bytes, ignore ``delim``, and default\n    ``unit_scale`` to True, ``unit_divisor`` to 1024, and ``unit`` to 'B'.\n* tee  : bool, optional  \n    If true, passes ``stdin`` to both ``stderr`` and ``stdout``.\n* update  : bool, optional  \n    If true, will treat input as newly elapsed iterations,\n    i.e. numbers to pass to ``update()``. Note that this is slow\n    (~2e5 it/s) since every input must be decoded as a number.\n* update_to  : bool, optional  \n    If true, will treat input as total elapsed iterations,\n    i.e. numbers to assign to ``self.n``. Note that this is slow\n    (~2e5 it/s) since every input must be decoded as a number.\n* null  : bool, optional  \n    If true, will discard input (no stdout).\n* manpath  : str, optional  \n    Directory in which to install tqdm man pages.\n* comppath  : str, optional  \n    Directory in which to place tqdm completion.\n* log  : str, optional  \n    CRITICAL|FATAL|ERROR|WARN(ING)|[default: 'INFO']|DEBUG|NOTSET.\n\nReturns\n~~~~~~~\n\n* out  : decorated iterator.  \n\n.. code:: python\n\n    class tqdm():\n      def update(self, n=1):\n          \"\"\"\n          Manually update the progress bar, useful for streams\n          such as reading files.\n          E.g.:\n          >>> t = tqdm(total=filesize) # Initialise\n          >>> for current_buffer in stream:\n          ...    ...\n          ...    t.update(len(current_buffer))\n          >>> t.close()\n          The last line is highly recommended, but possibly not necessary if\n          ``t.update()`` will be called in such a way that ``filesize`` will be\n          exactly reached and printed.\n\n          Parameters\n          ----------\n          n  : int or float, optional\n              Increment to add to the internal counter of iterations\n              [default: 1]. If using float, consider specifying ``{n:.3f}``\n              or similar in ``bar_format``, or specifying ``unit_scale``.\n\n          Returns\n          -------\n          out  : bool or None\n              True if a ``display()`` was triggered.\n          \"\"\"\n\n      def close(self):\n          \"\"\"Cleanup and (if leave=False) close the progressbar.\"\"\"\n\n      def clear(self, nomove=False):\n          \"\"\"Clear current bar display.\"\"\"\n\n      def refresh(self):\n          \"\"\"\n          Force refresh the display of this bar.\n\n          Parameters\n          ----------\n          nolock  : bool, optional\n              If ``True``, does not lock.\n              If [default: ``False``]: calls ``acquire()`` on internal lock.\n          lock_args  : tuple, optional\n              Passed to internal lock's ``acquire()``.\n              If specified, will only ``display()`` if ``acquire()`` returns ``True``.\n          \"\"\"\n\n      def unpause(self):\n          \"\"\"Restart tqdm timer from last print time.\"\"\"\n\n      def reset(self, total=None):\n          \"\"\"\n          Resets to 0 iterations for repeated use.\n\n          Consider combining with ``leave=True``.\n\n          Parameters\n          ----------\n          total  : int or float, optional. Total to use for the new bar.\n          \"\"\"\n\n      def set_description(self, desc=None, refresh=True):\n          \"\"\"\n          Set/modify description of the progress bar.\n\n          Parameters\n          ----------\n          desc  : str, optional\n          refresh  : bool, optional\n              Forces refresh [default: True].\n          \"\"\"\n\n      def set_postfix(self, ordered_dict=None, refresh=True, **tqdm_kwargs):\n          \"\"\"\n          Set/modify postfix (additional stats)\n          with automatic formatting based on datatype.\n\n          Parameters\n          ----------\n          ordered_dict  : dict or OrderedDict, optional\n          refresh  : bool, optional\n              Forces refresh [default: True].\n          kwargs  : dict, optional\n          \"\"\"\n\n      @classmethod\n      def write(cls, s, file=sys.stdout, end=\"\\n\"):\n          \"\"\"Print a message via tqdm (without overlap with bars).\"\"\"\n\n      @property\n      def format_dict(self):\n          \"\"\"Public API for read-only member access.\"\"\"\n\n      def display(self, msg=None, pos=None):\n          \"\"\"\n          Use ``self.sp`` to display ``msg`` in the specified ``pos``.\n\n          Consider overloading this function when inheriting to use e.g.:\n          ``self.some_frontend(**self.format_dict)`` instead of ``self.sp``.\n\n          Parameters\n          ----------\n          msg  : str, optional. What to display (default: ``repr(self)``).\n          pos  : int, optional. Position to ``moveto``\n            (default: ``abs(self.pos)``).\n          \"\"\"\n\n      @classmethod\n      @contextmanager\n      def wrapattr(cls, stream, method, total=None, bytes=True, **tqdm_kwargs):\n          \"\"\"\n          stream  : file-like object.\n          method  : str, \"read\" or \"write\". The result of ``read()`` and\n              the first argument of ``write()`` should have a ``len()``.\n\n          >>> with tqdm.wrapattr(file_obj, \"read\", total=file_obj.size) as fobj:\n          ...     while True:\n          ...         chunk = fobj.read(chunk_size)\n          ...         if not chunk:\n          ...             break\n          \"\"\"\n\n      @classmethod\n      def pandas(cls, *targs, **tqdm_kwargs):\n          \"\"\"Registers the current `tqdm` class with `pandas`.\"\"\"\n\n    def trange(*args, **tqdm_kwargs):\n        \"\"\"Shortcut for `tqdm(range(*args), **tqdm_kwargs)`.\"\"\"\n\nConvenience Functions\n~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: python\n\n    def tqdm.contrib.tenumerate(iterable, start=0, total=None,\n                                tqdm_class=tqdm.auto.tqdm, **tqdm_kwargs):\n        \"\"\"Equivalent of `numpy.ndenumerate` or builtin `enumerate`.\"\"\"\n\n    def tqdm.contrib.tzip(iter1, *iter2plus, **tqdm_kwargs):\n        \"\"\"Equivalent of builtin `zip`.\"\"\"\n\n    def tqdm.contrib.tmap(function, *sequences, **tqdm_kwargs):\n        \"\"\"Equivalent of builtin `map`.\"\"\"\n\nSubmodules\n~~~~~~~~~~\n\n.. code:: python\n\n    class tqdm.notebook.tqdm(tqdm.tqdm):\n        \"\"\"IPython/Jupyter Notebook widget.\"\"\"\n\n    class tqdm.auto.tqdm(tqdm.tqdm):\n        \"\"\"Automatically chooses beween `tqdm.notebook` and `tqdm.tqdm`.\"\"\"\n\n    class tqdm.asyncio.tqdm(tqdm.tqdm):\n      \"\"\"Asynchronous version.\"\"\"\n      @classmethod\n      def as_completed(cls, fs, *, loop=None, timeout=None, total=None,\n                       **tqdm_kwargs):\n          \"\"\"Wrapper for `asyncio.as_completed`.\"\"\"\n\n    class tqdm.gui.tqdm(tqdm.tqdm):\n        \"\"\"Matplotlib GUI version.\"\"\"\n\n    class tqdm.tk.tqdm(tqdm.tqdm):\n        \"\"\"Tkinter GUI version.\"\"\"\n\n    class tqdm.rich.tqdm(tqdm.tqdm):\n        \"\"\"`rich.progress` version.\"\"\"\n\n    class tqdm.keras.TqdmCallback(keras.callbacks.Callback):\n        \"\"\"Keras callback for epoch and batch progress.\"\"\"\n\n    class tqdm.dask.TqdmCallback(dask.callbacks.Callback):\n        \"\"\"Dask callback for task progress.\"\"\"\n\n\n``contrib``\n+++++++++++\n\nThe ``tqdm.contrib`` package also contains experimental modules:\n\n- ``tqdm.contrib.itertools``: Thin wrappers around ``itertools``\n- ``tqdm.contrib.concurrent``: Thin wrappers around ``concurrent.futures``\n- ``tqdm.contrib.slack``: Posts to `Slack <https://slack.com>`__ bots\n- ``tqdm.contrib.discord``: Posts to `Discord <https://discord.com>`__ bots\n- ``tqdm.contrib.telegram``: Posts to `Telegram <https://telegram.org>`__ bots\n- ``tqdm.contrib.bells``: Automagically enables all optional features\n\n  * ``auto``, ``pandas``, ``slack``, ``discord``, ``telegram``\n\nExamples and Advanced Usage\n---------------------------\n\n- See the `examples <https://github.com/tqdm/tqdm/tree/master/examples>`__\n  folder;\n- import the module and run ``help()``;\n- consult the `wiki <https://github.com/tqdm/tqdm/wiki>`__;\n\n  * this has an\n    `excellent article <https://github.com/tqdm/tqdm/wiki/How-to-make-a-great-Progress-Bar>`__\n    on how to make a **great** progressbar;\n\n- check out the `slides from PyData London <https://tqdm.github.io/PyData2019/slides.html>`__, or\n- run the |binder-demo|.\n\nDescription and additional stats\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCustom information can be displayed and updated dynamically on ``tqdm`` bars\nwith the ``desc`` and ``postfix`` arguments:\n\n.. code:: python\n\n    from tqdm import tqdm, trange\n    from random import random, randint\n    from time import sleep\n\n    with trange(10) as t:\n        for i in t:\n            # Description will be displayed on the left\n            t.set_description('GEN %i' % i)\n            # Postfix will be displayed on the right,\n            # formatted automatically based on argument's datatype\n            t.set_postfix(loss=random(), gen=randint(1,999), str='h',\n                          lst=[1, 2])\n            sleep(0.1)\n\n    with tqdm(total=10, bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\",\n              postfix=[\"Batch\", {\"value\": 0}]) as t:\n        for i in range(10):\n            sleep(0.1)\n            t.postfix[1][\"value\"] = i / 2\n            t.update()\n\nPoints to remember when using ``{postfix[...]}`` in the ``bar_format`` string:\n\n- ``postfix`` also needs to be passed as an initial argument in a compatible\n  format, and\n- ``postfix`` will be auto-converted to a string if it is a ``dict``-like\n  object. To prevent this behaviour, insert an extra item into the dictionary\n  where the key is not a string.\n\nAdditional ``bar_format`` parameters may also be defined by overriding\n``format_dict``, and the bar itself may be modified using ``ascii``:\n\n.. code:: python\n\n    from tqdm import tqdm\n    class TqdmExtraFormat(tqdm):\n        \"\"\"Provides a `total_time` format parameter\"\"\"\n        @property\n        def format_dict(self):\n            d = super().format_dict\n            total_time = d[\"elapsed\"] * (d[\"total\"] or 0) / max(d[\"n\"], 1)\n            d.update(total_time=self.format_interval(total_time) + \" in total\")\n            return d\n\n    for i in TqdmExtraFormat(\n          range(9), ascii=\" .oO0\",\n          bar_format=\"{total_time}: {percentage:.0f}%|{bar}{r_bar}\"):\n        if i == 4:\n            break\n\n.. code::\n\n    00:00 in total: 44%|0000.     | 4/9 [00:00<00:00, 962.93it/s]\n\nNote that ``{bar}`` also supports a format specifier ``[width][type]``.\n\n- ``width``\n\n  * unspecified (default): automatic to fill ``ncols``\n  * ``int >= 0``: fixed width overriding ``ncols`` logic\n  * ``int < 0``: subtract from the automatic default\n\n- ``type``\n\n  * ``a``: ascii (``ascii=True`` override)\n  * ``u``: unicode (``ascii=False`` override)\n  * ``b``: blank (``ascii=\"  \"`` override)\n\nThis means a fixed bar with right-justified text may be created by using:\n``bar_format=\"{l_bar}{bar:10}|{bar:-10b}right-justified\"``\n\nNested progress bars\n~~~~~~~~~~~~~~~~~~~~\n\n``tqdm`` supports nested progress bars. Here's an example:\n\n.. code:: python\n\n    from tqdm.auto import trange\n    from time import sleep\n\n    for i in trange(4, desc='1st loop'):\n        for j in trange(5, desc='2nd loop'):\n            for k in trange(50, desc='3rd loop', leave=False):\n                sleep(0.01)\n\nFor manual control over positioning (e.g. for multi-processing use),\nyou may specify ``position=n`` where ``n=0`` for the outermost bar,\n``n=1`` for the next, and so on.\nHowever, it's best to check if ``tqdm`` can work without manual ``position``\nfirst.\n\n.. code:: python\n\n    from time import sleep\n    from tqdm import trange, tqdm\n    from multiprocessing import Pool, RLock, freeze_support\n\n    L = list(range(9))\n\n    def progresser(n):\n        interval = 0.001 / (n + 2)\n        total = 5000\n        text = f\"#{n}, est. {interval * total:<04.2}s\"\n        for _ in trange(total, desc=text, position=n):\n            sleep(interval)\n\n    if __name__ == '__main__':\n        freeze_support()  # for Windows support\n        tqdm.set_lock(RLock())  # for managing output contention\n        p = Pool(initializer=tqdm.set_lock, initargs=(tqdm.get_lock(),))\n        p.map(progresser, L)\n\nNote that in Python 3, ``tqdm.write`` is thread-safe:\n\n.. code:: python\n\n    from time import sleep\n    from tqdm import tqdm, trange\n    from concurrent.futures import ThreadPoolExecutor\n\n    L = list(range(9))\n\n    def progresser(n):\n        interval = 0.001 / (n + 2)\n        total = 5000\n        text = f\"#{n}, est. {interval * total:<04.2}s\"\n        for _ in trange(total, desc=text):\n            sleep(interval)\n        if n == 6:\n            tqdm.write(\"n == 6 completed.\")\n            tqdm.write(\"`tqdm.write()` is thread-safe in py3!\")\n\n    if __name__ == '__main__':\n        with ThreadPoolExecutor() as p:\n            p.map(progresser, L)\n\nHooks and callbacks\n~~~~~~~~~~~~~~~~~~~\n\n``tqdm`` can easily support callbacks/hooks and manual updates.\nHere's an example with ``urllib``:\n\n**``urllib.urlretrieve`` documentation**\n\n    | [...]\n    | If present, the hook function will be called once\n    | on establishment of the network connection and once after each block read\n    | thereafter. The hook will be passed three arguments; a count of blocks\n    | transferred so far, a block size in bytes, and the total size of the file.\n    | [...]\n\n.. code:: python\n\n    import urllib, os\n    from tqdm import tqdm\n    urllib = getattr(urllib, 'request', urllib)\n\n    class TqdmUpTo(tqdm):\n        \"\"\"Provides `update_to(n)` which uses `tqdm.update(delta_n)`.\"\"\"\n        def update_to(self, b=1, bsize=1, tsize=None):\n            \"\"\"\n            b  : int, optional\n                Number of blocks transferred so far [default: 1].\n            bsize  : int, optional\n                Size of each block (in tqdm units) [default: 1].\n            tsize  : int, optional\n                Total size (in tqdm units). If [default: None] remains unchanged.\n            \"\"\"\n            if tsize is not None:\n                self.total = tsize\n            return self.update(b * bsize - self.n)  # also sets self.n = b * bsize\n\n    eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n    with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, miniters=1,\n                  desc=eg_link.split('/')[-1]) as t:  # all optional kwargs\n        urllib.urlretrieve(eg_link, filename=os.devnull,\n                           reporthook=t.update_to, data=None)\n        t.total = t.n\n\nInspired by `twine#242 <https://github.com/pypa/twine/pull/242>`__.\nFunctional alternative in\n`examples/tqdm_wget.py <https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py>`__.\n\nIt is recommend to use ``miniters=1`` whenever there is potentially\nlarge differences in iteration speed (e.g. downloading a file over\na patchy connection).\n\n**Wrapping read/write methods**\n\nTo measure throughput through a file-like object's ``read`` or ``write``\nmethods, use ``CallbackIOWrapper``:\n\n.. code:: python\n\n    from tqdm.auto import tqdm\n    from tqdm.utils import CallbackIOWrapper\n\n    with tqdm(total=file_obj.size,\n              unit='B', unit_scale=True, unit_divisor=1024) as t:\n        fobj = CallbackIOWrapper(t.update, file_obj, \"read\")\n        while True:\n            chunk = fobj.read(chunk_size)\n            if not chunk:\n                break\n        t.reset()\n        # ... continue to use `t` for something else\n\nAlternatively, use the even simpler ``wrapattr`` convenience function,\nwhich would condense both the ``urllib`` and ``CallbackIOWrapper`` examples\ndown to:\n\n.. code:: python\n\n    import urllib, os\n    from tqdm import tqdm\n\n    eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n    response = getattr(urllib, 'request', urllib).urlopen(eg_link)\n    with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n                       miniters=1, desc=eg_link.split('/')[-1],\n                       total=getattr(response, 'length', None)) as fout:\n        for chunk in response:\n            fout.write(chunk)\n\nThe ``requests`` equivalent is nearly identical:\n\n.. code:: python\n\n    import requests, os\n    from tqdm import tqdm\n\n    eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n    response = requests.get(eg_link, stream=True)\n    with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n                       miniters=1, desc=eg_link.split('/')[-1],\n                       total=int(response.headers.get('content-length', 0))) as fout:\n        for chunk in response.iter_content(chunk_size=4096):\n            fout.write(chunk)\n\n**Custom callback**\n\n``tqdm`` is known for intelligently skipping unnecessary displays. To make a\ncustom callback take advantage of this, simply use the return value of\n``update()``. This is set to ``True`` if a ``display()`` was triggered.\n\n.. code:: python\n\n    from tqdm.auto import tqdm as std_tqdm\n\n    def external_callback(*args, **kwargs):\n        ...\n\n    class TqdmExt(std_tqdm):\n        def update(self, n=1):\n            displayed = super().update(n)\n            if displayed:\n                external_callback(**self.format_dict)\n            return displayed\n\n``asyncio``\n~~~~~~~~~~~\n\nNote that ``break`` isn't currently caught by asynchronous iterators.\nThis means that ``tqdm`` cannot clean up after itself in this case:\n\n.. code:: python\n\n    from tqdm.asyncio import tqdm\n\n    async for i in tqdm(range(9)):\n        if i == 2:\n            break\n\nInstead, either call ``pbar.close()`` manually or use the context manager syntax:\n\n.. code:: python\n\n    from tqdm.asyncio import tqdm\n\n    with tqdm(range(9)) as pbar:\n        async for i in pbar:\n            if i == 2:\n                break\n\nPandas Integration\n~~~~~~~~~~~~~~~~~~\n\nDue to popular demand we've added support for ``pandas`` -- here's an example\nfor ``DataFrame.progress_apply`` and ``DataFrameGroupBy.progress_apply``:\n\n.. code:: python\n\n    import pandas as pd\n    import numpy as np\n    from tqdm import tqdm\n\n    df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n\n    # Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n    # (can use `tqdm.gui.tqdm`, `tqdm.notebook.tqdm`, optional kwargs, etc.)\n    tqdm.pandas(desc=\"my bar!\")\n\n    # Now you can use `progress_apply` instead of `apply`\n    # and `progress_map` instead of `map`\n    df.progress_apply(lambda x: x**2)\n    # can also groupby:\n    # df.groupby(0).progress_apply(lambda x: x**2)\n\nIn case you're interested in how this works (and how to modify it for your\nown callbacks), see the\n`examples <https://github.com/tqdm/tqdm/tree/master/examples>`__\nfolder or import the module and run ``help()``.\n\nKeras Integration\n~~~~~~~~~~~~~~~~~\n\nA ``keras`` callback is also available:\n\n.. code:: python\n\n    from tqdm.keras import TqdmCallback\n\n    ...\n\n    model.fit(..., verbose=0, callbacks=[TqdmCallback()])\n\nDask Integration\n~~~~~~~~~~~~~~~~\n\nA ``dask`` callback is also available:\n\n.. code:: python\n\n    from tqdm.dask import TqdmCallback\n\n    with TqdmCallback(desc=\"compute\"):\n        ...\n        arr.compute()\n\n    # or use callback globally\n    cb = TqdmCallback(desc=\"global\")\n    cb.register()\n    arr.compute()\n\nIPython/Jupyter Integration\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIPython/Jupyter is supported via the ``tqdm.notebook`` submodule:\n\n.. code:: python\n\n    from tqdm.notebook import trange, tqdm\n    from time import sleep\n\n    for i in trange(3, desc='1st loop'):\n        for j in tqdm(range(100), desc='2nd loop'):\n            sleep(0.01)\n\nIn addition to ``tqdm`` features, the submodule provides a native Jupyter\nwidget (compatible with IPython v1-v4 and Jupyter), fully working nested bars\nand colour hints (blue: normal, green: completed, red: error/interrupt,\nlight blue: no ETA); as demonstrated below.\n\n|Screenshot-Jupyter1|\n|Screenshot-Jupyter2|\n|Screenshot-Jupyter3|\n\nThe ``notebook`` version supports percentage or pixels for overall width\n(e.g.: ``ncols='100%'`` or ``ncols='480px'``).\n\nIt is also possible to let ``tqdm`` automatically choose between\nconsole or notebook versions by using the ``autonotebook`` submodule:\n\n.. code:: python\n\n    from tqdm.autonotebook import tqdm\n    tqdm.pandas()\n\nNote that this will issue a ``TqdmExperimentalWarning`` if run in a notebook\nsince it is not meant to be possible to distinguish between ``jupyter notebook``\nand ``jupyter console``. Use ``auto`` instead of ``autonotebook`` to suppress\nthis warning.\n\nNote that notebooks will display the bar in the cell where it was created.\nThis may be a different cell from the one where it is used.\nIf this is not desired, either\n\n- delay the creation of the bar to the cell where it must be displayed, or\n- create the bar with ``display=False``, and in a later cell call\n  ``display(bar.container)``:\n\n.. code:: python\n\n    from tqdm.notebook import tqdm\n    pbar = tqdm(..., display=False)\n\n.. code:: python\n\n    # different cell\n    display(pbar.container)\n\nThe ``keras`` callback has a ``display()`` method which can be used likewise:\n\n.. code:: python\n\n    from tqdm.keras import TqdmCallback\n    cbk = TqdmCallback(display=False)\n\n.. code:: python\n\n    # different cell\n    cbk.display()\n    model.fit(..., verbose=0, callbacks=[cbk])\n\nAnother possibility is to have a single bar (near the top of the notebook)\nwhich is constantly re-used (using ``reset()`` rather than ``close()``).\nFor this reason, the notebook version (unlike the CLI version) does not\nautomatically call ``close()`` upon ``Exception``.\n\n.. code:: python\n\n    from tqdm.notebook import tqdm\n    pbar = tqdm()\n\n.. code:: python\n\n    # different cell\n    iterable = range(100)\n    pbar.reset(total=len(iterable))  # initialise with new `total`\n    for i in iterable:\n        pbar.update()\n    pbar.refresh()  # force print final status but don't `close()`\n\nCustom Integration\n~~~~~~~~~~~~~~~~~~\n\nTo change the default arguments (such as making ``dynamic_ncols=True``),\nsimply use built-in Python magic:\n\n.. code:: python\n\n    from functools import partial\n    from tqdm import tqdm as std_tqdm\n    tqdm = partial(std_tqdm, dynamic_ncols=True)\n\nFor further customisation,\n``tqdm`` may be inherited from to create custom callbacks (as with the\n``TqdmUpTo`` example `above <#hooks-and-callbacks>`__) or for custom frontends\n(e.g. GUIs such as notebook or plotting packages). In the latter case:\n\n1. ``def __init__()`` to call ``super().__init__(..., gui=True)`` to disable\n   terminal ``status_printer`` creation.\n2. Redefine: ``close()``, ``clear()``, ``display()``.\n\nConsider overloading ``display()`` to use e.g.\n``self.frontend(**self.format_dict)`` instead of ``self.sp(repr(self))``.\n\nSome submodule examples of inheritance:\n\n- `tqdm/notebook.py <https://github.com/tqdm/tqdm/blob/master/tqdm/notebook.py>`__\n- `tqdm/gui.py <https://github.com/tqdm/tqdm/blob/master/tqdm/gui.py>`__\n- `tqdm/tk.py <https://github.com/tqdm/tqdm/blob/master/tqdm/tk.py>`__\n- `tqdm/contrib/slack.py <https://github.com/tqdm/tqdm/blob/master/tqdm/contrib/slack.py>`__\n- `tqdm/contrib/discord.py <https://github.com/tqdm/tqdm/blob/master/tqdm/contrib/discord.py>`__\n- `tqdm/contrib/telegram.py <https://github.com/tqdm/tqdm/blob/master/tqdm/contrib/telegram.py>`__\n\nDynamic Monitor/Meter\n~~~~~~~~~~~~~~~~~~~~~\n\nYou can use a ``tqdm`` as a meter which is not monotonically increasing.\nThis could be because ``n`` decreases (e.g. a CPU usage monitor) or ``total``\nchanges.\n\nOne example would be recursively searching for files. The ``total`` is the\nnumber of objects found so far, while ``n`` is the number of those objects which\nare files (rather than folders):\n\n.. code:: python\n\n    from tqdm import tqdm\n    import os.path\n\n    def find_files_recursively(path, show_progress=True):\n        files = []\n        # total=1 assumes `path` is a file\n        t = tqdm(total=1, unit=\"file\", disable=not show_progress)\n        if not os.path.exists(path):\n            raise IOError(\"Cannot find:\" + path)\n\n        def append_found_file(f):\n            files.append(f)\n            t.update()\n\n        def list_found_dir(path):\n            \"\"\"returns os.listdir(path) assuming os.path.isdir(path)\"\"\"\n            listing = os.listdir(path)\n            # subtract 1 since a \"file\" we found was actually this directory\n            t.total += len(listing) - 1\n            # fancy way to give info without forcing a refresh\n            t.set_postfix(dir=path[-10:], refresh=False)\n            t.update(0)  # may trigger a refresh\n            return listing\n\n        def recursively_search(path):\n            if os.path.isdir(path):\n                for f in list_found_dir(path):\n                    recursively_search(os.path.join(path, f))\n            else:\n                append_found_file(path)\n\n        recursively_search(path)\n        t.set_postfix(dir=path)\n        t.close()\n        return files\n\nUsing ``update(0)`` is a handy way to let ``tqdm`` decide when to trigger a\ndisplay refresh to avoid console spamming.\n\nWriting messages\n~~~~~~~~~~~~~~~~\n\nThis is a work in progress (see\n`#737 <https://github.com/tqdm/tqdm/issues/737>`__).\n\nSince ``tqdm`` uses a simple printing mechanism to display progress bars,\nyou should not write any message in the terminal using ``print()`` while\na progressbar is open.\n\nTo write messages in the terminal without any collision with ``tqdm`` bar\ndisplay, a ``.write()`` method is provided:\n\n.. code:: python\n\n    from tqdm.auto import tqdm, trange\n    from time import sleep\n\n    bar = trange(10)\n    for i in bar:\n        # Print using tqdm class method .write()\n        sleep(0.1)\n        if not (i % 3):\n            tqdm.write(\"Done task %i\" % i)\n        # Can also use bar.write()\n\nBy default, this will print to standard output ``sys.stdout``. but you can\nspecify any file-like object using the ``file`` argument. For example, this\ncan be used to redirect the messages writing to a log file or class.\n\nRedirecting writing\n~~~~~~~~~~~~~~~~~~~\n\nIf using a library that can print messages to the console, editing the library\nby  replacing ``print()`` with ``tqdm.write()`` may not be desirable.\nIn that case, redirecting ``sys.stdout`` to ``tqdm.write()`` is an option.\n\nTo redirect ``sys.stdout``, create a file-like class that will write\nany input string to ``tqdm.write()``, and supply the arguments\n``file=sys.stdout, dynamic_ncols=True``.\n\nA reusable canonical example is given below:\n\n.. code:: python\n\n    from time import sleep\n    import contextlib\n    import sys\n    from tqdm import tqdm\n    from tqdm.contrib import DummyTqdmFile\n\n\n    @contextlib.contextmanager\n    def std_out_err_redirect_tqdm():\n        orig_out_err = sys.stdout, sys.stderr\n        try:\n            sys.stdout, sys.stderr = map(DummyTqdmFile, orig_out_err)\n            yield orig_out_err[0]\n        # Relay exceptions\n        except Exception as exc:\n            raise exc\n        # Always restore sys.stdout/err if necessary\n        finally:\n            sys.stdout, sys.stderr = orig_out_err\n\n    def some_fun(i):\n        print(\"Fee, fi, fo,\".split()[i])\n\n    # Redirect stdout to tqdm.write() (don't forget the `as save_stdout`)\n    with std_out_err_redirect_tqdm() as orig_stdout:\n        # tqdm needs the original stdout\n        # and dynamic_ncols=True to autodetect console width\n        for i in tqdm(range(3), file=orig_stdout, dynamic_ncols=True):\n            sleep(.5)\n            some_fun(i)\n\n    # After the `with`, printing is restored\n    print(\"Done!\")\n\nRedirecting ``logging``\n~~~~~~~~~~~~~~~~~~~~~~~\n\nSimilar to ``sys.stdout``/``sys.stderr`` as detailed above, console ``logging``\nmay also be redirected to ``tqdm.write()``.\n\nWarning: if also redirecting ``sys.stdout``/``sys.stderr``, make sure to\nredirect ``logging`` first if needed.\n\nHelper methods are available in ``tqdm.contrib.logging``. For example:\n\n.. code:: python\n\n    import logging\n    from tqdm import trange\n    from tqdm.contrib.logging import logging_redirect_tqdm\n\n    LOG = logging.getLogger(__name__)\n\n    if __name__ == '__main__':\n        logging.basicConfig(level=logging.INFO)\n        with logging_redirect_tqdm():\n            for i in trange(9):\n                if i == 4:\n                    LOG.info(\"console logging redirected to `tqdm.write()`\")\n        # logging restored\n\nMonitoring thread, intervals and miniters\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n``tqdm`` implements a few tricks to increase efficiency and reduce overhead.\n\n- Avoid unnecessary frequent bar refreshing: ``mininterval`` defines how long\n  to wait between each refresh. ``tqdm`` always gets updated in the background,\n  but it will display only every ``mininterval``.\n- Reduce number of calls to check system clock/time.\n- ``mininterval`` is more intuitive to configure than ``miniters``.\n  A clever adjustment system ``dynamic_miniters`` will automatically adjust\n  ``miniters`` to the amount of iterations that fit into time ``mininterval``.\n  Essentially, ``tqdm`` will check if it's time to print without actually\n  checking time. This behaviour can be still be bypassed by manually setting\n  ``miniters``.\n\nHowever, consider a case with a combination of fast and slow iterations.\nAfter a few fast iterations, ``dynamic_miniters`` will set ``miniters`` to a\nlarge number. When iteration rate subsequently slows, ``miniters`` will\nremain large and thus reduce display update frequency. To address this:\n\n- ``maxinterval`` defines the maximum time between display refreshes.\n  A concurrent monitoring thread checks for overdue updates and forces one\n  where necessary.\n\nThe monitoring thread should not have a noticeable overhead, and guarantees\nupdates at least every 10 seconds by default.\nThis value can be directly changed by setting the ``monitor_interval`` of\nany ``tqdm`` instance (i.e. ``t = tqdm.tqdm(...); t.monitor_interval = 2``).\nThe monitor thread may be disabled application-wide by setting\n``tqdm.tqdm.monitor_interval = 0`` before instantiation of any ``tqdm`` bar.\n\n\nMerch\n-----\n\nYou can buy `tqdm branded merch <https://tqdm.github.io/merch>`__ now!\n\nContributions\n-------------\n\n|GitHub-Commits| |GitHub-Issues| |GitHub-PRs| |OpenHub-Status| |GitHub-Contributions| |CII Best Practices|\n\nAll source code is hosted on `GitHub <https://github.com/tqdm/tqdm>`__.\nContributions are welcome.\n\nSee the\n`CONTRIBUTING <https://github.com/tqdm/tqdm/blob/master/CONTRIBUTING.md>`__\nfile for more information.\n\nDevelopers who have made significant contributions, ranked by *SLoC*\n(surviving lines of code,\n`git fame <https://github.com/casperdcl/git-fame>`__ ``-wMC --excl '\\.(png|gif|jpg)$'``),\nare:\n\n==================== ======================================================== ==== ================================\nName                 ID                                                       SLoC Notes\n==================== ======================================================== ==== ================================\nCasper da Costa-Luis `casperdcl <https://github.com/casperdcl>`__             ~80% primary maintainer |Gift-Casper|\nStephen Larroque     `lrq3000 <https://github.com/lrq3000>`__                 ~9%  team member\nMartin Zugnoni       `martinzugnoni <https://github.com/martinzugnoni>`__     ~3%\nDaniel Ecer          `de-code <https://github.com/de-code>`__                 ~2%\nRichard Sheridan     `richardsheridan <https://github.com/richardsheridan>`__ ~1%\nGuangshuo Chen       `chengs <https://github.com/chengs>`__                   ~1%\nHelio Machado        `0x2b3bfa0 <https://github.com/0x2b3bfa0>`__             ~1%\nKyle Altendorf       `altendky <https://github.com/altendky>`__               <1%\nNoam Yorav-Raphael   `noamraph <https://github.com/noamraph>`__               <1%  original author\nMatthew Stevens      `mjstevens777 <https://github.com/mjstevens777>`__       <1%\nHadrien Mary         `hadim <https://github.com/hadim>`__                     <1%  team member\nMikhail Korobov      `kmike <https://github.com/kmike>`__                     <1%  team member\n==================== ======================================================== ==== ================================\n\nPorts to Other Languages\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nA list is available on\n`this wiki page <https://github.com/tqdm/tqdm/wiki/tqdm-ports>`__.\n\n\nLICENCE\n-------\n\nOpen Source (OSI approved): |LICENCE|\n\nCitation information: |DOI|\n\n|README-Hits| (Since 19 May 2016)\n\n.. |Logo| image:: https://tqdm.github.io/img/logo.gif\n.. |Screenshot| image:: https://tqdm.github.io/img/tqdm.gif\n.. |Video| image:: https://tqdm.github.io/img/video.jpg\n   :target: https://tqdm.github.io/video\n.. |Slides| image:: https://tqdm.github.io/img/slides.jpg\n   :target: https://tqdm.github.io/PyData2019/slides.html\n.. |Merch| image:: https://tqdm.github.io/img/merch.jpg\n   :target: https://tqdm.github.io/merch\n.. |Build-Status| image:: https://img.shields.io/github/actions/workflow/status/tqdm/tqdm/test.yml?branch=master&label=tqdm&logo=GitHub\n   :target: https://github.com/tqdm/tqdm/actions/workflows/test.yml\n.. |Coverage-Status| image:: https://img.shields.io/coveralls/github/tqdm/tqdm/master?logo=coveralls\n   :target: https://coveralls.io/github/tqdm/tqdm\n.. |Branch-Coverage-Status| image:: https://codecov.io/gh/tqdm/tqdm/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/tqdm/tqdm\n.. |Codacy-Grade| image:: https://app.codacy.com/project/badge/Grade/3f965571598f44549c7818f29cdcf177\n   :target: https://www.codacy.com/gh/tqdm/tqdm/dashboard\n.. |CII Best Practices| image:: https://bestpractices.coreinfrastructure.org/projects/3264/badge\n   :target: https://bestpractices.coreinfrastructure.org/projects/3264\n.. |GitHub-Status| image:: https://img.shields.io/github/tag/tqdm/tqdm.svg?maxAge=86400&logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/releases\n.. |GitHub-Forks| image:: https://img.shields.io/github/forks/tqdm/tqdm.svg?logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/network\n.. |GitHub-Stars| image:: https://img.shields.io/github/stars/tqdm/tqdm.svg?logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/stargazers\n.. |GitHub-Commits| image:: https://img.shields.io/github/commit-activity/y/tqdm/tqdm.svg?logo=git&logoColor=white\n   :target: https://github.com/tqdm/tqdm/graphs/commit-activity\n.. |GitHub-Issues| image:: https://img.shields.io/github/issues-closed/tqdm/tqdm.svg?logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/issues?q=\n.. |GitHub-PRs| image:: https://img.shields.io/github/issues-pr-closed/tqdm/tqdm.svg?logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/pulls\n.. |GitHub-Contributions| image:: https://img.shields.io/github/contributors/tqdm/tqdm.svg?logo=github&logoColor=white\n   :target: https://github.com/tqdm/tqdm/graphs/contributors\n.. |GitHub-Updated| image:: https://img.shields.io/github/last-commit/tqdm/tqdm/master.svg?logo=github&logoColor=white&label=pushed\n   :target: https://github.com/tqdm/tqdm/pulse\n.. |Gift-Casper| image:: https://img.shields.io/badge/dynamic/json.svg?color=ff69b4&label=gifts%20received&prefix=%C2%A3&query=%24..sum&url=https%3A%2F%2Fcaspersci.uk.to%2Fgifts.json\n   :target: https://cdcl.ml/sponsor\n.. |Versions| image:: https://img.shields.io/pypi/v/tqdm.svg\n   :target: https://tqdm.github.io/releases\n.. |PyPI-Downloads| image:: https://img.shields.io/pypi/dm/tqdm.svg?label=pypi%20downloads&logo=PyPI&logoColor=white\n   :target: https://pepy.tech/project/tqdm\n.. |Py-Versions| image:: https://img.shields.io/pypi/pyversions/tqdm.svg?logo=python&logoColor=white\n   :target: https://pypi.org/project/tqdm\n.. |Conda-Forge-Status| image:: https://img.shields.io/conda/v/conda-forge/tqdm.svg?label=conda-forge&logo=conda-forge\n   :target: https://anaconda.org/conda-forge/tqdm\n.. |Snapcraft| image:: https://img.shields.io/badge/snap-install-82BEA0.svg?logo=snapcraft\n   :target: https://snapcraft.io/tqdm\n.. |Docker| image:: https://img.shields.io/badge/docker-pull-blue.svg?logo=docker&logoColor=white\n   :target: https://hub.docker.com/r/tqdm/tqdm\n.. |Libraries-Rank| image:: https://img.shields.io/librariesio/sourcerank/pypi/tqdm.svg?logo=koding&logoColor=white\n   :target: https://libraries.io/pypi/tqdm\n.. |Libraries-Dependents| image:: https://img.shields.io/librariesio/dependent-repos/pypi/tqdm.svg?logo=koding&logoColor=white\n    :target: https://github.com/tqdm/tqdm/network/dependents\n.. |OpenHub-Status| image:: https://www.openhub.net/p/tqdm/widgets/project_thin_badge?format=gif\n   :target: https://www.openhub.net/p/tqdm?ref=Thin+badge\n.. |awesome-python| image:: https://awesome.re/mentioned-badge.svg\n   :target: https://github.com/vinta/awesome-python\n.. |LICENCE| image:: https://img.shields.io/pypi/l/tqdm.svg\n   :target: https://raw.githubusercontent.com/tqdm/tqdm/master/LICENCE\n.. |DOI| image:: https://img.shields.io/badge/DOI-10.5281/zenodo.595120-blue.svg\n   :target: https://doi.org/10.5281/zenodo.595120\n.. |binder-demo| image:: https://mybinder.org/badge_logo.svg\n   :target: https://mybinder.org/v2/gh/tqdm/tqdm/master?filepath=DEMO.ipynb\n.. |Screenshot-Jupyter1| image:: https://tqdm.github.io/img/jupyter-1.gif\n.. |Screenshot-Jupyter2| image:: https://tqdm.github.io/img/jupyter-2.gif\n.. |Screenshot-Jupyter3| image:: https://tqdm.github.io/img/jupyter-3.gif\n.. |README-Hits| image:: https://cgi.cdcl.ml/hits?q=tqdm&style=social&r=https://github.com/tqdm/tqdm&l=https://tqdm.github.io/img/favicon.png&f=https://tqdm.github.io/img/logo.gif\n   :target: https://cgi.cdcl.ml/hits?q=tqdm&a=plot&r=https://github.com/tqdm/tqdm&l=https://tqdm.github.io/img/favicon.png&f=https://tqdm.github.io/img/logo.gif&style=social\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "progressbar",
          "progressmeter",
          "progress",
          "bar",
          "meter",
          "rate",
          "eta",
          "console",
          "terminal",
          "time"
        ],
        "maintainer_email": "tqdm developers <devs@tqdm.ml>",
        "license": "MPL-2.0 AND MIT",
        "license_file": [
          "LICENCE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Environment :: Other Environment",
          "Environment :: Win32 (MS Windows)",
          "Environment :: X11 Applications",
          "Framework :: IPython",
          "Framework :: Jupyter",
          "Intended Audience :: Developers",
          "Intended Audience :: Education",
          "Intended Audience :: End Users/Desktop",
          "Intended Audience :: Other Audience",
          "Intended Audience :: System Administrators",
          "Operating System :: MacOS",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft",
          "Operating System :: Microsoft :: MS-DOS",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: POSIX :: BSD",
          "Operating System :: POSIX :: BSD :: FreeBSD",
          "Operating System :: POSIX :: Linux",
          "Operating System :: POSIX :: SunOS/Solaris",
          "Operating System :: Unix",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation",
          "Programming Language :: Python :: Implementation :: IronPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Unix Shell",
          "Topic :: Desktop Environment",
          "Topic :: Education :: Computer Aided Instruction (CAI)",
          "Topic :: Education :: Testing",
          "Topic :: Office/Business",
          "Topic :: Other/Nonlisted Topic",
          "Topic :: Software Development :: Build Tools",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Pre-processors",
          "Topic :: Software Development :: User Interfaces",
          "Topic :: System :: Installation/Setup",
          "Topic :: System :: Logging",
          "Topic :: System :: Monitoring",
          "Topic :: System :: Shells",
          "Topic :: Terminals",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "colorama; platform_system == \"Windows\"",
          "importlib_metadata; python_version < \"3.8\"",
          "pytest>=6; extra == \"dev\"",
          "pytest-cov; extra == \"dev\"",
          "pytest-timeout; extra == \"dev\"",
          "pytest-asyncio>=0.24; extra == \"dev\"",
          "nbval; extra == \"dev\"",
          "requests; extra == \"discord\"",
          "slack-sdk; extra == \"slack\"",
          "requests; extra == \"telegram\"",
          "ipywidgets>=6; extra == \"notebook\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "homepage, https://tqdm.github.io",
          "repository, https://github.com/tqdm/tqdm",
          "changelog, https://tqdm.github.io/releases",
          "wiki, https://github.com/tqdm/tqdm/wiki"
        ],
        "provides_extra": [
          "dev",
          "discord",
          "slack",
          "telegram",
          "notebook"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=4ed1cacbdc298c220f1bd249ed5287caa16f34d44ef4e9c3d0cbad5b521545e7",
          "hashes": {
            "sha256": "4ed1cacbdc298c220f1bd249ed5287caa16f34d44ef4e9c3d0cbad5b521545e7"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "typing-inspection",
        "version": "0.4.2",
        "summary": "Runtime typing introspection tools",
        "description": "# typing-inspection\n\n[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/typing-inspection/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/typing-inspection/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/typing-inspection.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/typing-inspection)\n[![PyPI](https://img.shields.io/pypi/v/typing-inspection.svg)](https://pypi.org/project/typing-inspection/)\n[![Versions](https://img.shields.io/pypi/pyversions/typing-inspection.svg)](https://github.com/pydantic/typing-inspection)\n[![License](https://img.shields.io/github/license/pydantic/typing-inspection.svg)](https://github.com/pydantic/typing-inspection/blob/main/LICENSE)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n\n`typing-inspection` provides tools to inspect type annotations at runtime.\n\n## Installation\n\nFrom [PyPI](https://pypi.org/project/typing-inspection/):\n\n```bash\npip install typing-inspection\n```\n\nThe library can be imported from the `typing_inspection` module.\n",
        "description_content_type": "text/markdown",
        "author_email": "Victorien Plot <contact@vctrn.dev>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.12.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/typing-inspection",
          "Documentation, https://pydantic.github.io/typing-inspection/dev/",
          "Source, https://github.com/pydantic/typing-inspection",
          "Changelog, https://github.com/pydantic/typing-inspection/blob/main/HISTORY.md"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/c7/b0/003792df09decd6849a5e39c28b513c06e84436a54440380862b5aeff25d/tzdata-2025.3-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=06a47e5700f3081aab02b2e513160914ff0694bce9947d6b76ebd6bf57cfc5d1",
          "hashes": {
            "sha256": "06a47e5700f3081aab02b2e513160914ff0694bce9947d6b76ebd6bf57cfc5d1"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "tzdata",
        "version": "2025.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Provider of IANA time zone data",
        "description": "tzdata: Python package providing IANA time zone data\n====================================================\n\nThis is a Python package containing ``zic``-compiled binaries for the IANA time\nzone database. It is intended to be a fallback for systems that do not have\nsystem time zone data installed (or don't have it installed in a standard\nlocation), as a part of `PEP 615 <https://www.python.org/dev/peps/pep-0615/>`_\n\nThis repository generates a ``pip``-installable package, published on PyPI as\n`tzdata <https://pypi.org/project/tzdata>`_.\n\nFor more information, see `the documentation <https://tzdata.readthedocs.io>`_.\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/python/tzdata",
        "author": "Python Software Foundation",
        "author_email": "datetime-sig@python.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE",
          "licenses/LICENSE_APACHE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3"
        ],
        "requires_python": ">=2",
        "project_url": [
          "Bug Reports, https://github.com/python/tzdata/issues",
          "Source, https://github.com/python/tzdata",
          "Documentation, https://tzdata.readthedocs.io"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/2e/54/647ade08bf0db230bfea292f893923872fd20be6ac6f53b2b936ba839d75/zipp-3.23.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=071652d6115ed432f5ce1d34c336c0adfd6a884660d1e9712a256d3d3bd4b14e",
          "hashes": {
            "sha256": "071652d6115ed432f5ce1d34c336c0adfd6a884660d1e9712a256d3d3bd4b14e"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "zipp",
        "version": "3.23.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Backport of pathlib-compatible object wrapper for zip files",
        "description": ".. image:: https://img.shields.io/pypi/v/zipp.svg\n   :target: https://pypi.org/project/zipp\n\n.. image:: https://img.shields.io/pypi/pyversions/zipp.svg\n\n.. image:: https://github.com/jaraco/zipp/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/jaraco/zipp/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://readthedocs.org/projects/zipp/badge/?version=latest\n..    :target: https://zipp.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2025-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/zipp\n   :target: https://tidelift.com/subscription/pkg/pypi-zipp?utm_source=pypi-zipp&utm_medium=readme\n\n\nA pathlib-compatible Zipfile object wrapper. Official backport of the standard library\n`Path object <https://docs.python.org/3.8/library/zipfile.html#path-objects>`_.\n\n\nCompatibility\n=============\n\nNew features are introduced in this third-party library and later merged\ninto CPython. The following table indicates which versions of this library\nwere contributed to different versions in the standard library:\n\n.. list-table::\n   :header-rows: 1\n\n   * - zipp\n     - stdlib\n   * - 3.18\n     - 3.13\n   * - 3.16\n     - 3.12\n   * - 3.5\n     - 3.11\n   * - 3.2\n     - 3.10\n   * - 3.3 ??\n     - 3.9\n   * - 1.0\n     - 3.8\n\n\nUsage\n=====\n\nUse ``zipp.Path`` in place of ``zipfile.Path`` on any Python.\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-zipp?utm_source=pypi-zipp&utm_medium=referral&utm_campaign=github>`_.\n",
        "description_content_type": "text/x-rst",
        "author_email": "\"Jason R. Coombs\" <jaraco@jaraco.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "pytest!=8.1.*,>=6; extra == \"test\"",
          "jaraco.itertools; extra == \"test\"",
          "jaraco.functools; extra == \"test\"",
          "more_itertools; extra == \"test\"",
          "big-O; extra == \"test\"",
          "pytest-ignore-flaky; extra == \"test\"",
          "jaraco.test; extra == \"test\"",
          "sphinx>=3.5; extra == \"doc\"",
          "jaraco.packaging>=9.3; extra == \"doc\"",
          "rst.linker>=1.9; extra == \"doc\"",
          "furo; extra == \"doc\"",
          "sphinx-lint; extra == \"doc\"",
          "jaraco.tidelift>=1.4; extra == \"doc\"",
          "pytest-checkdocs>=2.4; extra == \"check\"",
          "pytest-ruff>=0.2.1; sys_platform != \"cygwin\" and extra == \"check\"",
          "pytest-cov; extra == \"cover\"",
          "pytest-enabler>=2.2; extra == \"enabler\"",
          "pytest-mypy; extra == \"type\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source, https://github.com/jaraco/zipp"
        ],
        "provides_extra": [
          "test",
          "doc",
          "check",
          "cover",
          "enabler",
          "type"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7b/91/984aca2ec129e2757d1e4e3c81c3fcda9d0f85b74670a094cc443d9ee949/joblib-1.5.3-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=5fc3c5039fc5ca8c0276333a188bbd59d6b7ab37fe6632daa76bc7f9ec18e713",
          "hashes": {
            "sha256": "5fc3c5039fc5ca8c0276333a188bbd59d6b7ab37fe6632daa76bc7f9ec18e713"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "joblib",
        "version": "1.5.3",
        "dynamic": [
          "license-file"
        ],
        "platform": [
          "any"
        ],
        "summary": "Lightweight pipelining with Python functions",
        "description": "|PyPi| |CIStatus| |ReadTheDocs| |Codecov|\n\n.. |PyPi| image:: https://badge.fury.io/py/joblib.svg\n   :target: https://badge.fury.io/py/joblib\n   :alt: Joblib version\n\n.. |CIStatus| image:: https://github.com/joblib/joblib/actions/workflows/test.yml/badge.svg\n   :target: https://github.com/joblib/joblib/actions/workflows/test.yml?query=branch%3Amain\n   :alt: CI status\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/joblib/badge/?version=latest\n    :target: https://joblib.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. |Codecov| image:: https://codecov.io/gh/joblib/joblib/branch/main/graph/badge.svg\n   :target: https://codecov.io/gh/joblib/joblib\n   :alt: Codecov coverage\n\n\nThe homepage of joblib with user documentation is located on:\n\nhttps://joblib.readthedocs.io\n\nGetting the latest code\n=======================\n\nTo get the latest code using git, simply type::\n\n    git clone https://github.com/joblib/joblib.git\n\nIf you don't have git installed, you can download a zip\nof the latest code: https://github.com/joblib/joblib/archive/refs/heads/main.zip\n\nInstalling\n==========\n\nYou can use `pip` to install joblib from any directory::\n\n    pip install joblib\n\nor install it in editable mode from the source directory::\n\n    pip install -e .\n\nDependencies\n============\n\n- Joblib has no mandatory dependencies besides Python (supported versions are\n  3.9+).\n- Joblib has an optional dependency on Numpy (at least version 1.6.1) for array\n  manipulation.\n- Joblib includes its own vendored copy of\n  `loky <https://github.com/tomMoral/loky>`_ for process management.\n- Joblib can efficiently dump and load numpy arrays but does not require numpy\n  to be installed.\n- Joblib has an optional dependency on\n  `python-lz4 <https://pypi.python.org/pypi/lz4>`_ as a faster alternative to\n  zlib and gzip for compressed serialization.\n- Joblib has an optional dependency on psutil to mitigate memory leaks in\n  parallel worker processes.\n- Some examples require external dependencies such as pandas. See the\n  instructions in the `Building the docs`_ section for details.\n\nWorkflow to contribute\n======================\n\nTo contribute to joblib, first create an account on `github\n<https://github.com/>`_. Once this is done, fork the `joblib repository\n<https://github.com/joblib/joblib>`_ to have your own repository,\nclone it using ``git clone``. Make your changes in a branch of your clone, push\nthem to your github account, test them locally, and when you are happy with\nthem, send a pull request to the main repository.\n\nYou can use `pre-commit <https://pre-commit.com/#install>`_ to run code style checks\nbefore each commit::\n\n    pip install pre-commit\n    pre-commit install\n\npre-commit checks can be disabled for a single commit with::\n\n    git commit -n\n\nRunning the test suite\n======================\n\nTo run the test suite, you need the pytest (version >= 3) and coverage modules.\nRun the test suite using::\n\n    pytest joblib\n\nfrom the root of the project.\n\nBuilding the docs\n=================\n\nTo build the docs you need to have sphinx (>=1.4) and some dependencies\ninstalled::\n\n    pip install -U -r .readthedocs-requirements.txt\n\nThe docs can then be built with the following command::\n\n    make doc\n\nThe html docs are located in the ``doc/_build/html`` directory.\n\n\nMaking a source tarball\n=======================\n\nTo create a source tarball, eg for packaging or distributing, run the\nfollowing command::\n\n    pip install build\n    python -m build --sdist\n\nThe tarball will be created in the `dist` directory. This command will create\nthe resulting tarball that can be installed with no extra dependencies than the\nPython standard library.\n\nMaking a release and uploading it to PyPI\n=========================================\n\nThis command is only run by project manager, to make a release, and\nupload in to PyPI::\n\n    pip install build\n    python -m build --sdist --wheel\n    twine upload dist/*\n\n\nNote that the documentation should automatically get updated at each git\npush. If that is not the case, try building th doc locally and resolve\nany doc build error (in particular when running the examples).\n\nUpdating the changelog\n======================\n\nChanges are listed in the CHANGES.rst file. They must be manually updated\nbut, the following git command may be used to generate the lines::\n\n    git log --abbrev-commit --date=short --no-merges --sparse\n",
        "description_content_type": "text/x-rst",
        "author_email": "Gael Varoquaux <gael.varoquaux@normalesup.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Education",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Scientific/Engineering",
          "Topic :: Utilities",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://joblib.readthedocs.io",
          "Source, https://github.com/joblib/joblib"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/a4/8e/469e5a4a2f5855992e425f3cb33804cc07bf18d48f2db061aec61ce50270/more_itertools-10.8.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=52d4362373dcf7c52546bc4af9a86ee7c4579df9a8dc268be0a2f949d376cc9b",
          "hashes": {
            "sha256": "52d4362373dcf7c52546bc4af9a86ee7c4579df9a8dc268be0a2f949d376cc9b"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "more-itertools",
        "version": "10.8.0",
        "summary": "More routines for operating on iterables, beyond itertools",
        "description": "==============\nMore Itertools\n==============\n\n.. image:: https://readthedocs.org/projects/more-itertools/badge/?version=latest\n  :target: https://more-itertools.readthedocs.io/en/stable/\n\nPython's ``itertools`` library is a gem - you can compose elegant solutions\nfor a variety of problems with the functions it provides. In ``more-itertools``\nwe collect additional building blocks, recipes, and routines for working with\nPython iterables.\n\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Grouping               | `chunked <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.chunked>`_,                                                                               |\n|                        | `ichunked <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ichunked>`_,                                                                             |\n|                        | `chunked_even <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.chunked_even>`_,                                                                     |\n|                        | `sliced <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sliced>`_,                                                                                 |\n|                        | `constrained_batches <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.constrained_batches>`_,                                                       |\n|                        | `distribute <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distribute>`_,                                                                         |\n|                        | `divide <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.divide>`_,                                                                                 |\n|                        | `split_at <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_at>`_,                                                                             |\n|                        | `split_before <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_before>`_,                                                                     |\n|                        | `split_after <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_after>`_,                                                                       |\n|                        | `split_into <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_into>`_,                                                                         |\n|                        | `split_when <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_when>`_,                                                                         |\n|                        | `bucket <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.bucket>`_,                                                                                 |\n|                        | `unzip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unzip>`_,                                                                                   |\n|                        | `batched <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.batched>`_,                                                                               |\n|                        | `grouper <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.grouper>`_,                                                                               |\n|                        | `partition <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partition>`_,                                                                           |\n|                        | `transpose <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.transpose>`_                                                                            |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Lookahead and lookback | `spy <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.spy>`_,                                                                                       |\n|                        | `peekable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.peekable>`_,                                                                             |\n|                        | `seekable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.seekable>`_                                                                              |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Windowing              | `windowed <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.windowed>`_,                                                                             |\n|                        | `substrings <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.substrings>`_,                                                                         |\n|                        | `substrings_indexes <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.substrings_indexes>`_,                                                         |\n|                        | `stagger <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.stagger>`_,                                                                               |\n|                        | `windowed_complete <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.windowed_complete>`_,                                                           |\n|                        | `pairwise <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.pairwise>`_,                                                                             |\n|                        | `triplewise <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.triplewise>`_,                                                                         |\n|                        | `sliding_window <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sliding_window>`_,                                                                 |\n|                        | `subslices <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.subslices>`_                                                                            |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Augmenting             | `count_cycle <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.count_cycle>`_,                                                                       |\n|                        | `intersperse <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.intersperse>`_,                                                                       |\n|                        | `padded <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.padded>`_,                                                                                 |\n|                        | `repeat_each <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeat_each>`_,                                                                       |\n|                        | `mark_ends <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.mark_ends>`_,                                                                           |\n|                        | `repeat_last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeat_last>`_,                                                                       |\n|                        | `adjacent <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.adjacent>`_,                                                                             |\n|                        | `groupby_transform <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.groupby_transform>`_,                                                           |\n|                        | `pad_none <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.pad_none>`_,                                                                             |\n|                        | `ncycles <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ncycles>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Combining              | `collapse <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.collapse>`_,                                                                             |\n|                        | `sort_together <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sort_together>`_,                                                                   |\n|                        | `interleave <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave>`_,                                                                         |\n|                        | `interleave_longest <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_longest>`_,                                                         |\n|                        | `interleave_evenly <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_evenly>`_,                                                           |\n|                        | `interleave_randomly <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_randomly>`_,                                                       |\n|                        | `zip_offset <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_offset>`_,                                                                         |\n|                        | `zip_equal <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_equal>`_,                                                                           |\n|                        | `zip_broadcast <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_broadcast>`_,                                                                   |\n|                        | `flatten <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.flatten>`_,                                                                               |\n|                        | `roundrobin <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.roundrobin>`_,                                                                         |\n|                        | `prepend <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.prepend>`_,                                                                               |\n|                        | `value_chain <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.value_chain>`_,                                                                       |\n|                        | `partial_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partial_product>`_                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Summarizing            | `ilen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ilen>`_,                                                                                     |\n|                        | `unique_to_each <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_to_each>`_,                                                                 |\n|                        | `sample <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sample>`_,                                                                                 |\n|                        | `consecutive_groups <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consecutive_groups>`_,                                                         |\n|                        | `run_length <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.run_length>`_,                                                                         |\n|                        | `map_reduce <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_reduce>`_,                                                                         |\n|                        | `join_mappings <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.join_mappings>`_,                                                                   |\n|                        | `exactly_n <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.exactly_n>`_,                                                                           |\n|                        | `is_sorted <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.is_sorted>`_,                                                                           |\n|                        | `all_equal <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.all_equal>`_,                                                                           |\n|                        | `all_unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.all_unique>`_,                                                                         |\n|                        | `argmin <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.argmin>`_,                                                                                 |\n|                        | `argmax <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.argmax>`_,                                                                                 |\n|                        | `minmax <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.minmax>`_,                                                                                 |\n|                        | `first_true <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.first_true>`_,                                                                         |\n|                        | `quantify <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.quantify>`_,                                                                             |\n|                        | `iequals <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iequals>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Selecting              | `islice_extended <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.islice_extended>`_,                                                               |\n|                        | `first <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.first>`_,                                                                                   |\n|                        | `last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.last>`_,                                                                                     |\n|                        | `one <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.one>`_,                                                                                       |\n|                        | `only <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.only>`_,                                                                                     |\n|                        | `strictly_n <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.strictly_n>`_,                                                                         |\n|                        | `strip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.strip>`_,                                                                                   |\n|                        | `lstrip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.lstrip>`_,                                                                                 |\n|                        | `rstrip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.rstrip>`_,                                                                                 |\n|                        | `filter_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.filter_except>`_,                                                                   |\n|                        | `map_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_except>`_,                                                                         |\n|                        | `filter_map <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.filter_map>`_,                                                                         |\n|                        | `iter_suppress <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_suppress>`_,                                                                   |\n|                        | `nth_or_last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_or_last>`_,                                                                       |\n|                        | `extract <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.extract>`_,                                                                               |\n|                        | `unique_in_window <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_in_window>`_,                                                             |\n|                        | `before_and_after <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.before_and_after>`_,                                                             |\n|                        | `nth <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth>`_,                                                                                       |\n|                        | `take <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.take>`_,                                                                                     |\n|                        | `tail <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.tail>`_,                                                                                     |\n|                        | `unique_everseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_everseen>`_,                                                               |\n|                        | `unique_justseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_justseen>`_,                                                               |\n|                        | `unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique>`_,                                                                                 |\n|                        | `duplicates_everseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.duplicates_everseen>`_,                                                       |\n|                        | `duplicates_justseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.duplicates_justseen>`_,                                                       |\n|                        | `classify_unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.classify_unique>`_,                                                               |\n|                        | `longest_common_prefix <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.longest_common_prefix>`_,                                                   |\n|                        | `takewhile_inclusive <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.takewhile_inclusive>`_                                                        |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Math                   | `dft <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.dft>`_,                                                                                       |\n|                        | `idft <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.idft>`_,                                                                                     |\n|                        | `convolve <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.convolve>`_,                                                                             |\n|                        | `dotproduct <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.dotproduct>`_,                                                                         |\n|                        | `matmul <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.matmul>`_,                                                                                 |\n|                        | `polynomial_from_roots <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_from_roots>`_,                                                   |\n|                        | `polynomial_derivative <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_derivative>`_,                                                   |\n|                        | `polynomial_eval <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_eval>`_,                                                               |\n|                        | `sum_of_squares <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sum_of_squares>`_,                                                                 |\n|                        | `running_median <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.running_median>`_,                                                                 |\n|                        | `totient <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.totient>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Integer math           | `factor <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.factor>`_,                                                                                 |\n|                        | `is_prime <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.is_prime>`_,                                                                             |\n|                        | `multinomial <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.multinomial>`_,                                                                       |\n|                        | `nth_prime <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_prime>`_,                                                                           |\n|                        | `sieve <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sieve>`_                                                                                    |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Combinatorics          | `circular_shifts <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.circular_shifts>`_,                                                               |\n|                        | `derangements <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.derangements>`_,                                                                     |\n|                        | `gray_product  <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.gray_product>`_,                                                                    |\n|                        | `outer_product  <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.outer_product>`_,                                                                  |\n|                        | `partitions <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partitions>`_,                                                                         |\n|                        | `set_partitions <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.set_partitions>`_,                                                                 |\n|                        | `powerset <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.powerset>`_,                                                                             |\n|                        | `powerset_of_sets <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.powerset_of_sets>`_                                                              |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `distinct_combinations <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distinct_combinations>`_,                                                   |\n|                        | `distinct_permutations <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distinct_permutations>`_                                                    |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `combination_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.combination_index>`_,                                                           |\n|                        | `combination_with_replacement_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.combination_with_replacement_index>`_,                         |\n|                        | `permutation_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.permutation_index>`_,                                                           |\n|                        | `product_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.product_index>`_                                                                    |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `nth_combination <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_combination>`_,                                                               |\n|                        | `nth_combination_with_replacement <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_combination_with_replacement>`_,                             |\n|                        | `nth_permutation <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_permutation>`_,                                                               |\n|                        | `nth_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_product>`_                                                                        |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `random_combination <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_combination>`_,                                                         |\n|                        | `random_combination_with_replacement <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_combination_with_replacement>`_,                       |\n|                        | `random_permutation <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_permutation>`_,                                                         |\n|                        | `random_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_product>`_                                                                  |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Wrapping               | `always_iterable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.always_iterable>`_,                                                               |\n|                        | `always_reversible <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.always_reversible>`_,                                                           |\n|                        | `countable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.countable>`_,                                                                           |\n|                        | `consumer <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consumer>`_,                                                                             |\n|                        | `with_iter <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.with_iter>`_,                                                                           |\n|                        | `iter_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_except>`_                                                                        |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Others                 | `locate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.locate>`_,                                                                                 |\n|                        | `rlocate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.rlocate>`_,                                                                               |\n|                        | `replace <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.replace>`_,                                                                               |\n|                        | `numeric_range <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.numeric_range>`_,                                                                   |\n|                        | `side_effect <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.side_effect>`_,                                                                       |\n|                        | `iterate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iterate>`_,                                                                               |\n|                        | `loops <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.loops>`_,                                                                                   |\n|                        | `difference <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.difference>`_,                                                                         |\n|                        | `make_decorator <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.make_decorator>`_,                                                                 |\n|                        | `SequenceView <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.SequenceView>`_,                                                                     |\n|                        | `time_limited <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.time_limited>`_,                                                                     |\n|                        | `map_if <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_if>`_,                                                                                 |\n|                        | `iter_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_index>`_,                                                                         |\n|                        | `consume <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consume>`_,                                                                               |\n|                        | `tabulate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.tabulate>`_,                                                                             |\n|                        | `repeatfunc <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeatfunc>`_,                                                                         |\n|                        | `reshape <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.reshape>`_,                                                                               |\n|                        | `doublestarmap <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.doublestarmap>`_                                                                    |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\nGetting started\n===============\n\nTo get started, install the library with `pip <https://pip.pypa.io/en/stable/>`_:\n\n.. code-block:: shell\n\n    pip install more-itertools\n\nThe recipes from the `itertools docs <https://docs.python.org/3/library/itertools.html#itertools-recipes>`_\nare included in the top-level package:\n\n.. code-block:: python\n\n    >>> from more_itertools import flatten\n    >>> iterable = [(0, 1), (2, 3)]\n    >>> list(flatten(iterable))\n    [0, 1, 2, 3]\n\nSeveral new recipes are available as well:\n\n.. code-block:: python\n\n    >>> from more_itertools import chunked\n    >>> iterable = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    >>> list(chunked(iterable, 3))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\n    >>> from more_itertools import spy\n    >>> iterable = (x * x for x in range(1, 6))\n    >>> head, iterable = spy(iterable, n=3)\n    >>> list(head)\n    [1, 4, 9]\n    >>> list(iterable)\n    [1, 4, 9, 16, 25]\n\n\n\nFor the full listing of functions, see the `API documentation <https://more-itertools.readthedocs.io/en/stable/api.html>`_.\n\n\nLinks elsewhere\n===============\n\nBlog posts about ``more-itertools``:\n\n* `Yo, I heard you like decorators <https://www.bbayles.com/index/decorator_factory>`__\n* `Tour of Python Itertools <https://martinheinz.dev/blog/16>`__ (`Alternate <https://dev.to/martinheinz/tour-of-python-itertools-4122>`__)\n* `Real-World Python More Itertools <https://python.plainenglish.io/real-world-more-itertools-gideons-blog-a3901c607550>`_\n\n\nDevelopment\n===========\n\n``more-itertools`` is maintained by `@erikrose <https://github.com/erikrose>`_\nand `@bbayles <https://github.com/bbayles>`_, with help from `many others <https://github.com/more-itertools/more-itertools/graphs/contributors>`_.\nIf you have a problem or suggestion, please file a bug or pull request in this\nrepository. Thanks for contributing!\n\n\nVersion History\n===============\n\nThe version history can be found in `documentation <https://more-itertools.readthedocs.io/en/stable/versions.html>`_.\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "itertools",
          "iterator",
          "iteration",
          "filter",
          "peek",
          "peekable",
          "chunk",
          "chunked"
        ],
        "author_email": "Erik Rose <erikrose@grinchcentral.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://more-itertools.readthedocs.io/en/stable/",
          "Homepage, https://github.com/more-itertools/more-itertools"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/3e/b6/3fee2205ce1333eaa85fdf8500de4e412bbc112d77c9b0045cc8d5a6fcec/parse-1.21.0-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=6d81f7bae0ab25fd72818375c4a9c71c8705256bfc42e8725be609cf8b904aed",
          "hashes": {
            "sha256": "6d81f7bae0ab25fd72818375c4a9c71c8705256bfc42e8725be609cf8b904aed"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "parse",
        "version": "1.21.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "parse() is the opposite of format()",
        "description": "Installation\n------------\n\n.. code-block:: pycon\n\n    pip install parse\n\nUsage\n-----\n\nParse strings using a specification based on the Python `format()`_ syntax.\n\n   ``parse()`` is the opposite of ``format()``\n\nThe module is set up to only export ``parse()``, ``search()``, ``findall()``,\nand ``with_pattern()`` when ``import *`` is used:\n\n>>> from parse import *\n\nFrom there it's a simple thing to parse a string:\n\n.. code-block:: pycon\n\n    >>> parse(\"It's {}, I love it!\", \"It's spam, I love it!\")\n    <Result ('spam',) {}>\n    >>> _[0]\n    'spam'\n\nOr to search a string for some pattern:\n\n.. code-block:: pycon\n\n    >>> search('Age: {:d}\\n', 'Name: Rufus\\nAge: 42\\nColor: red\\n')\n    <Result (42,) {}>\n\nOr find all the occurrences of some pattern in a string:\n\n.. code-block:: pycon\n\n    >>> ''.join(r[0] for r in findall(\">{}<\", \"<p>the <b>bold</b> text</p>\"))\n    'the bold text'\n\nIf you're going to use the same pattern to match lots of strings you can\ncompile it once:\n\n.. code-block:: pycon\n\n    >>> from parse import compile\n    >>> p = compile(\"It's {}, I love it!\")\n    >>> print(p)\n    <Parser \"It's {}, I love it!\">\n    >>> p.parse(\"It's spam, I love it!\")\n    <Result ('spam',) {}>\n\n(\"compile\" is not exported for ``import *`` usage as it would override the\nbuilt-in ``compile()`` function)\n\nThe default behaviour is to match strings case insensitively. You may match with\ncase by specifying `case_sensitive=True`:\n\n.. code-block:: pycon\n\n    >>> parse('SPAM', 'spam', case_sensitive=True) is None\n    True\n\n.. _format():\n  https://docs.python.org/3/library/stdtypes.html#str.format\n\n\nFormat Syntax\n-------------\n\nA basic version of the `Format String Syntax`_ is supported with anonymous\n(fixed-position), named and formatted fields::\n\n   {[field name]:[format spec]}\n\nField names must be a valid Python identifiers, including dotted names;\nelement indexes imply dictionaries (see below for example).\n\nNumbered fields are also not supported: the result of parsing will include\nthe parsed fields in the order they are parsed.\n\nThe conversion of fields to types other than strings is done based on the\ntype in the format specification, which mirrors the ``format()`` behaviour.\nThere are no \"!\" field conversions like ``format()`` has.\n\nSome simple parse() format string examples:\n\n.. code-block:: pycon\n\n    >>> parse(\"Bring me a {}\", \"Bring me a shrubbery\")\n    <Result ('shrubbery',) {}>\n    >>> r = parse(\"The {} who {} {}\", \"The knights who say Ni!\")\n    >>> print(r)\n    <Result ('knights', 'say', 'Ni!') {}>\n    >>> print(r.fixed)\n    ('knights', 'say', 'Ni!')\n    >>> print(r[0])\n    knights\n    >>> print(r[1:])\n    ('say', 'Ni!')\n    >>> r = parse(\"Bring out the holy {item}\", \"Bring out the holy hand grenade\")\n    >>> print(r)\n    <Result () {'item': 'hand grenade'}>\n    >>> print(r.named)\n    {'item': 'hand grenade'}\n    >>> print(r['item'])\n    hand grenade\n    >>> 'item' in r\n    True\n\nNote that `in` only works if you have named fields.\n\nDotted names and indexes are possible with some limits. Only word identifiers\nare supported (ie. no numeric indexes) and the application must make additional\nsense of the result:\n\n.. code-block:: pycon\n\n    >>> r = parse(\"Mmm, {food.type}, I love it!\", \"Mmm, spam, I love it!\")\n    >>> print(r)\n    <Result () {'food.type': 'spam'}>\n    >>> print(r.named)\n    {'food.type': 'spam'}\n    >>> print(r['food.type'])\n    spam\n    >>> r = parse(\"My quest is {quest[name]}\", \"My quest is to seek the holy grail!\")\n    >>> print(r)\n    <Result () {'quest': {'name': 'to seek the holy grail!'}}>\n    >>> print(r['quest'])\n    {'name': 'to seek the holy grail!'}\n    >>> print(r['quest']['name'])\n    to seek the holy grail!\n\nIf the text you're matching has braces in it you can match those by including\na double-brace ``{{`` or ``}}`` in your format string, the same escaping method\nused in the ``format()`` syntax.\n\n\nFormat Specification\n--------------------\n\nMost often a straight format-less ``{}`` will suffice where a more complex\nformat specification might have been used.\n\nMost of `format()`'s `Format Specification Mini-Language`_ is supported:\n\n   [[fill]align][sign][0][width][grouping][.precision][type]\n\nThe differences between `parse()` and `format()` are:\n\n- The align operators will cause spaces (or specified fill character) to be\n  stripped from the parsed value. The width is not enforced; it just indicates\n  there may be whitespace or \"0\"s to strip.\n- Numeric parsing will automatically handle a \"0b\", \"0o\" or \"0x\" prefix.\n  That is, the \"#\" format character is handled automatically by d, b, o\n  and x formats. For \"d\" any will be accepted, but for the others the correct\n  prefix must be present if at all.\n- Numeric sign is handled automatically.  A sign specifier can be given, but\n  has no effect.\n- The thousands separator is handled automatically if the \"n\" type is used.\n- The types supported are a slightly different mix to the format() types.  Some\n  format() types come directly over: \"d\", \"n\", \"%\", \"f\", \"e\", \"b\", \"o\" and \"x\".\n  In addition some regular expression character group types \"D\", \"w\", \"W\", \"s\"\n  and \"S\" are also available.\n- The \"e\" and \"g\" types are case-insensitive so there is not need for\n  the \"E\" or \"G\" types. The \"e\" type handles Fortran formatted numbers (no\n  leading 0 before the decimal point).\n\n===== =========================================== ========\nType  Characters Matched                          Output\n===== =========================================== ========\nl     Letters (ASCII)                             str\nw     Letters, numbers and underscore             str\nW     Not letters, numbers and underscore         str\ns     Whitespace                                  str\nS     Non-whitespace                              str\nd     Integer numbers (optional sign, digits)     int\nD     Non-digit                                   str\nn     Numbers with thousands separators (, or .)  int\n%     Percentage (converted to value/100.0)       float\nf     Fixed-point numbers                         float\nF     Decimal numbers                             Decimal\ne     Floating-point numbers with exponent        float\n      e.g. 1.1e-10, NAN (all case insensitive)\ng     General number format (either d, f or e)    float\nb     Binary numbers                              int\no     Octal numbers                               int\nx     Hexadecimal numbers (lower and upper case)  int\nti    ISO 8601 format date/time                   datetime\n      e.g. 1972-01-20T10:21:36Z (\"T\" and \"Z\"\n      optional)\nte    RFC2822 e-mail format date/time             datetime\n      e.g. Mon, 20 Jan 1972 10:21:36 +1000\ntg    Global (day/month) format date/time         datetime\n      e.g. 20/1/1972 10:21:36 AM +1:00\nta    US (month/day) format date/time             datetime\n      e.g. 1/20/1972 10:21:36 PM +10:30\ntc    ctime() format date/time                    datetime\n      e.g. Sun Sep 16 01:03:52 1973\nth    HTTP log format date/time                   datetime\n      e.g. 21/Nov/2011:00:07:11 +0000\nts    Linux system log format date/time           datetime\n      e.g. Nov  9 03:37:44\ntt    Time                                        time\n      e.g. 10:21:36 PM -5:30\n===== =========================================== ========\n\nThe type can also be a datetime format string, following the\n`1989 C standard format codes`_, e.g. ``%Y-%m-%d``. Depending on the\ndirectives contained in the format string, parsed output may be an instance\nof ``datetime.datetime``, ``datetime.time``, or ``datetime.date``.\n\n.. code-block:: pycon\n\n    >>> parse(\"{:%Y-%m-%d %H:%M:%S}\", \"2023-11-23 12:56:47\")\n    <Result (datetime.datetime(2023, 11, 23, 12, 56, 47),) {}>\n    >>> parse(\"{:%H:%M}\", \"10:26\")\n    <Result (datetime.time(10, 26),) {}>\n    >>> parse(\"{:%Y/%m/%d}\", \"2023/11/25\")\n    <Result (datetime.date(2023, 11, 25),) {}>\n\n\nSome examples of typed parsing with ``None`` returned if the typing\ndoes not match:\n\n.. code-block:: pycon\n\n    >>> parse('Our {:d} {:w} are...', 'Our 3 weapons are...')\n    <Result (3, 'weapons') {}>\n    >>> parse('Our {:d} {:w} are...', 'Our three weapons are...')\n    >>> parse('Meet at {:tg}', 'Meet at 1/2/2011 11:00 PM')\n    <Result (datetime.datetime(2011, 2, 1, 23, 0),) {}>\n\nAnd messing about with alignment:\n\n.. code-block:: pycon\n\n    >>> parse('with {:>} herring', 'with     a herring')\n    <Result ('a',) {}>\n    >>> parse('spam {:^} spam', 'spam    lovely     spam')\n    <Result ('lovely',) {}>\n\nNote that the \"center\" alignment does not test to make sure the value is\ncentered - it just strips leading and trailing whitespace.\n\nWidth and precision may be used to restrict the size of matched text\nfrom the input. Width specifies a minimum size and precision specifies\na maximum. For example:\n\n.. code-block:: pycon\n\n    >>> parse('{:.2}{:.2}', 'look')           # specifying precision\n    <Result ('lo', 'ok') {}>\n    >>> parse('{:4}{:4}', 'look at that')     # specifying width\n    <Result ('look', 'at that') {}>\n    >>> parse('{:4}{:.4}', 'look at that')    # specifying both\n    <Result ('look at ', 'that') {}>\n    >>> parse('{:2d}{:2d}', '0440')           # parsing two contiguous numbers\n    <Result (4, 40) {}>\n\nSome notes for the special date and time types:\n\n- the presence of the time part is optional (including ISO 8601, starting\n  at the \"T\"). A full datetime object will always be returned; the time\n  will be set to 00:00:00. You may also specify a time without seconds.\n- when a seconds amount is present in the input fractions will be parsed\n  to give microseconds.\n- except in ISO 8601 the day and month digits may be 0-padded.\n- the date separator for the tg and ta formats may be \"-\" or \"/\".\n- named months (abbreviations or full names) may be used in the ta and tg\n  formats in place of numeric months.\n- as per RFC 2822 the e-mail format may omit the day (and comma), and the\n  seconds but nothing else.\n- hours greater than 12 will be happily accepted.\n- the AM/PM are optional, and if PM is found then 12 hours will be added\n  to the datetime object's hours amount - even if the hour is greater\n  than 12 (for consistency.)\n- in ISO 8601 the \"Z\" (UTC) timezone part may be a numeric offset\n- timezones are specified as \"+HH:MM\" or \"-HH:MM\". The hour may be one or two\n  digits (0-padded is OK.) Also, the \":\" is optional.\n- the timezone is optional in all except the e-mail format (it defaults to\n  UTC.)\n- named timezones are not handled yet.\n\nNote: attempting to match too many datetime fields in a single parse() will\ncurrently result in a resource allocation issue. A TooManyFields exception\nwill be raised in this instance. The current limit is about 15. It is hoped\nthat this limit will be removed one day.\n\n.. _`Format String Syntax`:\n  https://docs.python.org/3/library/string.html#format-string-syntax\n.. _`Format Specification Mini-Language`:\n  https://docs.python.org/3/library/string.html#format-specification-mini-language\n.. _`1989 C standard format codes`:\n  https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n\n\n\nResult and Match Objects\n------------------------\n\nThe result of a ``parse()`` and ``search()`` operation is either ``None`` (no match), a\n``Result`` instance or a ``Match`` instance if ``evaluate_result`` is False.\n\nThe ``Result`` instance has three attributes:\n\n``fixed``\n   A tuple of the fixed-position, anonymous fields extracted from the input.\n``named``\n   A dictionary of the named fields extracted from the input.\n``spans``\n   A dictionary mapping the names and fixed position indices matched to a\n   2-tuple slice range of where the match occurred in the input.\n   The span does not include any stripped padding (alignment or width).\n\nThe ``Match`` instance has one method:\n\n``evaluate_result()``\n   Generates and returns a ``Result`` instance for this ``Match`` object.\n\n\n\nCustom Type Conversions\n-----------------------\n\nIf you wish to have matched fields automatically converted to your own type you\nmay pass in a dictionary of type conversion information to ``parse()`` and\n``compile()``.\n\nThe converter will be passed the field string matched. Whatever it returns\nwill be substituted in the ``Result`` instance for that field.\n\nYour custom type conversions may override the builtin types if you supply one\nwith the same identifier:\n\n.. code-block:: pycon\n\n    >>> def shouty(string):\n    ...    return string.upper()\n    ...\n    >>> parse('{:shouty} world', 'hello world', {\"shouty\": shouty})\n    <Result ('HELLO',) {}>\n\nIf the type converter has the optional ``pattern`` attribute, it is used as\nregular expression for better pattern matching (instead of the default one):\n\n.. code-block:: pycon\n\n    >>> def parse_number(text):\n    ...    return int(text)\n    >>> parse_number.pattern = r'\\d+'\n    >>> parse('Answer: {number:Number}', 'Answer: 42', {\"Number\": parse_number})\n    <Result () {'number': 42}>\n    >>> _ = parse('Answer: {:Number}', 'Answer: Alice', {\"Number\": parse_number})\n    >>> assert _ is None, \"MISMATCH\"\n\nYou can also use the ``with_pattern(pattern)`` decorator to add this\ninformation to a type converter function:\n\n.. code-block:: pycon\n\n    >>> from parse import with_pattern\n    >>> @with_pattern(r'\\d+')\n    ... def parse_number(text):\n    ...    return int(text)\n    >>> parse('Answer: {number:Number}', 'Answer: 42', {\"Number\": parse_number})\n    <Result () {'number': 42}>\n\nA more complete example of a custom type might be:\n\n.. code-block:: pycon\n\n    >>> yesno_mapping = {\n    ...     \"yes\":  True,   \"no\":    False,\n    ...     \"on\":   True,   \"off\":   False,\n    ...     \"true\": True,   \"false\": False,\n    ... }\n    >>> @with_pattern(r\"|\".join(yesno_mapping))\n    ... def parse_yesno(text):\n    ...     return yesno_mapping[text.lower()]\n\n\nIf the type converter ``pattern`` uses regex-grouping (with parenthesis),\nyou should indicate this by using the optional ``regex_group_count`` parameter\nin the ``with_pattern()`` decorator:\n\n.. code-block:: pycon\n\n    >>> @with_pattern(r'((\\d+))', regex_group_count=2)\n    ... def parse_number2(text):\n    ...    return int(text)\n    >>> parse('Answer: {:Number2} {:Number2}', 'Answer: 42 43', {\"Number2\": parse_number2})\n    <Result (42, 43) {}>\n\nOtherwise, this may cause parsing problems with unnamed/fixed parameters.\n\n\nPotential Gotchas\n-----------------\n\n``parse()`` will always match the shortest text necessary (from left to right)\nto fulfil the parse pattern, so for example:\n\n\n.. code-block:: pycon\n\n    >>> pattern = '{dir1}/{dir2}'\n    >>> data = 'root/parent/subdir'\n    >>> sorted(parse(pattern, data).named.items())\n    [('dir1', 'root'), ('dir2', 'parent/subdir')]\n\nSo, even though `{'dir1': 'root/parent', 'dir2': 'subdir'}` would also fit\nthe pattern, the actual match represents the shortest successful match for\n``dir1``.\n\nDevelopers\n----------\n\nWant to contribute to parse? Fork the repo to your own GitHub account, and create a pull-request.\n\n.. code-block:: bash\n\n   git clone git@github.com:r1chardj0n3s/parse.git\n   git remote rename origin upstream\n   git remote add origin git@github.com:YOURUSERNAME/parse.git\n   git checkout -b myfeature\n\nTo run the tests locally:\n\n.. code-block:: bash\n\n   python -m venv .venv\n   source .venv/bin/activate\n   pip install -r tests/requirements.txt\n   pip install -e .\n   pytest\n\n----\n\nChangelog\n---------\n\n- 1.21.0 Allow grouping char (,_) in decimal format string (thanks @moi90)\n- 1.20.2 Template field names can now contain - character i.e. HYPHEN-MINUS, chr(0x2d)\n- 1.20.1 The `%f` directive accepts 1-6 digits, like strptime (thanks @bbertincourt)\n- 1.20.0 Added support for strptime codes (thanks @bendichter)\n- 1.19.1 Added support for sign specifiers in number formats (thanks @anntzer)\n- 1.19.0 Added slice access to fixed results (thanks @jonathangjertsen).\n  Also corrected matching of *full string* vs. *full line* (thanks @giladreti)\n  Fix issue with using digit field numbering and types\n- 1.18.0 Correct bug in int parsing introduced in 1.16.0 (thanks @maxxk)\n- 1.17.0 Make left- and center-aligned search consume up to next space\n- 1.16.0 Make compiled parse objects pickleable (thanks @martinResearch)\n- 1.15.0 Several fixes for parsing non-base 10 numbers (thanks @vladikcomper)\n- 1.14.0 More broad acceptance of Fortran number format (thanks @purpleskyfall)\n- 1.13.1 Project metadata correction.\n- 1.13.0 Handle Fortran formatted numbers with no leading 0 before decimal\n  point (thanks @purpleskyfall).\n  Handle comparison of FixedTzOffset with other types of object.\n- 1.12.1 Actually use the `case_sensitive` arg in compile (thanks @jacquev6)\n- 1.12.0 Do not assume closing brace when an opening one is found (thanks @mattsep)\n- 1.11.1 Revert having unicode char in docstring, it breaks Bamboo builds(?!)\n- 1.11.0 Implement `__contains__` for Result instances.\n- 1.10.0 Introduce a \"letters\" matcher, since \"w\" matches numbers\n  also.\n- 1.9.1 Fix deprecation warnings around backslashes in regex strings\n  (thanks Mickael Schoentgen). Also fix some documentation formatting\n  issues.\n- 1.9.0 We now honor precision and width specifiers when parsing numbers\n  and strings, allowing parsing of concatenated elements of fixed width\n  (thanks Julia Signell)\n- 1.8.4 Add LICENSE file at request of packagers.\n  Correct handling of AM/PM to follow most common interpretation.\n  Correct parsing of hexadecimal that looks like a binary prefix.\n  Add ability to parse case sensitively.\n  Add parsing of numbers to Decimal with \"F\" (thanks John Vandenberg)\n- 1.8.3 Add regex_group_count to with_pattern() decorator to support\n  user-defined types that contain brackets/parenthesis (thanks Jens Engel)\n- 1.8.2 add documentation for including braces in format string\n- 1.8.1 ensure bare hexadecimal digits are not matched\n- 1.8.0 support manual control over result evaluation (thanks Timo Furrer)\n- 1.7.0 parse dict fields (thanks Mark Visser) and adapted to allow\n  more than 100 re groups in Python 3.5+ (thanks David King)\n- 1.6.6 parse Linux system log dates (thanks Alex Cowan)\n- 1.6.5 handle precision in float format (thanks Levi Kilcher)\n- 1.6.4 handle pipe \"|\" characters in parse string (thanks Martijn Pieters)\n- 1.6.3 handle repeated instances of named fields, fix bug in PM time\n  overflow\n- 1.6.2 fix logging to use local, not root logger (thanks Necku)\n- 1.6.1 be more flexible regarding matched ISO datetimes and timezones in\n  general, fix bug in timezones without \":\" and improve docs\n- 1.6.0 add support for optional ``pattern`` attribute in user-defined types\n  (thanks Jens Engel)\n- 1.5.3 fix handling of question marks\n- 1.5.2 fix type conversion error with dotted names (thanks Sebastian Thiel)\n- 1.5.1 implement handling of named datetime fields\n- 1.5 add handling of dotted field names (thanks Sebastian Thiel)\n- 1.4.1 fix parsing of \"0\" in int conversion (thanks James Rowe)\n- 1.4 add __getitem__ convenience access on Result.\n- 1.3.3 fix Python 2.5 setup.py issue.\n- 1.3.2 fix Python 3.2 setup.py issue.\n- 1.3.1 fix a couple of Python 3.2 compatibility issues.\n- 1.3 added search() and findall(); removed compile() from ``import *``\n  export as it overwrites builtin.\n- 1.2 added ability for custom and override type conversions to be\n  provided; some cleanup\n- 1.1.9 to keep things simpler number sign is handled automatically;\n  significant robustification in the face of edge-case input.\n- 1.1.8 allow \"d\" fields to have number base \"0x\" etc. prefixes;\n  fix up some field type interactions after stress-testing the parser;\n  implement \"%\" type.\n- 1.1.7 Python 3 compatibility tweaks (2.5 to 2.7 and 3.2 are supported).\n- 1.1.6 add \"e\" and \"g\" field types; removed redundant \"h\" and \"X\";\n  removed need for explicit \"#\".\n- 1.1.5 accept textual dates in more places; Result now holds match span\n  positions.\n- 1.1.4 fixes to some int type conversion; implemented \"=\" alignment; added\n  date/time parsing with a variety of formats handled.\n- 1.1.3 type conversion is automatic based on specified field types. Also added\n  \"f\" and \"n\" types.\n- 1.1.2 refactored, added compile() and limited ``from parse import *``\n- 1.1.1 documentation improvements\n- 1.1.0 implemented more of the `Format Specification Mini-Language`_\n  and removed the restriction on mixing fixed-position and named fields\n- 1.0.0 initial release\n\nThis code is copyright 2012-2021 Richard Jones <richard@python.org>\nSee the end of the source file for the license of use.\n",
        "description_content_type": "text/x-rst",
        "author_email": "Richard Jones <richard@python.org>",
        "maintainer_email": "Wim Jeantine-Glenn <hey@wimglenn.com>",
        "license": "Copyright (c) 2012-2019 Richard Jones <richard@python.org>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Topic :: Software Development :: Code Generators",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "License :: OSI Approved :: MIT License"
        ],
        "project_url": [
          "homepage, https://github.com/r1chardj0n3s/parse"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/0c/c3/44f3fbbfa403ea2a7c779186dc20772604442dde72947e7d01069cbe98e3/pycparser-3.0-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=b727414169a36b7d524c1c3e31839a521725078d7b2ff038656844266160a992",
          "hashes": {
            "sha256": "b727414169a36b7d524c1c3e31839a521725078d7b2ff038656844266160a992"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.4",
        "name": "pycparser",
        "version": "3.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "C parser in Python",
        "description": "===============\npycparser v3.00\n===============\n\n\n.. image:: https://github.com/eliben/pycparser/workflows/pycparser-tests/badge.svg\n  :align: center\n  :target: https://github.com/eliben/pycparser/actions\n\n----\n\n.. contents::\n    :backlinks: none\n\n.. sectnum::\n\nIntroduction\n============\n\nWhat is pycparser?\n------------------\n\n**pycparser** is a parser for the C language, written in pure Python. It is a\nmodule designed to be easily integrated into applications that need to parse\nC source code.\n\nWhat is it good for?\n--------------------\n\nAnything that needs C code to be parsed. The following are some uses for\n**pycparser**, taken from real user reports:\n\n* C code obfuscator\n* Front-end for various specialized C compilers\n* Static code checker\n* Automatic unit-test discovery\n* Adding specialized extensions to the C language\n\nOne of the most popular uses of **pycparser** is in the `cffi\n<https://cffi.readthedocs.io/en/latest/>`_ library, which uses it to parse the\ndeclarations of C functions and types in order to auto-generate FFIs.\n\n**pycparser** is unique in the sense that it's written in pure Python - a very\nhigh level language that's easy to experiment with and tweak. To people familiar\nwith Lex and Yacc, **pycparser**'s code will be simple to understand. It also\nhas no external dependencies (except for a Python interpreter), making it very\nsimple to install and deploy.\n\nWhich version of C does pycparser support?\n------------------------------------------\n\n**pycparser** aims to support the full C99 language (according to the standard\nISO/IEC 9899). Some features from C11 are also supported, and patches to support\nmore are welcome.\n\n**pycparser** supports very few GCC extensions, but it's fairly easy to set\nthings up so that it parses code with a lot of GCC-isms successfully. See the\n`FAQ <https://github.com/eliben/pycparser/wiki/FAQ>`_ for more details.\n\nWhat grammar does pycparser follow?\n-----------------------------------\n\n**pycparser** very closely follows the C grammar provided in Annex A of the C99\nstandard (ISO/IEC 9899).\n\nHow is pycparser licensed?\n--------------------------\n\n`BSD license <https://github.com/eliben/pycparser/blob/master/LICENSE>`_.\n\nContact details\n---------------\n\nFor reporting problems with **pycparser** or submitting feature requests, please\nopen an `issue <https://github.com/eliben/pycparser/issues>`_, or submit a\npull request.\n\n\nInstalling\n==========\n\nPrerequisites\n-------------\n\n**pycparser** is being tested with modern versions of Python on\nLinux, macOS and Windows. See `the CI dashboard <https://github.com/eliben/pycparser/actions/workflows/ci.yml>`__\nfor details.\n\n**pycparser** has no external dependencies.\n\nInstallation process\n--------------------\n\nThe recommended way to install **pycparser** is with ``pip``::\n\n    > pip install pycparser\n\nUsing\n=====\n\nInteraction with the C preprocessor\n-----------------------------------\n\nIn order to be compilable, C code must be preprocessed by the C preprocessor -\n``cpp``. A compatible ``cpp`` handles preprocessing directives like ``#include`` and\n``#define``, removes comments, and performs other minor tasks that prepare the C\ncode for compilation.\n\nFor all but the most trivial snippets of C code **pycparser**, like a C\ncompiler, must receive preprocessed C code in order to function correctly. If\nyou import the top-level ``parse_file`` function from the **pycparser** package,\nit will interact with ``cpp`` for you, as long as it's in your PATH, or you\nprovide a path to it.\n\nNote also that you can use ``gcc -E`` or ``clang -E`` instead of ``cpp``. See\nthe ``using_gcc_E_libc.py`` example for more details. Windows users can download\nand install a binary build of Clang for Windows `from this website\n<http://llvm.org/releases/download.html>`_.\n\nWhat about the standard C library headers?\n------------------------------------------\n\nC code almost always ``#include``\\s various header files from the standard C\nlibrary, like ``stdio.h``. While (with some effort) **pycparser** can be made to\nparse the standard headers from any C compiler, it's much simpler to use the\nprovided \"fake\" standard includes for C11 in ``utils/fake_libc_include``. These\nare standard C header files that contain only the bare necessities to allow\nvalid parsing of the files that use them. As a bonus, since they're minimal, it\ncan significantly improve the performance of parsing large C files.\n\nThe key point to understand here is that **pycparser** doesn't really care about\nthe semantics of types. It only needs to know whether some token encountered in\nthe source is a previously defined type. This is essential in order to be able\nto parse C correctly.\n\nSee `this blog post\n<https://eli.thegreenplace.net/2015/on-parsing-c-type-declarations-and-fake-headers>`_\nfor more details.\n\nNote that the fake headers are not included in the ``pip`` package nor installed\nvia the package build (`#224 <https://github.com/eliben/pycparser/issues/224>`_).\n\nBasic usage\n-----------\n\nTake a look at the |examples|_ directory of the distribution for a few examples\nof using **pycparser**. These should be enough to get you started. Please note\nthat most realistic C code samples would require running the C preprocessor\nbefore passing the code to **pycparser**; see the previous sections for more\ndetails.\n\n.. |examples| replace:: ``examples``\n.. _examples: examples\n\n\nAdvanced usage\n--------------\n\nThe public interface of **pycparser** is well documented with comments in\n``pycparser/c_parser.py``. For a detailed overview of the various AST nodes\ncreated by the parser, see ``pycparser/_c_ast.cfg``.\n\nThere's also a `FAQ available here <https://github.com/eliben/pycparser/wiki/FAQ>`_.\nIn any case, you can always drop me an `email <eliben@gmail.com>`_ for help.\n\n\nModifying\n=========\n\nThere are a few points to keep in mind when modifying **pycparser**:\n\n* The code for **pycparser**'s AST nodes is automatically generated from a\n  configuration file - ``_c_ast.cfg``, by ``_ast_gen.py``. If you modify the AST\n  configuration, make sure to re-generate the code. This can be done by running\n  the ``_ast_gen.py`` script (from the repository root or the\n  ``pycparser`` directory).\n* Read the docstring in the constructor of the ``CParser`` class for details\n  on configuration and compatibility arguments.\n\n\nPackage contents\n================\n\nOnce you unzip the ``pycparser`` package, you'll see the following files and\ndirectories:\n\nREADME.rst:\n  This README file.\n\nLICENSE:\n  The pycparser license\n\nsetup.py:\n  Legacy installation script (build metadata lives in ``pyproject.toml``).\n\npyproject.toml:\n  Package metadata and build configuration.\n\nexamples/:\n  A directory with some examples of using **pycparser**\n\npycparser/:\n  The **pycparser** module source code.\n\ntests/:\n  Unit tests.\n\nutils/fake_libc_include:\n  Minimal standard C library include files that should allow to parse any C code.\n  Note that these headers now include C11 code, so they may not work when the\n  preprocessor is configured to an earlier C standard (like ``-std=c99``).\n\nutils/internal/:\n  Internal utilities for my own use. You probably don't need them.\n\n\nContributors\n============\n\nSome people have contributed to **pycparser** by opening issues on bugs they've\nfound and/or submitting patches. The list of contributors is in the CONTRIBUTORS\nfile in the source distribution. After **pycparser** moved to Github I stopped\nupdating this list because Github does a much better job at tracking\ncontributions.\n",
        "description_content_type": "text/x-rst",
        "author_email": "Eli Bendersky <eliben@gmail.com>",
        "maintainer_email": "Eli Bendersky <eliben@gmail.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/eliben/pycparser"
        ]
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/7b/44/4e421b96b67b2daff264473f7465db72fbdf36a07e05494f50300cc7b0c6/rfc3339_validator-0.1.4-py2.py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=24f6ec1eda14ef823da9e36ec7113124b39c04d50a4d3d3a3c2859577e7791fa",
          "hashes": {
            "sha256": "24f6ec1eda14ef823da9e36ec7113124b39c04d50a4d3d3a3c2859577e7791fa"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "rfc3339-validator",
        "version": "0.1.4",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "A pure python RFC3339 validator",
        "description": "# rfc3339-validator\n\nA pure python RFC3339 validator\n\n\n[![image](https://img.shields.io/pypi/v/rfc3339_validator.svg)](https://pypi.python.org/pypi/rfc3339_validator)\n[![Build Status](https://travis-ci.org/naimetti/rfc3339-validator.svg?branch=master)](https://travis-ci.org/naimetti/rfc3339-validator)\n\n# Install\n\n```shell script\npip install rfc3339-validator\n```\n\n# Usage\n\n```python\nfrom rfc3339_validator import validate_rfc3339\n\nvalidate_rfc3339('1424-45-93T15:32:12.9023368Z')\n>>> False\n\nvalidate_rfc3339('2001-10-23T15:32:12.9023368Z')\n>>> True\n```\n\n\n  - Free software: MIT license\n\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "rfc3339",
          "validator"
        ],
        "home_page": "https://github.com/naimetti/rfc3339-validator",
        "author": "Nicolas Aimetti",
        "author_email": "naimetti@yahoo.com.ar",
        "license": "MIT license",
        "classifier": [
          "Development Status :: 2 - Pre-Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8"
        ],
        "requires_dist": [
          "six"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
      }
    },
    {
      "download_info": {
        "url": "https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl",
        "archive_info": {
          "hash": "sha256=2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2",
          "hashes": {
            "sha256": "2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2"
          }
        }
      },
      "is_direct": false,
      "is_yanked": false,
      "requested": false,
      "metadata": {
        "metadata_version": "2.1",
        "name": "sniffio",
        "version": "1.3.1",
        "summary": "Sniff out which async library your code is running under",
        "description": ".. image:: https://img.shields.io/badge/chat-join%20now-blue.svg\r\n   :target: https://gitter.im/python-trio/general\r\n   :alt: Join chatroom\r\n\r\n.. image:: https://img.shields.io/badge/docs-read%20now-blue.svg\r\n   :target: https://sniffio.readthedocs.io/en/latest/?badge=latest\r\n   :alt: Documentation Status\r\n\r\n.. image:: https://img.shields.io/pypi/v/sniffio.svg\r\n   :target: https://pypi.org/project/sniffio\r\n   :alt: Latest PyPi version\r\n   \r\n.. image:: https://img.shields.io/conda/vn/conda-forge/sniffio.svg\r\n   :target: https://anaconda.org/conda-forge/sniffio \r\n   :alt: Latest conda-forge version   \r\n\r\n.. image:: https://travis-ci.org/python-trio/sniffio.svg?branch=master\r\n   :target: https://travis-ci.org/python-trio/sniffio\r\n   :alt: Automated test status\r\n\r\n.. image:: https://codecov.io/gh/python-trio/sniffio/branch/master/graph/badge.svg\r\n   :target: https://codecov.io/gh/python-trio/sniffio\r\n   :alt: Test coverage\r\n\r\n=================================================================\r\nsniffio: Sniff out which async library your code is running under\r\n=================================================================\r\n\r\nYou're writing a library. You've decided to be ambitious, and support\r\nmultiple async I/O packages, like `Trio\r\n<https://trio.readthedocs.io>`__, and `asyncio\r\n<https://docs.python.org/3/library/asyncio.html>`__, and ... You've\r\nwritten a bunch of clever code to handle all the differences. But...\r\nhow do you know *which* piece of clever code to run?\r\n\r\nThis is a tiny package whose only purpose is to let you detect which\r\nasync library your code is running under.\r\n\r\n* Documentation: https://sniffio.readthedocs.io\r\n\r\n* Bug tracker and source code: https://github.com/python-trio/sniffio\r\n\r\n* License: MIT or Apache License 2.0, your choice\r\n\r\n* Contributor guide: https://trio.readthedocs.io/en/latest/contributing.html\r\n\r\n* Code of conduct: Contributors are requested to follow our `code of\r\n  conduct\r\n  <https://trio.readthedocs.io/en/latest/code-of-conduct.html>`_\r\n  in all project spaces.\r\n\r\nThis library is maintained by the Trio project, as a service to the\r\nasync Python community as a whole.\r\n\r\n\r\nQuickstart\r\n----------\r\n\r\n.. code-block:: python3\r\n\r\n   from sniffio import current_async_library\r\n   import trio\r\n   import asyncio\r\n\r\n   async def print_library():\r\n       library = current_async_library()\r\n       print(\"This is:\", library)\r\n\r\n   # Prints \"This is trio\"\r\n   trio.run(print_library)\r\n\r\n   # Prints \"This is asyncio\"\r\n   asyncio.run(print_library())\r\n\r\nFor more details, including how to add support to new async libraries,\r\n`please peruse our fine manual <https://sniffio.readthedocs.io>`__.\r\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "async",
          "trio",
          "asyncio"
        ],
        "author_email": "\"Nathaniel J. Smith\" <njs@pobox.com>",
        "license": "MIT OR Apache-2.0",
        "license_file": [
          "LICENSE",
          "LICENSE.APACHE2",
          "LICENSE.MIT"
        ],
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "License :: OSI Approved :: Apache Software License",
          "Framework :: Trio",
          "Framework :: AsyncIO",
          "Operating System :: POSIX :: Linux",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Intended Audience :: Developers",
          "Development Status :: 5 - Production/Stable"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Homepage, https://github.com/python-trio/sniffio",
          "Documentation, https://sniffio.readthedocs.io/",
          "Changelog, https://sniffio.readthedocs.io/en/latest/history.html"
        ]
      }
    }
  ],
  "environment": {
    "implementation_name": "cpython",
    "implementation_version": "3.13.12",
    "os_name": "nt",
    "platform_machine": "AMD64",
    "platform_release": "11",
    "platform_system": "Windows",
    "platform_version": "10.0.26300",
    "python_full_version": "3.13.12",
    "platform_python_implementation": "CPython",
    "python_version": "3.13",
    "sys_platform": "win32"
  }
}